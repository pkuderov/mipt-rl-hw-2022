{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gwo9bpaVgxXF"
      },
      "source": [
        "## Setup\n",
        "\n",
        "You will need to make a copy of this notebook in your Google Drive before you can edit the homework files. You can do so with **File &rarr; Save a copy in Drive**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CAdiyTKi4Se",
        "outputId": "9beadbc8-00cf-4efa-cdd5-0ef136bc8e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#@title mount your Google Drive\n",
        "#@markdown Your work will be stored in a folder called `cds_rl_2022` by default to prevent Colab instance timeouts from deleting your edits.\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKE5nA1Fgwwy"
      },
      "outputs": [],
      "source": [
        "#@title set up mount symlink\n",
        "\n",
        "DRIVE_PATH = '/content/gdrive/My\\ Drive/cds_rl_2022'\n",
        "DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n",
        "if not os.path.exists(DRIVE_PYTHON_PATH):\n",
        "    !mkdir $DRIVE_PATH\n",
        "\n",
        "## the space in `My Drive` causes some issues,\n",
        "## make a symlink to avoid this\n",
        "SYM_PATH = '/content/cds_rl_2022'\n",
        "if not os.path.exists(SYM_PATH):\n",
        "    !ln -s $DRIVE_PATH $SYM_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FGK4kbpg3iP",
        "outputId": "c601c360-7bdf-4287-adc5-4134d6fa76a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to security.\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to security.\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.39\u001b[0m\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.39\u001b[0m\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r                                                                               \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 14.2 kB/88.7 k\u001b[0m\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,957 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,734 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,181 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,498 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,004 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [954 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,272 kB]\n",
            "Get:21 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 13.9 MB in 3s (5,117 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "52 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Note, selecting 'zlib1g-dev' instead of 'libz-dev'\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "libxi6 is already the newest version (2:1.7.9-1).\n",
            "libxi6 set to manually installed.\n",
            "libxrandr2 is already the newest version (2:1.5.1-1).\n",
            "libxrandr2 set to manually installed.\n",
            "lsb-release is already the newest version (9.20170808ubuntu1).\n",
            "lsb-release set to manually installed.\n",
            "make is already the newest version (4.1-9.1ubuntu1).\n",
            "make set to manually installed.\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "cmake is already the newest version (3.10.2-1ubuntu2.18.04.2).\n",
            "curl is already the newest version (7.58.0-2ubuntu3.17).\n",
            "git is already the newest version (1:2.17.1-1ubuntu0.11).\n",
            "libgl1-mesa-dev is already the newest version (20.0.8-0ubuntu1~18.04.1).\n",
            "libgl1-mesa-dev set to manually installed.\n",
            "unzip is already the newest version (6.0-21ubuntu1.1).\n",
            "wget is already the newest version (1.19.4-1ubuntu2.2).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2.1).\n",
            "zlib1g-dev set to manually installed.\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  ack libcapnp-0.6.1 libfile-next-perl libfontenc-dev libglew2.0 libgtk2.0-0\n",
            "  libgtk2.0-common libmirclient-dev libmirclient9 libmircommon-dev\n",
            "  libmircommon7 libmircookie-dev libmircookie2 libmircore-dev libmircore1\n",
            "  libmirprotobuf3 libosmesa6 libpciaccess-dev libpixman-1-dev libprotobuf-dev\n",
            "  libprotobuf-lite10 libxfont-dev libxkbcommon-dev libxkbfile-dev\n",
            "  mir-client-platform-mesa-dev python-cairo python-gi python-gi-cairo\n",
            "  python-gobject-2 python-gtk2 python-rencode swig3.0 x11-xserver-utils\n",
            "  x11proto-dri2-dev x11proto-fonts-dev x11proto-gl-dev x11proto-randr-dev\n",
            "  x11proto-render-dev x11proto-resource-dev x11proto-xf86bigfont-dev\n",
            "  x11proto-xinerama-dev xserver-xorg-core xserver-xorg-input-void\n",
            "  xserver-xorg-video-dummy\n",
            "Suggested packages:\n",
            "  glew-utils libegl1-mesa | libegl1-x11 libvulkan1 gvfs python-gobject-2-dbg\n",
            "  python-gtk2-doc libgle3 swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "  nickle cairo-5c xorg-docs-core openssh-server python-pyopencl\n",
            "  gstreamer1.0-plugins-base gstreamer1.0-plugins-good\n",
            "  | gstreamer1.0-plugins-ugly | gstreamer1.0-plugins-bad python-gst-1.0\n",
            "  pulseaudio pulseaudio-utils python-avahi python-netifaces cups-filters\n",
            "  cups-common cups-pdf python-cups python-opencv v4l2loopback-dkms python-yaml\n",
            "  xfonts-100dpi | xfonts-75dpi xfonts-scalable\n",
            "Recommended packages:\n",
            "  libvulkan-dev libxrandr-dev libgail-common libgtk2.0-bin ssh-askpass\n",
            "  python-lz4 python-lzo python-pil | python-imaging python-gtkglext1\n",
            "  python-dbus\n",
            "The following packages will be REMOVED:\n",
            "  xserver-xorg-core-hwe-18.04\n",
            "The following NEW packages will be installed:\n",
            "  ack ack-grep libcapnp-0.6.1 libfile-next-perl libfontenc-dev libgl1-mesa-glx\n",
            "  libglew-dev libglew2.0 libglfw3 libglfw3-dev libgtk2.0-0 libgtk2.0-common\n",
            "  libmirclient-dev libmirclient9 libmircommon-dev libmircommon7\n",
            "  libmircookie-dev libmircookie2 libmircore-dev libmircore1 libmirprotobuf3\n",
            "  libosmesa6 libosmesa6-dev libpciaccess-dev libpixman-1-dev libprotobuf-dev\n",
            "  libprotobuf-lite10 libxcursor-dev libxfont-dev libxinerama-dev\n",
            "  libxkbcommon-dev libxkbfile-dev mir-client-platform-mesa-dev patchelf\n",
            "  python-cairo python-gi python-gi-cairo python-gobject-2 python-gtk2\n",
            "  python-opengl python-rencode swig swig3.0 x11-xserver-utils\n",
            "  x11proto-dri2-dev x11proto-fonts-dev x11proto-gl-dev x11proto-randr-dev\n",
            "  x11proto-render-dev x11proto-resource-dev x11proto-xf86bigfont-dev\n",
            "  x11proto-xinerama-dev xpra xserver-xorg-core xserver-xorg-dev\n",
            "  xserver-xorg-input-void xserver-xorg-video-dummy xvfb\n",
            "The following packages will be upgraded:\n",
            "  gnupg2\n",
            "1 upgraded, 58 newly installed, 1 to remove and 51 not upgraded.\n",
            "Need to get 14.9 MB of archives.\n",
            "After this operation, 65.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 xserver-xorg-core amd64 2:1.19.6-1ubuntu4.10 [1,351 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libfile-next-perl all 1.16-2 [16.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ack all 2.22-1 [62.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ack-grep all 2.22-1 [5,268 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcapnp-0.6.1 amd64 0.6.1-1ubuntu1 [658 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfontenc-dev amd64 1:1.1.3-1 [13.8 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgl1-mesa-glx amd64 20.0.8-0ubuntu1~18.04.1 [5,532 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libglew2.0 amd64 2.0.0-5 [140 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libglew-dev amd64 2.0.0-5 [120 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libglfw3 amd64 3.2.1-1 [49.2 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libglfw3-dev amd64 3.2.1-1 [30.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircore1 amd64 0.31.1-0ubuntu1 [26.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircommon7 amd64 0.31.1-0ubuntu1 [73.9 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-lite10 amd64 3.0.0-9.1ubuntu1 [97.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirprotobuf3 amd64 0.31.1-0ubuntu1 [127 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirclient9 amd64 0.31.1-0ubuntu1 [199 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircore-dev amd64 0.31.1-0ubuntu1 [21.7 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-dev amd64 3.0.0-9.1ubuntu1 [959 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxkbcommon-dev amd64 0.8.2-1~ubuntu18.04.1 [150 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircommon-dev amd64 0.31.1-0ubuntu1 [13.9 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircookie2 amd64 0.31.1-0ubuntu1 [19.7 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircookie-dev amd64 0.31.1-0ubuntu1 [4,392 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirclient-dev amd64 0.31.1-0ubuntu1 [47.8 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-dev amd64 0.34.0-2 [244 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcursor-dev amd64 1:1.1.15-1 [26.5 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-fonts-dev all 2018.4-4 [2,620 B]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxfont-dev amd64 1:2.0.3-1 [118 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-xinerama-dev all 2018.4-4 [2,628 B]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxinerama-dev amd64 2:1.1.3-1 [8,404 B]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxkbfile-dev amd64 1:1.0.9-2 [74.3 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 mir-client-platform-mesa-dev amd64 0.31.1-0ubuntu1 [11.0 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/universe amd64 patchelf amd64 0.9-1 [46.5 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cairo amd64 1.16.2-1 [56.4 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-gi amd64 3.26.1-2ubuntu1 [197 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-gi-cairo amd64 3.26.1-2ubuntu1 [6,632 B]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-gobject-2 amd64 2.28.6-12ubuntu3 [180 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-gtk2 amd64 2.24.0-5.1ubuntu2 [619 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-rencode amd64 1.0.5-1build2 [37.4 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-xserver-utils amd64 7.7+7build1 [159 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-dri2-dev all 2018.4-4 [2,620 B]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-gl-dev all 2018.4-4 [2,612 B]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-randr-dev all 2018.4-4 [2,620 B]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-render-dev all 2:2018.4-4 [2,620 B]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-resource-dev all 2018.4-4 [2,620 B]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-xf86bigfont-dev all 2018.4-4 [2,628 B]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu bionic/universe amd64 xserver-xorg-input-void amd64 1:1.4.1-1build3 [6,806 B]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu bionic/main amd64 xserver-xorg-video-dummy amd64 1:0.3.8-1build1 [9,002 B]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu bionic/universe amd64 xpra amd64 2.1.3+dfsg-1ubuntu1 [1,720 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpciaccess-dev amd64 0.14-1 [20.2 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 xserver-xorg-dev amd64 2:1.19.6-1ubuntu4.10 [198 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.10 [784 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 gnupg2 all 2.2.4-1ubuntu1.4 [5,292 B]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libosmesa6 amd64 20.0.8-0ubuntu1~18.04.1 [2,641 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libosmesa6-dev amd64 20.0.8-0ubuntu1~18.04.1 [8,828 B]\n",
            "Fetched 14.9 MB in 2s (8,977 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "\u001b[1mdpkg:\u001b[0m xserver-xorg-core-hwe-18.04: dependency problems, but removing anyway as you requested:\n",
            " xserver-xorg-video-nvidia-510 depends on xorg-video-abi-24 | xorg-video-abi-23 | xorg-video-abi-20 | xorg-video-abi-19 | xorg-video-abi-18 | xorg-video-abi-15 | xorg-video-abi-14 | xorg-video-abi-13 | xorg-video-abi-12 | xorg-video-abi-11 | xorg-video-abi-10 | xorg-video-abi-8 | xorg-video-abi-6.0; however:\n",
            "  Package xorg-video-abi-24 is not installed.\n",
            "  Package xserver-xorg-core-hwe-18.04 which provides xorg-video-abi-24 is to be removed.\n",
            "  Package xorg-video-abi-23 is not installed.\n",
            "  Package xorg-video-abi-20 is not installed.\n",
            "  Package xorg-video-abi-19 is not installed.\n",
            "  Package xorg-video-abi-18 is not installed.\n",
            "  Package xorg-video-abi-15 is not installed.\n",
            "  Package xorg-video-abi-14 is not installed.\n",
            "  Package xorg-video-abi-13 is not installed.\n",
            "  Package xorg-video-abi-12 is not installed.\n",
            "  Package xorg-video-abi-11 is not installed.\n",
            "  Package xorg-video-abi-10 is not installed.\n",
            "  Package xorg-video-abi-8 is not installed.\n",
            "  Package xorg-video-abi-6.0 is not installed.\n",
            " xserver-xorg-video-nvidia-510 depends on xserver-xorg-core (>= 2:1.19.6-1ubuntu2~) | xserver-xorg-core-hwe-18.04; however:\n",
            "  Package xserver-xorg-core is not installed.\n",
            "  Package xserver-xorg-core-hwe-18.04 which provides xserver-xorg-core is to be removed.\n",
            "  Package xserver-xorg-core-hwe-18.04 is to be removed.\n",
            " xserver-xorg-video-nvidia-510 depends on xorg-video-abi-24 | xorg-video-abi-23 | xorg-video-abi-20 | xorg-video-abi-19 | xorg-video-abi-18 | xorg-video-abi-15 | xorg-video-abi-14 | xorg-video-abi-13 | xorg-video-abi-12 | xorg-video-abi-11 | xorg-video-abi-10 | xorg-video-abi-8 | xorg-video-abi-6.0; however:\n",
            "  Package xorg-video-abi-24 is not installed.\n",
            "  Package xserver-xorg-core-hwe-18.04 which provides xorg-video-abi-24 is to be removed.\n",
            "  Package xorg-video-abi-23 is not installed.\n",
            "  Package xorg-video-abi-20 is not installed.\n",
            "  Package xorg-video-abi-19 is not installed.\n",
            "  Package xorg-video-abi-18 is not installed.\n",
            "  Package xorg-video-abi-15 is not installed.\n",
            "  Package xorg-video-abi-14 is not installed.\n",
            "  Package xorg-video-abi-13 is not installed.\n",
            "  Package xorg-video-abi-12 is not installed.\n",
            "  Package xorg-video-abi-11 is not installed.\n",
            "  Package xorg-video-abi-10 is not installed.\n",
            "  Package xorg-video-abi-8 is not installed.\n",
            "  Package xorg-video-abi-6.0 is not installed.\n",
            " xserver-xorg-video-nvidia-510 depends on xserver-xorg-core (>= 2:1.19.6-1ubuntu2~) | xserver-xorg-core-hwe-18.04; however:\n",
            "  Package xserver-xorg-core is not installed.\n",
            "  Package xserver-xorg-core-hwe-18.04 which provides xserver-xorg-core is to be removed.\n",
            "  Package xserver-xorg-core-hwe-18.04 is to be removed.\n",
            " xserver-xorg-video-nvidia-510 depends on xorg-video-abi-24 | xorg-video-abi-23 | xorg-video-abi-20 | xorg-video-abi-19 | xorg-video-abi-18 | xorg-video-abi-15 | xorg-video-abi-14 | xorg-video-abi-13 | xorg-video-abi-12 | xorg-video-abi-11 | xorg-video-abi-10 | xorg-video-abi-8 | xorg-video-abi-6.0; however:\n",
            "  Package xorg-video-abi-24 is not installed.\n",
            "  Package xserver-xorg-core-hwe-18.04 which provides xorg-video-abi-24 is to be removed.\n",
            "  Package xorg-video-abi-23 is not installed.\n",
            "  Package xorg-video-abi-20 is not installed.\n",
            "  Package xorg-video-abi-19 is not installed.\n",
            "  Package xorg-video-abi-18 is not installed.\n",
            "  Package xorg-video-abi-15 is not installed.\n",
            "  Package xorg-video-abi-14 is not installed.\n",
            "  Package xorg-video-abi-13 is not installed.\n",
            "  Package xorg-video-abi-12 is not installed.\n",
            "  Package xorg-video-abi-11 is not installed.\n",
            "  Package xorg-video-abi-10 is not installed.\n",
            "  Package xorg-video-abi-8 is not installed.\n",
            "  Package xorg-video-abi-6.0 is not installed.\n",
            " xserver-xorg-video-nvidia-510 depends on xserver-xorg-core (>= 2:1.19.6-1ubuntu2~) | xserver-xorg-core-hwe-18.04; however:\n",
            "  Package xserver-xorg-core is not installed.\n",
            "  Package xserver-xorg-core-hwe-18.04 which provides xserver-xorg-core is to be removed.\n",
            "  Package xserver-xorg-core-hwe-18.04 is to be removed.\n",
            "\n",
            "(Reading database ... 155203 files and directories currently installed.)\n",
            "Removing xserver-xorg-core-hwe-18.04 (2:1.20.8-2ubuntu2.2~18.04.6) ...\n",
            "Selecting previously unselected package xserver-xorg-core.\n",
            "(Reading database ... 155164 files and directories currently installed.)\n",
            "Preparing to unpack .../00-xserver-xorg-core_2%3a1.19.6-1ubuntu4.10_amd64.deb ...\n",
            "Unpacking xserver-xorg-core (2:1.19.6-1ubuntu4.10) ...\n",
            "Selecting previously unselected package libfile-next-perl.\n",
            "Preparing to unpack .../01-libfile-next-perl_1.16-2_all.deb ...\n",
            "Unpacking libfile-next-perl (1.16-2) ...\n",
            "Selecting previously unselected package ack.\n",
            "Preparing to unpack .../02-ack_2.22-1_all.deb ...\n",
            "Unpacking ack (2.22-1) ...\n",
            "Selecting previously unselected package ack-grep.\n",
            "Preparing to unpack .../03-ack-grep_2.22-1_all.deb ...\n",
            "Unpacking ack-grep (2.22-1) ...\n",
            "Selecting previously unselected package libcapnp-0.6.1:amd64.\n",
            "Preparing to unpack .../04-libcapnp-0.6.1_0.6.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcapnp-0.6.1:amd64 (0.6.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libfontenc-dev:amd64.\n",
            "Preparing to unpack .../05-libfontenc-dev_1%3a1.1.3-1_amd64.deb ...\n",
            "Unpacking libfontenc-dev:amd64 (1:1.1.3-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "Preparing to unpack .../06-libgl1-mesa-glx_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Selecting previously unselected package libglew2.0:amd64.\n",
            "Preparing to unpack .../07-libglew2.0_2.0.0-5_amd64.deb ...\n",
            "Unpacking libglew2.0:amd64 (2.0.0-5) ...\n",
            "Selecting previously unselected package libglew-dev:amd64.\n",
            "Preparing to unpack .../08-libglew-dev_2.0.0-5_amd64.deb ...\n",
            "Unpacking libglew-dev:amd64 (2.0.0-5) ...\n",
            "Selecting previously unselected package libglfw3:amd64.\n",
            "Preparing to unpack .../09-libglfw3_3.2.1-1_amd64.deb ...\n",
            "Unpacking libglfw3:amd64 (3.2.1-1) ...\n",
            "Selecting previously unselected package libglfw3-dev:amd64.\n",
            "Preparing to unpack .../10-libglfw3-dev_3.2.1-1_amd64.deb ...\n",
            "Unpacking libglfw3-dev:amd64 (3.2.1-1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../11-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../12-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libmircore1:amd64.\n",
            "Preparing to unpack .../13-libmircore1_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircore1:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmircommon7:amd64.\n",
            "Preparing to unpack .../14-libmircommon7_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircommon7:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libprotobuf-lite10:amd64.\n",
            "Preparing to unpack .../15-libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libmirprotobuf3:amd64.\n",
            "Preparing to unpack .../16-libmirprotobuf3_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmirprotobuf3:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmirclient9:amd64.\n",
            "Preparing to unpack .../17-libmirclient9_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmirclient9:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmircore-dev:amd64.\n",
            "Preparing to unpack .../18-libmircore-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircore-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libprotobuf-dev:amd64.\n",
            "Preparing to unpack .../19-libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libxkbcommon-dev:amd64.\n",
            "Preparing to unpack .../20-libxkbcommon-dev_0.8.2-1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking libxkbcommon-dev:amd64 (0.8.2-1~ubuntu18.04.1) ...\n",
            "Selecting previously unselected package libmircommon-dev:amd64.\n",
            "Preparing to unpack .../21-libmircommon-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircommon-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmircookie2:amd64.\n",
            "Preparing to unpack .../22-libmircookie2_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircookie2:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmircookie-dev:amd64.\n",
            "Preparing to unpack .../23-libmircookie-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircookie-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmirclient-dev:amd64.\n",
            "Preparing to unpack .../24-libmirclient-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmirclient-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libpixman-1-dev:amd64.\n",
            "Preparing to unpack .../25-libpixman-1-dev_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libxcursor-dev:amd64.\n",
            "Preparing to unpack .../26-libxcursor-dev_1%3a1.1.15-1_amd64.deb ...\n",
            "Unpacking libxcursor-dev:amd64 (1:1.1.15-1) ...\n",
            "Selecting previously unselected package x11proto-fonts-dev.\n",
            "Preparing to unpack .../27-x11proto-fonts-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-fonts-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxfont-dev.\n",
            "Preparing to unpack .../28-libxfont-dev_1%3a2.0.3-1_amd64.deb ...\n",
            "Unpacking libxfont-dev (1:2.0.3-1) ...\n",
            "Selecting previously unselected package x11proto-xinerama-dev.\n",
            "Preparing to unpack .../29-x11proto-xinerama-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-xinerama-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxinerama-dev:amd64.\n",
            "Preparing to unpack .../30-libxinerama-dev_2%3a1.1.3-1_amd64.deb ...\n",
            "Unpacking libxinerama-dev:amd64 (2:1.1.3-1) ...\n",
            "Selecting previously unselected package libxkbfile-dev:amd64.\n",
            "Preparing to unpack .../31-libxkbfile-dev_1%3a1.0.9-2_amd64.deb ...\n",
            "Unpacking libxkbfile-dev:amd64 (1:1.0.9-2) ...\n",
            "Selecting previously unselected package mir-client-platform-mesa-dev:amd64.\n",
            "Preparing to unpack .../32-mir-client-platform-mesa-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking mir-client-platform-mesa-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package patchelf.\n",
            "Preparing to unpack .../33-patchelf_0.9-1_amd64.deb ...\n",
            "Unpacking patchelf (0.9-1) ...\n",
            "Selecting previously unselected package python-cairo:amd64.\n",
            "Preparing to unpack .../34-python-cairo_1.16.2-1_amd64.deb ...\n",
            "Unpacking python-cairo:amd64 (1.16.2-1) ...\n",
            "Selecting previously unselected package python-gi.\n",
            "Preparing to unpack .../35-python-gi_3.26.1-2ubuntu1_amd64.deb ...\n",
            "Unpacking python-gi (3.26.1-2ubuntu1) ...\n",
            "Selecting previously unselected package python-gi-cairo.\n",
            "Preparing to unpack .../36-python-gi-cairo_3.26.1-2ubuntu1_amd64.deb ...\n",
            "Unpacking python-gi-cairo (3.26.1-2ubuntu1) ...\n",
            "Selecting previously unselected package python-gobject-2.\n",
            "Preparing to unpack .../37-python-gobject-2_2.28.6-12ubuntu3_amd64.deb ...\n",
            "Unpacking python-gobject-2 (2.28.6-12ubuntu3) ...\n",
            "Selecting previously unselected package python-gtk2.\n",
            "Preparing to unpack .../38-python-gtk2_2.24.0-5.1ubuntu2_amd64.deb ...\n",
            "Unpacking python-gtk2 (2.24.0-5.1ubuntu2) ...\n",
            "Selecting previously unselected package python-opengl.\n",
            "Preparing to unpack .../39-python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Selecting previously unselected package python-rencode.\n",
            "Preparing to unpack .../40-python-rencode_1.0.5-1build2_amd64.deb ...\n",
            "Unpacking python-rencode (1.0.5-1build2) ...\n",
            "Selecting previously unselected package swig3.0.\n",
            "Preparing to unpack .../41-swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../42-swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Selecting previously unselected package x11-xserver-utils.\n",
            "Preparing to unpack .../43-x11-xserver-utils_7.7+7build1_amd64.deb ...\n",
            "Unpacking x11-xserver-utils (7.7+7build1) ...\n",
            "Selecting previously unselected package x11proto-dri2-dev.\n",
            "Preparing to unpack .../44-x11proto-dri2-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-dri2-dev (2018.4-4) ...\n",
            "Selecting previously unselected package x11proto-gl-dev.\n",
            "Preparing to unpack .../45-x11proto-gl-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-gl-dev (2018.4-4) ...\n",
            "Selecting previously unselected package x11proto-randr-dev.\n",
            "Preparing to unpack .../46-x11proto-randr-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-randr-dev (2018.4-4) ...\n",
            "Selecting previously unselected package x11proto-render-dev.\n",
            "Preparing to unpack .../47-x11proto-render-dev_2%3a2018.4-4_all.deb ...\n",
            "Unpacking x11proto-render-dev (2:2018.4-4) ...\n",
            "Selecting previously unselected package x11proto-resource-dev.\n",
            "Preparing to unpack .../48-x11proto-resource-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-resource-dev (2018.4-4) ...\n",
            "Selecting previously unselected package x11proto-xf86bigfont-dev.\n",
            "Preparing to unpack .../49-x11proto-xf86bigfont-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-xf86bigfont-dev (2018.4-4) ...\n",
            "Selecting previously unselected package xserver-xorg-input-void.\n",
            "Preparing to unpack .../50-xserver-xorg-input-void_1%3a1.4.1-1build3_amd64.deb ...\n",
            "Unpacking xserver-xorg-input-void (1:1.4.1-1build3) ...\n",
            "Selecting previously unselected package xserver-xorg-video-dummy.\n",
            "Preparing to unpack .../51-xserver-xorg-video-dummy_1%3a0.3.8-1build1_amd64.deb ...\n",
            "Unpacking xserver-xorg-video-dummy (1:0.3.8-1build1) ...\n",
            "Selecting previously unselected package xpra.\n",
            "Preparing to unpack .../52-xpra_2.1.3+dfsg-1ubuntu1_amd64.deb ...\n",
            "Unpacking xpra (2.1.3+dfsg-1ubuntu1) ...\n",
            "Selecting previously unselected package libpciaccess-dev:amd64.\n",
            "Preparing to unpack .../53-libpciaccess-dev_0.14-1_amd64.deb ...\n",
            "Unpacking libpciaccess-dev:amd64 (0.14-1) ...\n",
            "Selecting previously unselected package xserver-xorg-dev.\n",
            "Preparing to unpack .../54-xserver-xorg-dev_2%3a1.19.6-1ubuntu4.10_amd64.deb ...\n",
            "Unpacking xserver-xorg-dev (2:1.19.6-1ubuntu4.10) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../55-xvfb_2%3a1.19.6-1ubuntu4.10_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Preparing to unpack .../56-gnupg2_2.2.4-1ubuntu1.4_all.deb ...\n",
            "Unpacking gnupg2 (2.2.4-1ubuntu1.4) over (2.2.4-1ubuntu1.3) ...\n",
            "Selecting previously unselected package libosmesa6:amd64.\n",
            "Preparing to unpack .../57-libosmesa6_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libosmesa6:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Selecting previously unselected package libosmesa6-dev:amd64.\n",
            "Preparing to unpack .../58-libosmesa6-dev_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libosmesa6-dev:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Setting up x11proto-fonts-dev (2018.4-4) ...\n",
            "Setting up python-rencode (1.0.5-1build2) ...\n",
            "Setting up x11proto-dri2-dev (2018.4-4) ...\n",
            "Setting up libxcursor-dev:amd64 (1:1.1.15-1) ...\n",
            "Setting up patchelf (0.9-1) ...\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Setting up libxkbcommon-dev:amd64 (0.8.2-1~ubuntu18.04.1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Setting up libpciaccess-dev:amd64 (0.14-1) ...\n",
            "Setting up libmircore-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libfile-next-perl (1.16-2) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Setting up libosmesa6:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Setting up libglfw3:amd64 (3.2.1-1) ...\n",
            "Setting up ack (2.22-1) ...\n",
            "Setting up x11proto-xf86bigfont-dev (2018.4-4) ...\n",
            "Setting up libxkbfile-dev:amd64 (1:1.0.9-2) ...\n",
            "Setting up xserver-xorg-core (2:1.19.6-1ubuntu4.10) ...\n",
            "Setting up python-gobject-2 (2.28.6-12ubuntu3) ...\n",
            "Setting up gnupg2 (2.2.4-1ubuntu1.4) ...\n",
            "Setting up libmircookie2:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up python-gi (3.26.1-2ubuntu1) ...\n",
            "Setting up libfontenc-dev:amd64 (1:1.1.3-1) ...\n",
            "Setting up xserver-xorg-video-dummy (1:0.3.8-1build1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Setting up x11proto-xinerama-dev (2018.4-4) ...\n",
            "Setting up libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Setting up x11proto-randr-dev (2018.4-4) ...\n",
            "Setting up libxinerama-dev:amd64 (2:1.1.3-1) ...\n",
            "Setting up xserver-xorg-input-void (1:1.4.1-1build3) ...\n",
            "Setting up x11proto-gl-dev (2018.4-4) ...\n",
            "Setting up libcapnp-0.6.1:amd64 (0.6.1-1ubuntu1) ...\n",
            "Setting up python-cairo:amd64 (1.16.2-1) ...\n",
            "Setting up libglew2.0:amd64 (2.0.0-5) ...\n",
            "Setting up x11-xserver-utils (7.7+7build1) ...\n",
            "Setting up x11proto-resource-dev (2018.4-4) ...\n",
            "Setting up x11proto-render-dev (2:2018.4-4) ...\n",
            "Setting up libmircore1:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libglew-dev:amd64 (2.0.0-5) ...\n",
            "Setting up libglfw3-dev:amd64 (3.2.1-1) ...\n",
            "Setting up python-gi-cairo (3.26.1-2ubuntu1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up swig (3.0.12-1) ...\n",
            "Setting up ack-grep (2.22-1) ...\n",
            "Setting up libosmesa6-dev:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Setting up libmirprotobuf3:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up python-gtk2 (2.24.0-5.1ubuntu2) ...\n",
            "Setting up libmircookie-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libxfont-dev (1:2.0.3-1) ...\n",
            "Setting up libmircommon7:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up xpra (2.1.3+dfsg-1ubuntu1) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/xpra.service → /lib/systemd/system/xpra.service.\n",
            "Setting up libmirclient9:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libmircommon-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libmirclient-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up mir-client-platform-mesa-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up xserver-xorg-dev (2:1.19.6-1ubuntu4.10) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for shared-mime-info (1.9-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any of the parent directories): .git\\n\"\n",
            "Git LFS initialized.\n"
          ]
        }
      ],
      "source": [
        "#@title apt install requirements\n",
        "\n",
        "#@markdown Run each section with Shift+Enter\n",
        "\n",
        "#@markdown Double-click on section headers to show code.\n",
        "\n",
        "!apt update \n",
        "!apt install -y --no-install-recommends \\\n",
        "        build-essential \\\n",
        "        curl \\\n",
        "        git \\\n",
        "        git-lfs \\\n",
        "        gnupg2 \\\n",
        "        make \\\n",
        "        cmake \\\n",
        "        ffmpeg \\\n",
        "        swig \\\n",
        "        libz-dev \\\n",
        "        unzip \\\n",
        "        zlib1g-dev \\\n",
        "        libglfw3 \\\n",
        "        libglfw3-dev \\\n",
        "        libxrandr2 \\\n",
        "        libxinerama-dev \\\n",
        "        libxi6 \\\n",
        "        libxcursor-dev \\\n",
        "        libgl1-mesa-dev \\\n",
        "        libgl1-mesa-glx \\\n",
        "        libglew-dev \\\n",
        "        libosmesa6-dev \\\n",
        "        lsb-release \\\n",
        "        ack-grep \\\n",
        "        patchelf \\\n",
        "        wget \\\n",
        "        xpra \\\n",
        "        xserver-xorg-dev \\\n",
        "        xvfb \\\n",
        "        python-opengl \\\n",
        "        ffmpeg\n",
        "\n",
        "# set up git lfs\n",
        "!git lfs install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qsddgRpxkhqq",
        "outputId": "6b5a33c0-0aff-4b98-fe3d-2407f6f03138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting free-mujoco-py\n",
            "  Downloading free_mujoco_py-2.1.6-py3-none-any.whl (14.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1 MB 10.7 MB/s \n",
            "\u001b[?25hCollecting glfw<2.0.0,>=1.4.0\n",
            "  Downloading glfw-1.12.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (203 kB)\n",
            "\u001b[K     |████████████████████████████████| 203 kB 61.4 MB/s \n",
            "\u001b[?25hCollecting imageio<3.0.0,>=2.9.0\n",
            "  Downloading imageio-2.19.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 43.6 MB/s \n",
            "\u001b[?25hCollecting fasteners==0.15\n",
            "  Downloading fasteners-0.15-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: Cython<0.30.0,>=0.29.24 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (0.29.28)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.3 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (1.21.6)\n",
            "Collecting monotonic>=0.1\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fasteners==0.15->free-mujoco-py) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi<2.0.0,>=1.15.0->free-mujoco-py) (2.21)\n",
            "Collecting pillow>=8.3.2\n",
            "  Downloading Pillow-9.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 46.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow, monotonic, imageio, glfw, fasteners, free-mujoco-py\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed fasteners-0.15 free-mujoco-py-2.1.6 glfw-1.12.0 imageio-2.19.1 monotonic-1.6 pillow-9.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiling /usr/local/lib/python3.7/dist-packages/mujoco_py/cymj.pyx because it changed.\n",
            "[1/1] Cythonizing /usr/local/lib/python3.7/dist-packages/mujoco_py/cymj.pyx\n",
            "running build_ext\n",
            "building 'mujoco_py.cymj' extension\n",
            "creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder\n",
            "creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7\n",
            "creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr\n",
            "creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local\n",
            "creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib\n",
            "creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7\n",
            "creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7/dist-packages\n",
            "creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7/dist-packages/mujoco_py\n",
            "creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7/dist-packages/mujoco_py/gl\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/mujoco_py -I/usr/local/lib/python3.7/dist-packages/mujoco_py/binaries/linux/mujoco210/include -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c /usr/local/lib/python3.7/dist-packages/mujoco_py/cymj.c -o /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7/dist-packages/mujoco_py/cymj.o -fopenmp -w\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/mujoco_py -I/usr/local/lib/python3.7/dist-packages/mujoco_py/binaries/linux/mujoco210/include -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c /usr/local/lib/python3.7/dist-packages/mujoco_py/gl/osmesashim.c -o /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7/dist-packages/mujoco_py/gl/osmesashim.o -fopenmp -w\n",
            "creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/lib.linux-x86_64-3.7\n",
            "creating /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/lib.linux-x86_64-3.7/mujoco_py\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7/dist-packages/mujoco_py/cymj.o /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/usr/local/lib/python3.7/dist-packages/mujoco_py/gl/osmesashim.o -L/usr/local/lib/python3.7/dist-packages/mujoco_py/binaries/linux/mujoco210/bin -Wl,--enable-new-dtags,-R/usr/local/lib/python3.7/dist-packages/mujoco_py/binaries/linux/mujoco210/bin -lmujoco210 -lglewosmesa -lOSMesa -lGL -o /usr/local/lib/python3.7/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/lib.linux-x86_64-3.7/mujoco_py/cymj.cpython-37m-x86_64-linux-gnu.so -fopenmp\n"
          ]
        }
      ],
      "source": [
        "#@title install mujoco-py\n",
        "\n",
        "%pip install free-mujoco-py\n",
        "\n",
        "# Cythonizes pkg on the first run\n",
        "import mujoco_py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P--4k-PGkhqs"
      },
      "source": [
        "### Clone/update repo\n",
        "\n",
        "Now we need to clone the HW2 codebase. There are two options:\n",
        "\n",
        "1. Git clone the [repository](https://github.com/pkuderov/mipt-rl-hw-2022.git), install requirements, start coding HW2. This's the only option if you haven't cloned the repo yet for HW1. \n",
        "    If you have the repo already cloned, it's better to follow the 2-nd option. Otherwise, you will need to move the old `rl_hw` folder first. But don't delete it - make sure you've kept the HW1 solution as you will need it for this assignment!\n",
        "\n",
        "2. Use already cloned local repository in `rl_hw`. Save the HW1 solution to the separate branch, then git pull changes from the remote upstream to get HW2 codebase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItU_aIJHnhkn",
        "outputId": "c948f9ab-6607-4710-be83-dd6bdb5592c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/cds_rl_2022\n",
            "fatal: destination path 'rl_hw' already exists and is not an empty directory.\n",
            "/content/gdrive/My Drive/cds_rl_2022/rl_hw\n"
          ]
        }
      ],
      "source": [
        "#@title clone homework repo (option #1)\n",
        "%cd $SYM_PATH\n",
        "!git clone https://github.com/pkuderov/mipt-rl-hw-2022.git rl_hw\n",
        "%cd rl_hw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAdSe4uAkhqw",
        "outputId": "f5b1218c-58a7-4f40-ec8a-5be799932808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/cds_rl_2022/rl_hw/hw1\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from -r requirements.colab.txt (line 1)) (0.17.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.colab.txt (line 2)) (2.8.0)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 13.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.colab.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.colab.txt (line 5)) (5.5.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (from -r requirements.colab.txt (line 6)) (0.2.3.5)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.colab.txt (line 8)) (1.11.0+cu113)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.colab.txt (line 9)) (4.1.2.30)\n",
            "Collecting ipdb\n",
            "  Downloading ipdb-0.13.9.tar.gz (16 kB)\n",
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 62.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym->-r requirements.colab.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->-r requirements.colab.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->-r requirements.colab.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->-r requirements.colab.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->-r requirements.colab.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.colab.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.colab.txt (line 2)) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.colab.txt (line 2)) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.colab.txt (line 2)) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.colab.txt (line 2)) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.colab.txt (line 2)) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.colab.txt (line 2)) (1.44.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.colab.txt (line 2)) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.colab.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.colab.txt (line 2)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.colab.txt (line 2)) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.colab.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard->-r requirements.colab.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.colab.txt (line 2)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.colab.txt (line 2)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.colab.txt (line 2)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.colab.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.colab.txt (line 2)) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.colab.txt (line 2)) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.colab.txt (line 2)) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.colab.txt (line 2)) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.colab.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.colab.txt (line 2)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.colab.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.colab.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.colab.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.colab.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.colab.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.colab.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.colab.txt (line 4)) (3.0.8)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.colab.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.colab.txt (line 5)) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.colab.txt (line 5)) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.colab.txt (line 5)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.colab.txt (line 5)) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.colab.txt (line 5)) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.colab.txt (line 5)) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->-r requirements.colab.txt (line 5)) (0.2.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->-r requirements.colab.txt (line 6)) (2.19.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->-r requirements.colab.txt (line 6)) (4.64.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy->-r requirements.colab.txt (line 6)) (9.1.0)\n",
            "Collecting ipython\n",
            "  Downloading ipython-7.33.0-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 48.5 MB/s \n",
            "\u001b[?25hCollecting toml>=0.10.2\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting ipython\n",
            "  Downloading ipython-7.32.0-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 57.7 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.31.1-py3-none-any.whl (792 kB)\n",
            "\u001b[K     |████████████████████████████████| 792 kB 50.9 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.31.0-py3-none-any.whl (792 kB)\n",
            "\u001b[K     |████████████████████████████████| 792 kB 27.9 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.30.1-py3-none-any.whl (791 kB)\n",
            "\u001b[K     |████████████████████████████████| 791 kB 65.1 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.29.0-py3-none-any.whl (790 kB)\n",
            "\u001b[K     |████████████████████████████████| 790 kB 57.7 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.28.0-py3-none-any.whl (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 61.2 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.27.0-py3-none-any.whl (787 kB)\n",
            "\u001b[K     |████████████████████████████████| 787 kB 61.5 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.26.0-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 52.4 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.25.0-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 57.0 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.24.1-py3-none-any.whl (785 kB)\n",
            "\u001b[K     |████████████████████████████████| 785 kB 58.7 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.24.0-py3-none-any.whl (785 kB)\n",
            "\u001b[K     |████████████████████████████████| 785 kB 10.8 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.23.1-py3-none-any.whl (785 kB)\n",
            "\u001b[K     |████████████████████████████████| 785 kB 36.0 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.23.0-py3-none-any.whl (785 kB)\n",
            "\u001b[K     |████████████████████████████████| 785 kB 58.3 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.22.0-py3-none-any.whl (785 kB)\n",
            "\u001b[K     |████████████████████████████████| 785 kB 59.5 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.21.0-py3-none-any.whl (784 kB)\n",
            "\u001b[K     |████████████████████████████████| 784 kB 63.7 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.20.0-py3-none-any.whl (784 kB)\n",
            "\u001b[K     |████████████████████████████████| 784 kB 44.1 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.19.0-py3-none-any.whl (784 kB)\n",
            "\u001b[K     |████████████████████████████████| 784 kB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.colab.txt (line 5)) (0.18.1)\n",
            "  Downloading ipython-7.18.1-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 61.3 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.18.0-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 62.0 MB/s \n",
            "\u001b[?25h  Downloading ipython-7.17.0-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 62.8 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of ipdb to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting ipdb\n",
            "  Downloading ipdb-0.13.8.tar.gz (16 kB)\n",
            "  Downloading ipdb-0.13.7.tar.gz (16 kB)\n",
            "  Downloading ipdb-0.13.6.tar.gz (16 kB)\n",
            "  Downloading ipdb-0.13.5.tar.gz (16 kB)\n",
            "  Downloading ipdb-0.13.4.tar.gz (15 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements.colab.txt (line 5)) (0.7.0)\n",
            "Building wheels for collected packages: ipdb\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.13.4-py3-none-any.whl size=11000 sha256=2301bee92a1f14dc16dbc43c8c0a2c9c1e26932fa81400f3b7eb8a2e1c5de080\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/8b/69/d218d414a5b6262da8254659e6908c1a6afedb0804eed73f35\n",
            "Successfully built ipdb\n",
            "Installing collected packages: tensorboardX, pyvirtualdisplay, ipdb, box2d-py\n",
            "Successfully installed box2d-py-2.3.8 ipdb-0.13.4 pyvirtualdisplay-3.0 tensorboardX-2.5\n",
            "Obtaining file:///content/gdrive/My%20Drive/cds_rl_2022/rl_hw/hw1\n",
            "Installing collected packages: cds-rl\n",
            "  Running setup.py develop for cds-rl\n",
            "Successfully installed cds-rl-1.0.0\n",
            "/content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2\n",
            "Obtaining file:///content/gdrive/My%20Drive/cds_rl_2022/rl_hw/hw2\n",
            "Installing collected packages: hw2\n",
            "  Running setup.py develop for hw2\n",
            "Successfully installed hw2-1.0.0\n"
          ]
        }
      ],
      "source": [
        "#@title install requirements (from HW1 as HW2 has them the same)\n",
        "%cd hw1\n",
        "%pip install -r requirements.colab.txt\n",
        "%pip install -e .\n",
        "\n",
        "# also install hw2 package\n",
        "%cd ../hw2\n",
        "%pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noinfUbHiHW2",
        "outputId": "ebd2496f-0d59-4a3d-ae39-092d6567aea3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f5aa389eb10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#@title set up virtual display\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "COqsZLeliU9Y",
        "outputId": "1c78f66d-703a-4066-af54-375741e2006f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading video...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "                </video>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title test virtual display\n",
        "\n",
        "#@markdown If you see a video of a four-legged ant fumbling about, setup is complete!\n",
        "\n",
        "import gym\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from hw2.infrastructure.colab_utils import (\n",
        "    wrap_env,\n",
        "    show_video\n",
        ")\n",
        "\n",
        "env = wrap_env(gym.make(\"Ant-v2\"))\n",
        "\n",
        "observation = env.reset()\n",
        "for i in range(100):\n",
        "    env.render(mode='rgb_array')\n",
        "    obs, rew, term, _ = env.step(env.action_space.sample() ) \n",
        "    if term:\n",
        "        break;\n",
        "            \n",
        "env.close()\n",
        "print('Loading video...')\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygs968BbiYHr"
      },
      "source": [
        "## Editing Code\n",
        "\n",
        "To edit code, click the folder icon on the left menu. Navigate to the corresponding file (`cds_rl_2022/...`). Double click a file to open an editor. There is a timeout of about ~12 hours with Colab while it is active (and less if you close your browser window). We sync your edits to Google Drive so that you won't lose your work in the event of an instance timeout, but you will need to re-mount your Google Drive and re-install packages with every new instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qUmV93fif6S"
      },
      "source": [
        "## Run Policy Gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN-gZkqiijnR"
      },
      "outputs": [],
      "source": [
        "#@title imports\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from hw2.infrastructure.rl_trainer import RL_Trainer\n",
        "from hw2.agents.pg_agent import PGAgent\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Q6NaOWhOinnU"
      },
      "outputs": [],
      "source": [
        "#@title runtime arguments\n",
        "\n",
        "class Args:\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return getattr(self, key)\n",
        "\n",
        "    def __setitem__(self, key, val):\n",
        "        setattr(self, key, val)\n",
        "\n",
        "    def __contains__(self, key):\n",
        "        return hasattr(self, key)\n",
        "\n",
        "    env_name = 'CartPole-v0' #@param\n",
        "    exp_name = 'q1_sb_rtg_na' #@param\n",
        "\n",
        "    #@markdown main parameters of interest\n",
        "    n_iter = 100 #@param {type: \"integer\"}\n",
        "\n",
        "    ## PDF will tell you how to set ep_len\n",
        "    ## and discount for each environment\n",
        "    ep_len = 200 #@param {type: \"integer\"}\n",
        "    discount = 0.95 #@param {type: \"number\"}\n",
        "\n",
        "    reward_to_go = True #@param {type: \"boolean\"}\n",
        "    nn_baseline = False #@param {type: \"boolean\"}\n",
        "    gae_lambda = None #@param {type: \"number\"}\n",
        "    dont_standardize_advantages = False #@param {type: \"boolean\"}\n",
        "\n",
        "    #@markdown batches and steps\n",
        "    batch_size = 1000 #@param {type: \"integer\"}\n",
        "    eval_batch_size = 400 #@param {type: \"integer\"}\n",
        "\n",
        "    num_agent_train_steps_per_iter = 1 #@param {type: \"integer\"}\n",
        "    learning_rate =  5e-3 #@param {type: \"number\"}\n",
        "\n",
        "    #@markdown MLP parameters\n",
        "    n_layers = 2 #@param {type: \"integer\"}\n",
        "    size = 64 #@param {type: \"integer\"}\n",
        "\n",
        "    #@markdown system\n",
        "    save_params = False #@param {type: \"boolean\"}\n",
        "    no_gpu = False #@param {type: \"boolean\"}\n",
        "    which_gpu = 0 #@param {type: \"integer\"}\n",
        "    seed = 1 #@param {type: \"integer\"}\n",
        "\n",
        "    action_noise_std = 0 #@param {type: \"number\"}\n",
        "\n",
        "    #@markdown logging\n",
        "    ## default is to not log video so\n",
        "    ## that logs are small enough to be\n",
        "    ## uploaded to gradscope\n",
        "    video_log_freq =  -1#@param {type: \"integer\"}\n",
        "    scalar_log_freq =  1#@param {type: \"integer\"}\n",
        "\n",
        "\n",
        "args = Args()\n",
        "\n",
        "## ensure compatibility with hw1 code\n",
        "args['train_batch_size'] = args['batch_size']\n",
        "\n",
        "if args['video_log_freq'] > 0:\n",
        "    import warnings\n",
        "    warnings.warn(\n",
        "      '''\\nLogging videos will make eventfiles too'''\n",
        "      '''\\nlarge for the autograder. Set video_log_freq = -1'''\n",
        "      '''\\nfor the runs you intend to submit.'''\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eScWwHhnsYkd"
      },
      "outputs": [],
      "source": [
        "#@title create directory for logging\n",
        "\n",
        "data_path = '/content/cds_rl_2022/hw2/data'\n",
        "\n",
        "if not (os.path.exists(data_path)):\n",
        "    os.makedirs(data_path)\n",
        "\n",
        "logdir = args.exp_name + '_' + args.env_name + '_' + time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
        "logdir = os.path.join(data_path, logdir)\n",
        "args['logdir'] = logdir\n",
        "if not(os.path.exists(logdir)):\n",
        "    os.makedirs(logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aljzrLdAsvNu"
      },
      "outputs": [],
      "source": [
        "## define policy gradient trainer\n",
        "\n",
        "class PG_Trainer(object):\n",
        "    def __init__(self, params):\n",
        "\n",
        "        #####################\n",
        "        ## SET AGENT PARAMS\n",
        "        #####################\n",
        "\n",
        "        computation_graph_args = {\n",
        "            'n_layers': params['n_layers'],\n",
        "            'size': params['size'],\n",
        "            'learning_rate': params['learning_rate'],\n",
        "            }\n",
        "\n",
        "        estimate_advantage_args = {\n",
        "            'gamma': params['discount'],\n",
        "            'standardize_advantages': not(params['dont_standardize_advantages']),\n",
        "            'reward_to_go': params['reward_to_go'],\n",
        "            'nn_baseline': params['nn_baseline'],\n",
        "            'gae_lambda': params['gae_lambda'],\n",
        "        }\n",
        "\n",
        "        train_args = {\n",
        "            'num_agent_train_steps_per_iter': params['num_agent_train_steps_per_iter'],\n",
        "        }\n",
        "\n",
        "        agent_params = {**computation_graph_args, **estimate_advantage_args, **train_args}\n",
        "\n",
        "        self.params = params\n",
        "        self.params['agent_class'] = PGAgent\n",
        "        self.params['agent_params'] = agent_params\n",
        "        self.params['batch_size_initial'] = self.params['batch_size']\n",
        "\n",
        "        ################\n",
        "        ## RL TRAINER\n",
        "        ################\n",
        "\n",
        "        self.rl_trainer = RL_Trainer(self.params)\n",
        "\n",
        "    def run_training_loop(self):\n",
        "        self.rl_trainer.run_training_loop(\n",
        "            self.params['n_iter'],\n",
        "            collect_policy = self.rl_trainer.agent.actor,\n",
        "            eval_policy = self.rl_trainer.agent.actor,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2rCuQsRsd3N",
        "outputId": "2a453fe9-5a8f-4151-a631-73ce209bae4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/cds_rl_2022/hw2/data/q1_sb_rtg_na_CartPole-v0_05-05-2022_01-39-39\n",
            "########################\n",
            "logging outputs to  /content/cds_rl_2022/hw2/data/q1_sb_rtg_na_CartPole-v0_05-05-2022_01-39-39\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 35.46154022216797\n",
            "Eval_StdReturn : 28.075763702392578\n",
            "Eval_MaxReturn : 103.0\n",
            "Eval_MinReturn : 12.0\n",
            "Eval_AverageEpLen : 35.46153846153846\n",
            "Train_AverageReturn : 27.648649215698242\n",
            "Train_StdReturn : 12.643160820007324\n",
            "Train_MaxReturn : 65.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 27.64864864864865\n",
            "Train_EnvstepsSoFar : 1023\n",
            "TimeSinceStart : 0.9294743537902832\n",
            "Training Loss : -5.403212070465088\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 40.29999923706055\n",
            "Eval_StdReturn : 18.804521560668945\n",
            "Eval_MaxReturn : 75.0\n",
            "Eval_MinReturn : 12.0\n",
            "Eval_AverageEpLen : 40.3\n",
            "Train_AverageReturn : 30.363636016845703\n",
            "Train_StdReturn : 15.766897201538086\n",
            "Train_MaxReturn : 68.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 30.363636363636363\n",
            "Train_EnvstepsSoFar : 2025\n",
            "TimeSinceStart : 1.7895689010620117\n",
            "Training Loss : -17.46642303466797\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 53.375\n",
            "Eval_StdReturn : 30.88258934020996\n",
            "Eval_MaxReturn : 126.0\n",
            "Eval_MinReturn : 23.0\n",
            "Eval_AverageEpLen : 53.375\n",
            "Train_AverageReturn : 46.5\n",
            "Train_StdReturn : 21.908384323120117\n",
            "Train_MaxReturn : 100.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 46.5\n",
            "Train_EnvstepsSoFar : 3048\n",
            "TimeSinceStart : 2.6955151557922363\n",
            "Training Loss : -11.035774230957031\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 130.5\n",
            "Eval_StdReturn : 50.6976318359375\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 57.0\n",
            "Eval_AverageEpLen : 130.5\n",
            "Train_AverageReturn : 57.77777862548828\n",
            "Train_StdReturn : 35.239742279052734\n",
            "Train_MaxReturn : 180.0\n",
            "Train_MinReturn : 20.0\n",
            "Train_AverageEpLen : 57.77777777777778\n",
            "Train_EnvstepsSoFar : 4088\n",
            "TimeSinceStart : 3.673663854598999\n",
            "Training Loss : -5.854251861572266\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 68.71428680419922\n",
            "Eval_StdReturn : 30.414819717407227\n",
            "Eval_MaxReturn : 139.0\n",
            "Eval_MinReturn : 39.0\n",
            "Eval_AverageEpLen : 68.71428571428571\n",
            "Train_AverageReturn : 50.95000076293945\n",
            "Train_StdReturn : 21.930517196655273\n",
            "Train_MaxReturn : 99.0\n",
            "Train_MinReturn : 19.0\n",
            "Train_AverageEpLen : 50.95\n",
            "Train_EnvstepsSoFar : 5107\n",
            "TimeSinceStart : 4.596202611923218\n",
            "Training Loss : -17.384380340576172\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 73.0\n",
            "Eval_StdReturn : 18.230012893676758\n",
            "Eval_MaxReturn : 99.0\n",
            "Eval_MinReturn : 43.0\n",
            "Eval_AverageEpLen : 73.0\n",
            "Train_AverageReturn : 65.4117660522461\n",
            "Train_StdReturn : 32.27284240722656\n",
            "Train_MaxReturn : 137.0\n",
            "Train_MinReturn : 27.0\n",
            "Train_AverageEpLen : 65.41176470588235\n",
            "Train_EnvstepsSoFar : 6219\n",
            "TimeSinceStart : 5.558471202850342\n",
            "Training Loss : -23.049407958984375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 95.80000305175781\n",
            "Eval_StdReturn : 53.91994094848633\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 52.0\n",
            "Eval_AverageEpLen : 95.8\n",
            "Train_AverageReturn : 75.07142639160156\n",
            "Train_StdReturn : 23.22702980041504\n",
            "Train_MaxReturn : 126.0\n",
            "Train_MinReturn : 48.0\n",
            "Train_AverageEpLen : 75.07142857142857\n",
            "Train_EnvstepsSoFar : 7270\n",
            "TimeSinceStart : 6.55679178237915\n",
            "Training Loss : 3.422740936279297\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 113.4000015258789\n",
            "Eval_StdReturn : 47.47883605957031\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 59.0\n",
            "Eval_AverageEpLen : 113.4\n",
            "Train_AverageReturn : 82.84615325927734\n",
            "Train_StdReturn : 33.672279357910156\n",
            "Train_MaxReturn : 148.0\n",
            "Train_MinReturn : 40.0\n",
            "Train_AverageEpLen : 82.84615384615384\n",
            "Train_EnvstepsSoFar : 8347\n",
            "TimeSinceStart : 7.601103067398071\n",
            "Training Loss : 1.93170166015625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 113.5\n",
            "Eval_StdReturn : 52.9646110534668\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 66.0\n",
            "Eval_AverageEpLen : 113.5\n",
            "Train_AverageReturn : 93.63636016845703\n",
            "Train_StdReturn : 48.796932220458984\n",
            "Train_MaxReturn : 178.0\n",
            "Train_MinReturn : 42.0\n",
            "Train_AverageEpLen : 93.63636363636364\n",
            "Train_EnvstepsSoFar : 9377\n",
            "TimeSinceStart : 8.59524393081665\n",
            "Training Loss : -21.846111297607422\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 195.6666717529297\n",
            "Eval_StdReturn : 6.12825870513916\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 187.0\n",
            "Eval_AverageEpLen : 195.66666666666666\n",
            "Train_AverageReturn : 128.25\n",
            "Train_StdReturn : 41.441978454589844\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 69.0\n",
            "Train_AverageEpLen : 128.25\n",
            "Train_EnvstepsSoFar : 10403\n",
            "TimeSinceStart : 9.656093835830688\n",
            "Training Loss : -22.815719604492188\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 147.0\n",
            "Eval_StdReturn : 37.744754791259766\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 115.0\n",
            "Eval_AverageEpLen : 147.0\n",
            "Train_AverageReturn : 153.14285278320312\n",
            "Train_StdReturn : 31.3570613861084\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 97.0\n",
            "Train_AverageEpLen : 153.14285714285714\n",
            "Train_EnvstepsSoFar : 11475\n",
            "TimeSinceStart : 10.679715156555176\n",
            "Training Loss : -18.75982666015625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 187.6666717529297\n",
            "Eval_StdReturn : 17.441967010498047\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 163.0\n",
            "Eval_AverageEpLen : 187.66666666666666\n",
            "Train_AverageReturn : 166.7142791748047\n",
            "Train_StdReturn : 31.80617332458496\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 119.0\n",
            "Train_AverageEpLen : 166.71428571428572\n",
            "Train_EnvstepsSoFar : 12642\n",
            "TimeSinceStart : 11.889151096343994\n",
            "Training Loss : -29.946548461914062\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 170.0\n",
            "Eval_StdReturn : 27.79688262939453\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 133.0\n",
            "Eval_AverageEpLen : 170.0\n",
            "Train_AverageReturn : 189.1666717529297\n",
            "Train_StdReturn : 23.779659271240234\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 136.0\n",
            "Train_AverageEpLen : 189.16666666666666\n",
            "Train_EnvstepsSoFar : 13777\n",
            "TimeSinceStart : 13.04811406135559\n",
            "Training Loss : -13.207402229309082\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 188.6666717529297\n",
            "Train_StdReturn : 25.342103958129883\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 132.0\n",
            "Train_AverageEpLen : 188.66666666666666\n",
            "Train_EnvstepsSoFar : 14909\n",
            "TimeSinceStart : 14.144105434417725\n",
            "Training Loss : 0.5284643173217773\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 183.6666717529297\n",
            "Eval_StdReturn : 13.474254608154297\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 167.0\n",
            "Eval_AverageEpLen : 183.66666666666666\n",
            "Train_AverageReturn : 168.5\n",
            "Train_StdReturn : 33.37039566040039\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 125.0\n",
            "Train_AverageEpLen : 168.5\n",
            "Train_EnvstepsSoFar : 15920\n",
            "TimeSinceStart : 15.223166704177856\n",
            "Training Loss : -11.449729919433594\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 178.0\n",
            "Eval_StdReturn : 25.66450309753418\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 142.0\n",
            "Eval_AverageEpLen : 178.0\n",
            "Train_AverageReturn : 169.5\n",
            "Train_StdReturn : 31.132780075073242\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 127.0\n",
            "Train_AverageEpLen : 169.5\n",
            "Train_EnvstepsSoFar : 16937\n",
            "TimeSinceStart : 16.286272764205933\n",
            "Training Loss : -11.937507629394531\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 189.3333282470703\n",
            "Train_StdReturn : 23.851390838623047\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 136.0\n",
            "Train_AverageEpLen : 189.33333333333334\n",
            "Train_EnvstepsSoFar : 18073\n",
            "TimeSinceStart : 17.363632917404175\n",
            "Training Loss : -12.119897842407227\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 182.1666717529297\n",
            "Train_StdReturn : 17.96678924560547\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 160.0\n",
            "Train_AverageEpLen : 182.16666666666666\n",
            "Train_EnvstepsSoFar : 19166\n",
            "TimeSinceStart : 18.422666311264038\n",
            "Training Loss : -22.087909698486328\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 146.25\n",
            "Eval_StdReturn : 32.182098388671875\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 117.0\n",
            "Eval_AverageEpLen : 146.25\n",
            "Train_AverageReturn : 158.0\n",
            "Train_StdReturn : 24.24871063232422\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 120.0\n",
            "Train_AverageEpLen : 158.0\n",
            "Train_EnvstepsSoFar : 20272\n",
            "TimeSinceStart : 19.55301070213318\n",
            "Training Loss : -16.396678924560547\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 168.6666717529297\n",
            "Eval_StdReturn : 25.31578254699707\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 138.0\n",
            "Eval_AverageEpLen : 168.66666666666666\n",
            "Train_AverageReturn : 172.0\n",
            "Train_StdReturn : 28.58904266357422\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 134.0\n",
            "Train_AverageEpLen : 172.0\n",
            "Train_EnvstepsSoFar : 21304\n",
            "TimeSinceStart : 20.608848094940186\n",
            "Training Loss : -14.250070571899414\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 142.3333282470703\n",
            "Eval_StdReturn : 16.858890533447266\n",
            "Eval_MaxReturn : 166.0\n",
            "Eval_MinReturn : 128.0\n",
            "Eval_AverageEpLen : 142.33333333333334\n",
            "Train_AverageReturn : 148.42857360839844\n",
            "Train_StdReturn : 22.620201110839844\n",
            "Train_MaxReturn : 182.0\n",
            "Train_MinReturn : 124.0\n",
            "Train_AverageEpLen : 148.42857142857142\n",
            "Train_EnvstepsSoFar : 22343\n",
            "TimeSinceStart : 21.585458040237427\n",
            "Training Loss : -18.31367301940918\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 117.5\n",
            "Eval_StdReturn : 6.224949836730957\n",
            "Eval_MaxReturn : 124.0\n",
            "Eval_MinReturn : 108.0\n",
            "Eval_AverageEpLen : 117.5\n",
            "Train_AverageReturn : 139.125\n",
            "Train_StdReturn : 26.388622283935547\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 118.0\n",
            "Train_AverageEpLen : 139.125\n",
            "Train_EnvstepsSoFar : 23456\n",
            "TimeSinceStart : 22.64457941055298\n",
            "Training Loss : -35.59941864013672\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 125.0\n",
            "Eval_StdReturn : 15.29705810546875\n",
            "Eval_MaxReturn : 143.0\n",
            "Eval_MinReturn : 107.0\n",
            "Eval_AverageEpLen : 125.0\n",
            "Train_AverageReturn : 136.375\n",
            "Train_StdReturn : 26.893016815185547\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 104.0\n",
            "Train_AverageEpLen : 136.375\n",
            "Train_EnvstepsSoFar : 24547\n",
            "TimeSinceStart : 23.733319759368896\n",
            "Training Loss : -18.44928550720215\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 124.0\n",
            "Eval_StdReturn : 10.416333198547363\n",
            "Eval_MaxReturn : 141.0\n",
            "Eval_MinReturn : 115.0\n",
            "Eval_AverageEpLen : 124.0\n",
            "Train_AverageReturn : 119.33333587646484\n",
            "Train_StdReturn : 11.547004699707031\n",
            "Train_MaxReturn : 145.0\n",
            "Train_MinReturn : 105.0\n",
            "Train_AverageEpLen : 119.33333333333333\n",
            "Train_EnvstepsSoFar : 25621\n",
            "TimeSinceStart : 24.77112054824829\n",
            "Training Loss : -17.708759307861328\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 111.75\n",
            "Eval_StdReturn : 10.871407508850098\n",
            "Eval_MaxReturn : 130.0\n",
            "Eval_MinReturn : 103.0\n",
            "Eval_AverageEpLen : 111.75\n",
            "Train_AverageReturn : 111.77777862548828\n",
            "Train_StdReturn : 12.36282730102539\n",
            "Train_MaxReturn : 135.0\n",
            "Train_MinReturn : 98.0\n",
            "Train_AverageEpLen : 111.77777777777777\n",
            "Train_EnvstepsSoFar : 26627\n",
            "TimeSinceStart : 25.72470784187317\n",
            "Training Loss : -6.241397857666016\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 100.80000305175781\n",
            "Eval_StdReturn : 29.19178009033203\n",
            "Eval_MaxReturn : 129.0\n",
            "Eval_MinReturn : 45.0\n",
            "Eval_AverageEpLen : 100.8\n",
            "Train_AverageReturn : 111.88888549804688\n",
            "Train_StdReturn : 27.278173446655273\n",
            "Train_MaxReturn : 143.0\n",
            "Train_MinReturn : 41.0\n",
            "Train_AverageEpLen : 111.88888888888889\n",
            "Train_EnvstepsSoFar : 27634\n",
            "TimeSinceStart : 26.718539237976074\n",
            "Training Loss : -19.42290496826172\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 116.75\n",
            "Eval_StdReturn : 10.638961791992188\n",
            "Eval_MaxReturn : 133.0\n",
            "Eval_MinReturn : 105.0\n",
            "Eval_AverageEpLen : 116.75\n",
            "Train_AverageReturn : 104.4000015258789\n",
            "Train_StdReturn : 24.808063507080078\n",
            "Train_MaxReturn : 132.0\n",
            "Train_MinReturn : 46.0\n",
            "Train_AverageEpLen : 104.4\n",
            "Train_EnvstepsSoFar : 28678\n",
            "TimeSinceStart : 27.701513051986694\n",
            "Training Loss : -28.326866149902344\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.0\n",
            "Eval_StdReturn : 3.391165018081665\n",
            "Eval_MaxReturn : 112.0\n",
            "Eval_MinReturn : 103.0\n",
            "Eval_AverageEpLen : 107.0\n",
            "Train_AverageReturn : 111.77777862548828\n",
            "Train_StdReturn : 5.613036155700684\n",
            "Train_MaxReturn : 120.0\n",
            "Train_MinReturn : 103.0\n",
            "Train_AverageEpLen : 111.77777777777777\n",
            "Train_EnvstepsSoFar : 29684\n",
            "TimeSinceStart : 28.628785133361816\n",
            "Training Loss : -22.348915100097656\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 112.75\n",
            "Eval_StdReturn : 6.098155498504639\n",
            "Eval_MaxReturn : 122.0\n",
            "Eval_MinReturn : 105.0\n",
            "Eval_AverageEpLen : 112.75\n",
            "Train_AverageReturn : 115.22222137451172\n",
            "Train_StdReturn : 10.695562362670898\n",
            "Train_MaxReturn : 133.0\n",
            "Train_MinReturn : 102.0\n",
            "Train_AverageEpLen : 115.22222222222223\n",
            "Train_EnvstepsSoFar : 30721\n",
            "TimeSinceStart : 29.614333391189575\n",
            "Training Loss : -21.001262664794922\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 113.25\n",
            "Eval_StdReturn : 4.710361003875732\n",
            "Eval_MaxReturn : 119.0\n",
            "Eval_MinReturn : 106.0\n",
            "Eval_AverageEpLen : 113.25\n",
            "Train_AverageReturn : 106.4000015258789\n",
            "Train_StdReturn : 21.44854164123535\n",
            "Train_MaxReturn : 132.0\n",
            "Train_MinReturn : 48.0\n",
            "Train_AverageEpLen : 106.4\n",
            "Train_EnvstepsSoFar : 31785\n",
            "TimeSinceStart : 30.604610919952393\n",
            "Training Loss : -11.117374420166016\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 114.25\n",
            "Eval_StdReturn : 6.571719646453857\n",
            "Eval_MaxReturn : 125.0\n",
            "Eval_MinReturn : 108.0\n",
            "Eval_AverageEpLen : 114.25\n",
            "Train_AverageReturn : 106.30000305175781\n",
            "Train_StdReturn : 18.931718826293945\n",
            "Train_MaxReturn : 127.0\n",
            "Train_MinReturn : 57.0\n",
            "Train_AverageEpLen : 106.3\n",
            "Train_EnvstepsSoFar : 32848\n",
            "TimeSinceStart : 31.593534231185913\n",
            "Training Loss : -19.318523406982422\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 126.5\n",
            "Eval_StdReturn : 6.020797252655029\n",
            "Eval_MaxReturn : 133.0\n",
            "Eval_MinReturn : 120.0\n",
            "Eval_AverageEpLen : 126.5\n",
            "Train_AverageReturn : 111.4000015258789\n",
            "Train_StdReturn : 7.364781379699707\n",
            "Train_MaxReturn : 128.0\n",
            "Train_MinReturn : 101.0\n",
            "Train_AverageEpLen : 111.4\n",
            "Train_EnvstepsSoFar : 33962\n",
            "TimeSinceStart : 32.6405565738678\n",
            "Training Loss : -13.784683227539062\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 115.25\n",
            "Eval_StdReturn : 5.165994644165039\n",
            "Eval_MaxReturn : 124.0\n",
            "Eval_MinReturn : 111.0\n",
            "Eval_AverageEpLen : 115.25\n",
            "Train_AverageReturn : 111.33333587646484\n",
            "Train_StdReturn : 9.249624252319336\n",
            "Train_MaxReturn : 129.0\n",
            "Train_MinReturn : 99.0\n",
            "Train_AverageEpLen : 111.33333333333333\n",
            "Train_EnvstepsSoFar : 34964\n",
            "TimeSinceStart : 33.59455990791321\n",
            "Training Loss : -25.563318252563477\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 81.16666412353516\n",
            "Eval_StdReturn : 20.99536895751953\n",
            "Eval_MaxReturn : 109.0\n",
            "Eval_MinReturn : 57.0\n",
            "Eval_AverageEpLen : 81.16666666666667\n",
            "Train_AverageReturn : 112.55555725097656\n",
            "Train_StdReturn : 8.421019554138184\n",
            "Train_MaxReturn : 126.0\n",
            "Train_MinReturn : 98.0\n",
            "Train_AverageEpLen : 112.55555555555556\n",
            "Train_EnvstepsSoFar : 35977\n",
            "TimeSinceStart : 34.57609009742737\n",
            "Training Loss : -18.278657913208008\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 88.5999984741211\n",
            "Eval_StdReturn : 29.28890609741211\n",
            "Eval_MaxReturn : 135.0\n",
            "Eval_MinReturn : 58.0\n",
            "Eval_AverageEpLen : 88.6\n",
            "Train_AverageReturn : 93.0\n",
            "Train_StdReturn : 21.56596565246582\n",
            "Train_MaxReturn : 123.0\n",
            "Train_MinReturn : 55.0\n",
            "Train_AverageEpLen : 93.0\n",
            "Train_EnvstepsSoFar : 37000\n",
            "TimeSinceStart : 35.5460205078125\n",
            "Training Loss : -33.1245002746582\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 114.75\n",
            "Eval_StdReturn : 9.73075008392334\n",
            "Eval_MaxReturn : 127.0\n",
            "Eval_MinReturn : 100.0\n",
            "Eval_AverageEpLen : 114.75\n",
            "Train_AverageReturn : 96.0\n",
            "Train_StdReturn : 20.04086685180664\n",
            "Train_MaxReturn : 116.0\n",
            "Train_MinReturn : 55.0\n",
            "Train_AverageEpLen : 96.0\n",
            "Train_EnvstepsSoFar : 38056\n",
            "TimeSinceStart : 36.546229124069214\n",
            "Training Loss : -26.41290283203125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 121.0\n",
            "Eval_StdReturn : 11.76860237121582\n",
            "Eval_MaxReturn : 140.0\n",
            "Eval_MinReturn : 109.0\n",
            "Eval_AverageEpLen : 121.0\n",
            "Train_AverageReturn : 112.44444274902344\n",
            "Train_StdReturn : 10.83319091796875\n",
            "Train_MaxReturn : 134.0\n",
            "Train_MinReturn : 93.0\n",
            "Train_AverageEpLen : 112.44444444444444\n",
            "Train_EnvstepsSoFar : 39068\n",
            "TimeSinceStart : 37.51867318153381\n",
            "Training Loss : -37.73454284667969\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 136.0\n",
            "Eval_StdReturn : 16.753108978271484\n",
            "Eval_MaxReturn : 157.0\n",
            "Eval_MinReturn : 116.0\n",
            "Eval_AverageEpLen : 136.0\n",
            "Train_AverageReturn : 120.55555725097656\n",
            "Train_StdReturn : 4.449996471405029\n",
            "Train_MaxReturn : 129.0\n",
            "Train_MinReturn : 115.0\n",
            "Train_AverageEpLen : 120.55555555555556\n",
            "Train_EnvstepsSoFar : 40153\n",
            "TimeSinceStart : 38.498920917510986\n",
            "Training Loss : -19.21533203125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 157.0\n",
            "Eval_StdReturn : 19.442222595214844\n",
            "Eval_MaxReturn : 184.0\n",
            "Eval_MinReturn : 139.0\n",
            "Eval_AverageEpLen : 157.0\n",
            "Train_AverageReturn : 134.5\n",
            "Train_StdReturn : 11.597413063049316\n",
            "Train_MaxReturn : 153.0\n",
            "Train_MinReturn : 118.0\n",
            "Train_AverageEpLen : 134.5\n",
            "Train_EnvstepsSoFar : 41229\n",
            "TimeSinceStart : 39.5290265083313\n",
            "Training Loss : -30.857213973999023\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 146.3333282470703\n",
            "Eval_StdReturn : 20.88593292236328\n",
            "Eval_MaxReturn : 173.0\n",
            "Eval_MinReturn : 122.0\n",
            "Eval_AverageEpLen : 146.33333333333334\n",
            "Train_AverageReturn : 133.0\n",
            "Train_StdReturn : 14.186261177062988\n",
            "Train_MaxReturn : 167.0\n",
            "Train_MinReturn : 117.0\n",
            "Train_AverageEpLen : 133.0\n",
            "Train_EnvstepsSoFar : 42293\n",
            "TimeSinceStart : 40.54014348983765\n",
            "Training Loss : -29.17550277709961\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 174.3333282470703\n",
            "Eval_StdReturn : 4.784233093261719\n",
            "Eval_MaxReturn : 181.0\n",
            "Eval_MinReturn : 170.0\n",
            "Eval_AverageEpLen : 174.33333333333334\n",
            "Train_AverageReturn : 143.0\n",
            "Train_StdReturn : 8.10643482208252\n",
            "Train_MaxReturn : 155.0\n",
            "Train_MinReturn : 132.0\n",
            "Train_AverageEpLen : 143.0\n",
            "Train_EnvstepsSoFar : 43294\n",
            "TimeSinceStart : 41.579296350479126\n",
            "Training Loss : -30.595426559448242\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 173.3333282470703\n",
            "Eval_StdReturn : 7.1336445808410645\n",
            "Eval_MaxReturn : 183.0\n",
            "Eval_MinReturn : 166.0\n",
            "Eval_AverageEpLen : 173.33333333333334\n",
            "Train_AverageReturn : 156.42857360839844\n",
            "Train_StdReturn : 13.937176704406738\n",
            "Train_MaxReturn : 177.0\n",
            "Train_MinReturn : 137.0\n",
            "Train_AverageEpLen : 156.42857142857142\n",
            "Train_EnvstepsSoFar : 44389\n",
            "TimeSinceStart : 42.68298649787903\n",
            "Training Loss : -19.130767822265625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 186.0\n",
            "Eval_StdReturn : 8.286535263061523\n",
            "Eval_MaxReturn : 195.0\n",
            "Eval_MinReturn : 175.0\n",
            "Eval_AverageEpLen : 186.0\n",
            "Train_AverageReturn : 173.8333282470703\n",
            "Train_StdReturn : 12.522202491760254\n",
            "Train_MaxReturn : 194.0\n",
            "Train_MinReturn : 153.0\n",
            "Train_AverageEpLen : 173.83333333333334\n",
            "Train_EnvstepsSoFar : 45432\n",
            "TimeSinceStart : 43.78149914741516\n",
            "Training Loss : 4.805721282958984\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 157.6666717529297\n",
            "Eval_StdReturn : 10.656245231628418\n",
            "Eval_MaxReturn : 170.0\n",
            "Eval_MinReturn : 144.0\n",
            "Eval_AverageEpLen : 157.66666666666666\n",
            "Train_AverageReturn : 167.8333282470703\n",
            "Train_StdReturn : 10.945571899414062\n",
            "Train_MaxReturn : 182.0\n",
            "Train_MinReturn : 151.0\n",
            "Train_AverageEpLen : 167.83333333333334\n",
            "Train_EnvstepsSoFar : 46439\n",
            "TimeSinceStart : 44.7827935218811\n",
            "Training Loss : -35.81963348388672\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 180.3333282470703\n",
            "Eval_StdReturn : 13.76791763305664\n",
            "Eval_MaxReturn : 192.0\n",
            "Eval_MinReturn : 161.0\n",
            "Eval_AverageEpLen : 180.33333333333334\n",
            "Train_AverageReturn : 169.5\n",
            "Train_StdReturn : 19.729419708251953\n",
            "Train_MaxReturn : 199.0\n",
            "Train_MinReturn : 151.0\n",
            "Train_AverageEpLen : 169.5\n",
            "Train_EnvstepsSoFar : 47456\n",
            "TimeSinceStart : 45.84233784675598\n",
            "Training Loss : -4.382302284240723\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 167.0\n",
            "Eval_StdReturn : 1.632993221282959\n",
            "Eval_MaxReturn : 169.0\n",
            "Eval_MinReturn : 165.0\n",
            "Eval_AverageEpLen : 167.0\n",
            "Train_AverageReturn : 168.6666717529297\n",
            "Train_StdReturn : 19.136932373046875\n",
            "Train_MaxReturn : 197.0\n",
            "Train_MinReturn : 151.0\n",
            "Train_AverageEpLen : 168.66666666666666\n",
            "Train_EnvstepsSoFar : 48468\n",
            "TimeSinceStart : 46.89336848258972\n",
            "Training Loss : 2.1623992919921875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 176.6666717529297\n",
            "Eval_StdReturn : 9.741092681884766\n",
            "Eval_MaxReturn : 185.0\n",
            "Eval_MinReturn : 163.0\n",
            "Eval_AverageEpLen : 176.66666666666666\n",
            "Train_AverageReturn : 176.1666717529297\n",
            "Train_StdReturn : 15.410134315490723\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 160.0\n",
            "Train_AverageEpLen : 176.16666666666666\n",
            "Train_EnvstepsSoFar : 49525\n",
            "TimeSinceStart : 47.98987174034119\n",
            "Training Loss : -4.99107551574707\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 182.3333282470703\n",
            "Eval_StdReturn : 15.92342758178711\n",
            "Eval_MaxReturn : 196.0\n",
            "Eval_MinReturn : 160.0\n",
            "Eval_AverageEpLen : 182.33333333333334\n",
            "Train_AverageReturn : 183.6666717529297\n",
            "Train_StdReturn : 12.94432544708252\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 164.0\n",
            "Train_AverageEpLen : 183.66666666666666\n",
            "Train_EnvstepsSoFar : 50627\n",
            "TimeSinceStart : 49.17392611503601\n",
            "Training Loss : -19.66652488708496\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 182.6666717529297\n",
            "Eval_StdReturn : 13.888444900512695\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 166.0\n",
            "Eval_AverageEpLen : 182.66666666666666\n",
            "Train_AverageReturn : 184.6666717529297\n",
            "Train_StdReturn : 11.827463150024414\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 170.0\n",
            "Train_AverageEpLen : 184.66666666666666\n",
            "Train_EnvstepsSoFar : 51735\n",
            "TimeSinceStart : 50.31895136833191\n",
            "Training Loss : -23.84710121154785\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 194.3333282470703\n",
            "Eval_StdReturn : 4.921607494354248\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 188.0\n",
            "Eval_AverageEpLen : 194.33333333333334\n",
            "Train_AverageReturn : 193.8333282470703\n",
            "Train_StdReturn : 7.819136142730713\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 179.0\n",
            "Train_AverageEpLen : 193.83333333333334\n",
            "Train_EnvstepsSoFar : 52898\n",
            "TimeSinceStart : 51.537617921829224\n",
            "Training Loss : -20.184955596923828\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 196.6666717529297\n",
            "Eval_StdReturn : 2.357022762298584\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 195.0\n",
            "Eval_AverageEpLen : 196.66666666666666\n",
            "Train_AverageReturn : 198.1666717529297\n",
            "Train_StdReturn : 3.2871804237365723\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 191.0\n",
            "Train_AverageEpLen : 198.16666666666666\n",
            "Train_EnvstepsSoFar : 54087\n",
            "TimeSinceStart : 52.769301652908325\n",
            "Training Loss : -27.49196434020996\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 196.6666717529297\n",
            "Eval_StdReturn : 4.71404504776001\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 190.0\n",
            "Eval_AverageEpLen : 196.66666666666666\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 55087\n",
            "TimeSinceStart : 53.89494705200195\n",
            "Training Loss : -29.34733772277832\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 198.3333282470703\n",
            "Train_StdReturn : 3.2998316287994385\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 191.0\n",
            "Train_AverageEpLen : 198.33333333333334\n",
            "Train_EnvstepsSoFar : 56277\n",
            "TimeSinceStart : 55.04078459739685\n",
            "Training Loss : -6.57392692565918\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 57277\n",
            "TimeSinceStart : 56.03784513473511\n",
            "Training Loss : -15.951101303100586\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 197.3333282470703\n",
            "Eval_StdReturn : 3.771235942840576\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 192.0\n",
            "Eval_AverageEpLen : 197.33333333333334\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 58277\n",
            "TimeSinceStart : 57.147690296173096\n",
            "Training Loss : -4.653840065002441\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 59277\n",
            "TimeSinceStart : 58.154186964035034\n",
            "Training Loss : -6.363229751586914\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 60277\n",
            "TimeSinceStart : 59.17764854431152\n",
            "Training Loss : 4.71240234375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 61277\n",
            "TimeSinceStart : 60.2126727104187\n",
            "Training Loss : 3.7083282470703125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 62277\n",
            "TimeSinceStart : 61.21106290817261\n",
            "Training Loss : -3.9480791091918945\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 63277\n",
            "TimeSinceStart : 62.2115797996521\n",
            "Training Loss : 17.34485626220703\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 64277\n",
            "TimeSinceStart : 63.205952644348145\n",
            "Training Loss : 16.78676414489746\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 65277\n",
            "TimeSinceStart : 64.22507977485657\n",
            "Training Loss : 4.604056358337402\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 66277\n",
            "TimeSinceStart : 65.22628283500671\n",
            "Training Loss : 22.682754516601562\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 67277\n",
            "TimeSinceStart : 66.22780919075012\n",
            "Training Loss : 15.958548545837402\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 68277\n",
            "TimeSinceStart : 67.229243516922\n",
            "Training Loss : -11.688152313232422\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 69277\n",
            "TimeSinceStart : 68.21864128112793\n",
            "Training Loss : -14.614830017089844\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 70277\n",
            "TimeSinceStart : 69.20778226852417\n",
            "Training Loss : -7.5313005447387695\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 71277\n",
            "TimeSinceStart : 70.22201204299927\n",
            "Training Loss : -1.8892078399658203\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 72277\n",
            "TimeSinceStart : 71.22380042076111\n",
            "Training Loss : -14.745057106018066\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 73277\n",
            "TimeSinceStart : 72.24374151229858\n",
            "Training Loss : -28.530517578125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 74277\n",
            "TimeSinceStart : 73.24240469932556\n",
            "Training Loss : -17.737289428710938\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 75277\n",
            "TimeSinceStart : 74.23247861862183\n",
            "Training Loss : -29.944305419921875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.8333282470703\n",
            "Train_StdReturn : 0.3726779818534851\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 199.0\n",
            "Train_AverageEpLen : 199.83333333333334\n",
            "Train_EnvstepsSoFar : 76476\n",
            "TimeSinceStart : 75.4107825756073\n",
            "Training Loss : -14.527639389038086\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 199.0\n",
            "Eval_StdReturn : 1.4142135381698608\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 197.0\n",
            "Eval_AverageEpLen : 199.0\n",
            "Train_AverageReturn : 199.0\n",
            "Train_StdReturn : 2.2360680103302\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 194.0\n",
            "Train_AverageEpLen : 199.0\n",
            "Train_EnvstepsSoFar : 77670\n",
            "TimeSinceStart : 76.68026542663574\n",
            "Training Loss : -38.7213249206543\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 194.0\n",
            "Eval_StdReturn : 5.3541259765625\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 187.0\n",
            "Eval_AverageEpLen : 194.0\n",
            "Train_AverageReturn : 194.8333282470703\n",
            "Train_StdReturn : 6.743309497833252\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 182.0\n",
            "Train_AverageEpLen : 194.83333333333334\n",
            "Train_EnvstepsSoFar : 78839\n",
            "TimeSinceStart : 77.90075397491455\n",
            "Training Loss : -22.623001098632812\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 181.0\n",
            "Eval_StdReturn : 16.08311653137207\n",
            "Eval_MaxReturn : 197.0\n",
            "Eval_MinReturn : 159.0\n",
            "Eval_AverageEpLen : 181.0\n",
            "Train_AverageReturn : 189.3333282470703\n",
            "Train_StdReturn : 7.226494789123535\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 179.0\n",
            "Train_AverageEpLen : 189.33333333333334\n",
            "Train_EnvstepsSoFar : 79975\n",
            "TimeSinceStart : 79.11529064178467\n",
            "Training Loss : -22.799365997314453\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 182.3333282470703\n",
            "Eval_StdReturn : 2.8674418926239014\n",
            "Eval_MaxReturn : 186.0\n",
            "Eval_MinReturn : 179.0\n",
            "Eval_AverageEpLen : 182.33333333333334\n",
            "Train_AverageReturn : 183.8333282470703\n",
            "Train_StdReturn : 7.335227012634277\n",
            "Train_MaxReturn : 196.0\n",
            "Train_MinReturn : 174.0\n",
            "Train_AverageEpLen : 183.83333333333334\n",
            "Train_EnvstepsSoFar : 81078\n",
            "TimeSinceStart : 80.26684546470642\n",
            "Training Loss : -16.46451187133789\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 174.3333282470703\n",
            "Eval_StdReturn : 7.586537837982178\n",
            "Eval_MaxReturn : 185.0\n",
            "Eval_MinReturn : 168.0\n",
            "Eval_AverageEpLen : 174.33333333333334\n",
            "Train_AverageReturn : 171.6666717529297\n",
            "Train_StdReturn : 8.863157272338867\n",
            "Train_MaxReturn : 182.0\n",
            "Train_MinReturn : 157.0\n",
            "Train_AverageEpLen : 171.66666666666666\n",
            "Train_EnvstepsSoFar : 82108\n",
            "TimeSinceStart : 81.34263062477112\n",
            "Training Loss : -16.510751724243164\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 151.0\n",
            "Eval_StdReturn : 1.4142135381698608\n",
            "Eval_MaxReturn : 152.0\n",
            "Eval_MinReturn : 149.0\n",
            "Eval_AverageEpLen : 151.0\n",
            "Train_AverageReturn : 163.0\n",
            "Train_StdReturn : 10.433462142944336\n",
            "Train_MaxReturn : 178.0\n",
            "Train_MinReturn : 151.0\n",
            "Train_AverageEpLen : 163.0\n",
            "Train_EnvstepsSoFar : 83249\n",
            "TimeSinceStart : 82.44186782836914\n",
            "Training Loss : -9.244783401489258\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 146.3333282470703\n",
            "Eval_StdReturn : 2.357022762298584\n",
            "Eval_MaxReturn : 148.0\n",
            "Eval_MinReturn : 143.0\n",
            "Eval_AverageEpLen : 146.33333333333334\n",
            "Train_AverageReturn : 151.0\n",
            "Train_StdReturn : 3.625308036804199\n",
            "Train_MaxReturn : 157.0\n",
            "Train_MinReturn : 146.0\n",
            "Train_AverageEpLen : 151.0\n",
            "Train_EnvstepsSoFar : 84306\n",
            "TimeSinceStart : 83.46419072151184\n",
            "Training Loss : -45.51050567626953\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 138.6666717529297\n",
            "Eval_StdReturn : 8.339998245239258\n",
            "Eval_MaxReturn : 146.0\n",
            "Eval_MinReturn : 127.0\n",
            "Eval_AverageEpLen : 138.66666666666666\n",
            "Train_AverageReturn : 145.14285278320312\n",
            "Train_StdReturn : 4.7638092041015625\n",
            "Train_MaxReturn : 154.0\n",
            "Train_MinReturn : 138.0\n",
            "Train_AverageEpLen : 145.14285714285714\n",
            "Train_EnvstepsSoFar : 85322\n",
            "TimeSinceStart : 84.46990776062012\n",
            "Training Loss : -25.450122833251953\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 131.0\n",
            "Eval_StdReturn : 4.7434163093566895\n",
            "Eval_MaxReturn : 137.0\n",
            "Eval_MinReturn : 125.0\n",
            "Eval_AverageEpLen : 131.0\n",
            "Train_AverageReturn : 139.0\n",
            "Train_StdReturn : 5.958187580108643\n",
            "Train_MaxReturn : 149.0\n",
            "Train_MinReturn : 131.0\n",
            "Train_AverageEpLen : 139.0\n",
            "Train_EnvstepsSoFar : 86434\n",
            "TimeSinceStart : 85.56663012504578\n",
            "Training Loss : -23.221370697021484\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 120.25\n",
            "Eval_StdReturn : 5.068283557891846\n",
            "Eval_MaxReturn : 129.0\n",
            "Eval_MinReturn : 117.0\n",
            "Eval_AverageEpLen : 120.25\n",
            "Train_AverageReturn : 132.375\n",
            "Train_StdReturn : 3.038811445236206\n",
            "Train_MaxReturn : 136.0\n",
            "Train_MinReturn : 126.0\n",
            "Train_AverageEpLen : 132.375\n",
            "Train_EnvstepsSoFar : 87493\n",
            "TimeSinceStart : 86.58534860610962\n",
            "Training Loss : -33.41090774536133\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 120.75\n",
            "Eval_StdReturn : 3.1124749183654785\n",
            "Eval_MaxReturn : 126.0\n",
            "Eval_MinReturn : 118.0\n",
            "Eval_AverageEpLen : 120.75\n",
            "Train_AverageReturn : 127.375\n",
            "Train_StdReturn : 6.382348537445068\n",
            "Train_MaxReturn : 139.0\n",
            "Train_MinReturn : 117.0\n",
            "Train_AverageEpLen : 127.375\n",
            "Train_EnvstepsSoFar : 88512\n",
            "TimeSinceStart : 87.57314085960388\n",
            "Training Loss : -40.197784423828125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 124.0\n",
            "Eval_StdReturn : 1.5811388492584229\n",
            "Eval_MaxReturn : 126.0\n",
            "Eval_MinReturn : 122.0\n",
            "Eval_AverageEpLen : 124.0\n",
            "Train_AverageReturn : 118.88888549804688\n",
            "Train_StdReturn : 4.863570690155029\n",
            "Train_MaxReturn : 128.0\n",
            "Train_MinReturn : 112.0\n",
            "Train_AverageEpLen : 118.88888888888889\n",
            "Train_EnvstepsSoFar : 89582\n",
            "TimeSinceStart : 88.6006236076355\n",
            "Training Loss : -38.97721481323242\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 125.75\n",
            "Eval_StdReturn : 6.219927787780762\n",
            "Eval_MaxReturn : 135.0\n",
            "Eval_MinReturn : 118.0\n",
            "Eval_AverageEpLen : 125.75\n",
            "Train_AverageReturn : 124.66666412353516\n",
            "Train_StdReturn : 4.189935207366943\n",
            "Train_MaxReturn : 131.0\n",
            "Train_MinReturn : 119.0\n",
            "Train_AverageEpLen : 124.66666666666667\n",
            "Train_EnvstepsSoFar : 90704\n",
            "TimeSinceStart : 89.66404795646667\n",
            "Training Loss : -30.292686462402344\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 124.0\n",
            "Eval_StdReturn : 9.137833595275879\n",
            "Eval_MaxReturn : 137.0\n",
            "Eval_MinReturn : 114.0\n",
            "Eval_AverageEpLen : 124.0\n",
            "Train_AverageReturn : 125.875\n",
            "Train_StdReturn : 4.075459957122803\n",
            "Train_MaxReturn : 133.0\n",
            "Train_MinReturn : 121.0\n",
            "Train_AverageEpLen : 125.875\n",
            "Train_EnvstepsSoFar : 91711\n",
            "TimeSinceStart : 90.66860866546631\n",
            "Training Loss : -31.704490661621094\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 130.25\n",
            "Eval_StdReturn : 5.117372512817383\n",
            "Eval_MaxReturn : 138.0\n",
            "Eval_MinReturn : 124.0\n",
            "Eval_AverageEpLen : 130.25\n",
            "Train_AverageReturn : 122.22222137451172\n",
            "Train_StdReturn : 6.86015510559082\n",
            "Train_MaxReturn : 134.0\n",
            "Train_MinReturn : 111.0\n",
            "Train_AverageEpLen : 122.22222222222223\n",
            "Train_EnvstepsSoFar : 92811\n",
            "TimeSinceStart : 91.70740008354187\n",
            "Training Loss : -15.129318237304688\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 126.5\n",
            "Eval_StdReturn : 5.408327102661133\n",
            "Eval_MaxReturn : 134.0\n",
            "Eval_MinReturn : 120.0\n",
            "Eval_AverageEpLen : 126.5\n",
            "Train_AverageReturn : 125.625\n",
            "Train_StdReturn : 5.829611778259277\n",
            "Train_MaxReturn : 133.0\n",
            "Train_MinReturn : 114.0\n",
            "Train_AverageEpLen : 125.625\n",
            "Train_EnvstepsSoFar : 93816\n",
            "TimeSinceStart : 92.68996047973633\n",
            "Training Loss : -10.013992309570312\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 123.25\n",
            "Eval_StdReturn : 7.529109954833984\n",
            "Eval_MaxReturn : 135.0\n",
            "Eval_MinReturn : 114.0\n",
            "Eval_AverageEpLen : 123.25\n",
            "Train_AverageReturn : 131.625\n",
            "Train_StdReturn : 4.090766906738281\n",
            "Train_MaxReturn : 137.0\n",
            "Train_MinReturn : 125.0\n",
            "Train_AverageEpLen : 131.625\n",
            "Train_EnvstepsSoFar : 94869\n",
            "TimeSinceStart : 93.71703386306763\n",
            "Training Loss : -25.76091766357422\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 133.5\n",
            "Eval_StdReturn : 3.2015621662139893\n",
            "Eval_MaxReturn : 138.0\n",
            "Eval_MinReturn : 130.0\n",
            "Eval_AverageEpLen : 133.5\n",
            "Train_AverageReturn : 123.11111450195312\n",
            "Train_StdReturn : 5.782049655914307\n",
            "Train_MaxReturn : 130.0\n",
            "Train_MinReturn : 109.0\n",
            "Train_AverageEpLen : 123.11111111111111\n",
            "Train_EnvstepsSoFar : 95977\n",
            "TimeSinceStart : 94.77473711967468\n",
            "Training Loss : -18.458602905273438\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 145.3333282470703\n",
            "Eval_StdReturn : 7.3635735511779785\n",
            "Eval_MaxReturn : 154.0\n",
            "Eval_MinReturn : 136.0\n",
            "Eval_AverageEpLen : 145.33333333333334\n",
            "Train_AverageReturn : 131.75\n",
            "Train_StdReturn : 6.359048843383789\n",
            "Train_MaxReturn : 141.0\n",
            "Train_MinReturn : 120.0\n",
            "Train_AverageEpLen : 131.75\n",
            "Train_EnvstepsSoFar : 97031\n",
            "TimeSinceStart : 95.75906682014465\n",
            "Training Loss : -6.7927398681640625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 146.6666717529297\n",
            "Eval_StdReturn : 6.018489837646484\n",
            "Eval_MaxReturn : 155.0\n",
            "Eval_MinReturn : 141.0\n",
            "Eval_AverageEpLen : 146.66666666666666\n",
            "Train_AverageReturn : 141.125\n",
            "Train_StdReturn : 6.450532913208008\n",
            "Train_MaxReturn : 151.0\n",
            "Train_MinReturn : 129.0\n",
            "Train_AverageEpLen : 141.125\n",
            "Train_EnvstepsSoFar : 98160\n",
            "TimeSinceStart : 96.83253455162048\n",
            "Training Loss : -12.170831680297852\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 161.3333282470703\n",
            "Eval_StdReturn : 5.557777404785156\n",
            "Eval_MaxReturn : 169.0\n",
            "Eval_MinReturn : 156.0\n",
            "Eval_AverageEpLen : 161.33333333333334\n",
            "Train_AverageReturn : 149.2857208251953\n",
            "Train_StdReturn : 5.872801303863525\n",
            "Train_MaxReturn : 157.0\n",
            "Train_MinReturn : 140.0\n",
            "Train_AverageEpLen : 149.28571428571428\n",
            "Train_EnvstepsSoFar : 99205\n",
            "TimeSinceStart : 97.85730385780334\n",
            "Training Loss : -28.699512481689453\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 168.3333282470703\n",
            "Eval_StdReturn : 4.9888763427734375\n",
            "Eval_MaxReturn : 175.0\n",
            "Eval_MinReturn : 163.0\n",
            "Eval_AverageEpLen : 168.33333333333334\n",
            "Train_AverageReturn : 165.7142791748047\n",
            "Train_StdReturn : 7.065292835235596\n",
            "Train_MaxReturn : 172.0\n",
            "Train_MinReturn : 152.0\n",
            "Train_AverageEpLen : 165.71428571428572\n",
            "Train_EnvstepsSoFar : 100365\n",
            "TimeSinceStart : 98.98769950866699\n",
            "Training Loss : -28.79309844970703\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 181.6666717529297\n",
            "Eval_StdReturn : 8.57645320892334\n",
            "Eval_MaxReturn : 192.0\n",
            "Eval_MinReturn : 171.0\n",
            "Eval_AverageEpLen : 181.66666666666666\n",
            "Train_AverageReturn : 176.0\n",
            "Train_StdReturn : 6.608076095581055\n",
            "Train_MaxReturn : 184.0\n",
            "Train_MinReturn : 165.0\n",
            "Train_AverageEpLen : 176.0\n",
            "Train_EnvstepsSoFar : 101421\n",
            "TimeSinceStart : 100.0867645740509\n",
            "Training Loss : -24.588308334350586\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 197.0\n",
            "Eval_StdReturn : 2.4494898319244385\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 194.0\n",
            "Eval_AverageEpLen : 197.0\n",
            "Train_AverageReturn : 184.8333282470703\n",
            "Train_StdReturn : 7.151145935058594\n",
            "Train_MaxReturn : 195.0\n",
            "Train_MinReturn : 171.0\n",
            "Train_AverageEpLen : 184.83333333333334\n",
            "Train_EnvstepsSoFar : 102530\n",
            "TimeSinceStart : 101.26639485359192\n",
            "Training Loss : -27.87742042541504\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 197.1666717529297\n",
            "Train_StdReturn : 3.3374972343444824\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 192.0\n",
            "Train_AverageEpLen : 197.16666666666666\n",
            "Train_EnvstepsSoFar : 103713\n",
            "TimeSinceStart : 102.4289493560791\n",
            "Training Loss : -36.96876525878906\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.1666717529297\n",
            "Train_StdReturn : 1.8633898496627808\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 195.0\n",
            "Train_AverageEpLen : 199.16666666666666\n",
            "Train_EnvstepsSoFar : 104908\n",
            "TimeSinceStart : 103.63950824737549\n",
            "Training Loss : -16.175039291381836\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 105908\n",
            "TimeSinceStart : 104.68187141418457\n",
            "Training Loss : -1.826685905456543\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## run training\n",
        "\n",
        "print(args.logdir)\n",
        "trainer = PG_Trainer(args)\n",
        "trainer.run_training_loop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km7LlYvhqKTl",
        "outputId": "4f96cdb7-dfb1-44a6-d55b-46a5cfc5ccdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 3220."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown You can visualize your runs with tensorboard from within the notebook\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/cds_rl_2022/hw2/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_44ixLSXCMgK"
      },
      "source": [
        "#CartPole"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mk2t5Kf24zkp"
      },
      "outputs": [],
      "source": [
        "import pickle, gzip\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut9EQX-f6es4"
      },
      "outputs": [],
      "source": [
        "def plot(logfile, savefile):\n",
        "    Eval_AverageReturns_beh, Eval_Std_returns_beh = [], []\n",
        "    for summary in summary_iterator(logfile):\n",
        "        for v in summary.summary.value:\n",
        "            if v.tag == \"Eval_AverageReturn\":\n",
        "                Eval_AverageReturns_beh.append(v.simple_value)\n",
        "\n",
        "    plt.plot(Eval_AverageReturns_beh, label = \"Eval_AverageReturns\")\n",
        "    plt.legend()\n",
        "    plt.savefig(savefile)\n",
        "    plt.delaxes()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot('/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q1_sb_no_rtg_dsa_CartPole-v0_09-05-2022_13-37-18/events.out.tfevents.1652103438.1f515a41fb55', \n",
        "     '/content/cds_rl_2022/rl_hw/hw2/figure/q1_sb_1')\n",
        "\n",
        "plot('/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q1_sb_rtg_dsa_CartPole-v0_09-05-2022_13-38-04/events.out.tfevents.1652103484.1f515a41fb55', \n",
        "     '/content/cds_rl_2022/rl_hw/hw2/figure/q1_sb_2')\n",
        "\n",
        "plot('/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q1_sb_rtg_na_CartPole-v0_09-05-2022_13-39-11/events.out.tfevents.1652103551.1f515a41fb55', \n",
        "     '/content/cds_rl_2022/rl_hw/hw2/figure/q1_sb_3')\n",
        "\n",
        "plot('/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q1_lb_no_rtg_dsa_CartPole-v0_09-05-2022_13-40-17/events.out.tfevents.1652103617.1f515a41fb55', \n",
        "     '/content/cds_rl_2022/rl_hw/hw2/figure/q1_lb_1')\n",
        "\n",
        "plot('/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q1_lb_rtg_dsa_CartPole-v0_09-05-2022_13-42-59/events.out.tfevents.1652103779.1f515a41fb55', \n",
        "     '/content/cds_rl_2022/rl_hw/hw2/figure/q1_lb_2')\n",
        "\n",
        "plot('/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q1_lb_rtg_na_CartPole-v0_09-05-2022_13-47-22/events.out.tfevents.1652104042.1f515a41fb55', \n",
        "     '/content/cds_rl_2022/rl_hw/hw2/figure/q1_lb_3')"
      ],
      "metadata": {
        "id": "c58PnKmuOqeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "files = ['/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q1_sb_no_rtg_dsa_CartPole-v0_09-05-2022_13-37-18/events.out.tfevents.1652103438.1f515a41fb55',\n",
        "         '/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q1_sb_rtg_dsa_CartPole-v0_09-05-2022_13-38-04/events.out.tfevents.1652103484.1f515a41fb55',\n",
        "         '/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q1_sb_rtg_na_CartPole-v0_09-05-2022_13-39-11/events.out.tfevents.1652103551.1f515a41fb55']\n",
        "labels = ['no_rtg', 'rtg_dsa', 'rtg_na']\n",
        "for logfile in files:\n",
        "    Eval_AverageReturns = []\n",
        "    for summary in summary_iterator(logfile):\n",
        "        for v in summary.summary.value:\n",
        "            if v.tag == \"Eval_AverageReturn\":\n",
        "                Eval_AverageReturns.append(v.simple_value)\n",
        "\n",
        "    plt.plot(Eval_AverageReturns, label = labels[i])\n",
        "    i+=1\n",
        "plt.legend()\n",
        "plt.savefig('q1_sb')\n",
        "plt.delaxes()"
      ],
      "metadata": {
        "id": "i-lqE_bXqybp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "files = ['/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q1_lb_no_rtg_dsa_CartPole-v0_09-05-2022_13-40-17/events.out.tfevents.1652103617.1f515a41fb55',\n",
        "         '/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q1_lb_rtg_dsa_CartPole-v0_09-05-2022_13-42-59/events.out.tfevents.1652103779.1f515a41fb55',\n",
        "         '/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q1_lb_rtg_na_CartPole-v0_09-05-2022_13-47-22/events.out.tfevents.1652104042.1f515a41fb55']\n",
        "labels = ['no_rtg', 'rtg_dsa', 'rtg_na']\n",
        "for logfile in files:\n",
        "    Eval_AverageReturns = []\n",
        "    for summary in summary_iterator(logfile):\n",
        "        for v in summary.summary.value:\n",
        "            if v.tag == \"Eval_AverageReturn\":\n",
        "                Eval_AverageReturns.append(v.simple_value)\n",
        "\n",
        "    plt.plot(Eval_AverageReturns, label = labels[i])\n",
        "    i+=1\n",
        "plt.legend()\n",
        "plt.savefig('q1_lb')\n",
        "plt.delaxes()"
      ],
      "metadata": {
        "id": "YSl7Cdg2rZBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ_sgPUsCLwt",
        "outputId": "0bb80714-0b18-415c-bb42-9d295858507e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Train_AverageReturn : 198.3076934814453\n",
            "Train_StdReturn : 4.912849426269531\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 176.0\n",
            "Train_AverageEpLen : 198.30769230769232\n",
            "Train_EnvstepsSoFar : 111195\n",
            "TimeSinceStart : 52.89021587371826\n",
            "Training Loss : 264389.5\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 192.0\n",
            "Eval_StdReturn : 11.313708305358887\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 176.0\n",
            "Eval_AverageEpLen : 192.0\n",
            "Train_AverageReturn : 193.03846740722656\n",
            "Train_StdReturn : 11.057475090026855\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 163.0\n",
            "Train_AverageEpLen : 193.03846153846155\n",
            "Train_EnvstepsSoFar : 116214\n",
            "TimeSinceStart : 55.60227584838867\n",
            "Training Loss : 253275.0625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 191.62962341308594\n",
            "Train_StdReturn : 12.678791046142578\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 141.0\n",
            "Train_AverageEpLen : 191.62962962962962\n",
            "Train_EnvstepsSoFar : 121388\n",
            "TimeSinceStart : 58.29752254486084\n",
            "Training Loss : 260574.125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 198.92308044433594\n",
            "Train_StdReturn : 3.304112672805786\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 185.0\n",
            "Train_AverageEpLen : 198.92307692307693\n",
            "Train_EnvstepsSoFar : 126560\n",
            "TimeSinceStart : 61.00894856452942\n",
            "Training Loss : 268561.375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.8076934814453\n",
            "Train_StdReturn : 0.9615384340286255\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 195.0\n",
            "Train_AverageEpLen : 199.80769230769232\n",
            "Train_EnvstepsSoFar : 131755\n",
            "TimeSinceStart : 63.733545780181885\n",
            "Training Loss : 272381.875\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 136755\n",
            "TimeSinceStart : 66.42614126205444\n",
            "Training Loss : 261923.734375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 141755\n",
            "TimeSinceStart : 69.10733032226562\n",
            "Training Loss : 253732.984375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 146755\n",
            "TimeSinceStart : 71.71298956871033\n",
            "Training Loss : 253014.578125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 151755\n",
            "TimeSinceStart : 74.36212015151978\n",
            "Training Loss : 253175.296875\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 156755\n",
            "TimeSinceStart : 76.98600006103516\n",
            "Training Loss : 248491.5625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 161755\n",
            "TimeSinceStart : 79.63015508651733\n",
            "Training Loss : 243000.984375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 166755\n",
            "TimeSinceStart : 82.33384728431702\n",
            "Training Loss : 239818.75\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 171755\n",
            "TimeSinceStart : 85.00892663002014\n",
            "Training Loss : 239704.4375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 176755\n",
            "TimeSinceStart : 87.6731641292572\n",
            "Training Loss : 233863.625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 181755\n",
            "TimeSinceStart : 90.31120228767395\n",
            "Training Loss : 231349.625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 186755\n",
            "TimeSinceStart : 92.96528768539429\n",
            "Training Loss : 231909.140625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 191755\n",
            "TimeSinceStart : 95.64579701423645\n",
            "Training Loss : 225363.71875\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 196755\n",
            "TimeSinceStart : 98.28122544288635\n",
            "Training Loss : 226391.53125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 201755\n",
            "TimeSinceStart : 100.98593735694885\n",
            "Training Loss : 222545.890625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 206755\n",
            "TimeSinceStart : 103.68703126907349\n",
            "Training Loss : 221857.28125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 211755\n",
            "TimeSinceStart : 106.33050489425659\n",
            "Training Loss : 227179.015625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 216755\n",
            "TimeSinceStart : 108.9996407032013\n",
            "Training Loss : 223260.15625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 221755\n",
            "TimeSinceStart : 111.65673875808716\n",
            "Training Loss : 219216.15625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 226755\n",
            "TimeSinceStart : 114.34701251983643\n",
            "Training Loss : 219420.0625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 231755\n",
            "TimeSinceStart : 117.02019238471985\n",
            "Training Loss : 217196.375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 236755\n",
            "TimeSinceStart : 119.70661354064941\n",
            "Training Loss : 220770.25\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 241755\n",
            "TimeSinceStart : 122.36585021018982\n",
            "Training Loss : 221064.90625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 246755\n",
            "TimeSinceStart : 125.21549248695374\n",
            "Training Loss : 217883.875\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 251755\n",
            "TimeSinceStart : 127.91545176506042\n",
            "Training Loss : 223241.09375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 256755\n",
            "TimeSinceStart : 130.58795022964478\n",
            "Training Loss : 225953.234375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 261755\n",
            "TimeSinceStart : 133.2521026134491\n",
            "Training Loss : 222023.984375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 266755\n",
            "TimeSinceStart : 135.90473079681396\n",
            "Training Loss : 230319.390625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 271755\n",
            "TimeSinceStart : 138.5548906326294\n",
            "Training Loss : 235510.5\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 276755\n",
            "TimeSinceStart : 141.30381059646606\n",
            "Training Loss : 236575.375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 281755\n",
            "TimeSinceStart : 143.96248364448547\n",
            "Training Loss : 244320.234375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 286755\n",
            "TimeSinceStart : 146.59333181381226\n",
            "Training Loss : 243441.0\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 193.1923065185547\n",
            "Train_StdReturn : 22.191509246826172\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 104.0\n",
            "Train_AverageEpLen : 193.19230769230768\n",
            "Train_EnvstepsSoFar : 291778\n",
            "TimeSinceStart : 149.20422291755676\n",
            "Training Loss : 243932.390625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 166.0\n",
            "Eval_StdReturn : 48.08325958251953\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 98.0\n",
            "Eval_AverageEpLen : 166.0\n",
            "Train_AverageReturn : 195.5\n",
            "Train_StdReturn : 16.411182403564453\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 123.0\n",
            "Train_AverageEpLen : 195.5\n",
            "Train_EnvstepsSoFar : 296861\n",
            "TimeSinceStart : 151.8787326812744\n",
            "Training Loss : 251632.984375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 169.6666717529297\n",
            "Eval_StdReturn : 38.05551528930664\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 116.0\n",
            "Eval_AverageEpLen : 169.66666666666666\n",
            "Train_AverageReturn : 191.59259033203125\n",
            "Train_StdReturn : 29.104225158691406\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 55.0\n",
            "Train_AverageEpLen : 191.59259259259258\n",
            "Train_EnvstepsSoFar : 302034\n",
            "TimeSinceStart : 154.59926795959473\n",
            "Training Loss : 260655.640625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 183.14285278320312\n",
            "Train_StdReturn : 41.732749938964844\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 57.0\n",
            "Train_AverageEpLen : 183.14285714285714\n",
            "Train_EnvstepsSoFar : 307162\n",
            "TimeSinceStart : 157.26519632339478\n",
            "Training Loss : 251194.0625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 197.0\n",
            "Eval_StdReturn : 4.242640495300293\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 191.0\n",
            "Eval_AverageEpLen : 197.0\n",
            "Train_AverageReturn : 173.48275756835938\n",
            "Train_StdReturn : 46.59408187866211\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 45.0\n",
            "Train_AverageEpLen : 173.48275862068965\n",
            "Train_EnvstepsSoFar : 312193\n",
            "TimeSinceStart : 159.8795883655548\n",
            "Training Loss : 245525.125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 170.8000030517578\n",
            "Train_StdReturn : 53.66402053833008\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 43.0\n",
            "Train_AverageEpLen : 170.8\n",
            "Train_EnvstepsSoFar : 317317\n",
            "TimeSinceStart : 162.57360577583313\n",
            "Training Loss : 250814.359375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 148.0\n",
            "Eval_StdReturn : 63.895748138427734\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 58.0\n",
            "Eval_AverageEpLen : 148.0\n",
            "Train_AverageReturn : 180.10714721679688\n",
            "Train_StdReturn : 37.786373138427734\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 58.0\n",
            "Train_AverageEpLen : 180.10714285714286\n",
            "Train_EnvstepsSoFar : 322360\n",
            "TimeSinceStart : 165.26203393936157\n",
            "Training Loss : 241953.765625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 175.3333282470703\n",
            "Eval_StdReturn : 34.88393783569336\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 126.0\n",
            "Eval_AverageEpLen : 175.33333333333334\n",
            "Train_AverageReturn : 194.03846740722656\n",
            "Train_StdReturn : 29.807689666748047\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 45.0\n",
            "Train_AverageEpLen : 194.03846153846155\n",
            "Train_EnvstepsSoFar : 327405\n",
            "TimeSinceStart : 167.94093918800354\n",
            "Training Loss : 254176.328125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 194.46153259277344\n",
            "Train_StdReturn : 27.692304611206055\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 56.0\n",
            "Train_AverageEpLen : 194.46153846153845\n",
            "Train_EnvstepsSoFar : 332461\n",
            "TimeSinceStart : 170.6011803150177\n",
            "Training Loss : 256403.609375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 337461\n",
            "TimeSinceStart : 173.22634935379028\n",
            "Training Loss : 253701.359375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 193.42308044433594\n",
            "Train_StdReturn : 21.426389694213867\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 119.0\n",
            "Train_AverageEpLen : 193.42307692307693\n",
            "Train_EnvstepsSoFar : 342490\n",
            "TimeSinceStart : 175.975435256958\n",
            "Training Loss : 250827.390625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 347490\n",
            "TimeSinceStart : 178.6072609424591\n",
            "Training Loss : 254653.328125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 352490\n",
            "TimeSinceStart : 181.23547434806824\n",
            "Training Loss : 253604.53125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 189.0370330810547\n",
            "Train_StdReturn : 39.61058807373047\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 22.0\n",
            "Train_AverageEpLen : 189.03703703703704\n",
            "Train_EnvstepsSoFar : 357594\n",
            "TimeSinceStart : 183.91606664657593\n",
            "Training Loss : 258827.875\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 115.0\n",
            "Eval_StdReturn : 82.86856842041016\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 16.0\n",
            "Eval_AverageEpLen : 115.0\n",
            "Train_AverageReturn : 194.38461303710938\n",
            "Train_StdReturn : 28.076923370361328\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 54.0\n",
            "Train_AverageEpLen : 194.3846153846154\n",
            "Train_EnvstepsSoFar : 362648\n",
            "TimeSinceStart : 186.6136772632599\n",
            "Training Loss : 253904.1875\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 186.62962341308594\n",
            "Train_StdReturn : 47.28099060058594\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 16.0\n",
            "Train_AverageEpLen : 186.62962962962962\n",
            "Train_EnvstepsSoFar : 367687\n",
            "TimeSinceStart : 189.25196647644043\n",
            "Training Loss : 255173.46875\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 192.88461303710938\n",
            "Train_StdReturn : 35.57692337036133\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 15.0\n",
            "Train_AverageEpLen : 192.8846153846154\n",
            "Train_EnvstepsSoFar : 372702\n",
            "TimeSinceStart : 191.908695936203\n",
            "Training Loss : 252192.3125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 186.22222900390625\n",
            "Train_StdReturn : 48.712562561035156\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 186.22222222222223\n",
            "Train_EnvstepsSoFar : 377730\n",
            "TimeSinceStart : 194.54413080215454\n",
            "Training Loss : 255541.328125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 192.84616088867188\n",
            "Train_StdReturn : 35.769229888916016\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 14.0\n",
            "Train_AverageEpLen : 192.84615384615384\n",
            "Train_EnvstepsSoFar : 382744\n",
            "TimeSinceStart : 197.2116026878357\n",
            "Training Loss : 251720.328125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 193.0\n",
            "Train_StdReturn : 35.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 18.0\n",
            "Train_AverageEpLen : 193.0\n",
            "Train_EnvstepsSoFar : 387762\n",
            "TimeSinceStart : 199.95939469337463\n",
            "Training Loss : 244224.640625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 392762\n",
            "TimeSinceStart : 202.7044038772583\n",
            "Training Loss : 244771.53125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 397762\n",
            "TimeSinceStart : 205.45508217811584\n",
            "Training Loss : 242875.234375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 402762\n",
            "TimeSinceStart : 208.15913820266724\n",
            "Training Loss : 243319.09375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 194.07691955566406\n",
            "Train_StdReturn : 29.615381240844727\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 46.0\n",
            "Train_AverageEpLen : 194.07692307692307\n",
            "Train_EnvstepsSoFar : 407808\n",
            "TimeSinceStart : 210.87269496917725\n",
            "Training Loss : 236211.890625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 186.25926208496094\n",
            "Train_StdReturn : 48.58257293701172\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 186.25925925925927\n",
            "Train_EnvstepsSoFar : 412837\n",
            "TimeSinceStart : 213.60920071601868\n",
            "Training Loss : 239726.25\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 417837\n",
            "TimeSinceStart : 216.26256585121155\n",
            "Training Loss : 231589.359375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 422837\n",
            "TimeSinceStart : 218.96125721931458\n",
            "Training Loss : 239152.1875\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 427837\n",
            "TimeSinceStart : 221.7590732574463\n",
            "Training Loss : 237229.78125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 432837\n",
            "TimeSinceStart : 224.53775000572205\n",
            "Training Loss : 239814.875\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 437837\n",
            "TimeSinceStart : 227.2204532623291\n",
            "Training Loss : 235506.109375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 442837\n",
            "TimeSinceStart : 229.90595817565918\n",
            "Training Loss : 231407.78125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 447837\n",
            "TimeSinceStart : 232.66661047935486\n",
            "Training Loss : 228597.75\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 452837\n",
            "TimeSinceStart : 235.343514919281\n",
            "Training Loss : 229176.75\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 457837\n",
            "TimeSinceStart : 238.0205054283142\n",
            "Training Loss : 221022.109375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 462837\n",
            "TimeSinceStart : 240.65745902061462\n",
            "Training Loss : 220517.953125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 467837\n",
            "TimeSinceStart : 243.26210355758667\n",
            "Training Loss : 213238.640625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 472837\n",
            "TimeSinceStart : 245.93126130104065\n",
            "Training Loss : 217554.875\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 477837\n",
            "TimeSinceStart : 248.5556139945984\n",
            "Training Loss : 215172.953125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 482837\n",
            "TimeSinceStart : 251.16801738739014\n",
            "Training Loss : 215508.03125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 487837\n",
            "TimeSinceStart : 253.77153301239014\n",
            "Training Loss : 222832.8125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 492837\n",
            "TimeSinceStart : 256.4033212661743\n",
            "Training Loss : 220188.125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 497837\n",
            "TimeSinceStart : 259.0275239944458\n",
            "Training Loss : 219706.3125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 502837\n",
            "TimeSinceStart : 261.65159726142883\n",
            "Training Loss : 221779.53125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q1_lb_rtg_na_CartPole-v0_09-05-2022_13-47-22\n",
            "########################\n",
            "GPU not detected. Defaulting to CPU.\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 32.846153259277344\n",
            "Eval_StdReturn : 14.675182342529297\n",
            "Eval_MaxReturn : 73.0\n",
            "Eval_MinReturn : 16.0\n",
            "Eval_AverageEpLen : 32.84615384615385\n",
            "Train_AverageReturn : 25.33668327331543\n",
            "Train_StdReturn : 15.415263175964355\n",
            "Train_MaxReturn : 118.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 25.33668341708543\n",
            "Train_EnvstepsSoFar : 5042\n",
            "TimeSinceStart : 1.80078125\n",
            "Training Loss : -17.361915588378906\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 36.33333206176758\n",
            "Eval_StdReturn : 26.195844650268555\n",
            "Eval_MaxReturn : 118.0\n",
            "Eval_MinReturn : 15.0\n",
            "Eval_AverageEpLen : 36.333333333333336\n",
            "Train_AverageReturn : 33.83783721923828\n",
            "Train_StdReturn : 18.024402618408203\n",
            "Train_MaxReturn : 108.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 33.83783783783784\n",
            "Train_EnvstepsSoFar : 10050\n",
            "TimeSinceStart : 3.640791893005371\n",
            "Training Loss : -32.25387954711914\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.57143020629883\n",
            "Eval_StdReturn : 21.790281295776367\n",
            "Eval_MaxReturn : 84.0\n",
            "Eval_MinReturn : 18.0\n",
            "Eval_AverageEpLen : 59.57142857142857\n",
            "Train_AverageReturn : 41.057376861572266\n",
            "Train_StdReturn : 22.421558380126953\n",
            "Train_MaxReturn : 135.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 41.057377049180324\n",
            "Train_EnvstepsSoFar : 15059\n",
            "TimeSinceStart : 5.538935422897339\n",
            "Training Loss : -44.972320556640625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 63.57143020629883\n",
            "Eval_StdReturn : 21.62575912475586\n",
            "Eval_MaxReturn : 89.0\n",
            "Eval_MinReturn : 31.0\n",
            "Eval_AverageEpLen : 63.57142857142857\n",
            "Train_AverageReturn : 50.5\n",
            "Train_StdReturn : 29.640344619750977\n",
            "Train_MaxReturn : 156.0\n",
            "Train_MinReturn : 16.0\n",
            "Train_AverageEpLen : 50.5\n",
            "Train_EnvstepsSoFar : 20109\n",
            "TimeSinceStart : 7.568555593490601\n",
            "Training Loss : -37.0191764831543\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 70.83333587646484\n",
            "Eval_StdReturn : 45.09033966064453\n",
            "Eval_MaxReturn : 138.0\n",
            "Eval_MinReturn : 37.0\n",
            "Eval_AverageEpLen : 70.83333333333333\n",
            "Train_AverageReturn : 59.83333206176758\n",
            "Train_StdReturn : 25.841012954711914\n",
            "Train_MaxReturn : 163.0\n",
            "Train_MinReturn : 22.0\n",
            "Train_AverageEpLen : 59.833333333333336\n",
            "Train_EnvstepsSoFar : 25135\n",
            "TimeSinceStart : 9.541006803512573\n",
            "Training Loss : -29.045339584350586\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 111.5999984741211\n",
            "Eval_StdReturn : 44.66139221191406\n",
            "Eval_MaxReturn : 182.0\n",
            "Eval_MinReturn : 42.0\n",
            "Eval_AverageEpLen : 111.6\n",
            "Train_AverageReturn : 69.39726257324219\n",
            "Train_StdReturn : 30.357568740844727\n",
            "Train_MaxReturn : 163.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 69.3972602739726\n",
            "Train_EnvstepsSoFar : 30201\n",
            "TimeSinceStart : 11.622389078140259\n",
            "Training Loss : -27.213886260986328\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 79.0\n",
            "Eval_StdReturn : 14.651507377624512\n",
            "Eval_MaxReturn : 103.0\n",
            "Eval_MinReturn : 59.0\n",
            "Eval_AverageEpLen : 79.0\n",
            "Train_AverageReturn : 85.76271057128906\n",
            "Train_StdReturn : 36.58440017700195\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 35.0\n",
            "Train_AverageEpLen : 85.76271186440678\n",
            "Train_EnvstepsSoFar : 35261\n",
            "TimeSinceStart : 13.795275926589966\n",
            "Training Loss : -28.052461624145508\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 118.5\n",
            "Eval_StdReturn : 35.23137664794922\n",
            "Eval_MaxReturn : 157.0\n",
            "Eval_MinReturn : 79.0\n",
            "Eval_AverageEpLen : 118.5\n",
            "Train_AverageReturn : 99.78431701660156\n",
            "Train_StdReturn : 40.007015228271484\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 35.0\n",
            "Train_AverageEpLen : 99.7843137254902\n",
            "Train_EnvstepsSoFar : 40350\n",
            "TimeSinceStart : 16.055973052978516\n",
            "Training Loss : -37.807193756103516\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 161.0\n",
            "Eval_StdReturn : 31.843366622924805\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 122.0\n",
            "Eval_AverageEpLen : 161.0\n",
            "Train_AverageReturn : 131.86842346191406\n",
            "Train_StdReturn : 45.837913513183594\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 43.0\n",
            "Train_AverageEpLen : 131.8684210526316\n",
            "Train_EnvstepsSoFar : 45361\n",
            "TimeSinceStart : 18.47750997543335\n",
            "Training Loss : -4.72127103805542\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 159.0\n",
            "Eval_StdReturn : 40.422767639160156\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 104.0\n",
            "Eval_AverageEpLen : 159.0\n",
            "Train_AverageReturn : 155.18182373046875\n",
            "Train_StdReturn : 39.72515869140625\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 45.0\n",
            "Train_AverageEpLen : 155.1818181818182\n",
            "Train_EnvstepsSoFar : 50482\n",
            "TimeSinceStart : 21.08691930770874\n",
            "Training Loss : -78.14473724365234\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 148.0\n",
            "Eval_StdReturn : 40.922691345214844\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 100.0\n",
            "Eval_AverageEpLen : 148.0\n",
            "Train_AverageReturn : 163.48387145996094\n",
            "Train_StdReturn : 32.74620819091797\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 56.0\n",
            "Train_AverageEpLen : 163.48387096774192\n",
            "Train_EnvstepsSoFar : 55550\n",
            "TimeSinceStart : 23.660486698150635\n",
            "Training Loss : -61.693756103515625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 154.0\n",
            "Eval_StdReturn : 35.05234146118164\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 115.0\n",
            "Eval_AverageEpLen : 154.0\n",
            "Train_AverageReturn : 167.89999389648438\n",
            "Train_StdReturn : 33.415916442871094\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 102.0\n",
            "Train_AverageEpLen : 167.9\n",
            "Train_EnvstepsSoFar : 60587\n",
            "TimeSinceStart : 26.274250507354736\n",
            "Training Loss : -14.94861125946045\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 159.3333282470703\n",
            "Eval_StdReturn : 42.34252166748047\n",
            "Eval_MaxReturn : 196.0\n",
            "Eval_MinReturn : 100.0\n",
            "Eval_AverageEpLen : 159.33333333333334\n",
            "Train_AverageReturn : 165.2903289794922\n",
            "Train_StdReturn : 34.539546966552734\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 109.0\n",
            "Train_AverageEpLen : 165.29032258064515\n",
            "Train_EnvstepsSoFar : 65711\n",
            "TimeSinceStart : 28.913947343826294\n",
            "Training Loss : -48.1048583984375\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 160.6666717529297\n",
            "Eval_StdReturn : 28.76726531982422\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 132.0\n",
            "Eval_AverageEpLen : 160.66666666666666\n",
            "Train_AverageReturn : 161.61289978027344\n",
            "Train_StdReturn : 37.5264892578125\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 75.0\n",
            "Train_AverageEpLen : 161.61290322580646\n",
            "Train_EnvstepsSoFar : 70721\n",
            "TimeSinceStart : 31.52853298187256\n",
            "Training Loss : -32.803489685058594\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 186.07408142089844\n",
            "Train_StdReturn : 25.476097106933594\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 96.0\n",
            "Train_AverageEpLen : 186.07407407407408\n",
            "Train_EnvstepsSoFar : 75745\n",
            "TimeSinceStart : 34.2257182598114\n",
            "Training Loss : -33.996437072753906\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 184.25\n",
            "Train_StdReturn : 27.943342208862305\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 106.0\n",
            "Train_AverageEpLen : 184.25\n",
            "Train_EnvstepsSoFar : 80904\n",
            "TimeSinceStart : 36.96985673904419\n",
            "Training Loss : -0.8779029846191406\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 191.8148193359375\n",
            "Train_StdReturn : 15.260787010192871\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 140.0\n",
            "Train_AverageEpLen : 191.8148148148148\n",
            "Train_EnvstepsSoFar : 86083\n",
            "TimeSinceStart : 39.86043882369995\n",
            "Training Loss : -12.751079559326172\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 191.25926208496094\n",
            "Train_StdReturn : 25.041582107543945\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 93.0\n",
            "Train_AverageEpLen : 191.25925925925927\n",
            "Train_EnvstepsSoFar : 91247\n",
            "TimeSinceStart : 42.667006969451904\n",
            "Training Loss : -3.9812889099121094\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.3076934814453\n",
            "Train_StdReturn : 2.770299196243286\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 186.0\n",
            "Train_AverageEpLen : 199.30769230769232\n",
            "Train_EnvstepsSoFar : 96429\n",
            "TimeSinceStart : 45.49709367752075\n",
            "Training Loss : -12.363521575927734\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 198.73077392578125\n",
            "Train_StdReturn : 6.34615421295166\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 167.0\n",
            "Train_AverageEpLen : 198.73076923076923\n",
            "Train_EnvstepsSoFar : 101596\n",
            "TimeSinceStart : 48.281206369400024\n",
            "Training Loss : -63.69105911254883\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 106596\n",
            "TimeSinceStart : 51.0102105140686\n",
            "Training Loss : 15.25762939453125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 111596\n",
            "TimeSinceStart : 53.7222797870636\n",
            "Training Loss : -42.20166015625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 116596\n",
            "TimeSinceStart : 56.50523257255554\n",
            "Training Loss : -46.39767074584961\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 121596\n",
            "TimeSinceStart : 59.224793434143066\n",
            "Training Loss : -65.63179779052734\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 126596\n",
            "TimeSinceStart : 61.95413947105408\n",
            "Training Loss : -88.57928466796875\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 131596\n",
            "TimeSinceStart : 64.78690934181213\n",
            "Training Loss : -96.09598541259766\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 136596\n",
            "TimeSinceStart : 67.71735405921936\n",
            "Training Loss : -58.69213104248047\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 141596\n",
            "TimeSinceStart : 70.57777953147888\n",
            "Training Loss : -102.01912689208984\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 146596\n",
            "TimeSinceStart : 73.44807767868042\n",
            "Training Loss : -81.02608489990234\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 171.0\n",
            "Eval_StdReturn : 28.083209991455078\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 133.0\n",
            "Eval_AverageEpLen : 171.0\n",
            "Train_AverageReturn : 194.53846740722656\n",
            "Train_StdReturn : 13.898618698120117\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 134.0\n",
            "Train_AverageEpLen : 194.53846153846155\n",
            "Train_EnvstepsSoFar : 151654\n",
            "TimeSinceStart : 76.33556461334229\n",
            "Training Loss : -172.1358642578125\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 176.0\n",
            "Eval_StdReturn : 12.328827857971191\n",
            "Eval_MaxReturn : 190.0\n",
            "Eval_MinReturn : 160.0\n",
            "Eval_AverageEpLen : 176.0\n",
            "Train_AverageReturn : 183.07142639160156\n",
            "Train_StdReturn : 17.842422485351562\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 134.0\n",
            "Train_AverageEpLen : 183.07142857142858\n",
            "Train_EnvstepsSoFar : 156780\n",
            "TimeSinceStart : 79.19557023048401\n",
            "Training Loss : -139.2299041748047\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 166.0\n",
            "Eval_StdReturn : 27.53179931640625\n",
            "Eval_MaxReturn : 195.0\n",
            "Eval_MinReturn : 129.0\n",
            "Eval_AverageEpLen : 166.0\n",
            "Train_AverageReturn : 165.51612854003906\n",
            "Train_StdReturn : 18.711511611938477\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 130.0\n",
            "Train_AverageEpLen : 165.51612903225808\n",
            "Train_EnvstepsSoFar : 161911\n",
            "TimeSinceStart : 81.89671969413757\n",
            "Training Loss : -147.93643188476562\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 187.6666717529297\n",
            "Eval_StdReturn : 10.873004913330078\n",
            "Eval_MaxReturn : 199.0\n",
            "Eval_MinReturn : 173.0\n",
            "Eval_AverageEpLen : 187.66666666666666\n",
            "Train_AverageReturn : 169.26666259765625\n",
            "Train_StdReturn : 18.27189826965332\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 129.0\n",
            "Train_AverageEpLen : 169.26666666666668\n",
            "Train_EnvstepsSoFar : 166989\n",
            "TimeSinceStart : 84.5605616569519\n",
            "Training Loss : -180.5328826904297\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 187.3333282470703\n",
            "Eval_StdReturn : 11.556624412536621\n",
            "Eval_MaxReturn : 196.0\n",
            "Eval_MinReturn : 171.0\n",
            "Eval_AverageEpLen : 187.33333333333334\n",
            "Train_AverageReturn : 184.7142791748047\n",
            "Train_StdReturn : 11.529023170471191\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 160.0\n",
            "Train_AverageEpLen : 184.71428571428572\n",
            "Train_EnvstepsSoFar : 172161\n",
            "TimeSinceStart : 87.35285544395447\n",
            "Training Loss : -155.0044403076172\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 191.51852416992188\n",
            "Train_StdReturn : 8.234392166137695\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 172.0\n",
            "Train_AverageEpLen : 191.5185185185185\n",
            "Train_EnvstepsSoFar : 177332\n",
            "TimeSinceStart : 90.12919211387634\n",
            "Training Loss : -165.7401123046875\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 198.03846740722656\n",
            "Train_StdReturn : 4.4848527908325195\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 181.0\n",
            "Train_AverageEpLen : 198.03846153846155\n",
            "Train_EnvstepsSoFar : 182481\n",
            "TimeSinceStart : 92.94102072715759\n",
            "Training Loss : -147.24000549316406\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 187481\n",
            "TimeSinceStart : 95.6484272480011\n",
            "Training Loss : -75.75298309326172\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 192481\n",
            "TimeSinceStart : 98.37394952774048\n",
            "Training Loss : -72.20172119140625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 197481\n",
            "TimeSinceStart : 101.15876054763794\n",
            "Training Loss : -81.36429595947266\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 202481\n",
            "TimeSinceStart : 103.87006258964539\n",
            "Training Loss : -25.992958068847656\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 207481\n",
            "TimeSinceStart : 106.60063147544861\n",
            "Training Loss : -79.06399536132812\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 212481\n",
            "TimeSinceStart : 109.309166431427\n",
            "Training Loss : 5.491153717041016\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 217481\n",
            "TimeSinceStart : 112.00181150436401\n",
            "Training Loss : 35.45500946044922\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 222481\n",
            "TimeSinceStart : 114.79362106323242\n",
            "Training Loss : -20.470584869384766\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 227481\n",
            "TimeSinceStart : 117.56964683532715\n",
            "Training Loss : 4.227691650390625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 232481\n",
            "TimeSinceStart : 120.3701913356781\n",
            "Training Loss : 16.70370101928711\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 237481\n",
            "TimeSinceStart : 123.22543978691101\n",
            "Training Loss : -18.36273956298828\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 242481\n",
            "TimeSinceStart : 125.95394587516785\n",
            "Training Loss : -22.12793731689453\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 247481\n",
            "TimeSinceStart : 128.67661452293396\n",
            "Training Loss : 70.96339416503906\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 252481\n",
            "TimeSinceStart : 131.39510369300842\n",
            "Training Loss : -29.15847396850586\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 194.34616088867188\n",
            "Train_StdReturn : 15.808815002441406\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 142.0\n",
            "Train_AverageEpLen : 194.34615384615384\n",
            "Train_EnvstepsSoFar : 257534\n",
            "TimeSinceStart : 134.11175084114075\n",
            "Training Loss : 11.5816011428833\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 183.0\n",
            "Eval_StdReturn : 24.041629791259766\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 149.0\n",
            "Eval_AverageEpLen : 183.0\n",
            "Train_AverageReturn : 192.37037658691406\n",
            "Train_StdReturn : 23.493337631225586\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 92.0\n",
            "Train_AverageEpLen : 192.37037037037038\n",
            "Train_EnvstepsSoFar : 262728\n",
            "TimeSinceStart : 137.04613542556763\n",
            "Training Loss : -27.45386505126953\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 186.1481475830078\n",
            "Train_StdReturn : 31.36960220336914\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 88.0\n",
            "Train_AverageEpLen : 186.14814814814815\n",
            "Train_EnvstepsSoFar : 267754\n",
            "TimeSinceStart : 139.74423551559448\n",
            "Training Loss : -42.93058395385742\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 188.37037658691406\n",
            "Train_StdReturn : 27.190885543823242\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 85.0\n",
            "Train_AverageEpLen : 188.37037037037038\n",
            "Train_EnvstepsSoFar : 272840\n",
            "TimeSinceStart : 142.4592719078064\n",
            "Training Loss : -23.469173431396484\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 181.9642791748047\n",
            "Train_StdReturn : 32.005001068115234\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 85.0\n",
            "Train_AverageEpLen : 181.96428571428572\n",
            "Train_EnvstepsSoFar : 277935\n",
            "TimeSinceStart : 145.15255403518677\n",
            "Training Loss : -54.37497329711914\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 198.6923065185547\n",
            "Train_StdReturn : 6.538461685180664\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 166.0\n",
            "Train_AverageEpLen : 198.69230769230768\n",
            "Train_EnvstepsSoFar : 283101\n",
            "TimeSinceStart : 147.95657873153687\n",
            "Training Loss : 49.64930725097656\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 195.5\n",
            "Train_StdReturn : 15.046721458435059\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 141.0\n",
            "Train_AverageEpLen : 195.5\n",
            "Train_EnvstepsSoFar : 288184\n",
            "TimeSinceStart : 150.71083283424377\n",
            "Training Loss : -8.869650840759277\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 192.84616088867188\n",
            "Train_StdReturn : 18.701486587524414\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 137.0\n",
            "Train_AverageEpLen : 192.84615384615384\n",
            "Train_EnvstepsSoFar : 293198\n",
            "TimeSinceStart : 153.4165825843811\n",
            "Training Loss : -32.563148498535156\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 193.0\n",
            "Train_StdReturn : 16.354251861572266\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 140.0\n",
            "Train_AverageEpLen : 193.0\n",
            "Train_EnvstepsSoFar : 298216\n",
            "TimeSinceStart : 156.0830159187317\n",
            "Training Loss : 4.229192733764648\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 199.6666717529297\n",
            "Eval_StdReturn : 0.471404492855072\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 199.0\n",
            "Eval_AverageEpLen : 199.66666666666666\n",
            "Train_AverageReturn : 197.11538696289062\n",
            "Train_StdReturn : 9.386270523071289\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 155.0\n",
            "Train_AverageEpLen : 197.1153846153846\n",
            "Train_EnvstepsSoFar : 303341\n",
            "TimeSinceStart : 158.93373942375183\n",
            "Training Loss : 39.75648880004883\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 194.84616088867188\n",
            "Train_StdReturn : 13.580789566040039\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 154.0\n",
            "Train_AverageEpLen : 194.84615384615384\n",
            "Train_EnvstepsSoFar : 308407\n",
            "TimeSinceStart : 161.7774839401245\n",
            "Training Loss : 2.418306350708008\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 196.84616088867188\n",
            "Train_StdReturn : 11.343219757080078\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 148.0\n",
            "Train_AverageEpLen : 196.84615384615384\n",
            "Train_EnvstepsSoFar : 313525\n",
            "TimeSinceStart : 164.60787391662598\n",
            "Training Loss : -15.841378211975098\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.76922607421875\n",
            "Train_StdReturn : 1.1538461446762085\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 194.0\n",
            "Train_AverageEpLen : 199.76923076923077\n",
            "Train_EnvstepsSoFar : 318719\n",
            "TimeSinceStart : 167.54279327392578\n",
            "Training Loss : -42.19755935668945\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.92308044433594\n",
            "Train_StdReturn : 0.38461536169052124\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 198.0\n",
            "Train_AverageEpLen : 199.92307692307693\n",
            "Train_EnvstepsSoFar : 323917\n",
            "TimeSinceStart : 170.3719401359558\n",
            "Training Loss : -13.64614486694336\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 199.0\n",
            "Eval_StdReturn : 1.4142135381698608\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 197.0\n",
            "Eval_AverageEpLen : 199.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 328917\n",
            "TimeSinceStart : 173.25596976280212\n",
            "Training Loss : -74.16714477539062\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 333917\n",
            "TimeSinceStart : 175.99431991577148\n",
            "Training Loss : -10.448175430297852\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 196.53846740722656\n",
            "Train_StdReturn : 12.248172760009766\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 146.0\n",
            "Train_AverageEpLen : 196.53846153846155\n",
            "Train_EnvstepsSoFar : 339027\n",
            "TimeSinceStart : 178.8941671848297\n",
            "Training Loss : -26.31203269958496\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 344027\n",
            "TimeSinceStart : 181.62669944763184\n",
            "Training Loss : 17.484703063964844\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 349027\n",
            "TimeSinceStart : 184.36423254013062\n",
            "Training Loss : -48.432857513427734\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 354027\n",
            "TimeSinceStart : 187.08506178855896\n",
            "Training Loss : 13.801280975341797\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 198.0\n",
            "Train_StdReturn : 10.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 148.0\n",
            "Train_AverageEpLen : 198.0\n",
            "Train_EnvstepsSoFar : 359175\n",
            "TimeSinceStart : 189.9924144744873\n",
            "Training Loss : -14.213982582092285\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 364175\n",
            "TimeSinceStart : 192.78957772254944\n",
            "Training Loss : -4.253130912780762\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 369175\n",
            "TimeSinceStart : 195.66764545440674\n",
            "Training Loss : -6.605432510375977\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.46153259277344\n",
            "Train_StdReturn : 2.692307710647583\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 186.0\n",
            "Train_AverageEpLen : 199.46153846153845\n",
            "Train_EnvstepsSoFar : 374361\n",
            "TimeSinceStart : 198.54557299613953\n",
            "Training Loss : 35.52301025390625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 379361\n",
            "TimeSinceStart : 201.30713844299316\n",
            "Training Loss : 6.821107864379883\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 384361\n",
            "TimeSinceStart : 204.04607892036438\n",
            "Training Loss : -31.352664947509766\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 198.92308044433594\n",
            "Train_StdReturn : 5.384614944458008\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 172.0\n",
            "Train_AverageEpLen : 198.92307692307693\n",
            "Train_EnvstepsSoFar : 389533\n",
            "TimeSinceStart : 206.87940168380737\n",
            "Training Loss : 15.154705047607422\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 394533\n",
            "TimeSinceStart : 209.6067249774933\n",
            "Training Loss : 41.93876647949219\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 399533\n",
            "TimeSinceStart : 212.35697984695435\n",
            "Training Loss : 6.156009674072266\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 198.84616088867188\n",
            "Train_StdReturn : 5.769230842590332\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 170.0\n",
            "Train_AverageEpLen : 198.84615384615384\n",
            "Train_EnvstepsSoFar : 404703\n",
            "TimeSinceStart : 215.14170145988464\n",
            "Training Loss : -32.05262756347656\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.6923065185547\n",
            "Train_StdReturn : 1.538461685180664\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 192.0\n",
            "Train_AverageEpLen : 199.69230769230768\n",
            "Train_EnvstepsSoFar : 409895\n",
            "TimeSinceStart : 218.01843976974487\n",
            "Training Loss : 1.80670166015625\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.26922607421875\n",
            "Train_StdReturn : 3.653846025466919\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 181.0\n",
            "Train_AverageEpLen : 199.26923076923077\n",
            "Train_EnvstepsSoFar : 415076\n",
            "TimeSinceStart : 220.89997696876526\n",
            "Training Loss : 50.90283966064453\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 420076\n",
            "TimeSinceStart : 223.64192008972168\n",
            "Training Loss : -8.040852546691895\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 186.0\n",
            "Eval_StdReturn : 19.79899024963379\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 158.0\n",
            "Eval_AverageEpLen : 186.0\n",
            "Train_AverageReturn : 196.61538696289062\n",
            "Train_StdReturn : 16.923076629638672\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 112.0\n",
            "Train_AverageEpLen : 196.6153846153846\n",
            "Train_EnvstepsSoFar : 425188\n",
            "TimeSinceStart : 226.45356345176697\n",
            "Training Loss : 43.778202056884766\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 430188\n",
            "TimeSinceStart : 229.19125509262085\n",
            "Training Loss : 25.31049346923828\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 179.6666717529297\n",
            "Eval_StdReturn : 28.75567626953125\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 139.0\n",
            "Eval_AverageEpLen : 179.66666666666666\n",
            "Train_AverageReturn : 196.65383911132812\n",
            "Train_StdReturn : 16.730770111083984\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 113.0\n",
            "Train_AverageEpLen : 196.65384615384616\n",
            "Train_EnvstepsSoFar : 435301\n",
            "TimeSinceStart : 232.06812620162964\n",
            "Training Loss : -19.996854782104492\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 196.96153259277344\n",
            "Train_StdReturn : 15.19230842590332\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 121.0\n",
            "Train_AverageEpLen : 196.96153846153845\n",
            "Train_EnvstepsSoFar : 440422\n",
            "TimeSinceStart : 234.9624044895172\n",
            "Training Loss : -49.46392059326172\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.8076934814453\n",
            "Train_StdReturn : 0.9615384340286255\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 195.0\n",
            "Train_AverageEpLen : 199.80769230769232\n",
            "Train_EnvstepsSoFar : 445617\n",
            "TimeSinceStart : 237.89339756965637\n",
            "Training Loss : 15.441299438476562\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 450617\n",
            "TimeSinceStart : 240.61730575561523\n",
            "Training Loss : 22.229909896850586\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 196.65383911132812\n",
            "Train_StdReturn : 11.330496788024902\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 147.0\n",
            "Train_AverageEpLen : 196.65384615384616\n",
            "Train_EnvstepsSoFar : 455730\n",
            "TimeSinceStart : 243.45958256721497\n",
            "Training Loss : -13.123327255249023\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 196.07691955566406\n",
            "Train_StdReturn : 13.03522777557373\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 136.0\n",
            "Train_AverageEpLen : 196.07692307692307\n",
            "Train_EnvstepsSoFar : 460828\n",
            "TimeSinceStart : 246.2632758617401\n",
            "Training Loss : 15.004852294921875\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.38461303710938\n",
            "Train_StdReturn : 3.076923370361328\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 184.0\n",
            "Train_AverageEpLen : 199.3846153846154\n",
            "Train_EnvstepsSoFar : 466012\n",
            "TimeSinceStart : 249.13613486289978\n",
            "Training Loss : 23.789569854736328\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 198.65383911132812\n",
            "Train_StdReturn : 6.730769634246826\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 165.0\n",
            "Train_AverageEpLen : 198.65384615384616\n",
            "Train_EnvstepsSoFar : 471177\n",
            "TimeSinceStart : 251.99206829071045\n",
            "Training Loss : 19.805604934692383\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.88461303710938\n",
            "Train_StdReturn : 0.5769230723381042\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 197.0\n",
            "Train_AverageEpLen : 199.8846153846154\n",
            "Train_EnvstepsSoFar : 476374\n",
            "TimeSinceStart : 254.9582359790802\n",
            "Training Loss : 60.24607849121094\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.76922607421875\n",
            "Train_StdReturn : 1.1538461446762085\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 194.0\n",
            "Train_AverageEpLen : 199.76923076923077\n",
            "Train_EnvstepsSoFar : 481568\n",
            "TimeSinceStart : 257.99281644821167\n",
            "Training Loss : -13.674249649047852\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 486568\n",
            "TimeSinceStart : 260.8903524875641\n",
            "Training Loss : 39.26082992553711\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 491568\n",
            "TimeSinceStart : 263.7688581943512\n",
            "Training Loss : -48.721473693847656\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 196.88461303710938\n",
            "Train_StdReturn : 15.576923370361328\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 119.0\n",
            "Train_AverageEpLen : 196.8846153846154\n",
            "Train_EnvstepsSoFar : 496687\n",
            "TimeSinceStart : 266.70240902900696\n",
            "Training Loss : 47.18126678466797\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.15383911132812\n",
            "Train_StdReturn : 4.230769634246826\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 178.0\n",
            "Train_AverageEpLen : 199.15384615384616\n",
            "Train_EnvstepsSoFar : 501865\n",
            "TimeSinceStart : 269.62657833099365\n",
            "Training Loss : -5.072759628295898\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 506865\n",
            "TimeSinceStart : 272.4898781776428\n",
            "Training Loss : 46.21497344970703\n",
            "Initial_DataCollection_AverageReturn : 25.33668327331543\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name CartPole-v0 -n 100 -b 1000 \\\n",
        "    -dsa --exp_name q1_sb_no_rtg_dsa\n",
        "\n",
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name CartPole-v0 -n 100 -b 1000 \\\n",
        "    -rtg -dsa --exp_name q1_sb_rtg_dsa\n",
        "\n",
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name CartPole-v0 -n 100 -b 1000 \\\n",
        "    -rtg --exp_name q1_sb_rtg_na\n",
        "\n",
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name CartPole-v0 -n 100 -b 5000 \\\n",
        "    -dsa --exp_name q1_lb_no_rtg_dsa\n",
        "\n",
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name CartPole-v0 -n 100 -b 5000 \\\n",
        "    -rtg -dsa --exp_name q1_lb_rtg_dsa\n",
        "\n",
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name CartPole-v0 -n 100 -b 5000 \\\n",
        "    -rtg --exp_name q1_lb_rtg_na"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWHYEZqyP9sr"
      },
      "source": [
        "#InvertedPendulum"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot('/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q2_b800_r0.02_InvertedPendulum-v2_09-05-2022_13-31-53/events.out.tfevents.1652103113.1f515a41fb55', \n",
        "     '/content/cds_rl_2022/rl_hw/hw2/figure/q2_b800_l0.02.png')"
      ],
      "metadata": {
        "id": "SfnZQMlFd4qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-ldvCbcP8f-",
        "outputId": "dff1f708-e38b-4e2f-970a-44c561f775cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q2_b800_r0.02_InvertedPendulum-v2_09-05-2022_13-31-53\n",
            "########################\n",
            "GPU not detected. Defaulting to CPU.\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.931034564971924\n",
            "Eval_StdReturn : 2.5384089946746826\n",
            "Eval_MaxReturn : 15.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 6.931034482758621\n",
            "Train_AverageReturn : 9.218390464782715\n",
            "Train_StdReturn : 5.138149738311768\n",
            "Train_MaxReturn : 28.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 9.218390804597702\n",
            "Train_EnvstepsSoFar : 802\n",
            "TimeSinceStart : 0.7249488830566406\n",
            "Training Loss : -29.24660301208496\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.4375\n",
            "Eval_StdReturn : 16.019397735595703\n",
            "Eval_MaxReturn : 83.0\n",
            "Eval_MinReturn : 12.0\n",
            "Eval_AverageEpLen : 25.4375\n",
            "Train_AverageReturn : 7.584905624389648\n",
            "Train_StdReturn : 2.576629161834717\n",
            "Train_MaxReturn : 20.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 7.584905660377358\n",
            "Train_EnvstepsSoFar : 1606\n",
            "TimeSinceStart : 1.4303855895996094\n",
            "Training Loss : 15.212735176086426\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 21.157894134521484\n",
            "Eval_StdReturn : 11.108381271362305\n",
            "Eval_MaxReturn : 56.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 21.157894736842106\n",
            "Train_AverageReturn : 24.41176414489746\n",
            "Train_StdReturn : 13.51495361328125\n",
            "Train_MaxReturn : 70.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 24.41176470588235\n",
            "Train_EnvstepsSoFar : 2436\n",
            "TimeSinceStart : 2.137995481491089\n",
            "Training Loss : -27.835899353027344\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 15.714285850524902\n",
            "Eval_StdReturn : 7.846096038818359\n",
            "Eval_MaxReturn : 42.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 15.714285714285714\n",
            "Train_AverageReturn : 17.69565200805664\n",
            "Train_StdReturn : 5.747852325439453\n",
            "Train_MaxReturn : 33.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 17.695652173913043\n",
            "Train_EnvstepsSoFar : 3250\n",
            "TimeSinceStart : 2.8604183197021484\n",
            "Training Loss : -37.21684646606445\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 20.049999237060547\n",
            "Eval_StdReturn : 11.213719367980957\n",
            "Eval_MaxReturn : 61.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 20.05\n",
            "Train_AverageReturn : 15.615385055541992\n",
            "Train_StdReturn : 9.870612144470215\n",
            "Train_MaxReturn : 70.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 15.615384615384615\n",
            "Train_EnvstepsSoFar : 4062\n",
            "TimeSinceStart : 3.5668933391571045\n",
            "Training Loss : 1.7478961944580078\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.64285659790039\n",
            "Eval_StdReturn : 16.263925552368164\n",
            "Eval_MaxReturn : 59.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 31.642857142857142\n",
            "Train_AverageReturn : 21.894737243652344\n",
            "Train_StdReturn : 10.510119438171387\n",
            "Train_MaxReturn : 45.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 21.894736842105264\n",
            "Train_EnvstepsSoFar : 4894\n",
            "TimeSinceStart : 4.303949594497681\n",
            "Training Loss : 5.844484329223633\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 45.77777862548828\n",
            "Eval_StdReturn : 21.81629180908203\n",
            "Eval_MaxReturn : 78.0\n",
            "Eval_MinReturn : 20.0\n",
            "Eval_AverageEpLen : 45.77777777777778\n",
            "Train_AverageReturn : 38.04545593261719\n",
            "Train_StdReturn : 20.733104705810547\n",
            "Train_MaxReturn : 111.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 38.04545454545455\n",
            "Train_EnvstepsSoFar : 5731\n",
            "TimeSinceStart : 5.048065662384033\n",
            "Training Loss : -44.47869110107422\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 34.0\n",
            "Eval_StdReturn : 15.79556941986084\n",
            "Eval_MaxReturn : 63.0\n",
            "Eval_MinReturn : 18.0\n",
            "Eval_AverageEpLen : 34.0\n",
            "Train_AverageReturn : 39.0\n",
            "Train_StdReturn : 22.640039443969727\n",
            "Train_MaxReturn : 99.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 39.0\n",
            "Train_EnvstepsSoFar : 6550\n",
            "TimeSinceStart : 5.805680513381958\n",
            "Training Loss : -43.34375762939453\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.923076629638672\n",
            "Eval_StdReturn : 22.832033157348633\n",
            "Eval_MaxReturn : 101.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 31.923076923076923\n",
            "Train_AverageReturn : 47.117645263671875\n",
            "Train_StdReturn : 32.17942810058594\n",
            "Train_MaxReturn : 148.0\n",
            "Train_MinReturn : 7.0\n",
            "Train_AverageEpLen : 47.11764705882353\n",
            "Train_EnvstepsSoFar : 7351\n",
            "TimeSinceStart : 6.538333415985107\n",
            "Training Loss : -37.00041961669922\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 45.66666793823242\n",
            "Eval_StdReturn : 12.995725631713867\n",
            "Eval_MaxReturn : 61.0\n",
            "Eval_MinReturn : 16.0\n",
            "Eval_AverageEpLen : 45.666666666666664\n",
            "Train_AverageReturn : 36.59090805053711\n",
            "Train_StdReturn : 18.04705810546875\n",
            "Train_MaxReturn : 68.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 36.59090909090909\n",
            "Train_EnvstepsSoFar : 8156\n",
            "TimeSinceStart : 7.266486406326294\n",
            "Training Loss : -24.167497634887695\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 38.54545593261719\n",
            "Eval_StdReturn : 24.156171798706055\n",
            "Eval_MaxReturn : 77.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 38.54545454545455\n",
            "Train_AverageReturn : 48.70588302612305\n",
            "Train_StdReturn : 24.104585647583008\n",
            "Train_MaxReturn : 113.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 48.705882352941174\n",
            "Train_EnvstepsSoFar : 8984\n",
            "TimeSinceStart : 8.06710696220398\n",
            "Training Loss : -53.94867706298828\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 48.11111068725586\n",
            "Eval_StdReturn : 29.19072914123535\n",
            "Eval_MaxReturn : 92.0\n",
            "Eval_MinReturn : 14.0\n",
            "Eval_AverageEpLen : 48.111111111111114\n",
            "Train_AverageReturn : 42.47368240356445\n",
            "Train_StdReturn : 24.7181339263916\n",
            "Train_MaxReturn : 91.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 42.473684210526315\n",
            "Train_EnvstepsSoFar : 9791\n",
            "TimeSinceStart : 8.789685487747192\n",
            "Training Loss : -75.30410766601562\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 53.11111068725586\n",
            "Eval_StdReturn : 24.794462203979492\n",
            "Eval_MaxReturn : 93.0\n",
            "Eval_MinReturn : 14.0\n",
            "Eval_AverageEpLen : 53.111111111111114\n",
            "Train_AverageReturn : 58.5\n",
            "Train_StdReturn : 24.13577651977539\n",
            "Train_MaxReturn : 111.0\n",
            "Train_MinReturn : 7.0\n",
            "Train_AverageEpLen : 58.5\n",
            "Train_EnvstepsSoFar : 10610\n",
            "TimeSinceStart : 9.54187798500061\n",
            "Training Loss : -26.144161224365234\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 55.625\n",
            "Eval_StdReturn : 33.548240661621094\n",
            "Eval_MaxReturn : 139.0\n",
            "Eval_MinReturn : 26.0\n",
            "Eval_AverageEpLen : 55.625\n",
            "Train_AverageReturn : 69.75\n",
            "Train_StdReturn : 30.221750259399414\n",
            "Train_MaxReturn : 135.0\n",
            "Train_MinReturn : 31.0\n",
            "Train_AverageEpLen : 69.75\n",
            "Train_EnvstepsSoFar : 11447\n",
            "TimeSinceStart : 10.315698385238647\n",
            "Training Loss : -18.891958236694336\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 86.19999694824219\n",
            "Eval_StdReturn : 29.56619644165039\n",
            "Eval_MaxReturn : 131.0\n",
            "Eval_MinReturn : 53.0\n",
            "Eval_AverageEpLen : 86.2\n",
            "Train_AverageReturn : 95.88888549804688\n",
            "Train_StdReturn : 45.91645812988281\n",
            "Train_MaxReturn : 184.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 95.88888888888889\n",
            "Train_EnvstepsSoFar : 12310\n",
            "TimeSinceStart : 11.12995958328247\n",
            "Training Loss : -26.96329116821289\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 51.0\n",
            "Eval_StdReturn : 23.494680404663086\n",
            "Eval_MaxReturn : 92.0\n",
            "Eval_MinReturn : 22.0\n",
            "Eval_AverageEpLen : 51.0\n",
            "Train_AverageReturn : 58.266666412353516\n",
            "Train_StdReturn : 27.788408279418945\n",
            "Train_MaxReturn : 132.0\n",
            "Train_MinReturn : 24.0\n",
            "Train_AverageEpLen : 58.266666666666666\n",
            "Train_EnvstepsSoFar : 13184\n",
            "TimeSinceStart : 11.891544818878174\n",
            "Training Loss : -2.2289562225341797\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 108.0\n",
            "Eval_StdReturn : 19.118053436279297\n",
            "Eval_MaxReturn : 128.0\n",
            "Eval_MinReturn : 77.0\n",
            "Eval_AverageEpLen : 108.0\n",
            "Train_AverageReturn : 57.21428680419922\n",
            "Train_StdReturn : 29.17723846435547\n",
            "Train_MaxReturn : 130.0\n",
            "Train_MinReturn : 21.0\n",
            "Train_AverageEpLen : 57.214285714285715\n",
            "Train_EnvstepsSoFar : 13985\n",
            "TimeSinceStart : 12.612428188323975\n",
            "Training Loss : -26.759685516357422\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 69.71428680419922\n",
            "Eval_StdReturn : 35.71999740600586\n",
            "Eval_MaxReturn : 128.0\n",
            "Eval_MinReturn : 25.0\n",
            "Eval_AverageEpLen : 69.71428571428571\n",
            "Train_AverageReturn : 86.30000305175781\n",
            "Train_StdReturn : 29.434843063354492\n",
            "Train_MaxReturn : 134.0\n",
            "Train_MinReturn : 24.0\n",
            "Train_AverageEpLen : 86.3\n",
            "Train_EnvstepsSoFar : 14848\n",
            "TimeSinceStart : 13.420338153839111\n",
            "Training Loss : 11.452667236328125\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 110.0\n",
            "Eval_StdReturn : 4.3011627197265625\n",
            "Eval_MaxReturn : 116.0\n",
            "Eval_MinReturn : 105.0\n",
            "Eval_AverageEpLen : 110.0\n",
            "Train_AverageReturn : 93.33333587646484\n",
            "Train_StdReturn : 31.340425491333008\n",
            "Train_MaxReturn : 155.0\n",
            "Train_MinReturn : 46.0\n",
            "Train_AverageEpLen : 93.33333333333333\n",
            "Train_EnvstepsSoFar : 15688\n",
            "TimeSinceStart : 14.195306301116943\n",
            "Training Loss : -4.285943984985352\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 90.5999984741211\n",
            "Eval_StdReturn : 43.98908615112305\n",
            "Eval_MaxReturn : 143.0\n",
            "Eval_MinReturn : 38.0\n",
            "Eval_AverageEpLen : 90.6\n",
            "Train_AverageReturn : 124.28571319580078\n",
            "Train_StdReturn : 19.49149513244629\n",
            "Train_MaxReturn : 151.0\n",
            "Train_MinReturn : 99.0\n",
            "Train_AverageEpLen : 124.28571428571429\n",
            "Train_EnvstepsSoFar : 16558\n",
            "TimeSinceStart : 15.032079696655273\n",
            "Training Loss : -33.66337585449219\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 111.0\n",
            "Eval_StdReturn : 46.67975997924805\n",
            "Eval_MaxReturn : 158.0\n",
            "Eval_MinReturn : 34.0\n",
            "Eval_AverageEpLen : 111.0\n",
            "Train_AverageReturn : 119.125\n",
            "Train_StdReturn : 28.387662887573242\n",
            "Train_MaxReturn : 154.0\n",
            "Train_MinReturn : 68.0\n",
            "Train_AverageEpLen : 119.125\n",
            "Train_EnvstepsSoFar : 17511\n",
            "TimeSinceStart : 15.884182691574097\n",
            "Training Loss : -36.309654235839844\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 122.75\n",
            "Eval_StdReturn : 50.53402328491211\n",
            "Eval_MaxReturn : 176.0\n",
            "Eval_MinReturn : 42.0\n",
            "Eval_AverageEpLen : 122.75\n",
            "Train_AverageReturn : 135.1666717529297\n",
            "Train_StdReturn : 33.81033706665039\n",
            "Train_MaxReturn : 177.0\n",
            "Train_MinReturn : 68.0\n",
            "Train_AverageEpLen : 135.16666666666666\n",
            "Train_EnvstepsSoFar : 18322\n",
            "TimeSinceStart : 16.699436902999878\n",
            "Training Loss : 10.565370559692383\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 178.0\n",
            "Eval_StdReturn : 35.36476516723633\n",
            "Eval_MaxReturn : 224.0\n",
            "Eval_MinReturn : 138.0\n",
            "Eval_AverageEpLen : 178.0\n",
            "Train_AverageReturn : 134.85714721679688\n",
            "Train_StdReturn : 36.25082778930664\n",
            "Train_MaxReturn : 171.0\n",
            "Train_MinReturn : 57.0\n",
            "Train_AverageEpLen : 134.85714285714286\n",
            "Train_EnvstepsSoFar : 19266\n",
            "TimeSinceStart : 17.676290035247803\n",
            "Training Loss : 7.033337593078613\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 185.0\n",
            "Eval_StdReturn : 43.96210479736328\n",
            "Eval_MaxReturn : 247.0\n",
            "Eval_MinReturn : 150.0\n",
            "Eval_AverageEpLen : 185.0\n",
            "Train_AverageReturn : 193.0\n",
            "Train_StdReturn : 24.7951602935791\n",
            "Train_MaxReturn : 229.0\n",
            "Train_MinReturn : 164.0\n",
            "Train_AverageEpLen : 193.0\n",
            "Train_EnvstepsSoFar : 20231\n",
            "TimeSinceStart : 18.70665216445923\n",
            "Training Loss : -23.316055297851562\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 158.6666717529297\n",
            "Eval_StdReturn : 22.66176414489746\n",
            "Eval_MaxReturn : 184.0\n",
            "Eval_MinReturn : 129.0\n",
            "Eval_AverageEpLen : 158.66666666666666\n",
            "Train_AverageReturn : 217.5\n",
            "Train_StdReturn : 74.94164276123047\n",
            "Train_MaxReturn : 341.0\n",
            "Train_MinReturn : 148.0\n",
            "Train_AverageEpLen : 217.5\n",
            "Train_EnvstepsSoFar : 21101\n",
            "TimeSinceStart : 19.668680667877197\n",
            "Training Loss : 5.066887855529785\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 215.0\n",
            "Eval_StdReturn : 60.0\n",
            "Eval_MaxReturn : 275.0\n",
            "Eval_MinReturn : 155.0\n",
            "Eval_AverageEpLen : 215.0\n",
            "Train_AverageReturn : 151.0\n",
            "Train_StdReturn : 33.560890197753906\n",
            "Train_MaxReturn : 193.0\n",
            "Train_MinReturn : 85.0\n",
            "Train_AverageEpLen : 151.0\n",
            "Train_EnvstepsSoFar : 22007\n",
            "TimeSinceStart : 20.53055715560913\n",
            "Training Loss : -70.30108642578125\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 309.5\n",
            "Eval_StdReturn : 52.5\n",
            "Eval_MaxReturn : 362.0\n",
            "Eval_MinReturn : 257.0\n",
            "Eval_AverageEpLen : 309.5\n",
            "Train_AverageReturn : 217.0\n",
            "Train_StdReturn : 60.17890167236328\n",
            "Train_MaxReturn : 317.0\n",
            "Train_MinReturn : 156.0\n",
            "Train_AverageEpLen : 217.0\n",
            "Train_EnvstepsSoFar : 22875\n",
            "TimeSinceStart : 21.54000425338745\n",
            "Training Loss : 9.653291702270508\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 423.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 423.0\n",
            "Eval_MinReturn : 423.0\n",
            "Eval_AverageEpLen : 423.0\n",
            "Train_AverageReturn : 262.0\n",
            "Train_StdReturn : 47.817359924316406\n",
            "Train_MaxReturn : 331.0\n",
            "Train_MinReturn : 214.0\n",
            "Train_AverageEpLen : 262.0\n",
            "Train_EnvstepsSoFar : 23923\n",
            "TimeSinceStart : 22.583694458007812\n",
            "Training Loss : -30.468416213989258\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 209.6666717529297\n",
            "Eval_StdReturn : 85.82669830322266\n",
            "Eval_MaxReturn : 297.0\n",
            "Eval_MinReturn : 93.0\n",
            "Eval_AverageEpLen : 209.66666666666666\n",
            "Train_AverageReturn : 320.0\n",
            "Train_StdReturn : 18.493242263793945\n",
            "Train_MaxReturn : 344.0\n",
            "Train_MinReturn : 299.0\n",
            "Train_AverageEpLen : 320.0\n",
            "Train_EnvstepsSoFar : 24883\n",
            "TimeSinceStart : 23.769804000854492\n",
            "Training Loss : 1.2530312538146973\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 407.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 407.0\n",
            "Eval_MinReturn : 407.0\n",
            "Eval_AverageEpLen : 407.0\n",
            "Train_AverageReturn : 230.25\n",
            "Train_StdReturn : 96.15969848632812\n",
            "Train_MaxReturn : 331.0\n",
            "Train_MinReturn : 74.0\n",
            "Train_AverageEpLen : 230.25\n",
            "Train_EnvstepsSoFar : 25804\n",
            "TimeSinceStart : 24.77200961112976\n",
            "Training Loss : -18.830028533935547\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 346.3333435058594\n",
            "Train_StdReturn : 41.2822265625\n",
            "Train_MaxReturn : 392.0\n",
            "Train_MinReturn : 292.0\n",
            "Train_AverageEpLen : 346.3333333333333\n",
            "Train_EnvstepsSoFar : 26843\n",
            "TimeSinceStart : 26.275474309921265\n",
            "Training Loss : 1.132709264755249\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 27843\n",
            "TimeSinceStart : 28.48291826248169\n",
            "Training Loss : -26.877912521362305\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 28843\n",
            "TimeSinceStart : 30.736112117767334\n",
            "Training Loss : 6.277846336364746\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 29843\n",
            "TimeSinceStart : 32.94677519798279\n",
            "Training Loss : 22.330867767333984\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 30843\n",
            "TimeSinceStart : 35.18277144432068\n",
            "Training Loss : 18.124691009521484\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 737.0\n",
            "Train_StdReturn : 263.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 474.0\n",
            "Train_AverageEpLen : 737.0\n",
            "Train_EnvstepsSoFar : 32317\n",
            "TimeSinceStart : 38.06617879867554\n",
            "Training Loss : -22.221744537353516\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 33317\n",
            "TimeSinceStart : 40.36551642417908\n",
            "Training Loss : -17.5741024017334\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 897.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 897.0\n",
            "Eval_MinReturn : 897.0\n",
            "Eval_AverageEpLen : 897.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 34317\n",
            "TimeSinceStart : 42.56971025466919\n",
            "Training Loss : -64.14317321777344\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 185.3333282470703\n",
            "Eval_StdReturn : 79.20578002929688\n",
            "Eval_MaxReturn : 296.0\n",
            "Eval_MinReturn : 115.0\n",
            "Eval_AverageEpLen : 185.33333333333334\n",
            "Train_AverageReturn : 883.5\n",
            "Train_StdReturn : 116.5\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 767.0\n",
            "Train_AverageEpLen : 883.5\n",
            "Train_EnvstepsSoFar : 36084\n",
            "TimeSinceStart : 44.98673987388611\n",
            "Training Loss : -5.09657621383667\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 223.3333282470703\n",
            "Eval_StdReturn : 129.13128662109375\n",
            "Eval_MaxReturn : 393.0\n",
            "Eval_MinReturn : 80.0\n",
            "Eval_AverageEpLen : 223.33333333333334\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 37084\n",
            "TimeSinceStart : 47.12032413482666\n",
            "Training Loss : 17.75786590576172\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 175.6666717529297\n",
            "Eval_StdReturn : 37.2409553527832\n",
            "Eval_MaxReturn : 223.0\n",
            "Eval_MinReturn : 132.0\n",
            "Eval_AverageEpLen : 175.66666666666666\n",
            "Train_AverageReturn : 303.0\n",
            "Train_StdReturn : 257.70654296875\n",
            "Train_MaxReturn : 653.0\n",
            "Train_MinReturn : 40.0\n",
            "Train_AverageEpLen : 303.0\n",
            "Train_EnvstepsSoFar : 37993\n",
            "TimeSinceStart : 48.46622848510742\n",
            "Training Loss : 4.598082542419434\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 968.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 968.0\n",
            "Eval_MinReturn : 968.0\n",
            "Eval_AverageEpLen : 968.0\n",
            "Train_AverageReturn : 239.75\n",
            "Train_StdReturn : 168.85255432128906\n",
            "Train_MaxReturn : 426.0\n",
            "Train_MinReturn : 20.0\n",
            "Train_AverageEpLen : 239.75\n",
            "Train_EnvstepsSoFar : 38952\n",
            "TimeSinceStart : 49.843756675720215\n",
            "Training Loss : -51.08249282836914\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 267.6666564941406\n",
            "Train_StdReturn : 152.8797607421875\n",
            "Train_MaxReturn : 436.0\n",
            "Train_MinReturn : 66.0\n",
            "Train_AverageEpLen : 267.6666666666667\n",
            "Train_EnvstepsSoFar : 39755\n",
            "TimeSinceStart : 51.125582218170166\n",
            "Training Loss : 14.75173282623291\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 40755\n",
            "TimeSinceStart : 53.375476121902466\n",
            "Training Loss : -15.347810745239258\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 41755\n",
            "TimeSinceStart : 55.59528613090515\n",
            "Training Loss : 1.4518228769302368\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 279.0\n",
            "Eval_StdReturn : 161.0\n",
            "Eval_MaxReturn : 440.0\n",
            "Eval_MinReturn : 118.0\n",
            "Eval_AverageEpLen : 279.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 42755\n",
            "TimeSinceStart : 57.614190101623535\n",
            "Training Loss : 11.479276657104492\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.375\n",
            "Eval_StdReturn : 22.050722122192383\n",
            "Eval_MaxReturn : 86.0\n",
            "Eval_MinReturn : 18.0\n",
            "Eval_AverageEpLen : 50.375\n",
            "Train_AverageReturn : 594.0\n",
            "Train_StdReturn : 368.0135803222656\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 109.0\n",
            "Train_AverageEpLen : 594.0\n",
            "Train_EnvstepsSoFar : 44537\n",
            "TimeSinceStart : 59.91574287414551\n",
            "Training Loss : 4.5884175300598145\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 387.3333435058594\n",
            "Eval_StdReturn : 434.8457946777344\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 35.0\n",
            "Eval_AverageEpLen : 387.3333333333333\n",
            "Train_AverageReturn : 89.69999694824219\n",
            "Train_StdReturn : 62.19010925292969\n",
            "Train_MaxReturn : 186.0\n",
            "Train_MinReturn : 17.0\n",
            "Train_AverageEpLen : 89.7\n",
            "Train_EnvstepsSoFar : 45434\n",
            "TimeSinceStart : 61.090935707092285\n",
            "Training Loss : -60.988487243652344\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 674.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 674.0\n",
            "Eval_MinReturn : 674.0\n",
            "Eval_AverageEpLen : 674.0\n",
            "Train_AverageReturn : 447.6666564941406\n",
            "Train_StdReturn : 410.1758728027344\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 18.0\n",
            "Train_AverageEpLen : 447.6666666666667\n",
            "Train_EnvstepsSoFar : 46777\n",
            "TimeSinceStart : 63.298115491867065\n",
            "Training Loss : 10.036428451538086\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 47777\n",
            "TimeSinceStart : 65.59032344818115\n",
            "Training Loss : -29.85533905029297\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 48777\n",
            "TimeSinceStart : 67.88007140159607\n",
            "Training Loss : -24.95949935913086\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 49777\n",
            "TimeSinceStart : 70.13393521308899\n",
            "Training Loss : -31.073226928710938\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 50777\n",
            "TimeSinceStart : 72.381582736969\n",
            "Training Loss : 6.976734161376953\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 51777\n",
            "TimeSinceStart : 74.62633800506592\n",
            "Training Loss : 18.317874908447266\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 52777\n",
            "TimeSinceStart : 76.92516231536865\n",
            "Training Loss : 15.061923027038574\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 53777\n",
            "TimeSinceStart : 79.13074040412903\n",
            "Training Loss : -60.21708679199219\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 146.6666717529297\n",
            "Eval_StdReturn : 55.48173141479492\n",
            "Eval_MaxReturn : 222.0\n",
            "Eval_MinReturn : 90.0\n",
            "Eval_AverageEpLen : 146.66666666666666\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 54777\n",
            "TimeSinceStart : 81.09303498268127\n",
            "Training Loss : 5.10883903503418\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.4000015258789\n",
            "Eval_StdReturn : 57.725555419921875\n",
            "Eval_MaxReturn : 181.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 107.4\n",
            "Train_AverageReturn : 163.1999969482422\n",
            "Train_StdReturn : 82.1763916015625\n",
            "Train_MaxReturn : 250.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 163.2\n",
            "Train_EnvstepsSoFar : 55593\n",
            "TimeSinceStart : 82.01050543785095\n",
            "Training Loss : -39.24077606201172\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 89.19999694824219\n",
            "Eval_StdReturn : 48.122344970703125\n",
            "Eval_MaxReturn : 146.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 89.2\n",
            "Train_AverageReturn : 117.0\n",
            "Train_StdReturn : 70.91645050048828\n",
            "Train_MaxReturn : 218.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 117.0\n",
            "Train_EnvstepsSoFar : 56412\n",
            "TimeSinceStart : 82.8132712841034\n",
            "Training Loss : 7.927961826324463\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 132.0\n",
            "Eval_StdReturn : 123.5131607055664\n",
            "Eval_MaxReturn : 334.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 132.0\n",
            "Train_AverageReturn : 85.18181610107422\n",
            "Train_StdReturn : 35.91864013671875\n",
            "Train_MaxReturn : 159.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 85.18181818181819\n",
            "Train_EnvstepsSoFar : 57349\n",
            "TimeSinceStart : 83.68038296699524\n",
            "Training Loss : -19.923538208007812\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 84.4000015258789\n",
            "Eval_StdReturn : 35.46603775024414\n",
            "Eval_MaxReturn : 134.0\n",
            "Eval_MinReturn : 53.0\n",
            "Eval_AverageEpLen : 84.4\n",
            "Train_AverageReturn : 144.8333282470703\n",
            "Train_StdReturn : 52.01736068725586\n",
            "Train_MaxReturn : 239.0\n",
            "Train_MinReturn : 97.0\n",
            "Train_AverageEpLen : 144.83333333333334\n",
            "Train_EnvstepsSoFar : 58218\n",
            "TimeSinceStart : 84.52010488510132\n",
            "Training Loss : -13.353214263916016\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 46.5\n",
            "Eval_StdReturn : 24.134000778198242\n",
            "Eval_MaxReturn : 90.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 46.5\n",
            "Train_AverageReturn : 83.19999694824219\n",
            "Train_StdReturn : 26.079875946044922\n",
            "Train_MaxReturn : 128.0\n",
            "Train_MinReturn : 53.0\n",
            "Train_AverageEpLen : 83.2\n",
            "Train_EnvstepsSoFar : 59050\n",
            "TimeSinceStart : 85.30748343467712\n",
            "Training Loss : -17.193513870239258\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 39.6363639831543\n",
            "Eval_StdReturn : 23.86809539794922\n",
            "Eval_MaxReturn : 96.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 39.63636363636363\n",
            "Train_AverageReturn : 93.22222137451172\n",
            "Train_StdReturn : 49.00289535522461\n",
            "Train_MaxReturn : 176.0\n",
            "Train_MinReturn : 49.0\n",
            "Train_AverageEpLen : 93.22222222222223\n",
            "Train_EnvstepsSoFar : 59889\n",
            "TimeSinceStart : 86.09311437606812\n",
            "Training Loss : -26.981307983398438\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 20.75\n",
            "Eval_StdReturn : 16.672956466674805\n",
            "Eval_MaxReturn : 66.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 20.75\n",
            "Train_AverageReturn : 38.28571319580078\n",
            "Train_StdReturn : 22.013294219970703\n",
            "Train_MaxReturn : 88.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 38.285714285714285\n",
            "Train_EnvstepsSoFar : 60693\n",
            "TimeSinceStart : 86.79395627975464\n",
            "Training Loss : -44.90604782104492\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 135.25\n",
            "Eval_StdReturn : 86.26811218261719\n",
            "Eval_MaxReturn : 231.0\n",
            "Eval_MinReturn : 13.0\n",
            "Eval_AverageEpLen : 135.25\n",
            "Train_AverageReturn : 24.24242401123047\n",
            "Train_StdReturn : 16.626066207885742\n",
            "Train_MaxReturn : 64.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 24.242424242424242\n",
            "Train_EnvstepsSoFar : 61493\n",
            "TimeSinceStart : 87.54947400093079\n",
            "Training Loss : -73.04764556884766\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 636.5\n",
            "Eval_StdReturn : 363.5\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 273.0\n",
            "Eval_AverageEpLen : 636.5\n",
            "Train_AverageReturn : 119.28571319580078\n",
            "Train_StdReturn : 89.45983123779297\n",
            "Train_MaxReturn : 258.0\n",
            "Train_MinReturn : 31.0\n",
            "Train_AverageEpLen : 119.28571428571429\n",
            "Train_EnvstepsSoFar : 62328\n",
            "TimeSinceStart : 88.79187154769897\n",
            "Training Loss : 18.77761459350586\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 769.5\n",
            "Train_StdReturn : 230.5\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 539.0\n",
            "Train_AverageEpLen : 769.5\n",
            "Train_EnvstepsSoFar : 63867\n",
            "TimeSinceStart : 91.3392870426178\n",
            "Training Loss : 13.31739330291748\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 64867\n",
            "TimeSinceStart : 93.61004257202148\n",
            "Training Loss : 6.854615211486816\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 65867\n",
            "TimeSinceStart : 95.85893774032593\n",
            "Training Loss : 9.440895080566406\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 66867\n",
            "TimeSinceStart : 98.11110806465149\n",
            "Training Loss : -18.008968353271484\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 422.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 422.0\n",
            "Eval_MinReturn : 422.0\n",
            "Eval_AverageEpLen : 422.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 67867\n",
            "TimeSinceStart : 100.07391929626465\n",
            "Training Loss : -4.729558944702148\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 68.5\n",
            "Eval_StdReturn : 22.1791934967041\n",
            "Eval_MaxReturn : 98.0\n",
            "Eval_MinReturn : 30.0\n",
            "Eval_AverageEpLen : 68.5\n",
            "Train_AverageReturn : 300.25\n",
            "Train_StdReturn : 139.4406280517578\n",
            "Train_MaxReturn : 523.0\n",
            "Train_MinReturn : 138.0\n",
            "Train_AverageEpLen : 300.25\n",
            "Train_EnvstepsSoFar : 69068\n",
            "TimeSinceStart : 101.39858508110046\n",
            "Training Loss : -21.20176887512207\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.0\n",
            "Eval_StdReturn : 25.06879425048828\n",
            "Eval_MaxReturn : 88.0\n",
            "Eval_MinReturn : 24.0\n",
            "Eval_AverageEpLen : 50.0\n",
            "Train_AverageReturn : 94.88888549804688\n",
            "Train_StdReturn : 63.488311767578125\n",
            "Train_MaxReturn : 216.0\n",
            "Train_MinReturn : 32.0\n",
            "Train_AverageEpLen : 94.88888888888889\n",
            "Train_EnvstepsSoFar : 69922\n",
            "TimeSinceStart : 102.21479630470276\n",
            "Training Loss : -12.09287166595459\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 37.90909194946289\n",
            "Eval_StdReturn : 9.912842750549316\n",
            "Eval_MaxReturn : 59.0\n",
            "Eval_MinReturn : 23.0\n",
            "Eval_AverageEpLen : 37.90909090909091\n",
            "Train_AverageReturn : 41.70000076293945\n",
            "Train_StdReturn : 15.675139427185059\n",
            "Train_MaxReturn : 74.0\n",
            "Train_MinReturn : 24.0\n",
            "Train_AverageEpLen : 41.7\n",
            "Train_EnvstepsSoFar : 70756\n",
            "TimeSinceStart : 102.9656708240509\n",
            "Training Loss : -17.23870849609375\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 30.214284896850586\n",
            "Eval_StdReturn : 10.24819564819336\n",
            "Eval_MaxReturn : 50.0\n",
            "Eval_MinReturn : 11.0\n",
            "Eval_AverageEpLen : 30.214285714285715\n",
            "Train_AverageReturn : 40.45000076293945\n",
            "Train_StdReturn : 19.134981155395508\n",
            "Train_MaxReturn : 98.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 40.45\n",
            "Train_EnvstepsSoFar : 71565\n",
            "TimeSinceStart : 103.69269752502441\n",
            "Training Loss : -5.748395919799805\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.538461685180664\n",
            "Eval_StdReturn : 17.292129516601562\n",
            "Eval_MaxReturn : 57.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 31.53846153846154\n",
            "Train_AverageReturn : 34.0\n",
            "Train_StdReturn : 14.68877124786377\n",
            "Train_MaxReturn : 67.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 34.0\n",
            "Train_EnvstepsSoFar : 72415\n",
            "TimeSinceStart : 104.42567133903503\n",
            "Training Loss : -5.501227855682373\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 40.599998474121094\n",
            "Eval_StdReturn : 24.270145416259766\n",
            "Eval_MaxReturn : 87.0\n",
            "Eval_MinReturn : 11.0\n",
            "Eval_AverageEpLen : 40.6\n",
            "Train_AverageReturn : 24.24242401123047\n",
            "Train_StdReturn : 12.222756385803223\n",
            "Train_MaxReturn : 44.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 24.242424242424242\n",
            "Train_EnvstepsSoFar : 73215\n",
            "TimeSinceStart : 105.14922833442688\n",
            "Training Loss : -4.697968482971191\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 62.71428680419922\n",
            "Eval_StdReturn : 25.160707473754883\n",
            "Eval_MaxReturn : 118.0\n",
            "Eval_MinReturn : 38.0\n",
            "Eval_AverageEpLen : 62.714285714285715\n",
            "Train_AverageReturn : 32.560001373291016\n",
            "Train_StdReturn : 13.761046409606934\n",
            "Train_MaxReturn : 58.0\n",
            "Train_MinReturn : 12.0\n",
            "Train_AverageEpLen : 32.56\n",
            "Train_EnvstepsSoFar : 74029\n",
            "TimeSinceStart : 105.87987518310547\n",
            "Training Loss : -6.3116774559021\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.4000015258789\n",
            "Eval_StdReturn : 38.45828628540039\n",
            "Eval_MaxReturn : 167.0\n",
            "Eval_MinReturn : 59.0\n",
            "Eval_AverageEpLen : 92.4\n",
            "Train_AverageReturn : 73.16666412353516\n",
            "Train_StdReturn : 34.299739837646484\n",
            "Train_MaxReturn : 155.0\n",
            "Train_MinReturn : 36.0\n",
            "Train_AverageEpLen : 73.16666666666667\n",
            "Train_EnvstepsSoFar : 74907\n",
            "TimeSinceStart : 106.66973948478699\n",
            "Training Loss : 0.8401796817779541\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 374.0\n",
            "Eval_StdReturn : 273.0\n",
            "Eval_MaxReturn : 647.0\n",
            "Eval_MinReturn : 101.0\n",
            "Eval_AverageEpLen : 374.0\n",
            "Train_AverageReturn : 139.7142791748047\n",
            "Train_StdReturn : 54.65401077270508\n",
            "Train_MaxReturn : 257.0\n",
            "Train_MinReturn : 80.0\n",
            "Train_AverageEpLen : 139.71428571428572\n",
            "Train_EnvstepsSoFar : 75885\n",
            "TimeSinceStart : 107.73121690750122\n",
            "Training Loss : 17.223724365234375\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 103.0\n",
            "Eval_StdReturn : 25.149553298950195\n",
            "Eval_MaxReturn : 146.0\n",
            "Eval_MinReturn : 84.0\n",
            "Eval_AverageEpLen : 103.0\n",
            "Train_AverageReturn : 431.0\n",
            "Train_StdReturn : 329.9643859863281\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 191.0\n",
            "Train_AverageEpLen : 431.0\n",
            "Train_EnvstepsSoFar : 77609\n",
            "TimeSinceStart : 110.069664478302\n",
            "Training Loss : -5.45897102355957\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 258.5\n",
            "Eval_StdReturn : 56.5\n",
            "Eval_MaxReturn : 315.0\n",
            "Eval_MinReturn : 202.0\n",
            "Eval_AverageEpLen : 258.5\n",
            "Train_AverageReturn : 186.8000030517578\n",
            "Train_StdReturn : 30.544395446777344\n",
            "Train_MaxReturn : 219.0\n",
            "Train_MinReturn : 139.0\n",
            "Train_AverageEpLen : 186.8\n",
            "Train_EnvstepsSoFar : 78543\n",
            "TimeSinceStart : 111.04475688934326\n",
            "Training Loss : 12.606315612792969\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 129.5\n",
            "Eval_StdReturn : 9.708244323730469\n",
            "Eval_MaxReturn : 143.0\n",
            "Eval_MinReturn : 116.0\n",
            "Eval_AverageEpLen : 129.5\n",
            "Train_AverageReturn : 162.0\n",
            "Train_StdReturn : 38.31970977783203\n",
            "Train_MaxReturn : 203.0\n",
            "Train_MinReturn : 103.0\n",
            "Train_AverageEpLen : 162.0\n",
            "Train_EnvstepsSoFar : 79353\n",
            "TimeSinceStart : 111.92256045341492\n",
            "Training Loss : -23.260496139526367\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 100.0\n",
            "Eval_StdReturn : 3.674234628677368\n",
            "Eval_MaxReturn : 104.0\n",
            "Eval_MinReturn : 95.0\n",
            "Eval_AverageEpLen : 100.0\n",
            "Train_AverageReturn : 141.14285278320312\n",
            "Train_StdReturn : 33.33564758300781\n",
            "Train_MaxReturn : 192.0\n",
            "Train_MinReturn : 106.0\n",
            "Train_AverageEpLen : 141.14285714285714\n",
            "Train_EnvstepsSoFar : 80341\n",
            "TimeSinceStart : 112.79375982284546\n",
            "Training Loss : 7.249750137329102\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 89.4000015258789\n",
            "Eval_StdReturn : 5.0438079833984375\n",
            "Eval_MaxReturn : 98.0\n",
            "Eval_MinReturn : 83.0\n",
            "Eval_AverageEpLen : 89.4\n",
            "Train_AverageReturn : 97.33333587646484\n",
            "Train_StdReturn : 8.99382495880127\n",
            "Train_MaxReturn : 116.0\n",
            "Train_MinReturn : 88.0\n",
            "Train_AverageEpLen : 97.33333333333333\n",
            "Train_EnvstepsSoFar : 81217\n",
            "TimeSinceStart : 113.63441586494446\n",
            "Training Loss : 12.23934555053711\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 129.25\n",
            "Eval_StdReturn : 9.549214363098145\n",
            "Eval_MaxReturn : 143.0\n",
            "Eval_MinReturn : 117.0\n",
            "Eval_AverageEpLen : 129.25\n",
            "Train_AverageReturn : 90.55555725097656\n",
            "Train_StdReturn : 8.858281135559082\n",
            "Train_MaxReturn : 104.0\n",
            "Train_MinReturn : 76.0\n",
            "Train_AverageEpLen : 90.55555555555556\n",
            "Train_EnvstepsSoFar : 82032\n",
            "TimeSinceStart : 114.43257021903992\n",
            "Training Loss : 26.12607192993164\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 130.5\n",
            "Eval_StdReturn : 5.5452680587768555\n",
            "Eval_MaxReturn : 140.0\n",
            "Eval_MinReturn : 126.0\n",
            "Eval_AverageEpLen : 130.5\n",
            "Train_AverageReturn : 124.42857360839844\n",
            "Train_StdReturn : 6.4110870361328125\n",
            "Train_MaxReturn : 137.0\n",
            "Train_MinReturn : 117.0\n",
            "Train_AverageEpLen : 124.42857142857143\n",
            "Train_EnvstepsSoFar : 82903\n",
            "TimeSinceStart : 115.30324983596802\n",
            "Training Loss : -15.909443855285645\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 143.3333282470703\n",
            "Train_StdReturn : 4.8534064292907715\n",
            "Train_MaxReturn : 150.0\n",
            "Train_MinReturn : 137.0\n",
            "Train_AverageEpLen : 143.33333333333334\n",
            "Train_EnvstepsSoFar : 83763\n",
            "TimeSinceStart : 116.4132227897644\n",
            "Training Loss : -8.23306655883789\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 84763\n",
            "TimeSinceStart : 118.7034604549408\n",
            "Training Loss : -26.141159057617188\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 85763\n",
            "TimeSinceStart : 120.96418166160583\n",
            "Training Loss : 22.71356201171875\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 86763\n",
            "TimeSinceStart : 123.2480080127716\n",
            "Training Loss : -35.793460845947266\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 87763\n",
            "TimeSinceStart : 125.5183618068695\n",
            "Training Loss : 10.070219039916992\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 88763\n",
            "TimeSinceStart : 127.75895738601685\n",
            "Training Loss : 13.533435821533203\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 89763\n",
            "TimeSinceStart : 130.03306484222412\n",
            "Training Loss : 21.077022552490234\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 90763\n",
            "TimeSinceStart : 132.29048204421997\n",
            "Training Loss : 22.1236515045166\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 91763\n",
            "TimeSinceStart : 134.54758524894714\n",
            "Training Loss : 5.267736911773682\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 92763\n",
            "TimeSinceStart : 136.81489396095276\n",
            "Training Loss : -17.524980545043945\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 846.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 846.0\n",
            "Eval_MinReturn : 846.0\n",
            "Eval_AverageEpLen : 846.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 93763\n",
            "TimeSinceStart : 139.00579833984375\n",
            "Training Loss : 9.068276405334473\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.939393997192383\n",
            "Eval_StdReturn : 5.438022136688232\n",
            "Eval_MaxReturn : 30.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 12.93939393939394\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 94763\n",
            "TimeSinceStart : 141.0239200592041\n",
            "Training Loss : -23.818998336791992\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 15.207547187805176\n",
            "Train_StdReturn : 6.382046222686768\n",
            "Train_MaxReturn : 35.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 15.20754716981132\n",
            "Train_EnvstepsSoFar : 95569\n",
            "TimeSinceStart : 142.00043487548828\n",
            "Training Loss : -56.3813362121582\n",
            "Initial_DataCollection_AverageReturn : 9.218390464782715\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name InvertedPendulum-v2 \\\n",
        "    --ep_len 1000 --discount 0.9 -n 100 -l 2 -s 64 \\\n",
        "    -b 800 -lr 0.02 -rtg \\\n",
        "    --exp_name q2_b800_r0.02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuaKDhfcGMQO"
      },
      "source": [
        "#LunarLander"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot('/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q3_b40000_r0.005_LunarLanderContinuous-v2_09-05-2022_15-23-00/events.out.tfevents.1652109780.2abbffd1bee5', \n",
        "     '/content/cds_rl_2022/rl_hw/hw2/figure/q3')"
      ],
      "metadata": {
        "id": "vvt97XuyerSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBk9_w_dGSqT",
        "outputId": "73e1b6df-b585-4074-e996-254f5d696bae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q3_b40000_r0.005_LunarLanderContinuous-v2_09-05-2022_15-23-00\n",
            "########################\n",
            "GPU not detected. Defaulting to CPU.\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -233.004638671875\n",
            "Eval_StdReturn : 120.61140441894531\n",
            "Eval_MaxReturn : -92.01519012451172\n",
            "Eval_MinReturn : -405.04052734375\n",
            "Eval_AverageEpLen : 116.75\n",
            "Train_AverageReturn : -312.86669921875\n",
            "Train_StdReturn : 160.94387817382812\n",
            "Train_MaxReturn : 32.98016357421875\n",
            "Train_MinReturn : -763.250732421875\n",
            "Train_AverageEpLen : 111.12777777777778\n",
            "Train_EnvstepsSoFar : 40006\n",
            "TimeSinceStart : 46.63747549057007\n",
            "Training Loss : -201.7047119140625\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -263.4136962890625\n",
            "Eval_StdReturn : 123.2025375366211\n",
            "Eval_MaxReturn : -70.0846939086914\n",
            "Eval_MinReturn : -378.550048828125\n",
            "Eval_AverageEpLen : 102.5\n",
            "Train_AverageReturn : -178.2994384765625\n",
            "Train_StdReturn : 107.41215515136719\n",
            "Train_MaxReturn : 25.72332000732422\n",
            "Train_MinReturn : -563.9736938476562\n",
            "Train_AverageEpLen : 100.27568922305764\n",
            "Train_EnvstepsSoFar : 80016\n",
            "TimeSinceStart : 85.5093183517456\n",
            "Training Loss : 234.8215789794922\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -147.8714141845703\n",
            "Eval_StdReturn : 67.35498809814453\n",
            "Eval_MaxReturn : -95.31854248046875\n",
            "Eval_MinReturn : -278.25506591796875\n",
            "Eval_AverageEpLen : 91.6\n",
            "Train_AverageReturn : -156.17953491210938\n",
            "Train_StdReturn : 86.94270324707031\n",
            "Train_MaxReturn : 45.132537841796875\n",
            "Train_MinReturn : -497.0280456542969\n",
            "Train_AverageEpLen : 93.07674418604651\n",
            "Train_EnvstepsSoFar : 120039\n",
            "TimeSinceStart : 123.68637299537659\n",
            "Training Loss : -238.8880615234375\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -100.63806915283203\n",
            "Eval_StdReturn : 20.662464141845703\n",
            "Eval_MaxReturn : -65.04299926757812\n",
            "Eval_MinReturn : -122.74613189697266\n",
            "Eval_AverageEpLen : 84.0\n",
            "Train_AverageReturn : -139.12728881835938\n",
            "Train_StdReturn : 70.4603500366211\n",
            "Train_MaxReturn : 33.653717041015625\n",
            "Train_MinReturn : -407.5083312988281\n",
            "Train_AverageEpLen : 92.30875576036867\n",
            "Train_EnvstepsSoFar : 160101\n",
            "TimeSinceStart : 160.62856459617615\n",
            "Training Loss : -344.66949462890625\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -88.05189514160156\n",
            "Eval_StdReturn : 34.564327239990234\n",
            "Eval_MaxReturn : -42.25442123413086\n",
            "Eval_MinReturn : -146.95947265625\n",
            "Eval_AverageEpLen : 82.2\n",
            "Train_AverageReturn : -132.1863250732422\n",
            "Train_StdReturn : 63.972862243652344\n",
            "Train_MaxReturn : 38.58095169067383\n",
            "Train_MinReturn : -394.3745422363281\n",
            "Train_AverageEpLen : 88.48344370860927\n",
            "Train_EnvstepsSoFar : 200184\n",
            "TimeSinceStart : 197.2023811340332\n",
            "Training Loss : -84.85872650146484\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -88.79019927978516\n",
            "Eval_StdReturn : 56.946990966796875\n",
            "Eval_MaxReturn : -34.79972839355469\n",
            "Eval_MinReturn : -198.83555603027344\n",
            "Eval_AverageEpLen : 88.8\n",
            "Train_AverageReturn : -114.39482879638672\n",
            "Train_StdReturn : 49.15561294555664\n",
            "Train_MaxReturn : 41.01066589355469\n",
            "Train_MinReturn : -333.32391357421875\n",
            "Train_AverageEpLen : 87.5382932166302\n",
            "Train_EnvstepsSoFar : 240189\n",
            "TimeSinceStart : 233.63558149337769\n",
            "Training Loss : 383.1672058105469\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -172.4805145263672\n",
            "Eval_StdReturn : 118.74616241455078\n",
            "Eval_MaxReturn : -73.76329803466797\n",
            "Eval_MinReturn : -371.0107421875\n",
            "Eval_AverageEpLen : 110.0\n",
            "Train_AverageReturn : -108.80870819091797\n",
            "Train_StdReturn : 47.055076599121094\n",
            "Train_MaxReturn : 16.573440551757812\n",
            "Train_MinReturn : -379.1365661621094\n",
            "Train_AverageEpLen : 90.5158371040724\n",
            "Train_EnvstepsSoFar : 280197\n",
            "TimeSinceStart : 270.7225134372711\n",
            "Training Loss : 303.1842041015625\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -89.92201232910156\n",
            "Eval_StdReturn : 25.14799690246582\n",
            "Eval_MaxReturn : -48.74335479736328\n",
            "Eval_MinReturn : -115.88278198242188\n",
            "Eval_AverageEpLen : 105.5\n",
            "Train_AverageReturn : -103.65626525878906\n",
            "Train_StdReturn : 46.282981872558594\n",
            "Train_MaxReturn : 65.68988800048828\n",
            "Train_MinReturn : -333.1358642578125\n",
            "Train_AverageEpLen : 95.84928229665071\n",
            "Train_EnvstepsSoFar : 320262\n",
            "TimeSinceStart : 310.51132106781006\n",
            "Training Loss : 151.79859924316406\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -70.3735580444336\n",
            "Eval_StdReturn : 24.29381561279297\n",
            "Eval_MaxReturn : -44.677276611328125\n",
            "Eval_MinReturn : -110.19139099121094\n",
            "Eval_AverageEpLen : 113.75\n",
            "Train_AverageReturn : -91.93965911865234\n",
            "Train_StdReturn : 52.92646408081055\n",
            "Train_MaxReturn : 53.6348876953125\n",
            "Train_MinReturn : -355.3900451660156\n",
            "Train_AverageEpLen : 104.2578125\n",
            "Train_EnvstepsSoFar : 360297\n",
            "TimeSinceStart : 352.0374927520752\n",
            "Training Loss : 166.71527099609375\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -43.688663482666016\n",
            "Eval_StdReturn : 14.168940544128418\n",
            "Eval_MaxReturn : -25.592674255371094\n",
            "Eval_MinReturn : -65.28205108642578\n",
            "Eval_AverageEpLen : 116.5\n",
            "Train_AverageReturn : -77.13026428222656\n",
            "Train_StdReturn : 41.29877853393555\n",
            "Train_MaxReturn : 44.703067779541016\n",
            "Train_MinReturn : -303.3688049316406\n",
            "Train_AverageEpLen : 112.03072625698324\n",
            "Train_EnvstepsSoFar : 400404\n",
            "TimeSinceStart : 397.95441913604736\n",
            "Training Loss : 21.48660659790039\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.493000030517578\n",
            "Eval_StdReturn : 27.508718490600586\n",
            "Eval_MaxReturn : 7.00927734375\n",
            "Eval_MinReturn : -64.56287384033203\n",
            "Eval_AverageEpLen : 113.75\n",
            "Train_AverageReturn : -55.637699127197266\n",
            "Train_StdReturn : 36.682273864746094\n",
            "Train_MaxReturn : 44.955081939697266\n",
            "Train_MinReturn : -232.65882873535156\n",
            "Train_AverageEpLen : 133.8628762541806\n",
            "Train_EnvstepsSoFar : 440429\n",
            "TimeSinceStart : 454.00412034988403\n",
            "Training Loss : -132.8216094970703\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -68.19877624511719\n",
            "Eval_StdReturn : 48.91917419433594\n",
            "Eval_MaxReturn : -19.27960205078125\n",
            "Eval_MinReturn : -117.1179428100586\n",
            "Eval_AverageEpLen : 217.0\n",
            "Train_AverageReturn : -55.02162170410156\n",
            "Train_StdReturn : 46.30708694458008\n",
            "Train_MaxReturn : 33.12806701660156\n",
            "Train_MinReturn : -272.5103454589844\n",
            "Train_AverageEpLen : 148.75092936802974\n",
            "Train_EnvstepsSoFar : 480443\n",
            "TimeSinceStart : 510.36413621902466\n",
            "Training Loss : 281.0833740234375\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -225.3896026611328\n",
            "Eval_StdReturn : 180.73532104492188\n",
            "Eval_MaxReturn : -44.654273986816406\n",
            "Eval_MinReturn : -406.12493896484375\n",
            "Eval_AverageEpLen : 208.0\n",
            "Train_AverageReturn : -52.421470642089844\n",
            "Train_StdReturn : 61.73292541503906\n",
            "Train_MaxReturn : 62.39352798461914\n",
            "Train_MinReturn : -355.08856201171875\n",
            "Train_AverageEpLen : 186.86046511627907\n",
            "Train_EnvstepsSoFar : 520618\n",
            "TimeSinceStart : 580.7345218658447\n",
            "Training Loss : -430.4025573730469\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -168.19686889648438\n",
            "Eval_StdReturn : 21.44945526123047\n",
            "Eval_MaxReturn : -146.74740600585938\n",
            "Eval_MinReturn : -189.6463165283203\n",
            "Eval_AverageEpLen : 359.5\n",
            "Train_AverageReturn : -62.78995132446289\n",
            "Train_StdReturn : 71.58331298828125\n",
            "Train_MaxReturn : 55.41380310058594\n",
            "Train_MinReturn : -325.0296325683594\n",
            "Train_AverageEpLen : 239.89221556886227\n",
            "Train_EnvstepsSoFar : 560680\n",
            "TimeSinceStart : 668.4967932701111\n",
            "Training Loss : 110.75993347167969\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -99.12872314453125\n",
            "Eval_StdReturn : 60.13882064819336\n",
            "Eval_MaxReturn : -38.989906311035156\n",
            "Eval_MinReturn : -159.26754760742188\n",
            "Eval_AverageEpLen : 614.5\n",
            "Train_AverageReturn : -105.18048095703125\n",
            "Train_StdReturn : 89.63728332519531\n",
            "Train_MaxReturn : 60.79279327392578\n",
            "Train_MinReturn : -389.1112060546875\n",
            "Train_AverageEpLen : 354.12389380530976\n",
            "Train_EnvstepsSoFar : 600696\n",
            "TimeSinceStart : 779.8407297134399\n",
            "Training Loss : 194.85067749023438\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -165.92803955078125\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : -165.92803955078125\n",
            "Eval_MinReturn : -165.92803955078125\n",
            "Eval_AverageEpLen : 513.0\n",
            "Train_AverageReturn : -118.81072998046875\n",
            "Train_StdReturn : 80.51612854003906\n",
            "Train_MaxReturn : 65.06498718261719\n",
            "Train_MinReturn : -340.51373291015625\n",
            "Train_AverageEpLen : 398.2277227722772\n",
            "Train_EnvstepsSoFar : 640917\n",
            "TimeSinceStart : 903.8036985397339\n",
            "Training Loss : -253.64271545410156\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.452484130859375\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : -42.452484130859375\n",
            "Eval_MinReturn : -42.452484130859375\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : -139.9838104248047\n",
            "Train_StdReturn : 81.95397186279297\n",
            "Train_MaxReturn : 45.05293273925781\n",
            "Train_MinReturn : -466.6217956542969\n",
            "Train_AverageEpLen : 479.10714285714283\n",
            "Train_EnvstepsSoFar : 681162\n",
            "TimeSinceStart : 1047.0070188045502\n",
            "Training Loss : -175.07977294921875\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -285.83038330078125\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : -285.83038330078125\n",
            "Eval_MinReturn : -285.83038330078125\n",
            "Eval_AverageEpLen : 528.0\n",
            "Train_AverageReturn : -118.63080596923828\n",
            "Train_StdReturn : 80.21784973144531\n",
            "Train_MaxReturn : 39.810977935791016\n",
            "Train_MinReturn : -341.8813781738281\n",
            "Train_AverageEpLen : 446.0111111111111\n",
            "Train_EnvstepsSoFar : 721303\n",
            "TimeSinceStart : 1180.799036026001\n",
            "Training Loss : -381.8982849121094\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 11.720623016357422\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 11.720623016357422\n",
            "Eval_MinReturn : 11.720623016357422\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : -107.3271255493164\n",
            "Train_StdReturn : 82.61866760253906\n",
            "Train_MaxReturn : 23.03404998779297\n",
            "Train_MinReturn : -486.73065185546875\n",
            "Train_AverageEpLen : 457.1136363636364\n",
            "Train_EnvstepsSoFar : 761529\n",
            "TimeSinceStart : 1313.3462882041931\n",
            "Training Loss : 133.46324157714844\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.7259979248046875\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 5.7259979248046875\n",
            "Eval_MinReturn : 5.7259979248046875\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : -72.96612548828125\n",
            "Train_StdReturn : 74.22764587402344\n",
            "Train_MaxReturn : 70.65380859375\n",
            "Train_MinReturn : -259.3113708496094\n",
            "Train_AverageEpLen : 529.9868421052631\n",
            "Train_EnvstepsSoFar : 801808\n",
            "TimeSinceStart : 1459.5793948173523\n",
            "Training Loss : -558.2915649414062\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.95518493652344\n",
            "Eval_StdReturn : 40.25446701049805\n",
            "Eval_MaxReturn : -6.700717926025391\n",
            "Eval_MinReturn : -87.20965576171875\n",
            "Eval_AverageEpLen : 642.5\n",
            "Train_AverageReturn : -41.04094696044922\n",
            "Train_StdReturn : 81.6971664428711\n",
            "Train_MaxReturn : 58.065406799316406\n",
            "Train_MinReturn : -350.4747619628906\n",
            "Train_AverageEpLen : 545.7837837837837\n",
            "Train_EnvstepsSoFar : 842196\n",
            "TimeSinceStart : 1614.5136637687683\n",
            "Training Loss : -168.66647338867188\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -213.8420867919922\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : -213.8420867919922\n",
            "Eval_MinReturn : -213.8420867919922\n",
            "Eval_AverageEpLen : 474.0\n",
            "Train_AverageReturn : -21.46377182006836\n",
            "Train_StdReturn : 64.46665954589844\n",
            "Train_MaxReturn : 93.63760375976562\n",
            "Train_MinReturn : -278.9098815917969\n",
            "Train_AverageEpLen : 633.921875\n",
            "Train_EnvstepsSoFar : 882767\n",
            "TimeSinceStart : 1773.7637901306152\n",
            "Training Loss : -465.5675048828125\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -3.7155838012695312\n",
            "Eval_StdReturn : 43.38327407836914\n",
            "Eval_MaxReturn : 39.66769027709961\n",
            "Eval_MinReturn : -47.09885787963867\n",
            "Eval_AverageEpLen : 268.5\n",
            "Train_AverageReturn : -4.1731367111206055\n",
            "Train_StdReturn : 48.844844818115234\n",
            "Train_MaxReturn : 91.44371032714844\n",
            "Train_MinReturn : -168.60427856445312\n",
            "Train_AverageEpLen : 542.9594594594595\n",
            "Train_EnvstepsSoFar : 922946\n",
            "TimeSinceStart : 1926.1900086402893\n",
            "Training Loss : 16.295272827148438\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 83.20968627929688\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 83.20968627929688\n",
            "Eval_MinReturn : 83.20968627929688\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 9.00832462310791\n",
            "Train_StdReturn : 49.35106658935547\n",
            "Train_MaxReturn : 96.07460021972656\n",
            "Train_MinReturn : -145.6214141845703\n",
            "Train_AverageEpLen : 526.421052631579\n",
            "Train_EnvstepsSoFar : 962954\n",
            "TimeSinceStart : 2077.1073570251465\n",
            "Training Loss : -145.3617706298828\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 38.20594787597656\n",
            "Eval_StdReturn : 12.943107604980469\n",
            "Eval_MaxReturn : 51.14905548095703\n",
            "Eval_MinReturn : 25.262840270996094\n",
            "Eval_AverageEpLen : 629.0\n",
            "Train_AverageReturn : 14.087990760803223\n",
            "Train_StdReturn : 44.00502395629883\n",
            "Train_MaxReturn : 115.2680435180664\n",
            "Train_MinReturn : -139.19097900390625\n",
            "Train_AverageEpLen : 487.8292682926829\n",
            "Train_EnvstepsSoFar : 1002956\n",
            "TimeSinceStart : 2221.009471178055\n",
            "Training Loss : -116.26431274414062\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.496333122253418\n",
            "Eval_StdReturn : 47.539974212646484\n",
            "Eval_MaxReturn : 36.7952880859375\n",
            "Eval_MinReturn : -76.73792266845703\n",
            "Eval_AverageEpLen : 194.33333333333334\n",
            "Train_AverageReturn : 12.006766319274902\n",
            "Train_StdReturn : 53.7304573059082\n",
            "Train_MaxReturn : 120.1875991821289\n",
            "Train_MinReturn : -144.64073181152344\n",
            "Train_AverageEpLen : 455.4886363636364\n",
            "Train_EnvstepsSoFar : 1043039\n",
            "TimeSinceStart : 2356.2233595848083\n",
            "Training Loss : -307.2694396972656\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.65916061401367\n",
            "Eval_StdReturn : 50.23123550415039\n",
            "Eval_MaxReturn : 14.572074890136719\n",
            "Eval_MinReturn : -85.89039611816406\n",
            "Eval_AverageEpLen : 235.0\n",
            "Train_AverageReturn : 23.092670440673828\n",
            "Train_StdReturn : 50.52218246459961\n",
            "Train_MaxReturn : 139.41220092773438\n",
            "Train_MinReturn : -166.59686279296875\n",
            "Train_AverageEpLen : 504.2625\n",
            "Train_EnvstepsSoFar : 1083380\n",
            "TimeSinceStart : 2498.0128898620605\n",
            "Training Loss : -292.6767272949219\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -1.3767623901367188\n",
            "Eval_StdReturn : 99.6506576538086\n",
            "Eval_MaxReturn : 98.27389526367188\n",
            "Eval_MinReturn : -101.02742004394531\n",
            "Eval_AverageEpLen : 658.0\n",
            "Train_AverageReturn : 29.234352111816406\n",
            "Train_StdReturn : 42.41608428955078\n",
            "Train_MaxReturn : 150.5644073486328\n",
            "Train_MinReturn : -74.10614776611328\n",
            "Train_AverageEpLen : 455.53409090909093\n",
            "Train_EnvstepsSoFar : 1123467\n",
            "TimeSinceStart : 2639.7299704551697\n",
            "Training Loss : -165.96218872070312\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 85.23507690429688\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 85.23507690429688\n",
            "Eval_MinReturn : 85.23507690429688\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 25.329381942749023\n",
            "Train_StdReturn : 61.255802154541016\n",
            "Train_MaxReturn : 139.068115234375\n",
            "Train_MinReturn : -180.0547637939453\n",
            "Train_AverageEpLen : 483.3855421686747\n",
            "Train_EnvstepsSoFar : 1163588\n",
            "TimeSinceStart : 2776.3007457256317\n",
            "Training Loss : -233.43368530273438\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.2010383605957\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 59.2010383605957\n",
            "Eval_MinReturn : 59.2010383605957\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 34.81063461303711\n",
            "Train_StdReturn : 52.62941360473633\n",
            "Train_MaxReturn : 152.07424926757812\n",
            "Train_MinReturn : -92.45661163330078\n",
            "Train_AverageEpLen : 481.01176470588234\n",
            "Train_EnvstepsSoFar : 1204474\n",
            "TimeSinceStart : 2911.441931247711\n",
            "Training Loss : 62.097930908203125\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 111.65827178955078\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 111.65827178955078\n",
            "Eval_MinReturn : 111.65827178955078\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 54.64902114868164\n",
            "Train_StdReturn : 59.20944595336914\n",
            "Train_MaxReturn : 162.69461059570312\n",
            "Train_MinReturn : -149.59732055664062\n",
            "Train_AverageEpLen : 698.3620689655172\n",
            "Train_EnvstepsSoFar : 1244979\n",
            "TimeSinceStart : 3060.633671283722\n",
            "Training Loss : -67.98091125488281\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.183225631713867\n",
            "Eval_StdReturn : 1.1298198699951172\n",
            "Eval_MaxReturn : 14.313045501708984\n",
            "Eval_MinReturn : 12.05340576171875\n",
            "Eval_AverageEpLen : 603.0\n",
            "Train_AverageReturn : 45.476837158203125\n",
            "Train_StdReturn : 54.22264099121094\n",
            "Train_MaxReturn : 166.17710876464844\n",
            "Train_MinReturn : -69.60757446289062\n",
            "Train_AverageEpLen : 576.2571428571429\n",
            "Train_EnvstepsSoFar : 1285317\n",
            "TimeSinceStart : 3198.4584810733795\n",
            "Training Loss : -73.43685913085938\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.84065628051758\n",
            "Eval_StdReturn : 28.454639434814453\n",
            "Eval_MaxReturn : 79.29529571533203\n",
            "Eval_MinReturn : 22.386016845703125\n",
            "Eval_AverageEpLen : 209.0\n",
            "Train_AverageReturn : 56.54789733886719\n",
            "Train_StdReturn : 55.88254165649414\n",
            "Train_MaxReturn : 147.416748046875\n",
            "Train_MinReturn : -105.49876403808594\n",
            "Train_AverageEpLen : 671.1639344262295\n",
            "Train_EnvstepsSoFar : 1326258\n",
            "TimeSinceStart : 3331.9946160316467\n",
            "Training Loss : -246.67156982421875\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 74.19523620605469\n",
            "Eval_StdReturn : 17.228012084960938\n",
            "Eval_MaxReturn : 91.42324829101562\n",
            "Eval_MinReturn : 56.96722412109375\n",
            "Eval_AverageEpLen : 593.0\n",
            "Train_AverageReturn : 82.43798065185547\n",
            "Train_StdReturn : 69.98133850097656\n",
            "Train_MaxReturn : 171.5692901611328\n",
            "Train_MinReturn : -193.82760620117188\n",
            "Train_AverageEpLen : 757.8148148148148\n",
            "Train_EnvstepsSoFar : 1367180\n",
            "TimeSinceStart : 3470.7672550678253\n",
            "Training Loss : -48.332427978515625\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.065114974975586\n",
            "Eval_StdReturn : 48.31475067138672\n",
            "Eval_MaxReturn : 21.249637603759766\n",
            "Eval_MinReturn : -75.37986755371094\n",
            "Eval_AverageEpLen : 262.0\n",
            "Train_AverageReturn : 74.00650024414062\n",
            "Train_StdReturn : 62.225868225097656\n",
            "Train_MaxReturn : 179.63726806640625\n",
            "Train_MinReturn : -43.89575958251953\n",
            "Train_AverageEpLen : 682.7966101694915\n",
            "Train_EnvstepsSoFar : 1407465\n",
            "TimeSinceStart : 3607.1179292201996\n",
            "Training Loss : -151.4696044921875\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.784503936767578\n",
            "Eval_StdReturn : 22.091869354248047\n",
            "Eval_MaxReturn : -3.6926345825195312\n",
            "Eval_MinReturn : -47.876373291015625\n",
            "Eval_AverageEpLen : 211.5\n",
            "Train_AverageReturn : 74.88032531738281\n",
            "Train_StdReturn : 70.35612487792969\n",
            "Train_MaxReturn : 172.5784149169922\n",
            "Train_MinReturn : -161.34291076660156\n",
            "Train_AverageEpLen : 647.952380952381\n",
            "Train_EnvstepsSoFar : 1448286\n",
            "TimeSinceStart : 3738.732911348343\n",
            "Training Loss : -241.2215576171875\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 75.5738754272461\n",
            "Eval_StdReturn : 45.28319549560547\n",
            "Eval_MaxReturn : 120.85707092285156\n",
            "Eval_MinReturn : 30.29067611694336\n",
            "Eval_AverageEpLen : 584.5\n",
            "Train_AverageReturn : 87.26029968261719\n",
            "Train_StdReturn : 57.68376922607422\n",
            "Train_MaxReturn : 178.40728759765625\n",
            "Train_MinReturn : -23.596084594726562\n",
            "Train_AverageEpLen : 657.0\n",
            "Train_EnvstepsSoFar : 1489020\n",
            "TimeSinceStart : 3874.5448427200317\n",
            "Training Loss : -106.86005401611328\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.80192565917969\n",
            "Eval_StdReturn : 8.771011352539062\n",
            "Eval_MaxReturn : 42.57293701171875\n",
            "Eval_MinReturn : 25.030914306640625\n",
            "Eval_AverageEpLen : 208.5\n",
            "Train_AverageReturn : 105.09707641601562\n",
            "Train_StdReturn : 59.094268798828125\n",
            "Train_MaxReturn : 243.98838806152344\n",
            "Train_MinReturn : -20.521507263183594\n",
            "Train_AverageEpLen : 744.0370370370371\n",
            "Train_EnvstepsSoFar : 1529198\n",
            "TimeSinceStart : 4008.629783630371\n",
            "Training Loss : -167.8347930908203\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 160.17835998535156\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 160.17835998535156\n",
            "Eval_MinReturn : 160.17835998535156\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 92.16358947753906\n",
            "Train_StdReturn : 61.53620147705078\n",
            "Train_MaxReturn : 240.4020233154297\n",
            "Train_MinReturn : -30.364574432373047\n",
            "Train_AverageEpLen : 667.4754098360655\n",
            "Train_EnvstepsSoFar : 1569914\n",
            "TimeSinceStart : 4133.766917467117\n",
            "Training Loss : 331.8539123535156\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 264.3971252441406\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 264.3971252441406\n",
            "Eval_MinReturn : 264.3971252441406\n",
            "Eval_AverageEpLen : 731.0\n",
            "Train_AverageReturn : 95.04594421386719\n",
            "Train_StdReturn : 71.78898620605469\n",
            "Train_MaxReturn : 289.8401184082031\n",
            "Train_MinReturn : 3.7151737213134766\n",
            "Train_AverageEpLen : 587.3478260869565\n",
            "Train_EnvstepsSoFar : 1610441\n",
            "TimeSinceStart : 4253.051626205444\n",
            "Training Loss : -115.36969757080078\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 45.29374694824219\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 45.29374694824219\n",
            "Eval_MinReturn : 45.29374694824219\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 108.43358612060547\n",
            "Train_StdReturn : 81.93737030029297\n",
            "Train_MaxReturn : 281.6602783203125\n",
            "Train_MinReturn : -102.13804626464844\n",
            "Train_AverageEpLen : 755.566037735849\n",
            "Train_EnvstepsSoFar : 1650486\n",
            "TimeSinceStart : 4382.642365217209\n",
            "Training Loss : -412.5067138671875\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 176.72329711914062\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 176.72329711914062\n",
            "Eval_MinReturn : 176.72329711914062\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 117.63786315917969\n",
            "Train_StdReturn : 87.46646881103516\n",
            "Train_MaxReturn : 285.43206787109375\n",
            "Train_MinReturn : -130.04263305664062\n",
            "Train_AverageEpLen : 819.2244897959183\n",
            "Train_EnvstepsSoFar : 1690628\n",
            "TimeSinceStart : 4516.176490783691\n",
            "Training Loss : 12.815093994140625\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 193.8045196533203\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 193.8045196533203\n",
            "Eval_MinReturn : 193.8045196533203\n",
            "Eval_AverageEpLen : 844.0\n",
            "Train_AverageReturn : 110.94281005859375\n",
            "Train_StdReturn : 87.12004089355469\n",
            "Train_MaxReturn : 269.2524719238281\n",
            "Train_MinReturn : -136.83358764648438\n",
            "Train_AverageEpLen : 817.8775510204082\n",
            "Train_EnvstepsSoFar : 1730704\n",
            "TimeSinceStart : 4649.2997188568115\n",
            "Training Loss : 365.6990051269531\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 87.94789123535156\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 87.94789123535156\n",
            "Eval_MinReturn : 87.94789123535156\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 121.40222930908203\n",
            "Train_StdReturn : 62.264888763427734\n",
            "Train_MaxReturn : 293.47747802734375\n",
            "Train_MinReturn : 13.05908203125\n",
            "Train_AverageEpLen : 859.1914893617021\n",
            "Train_EnvstepsSoFar : 1771086\n",
            "TimeSinceStart : 4789.291181087494\n",
            "Training Loss : 4.997386932373047\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 79.98414611816406\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 79.98414611816406\n",
            "Eval_MinReturn : 79.98414611816406\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 130.3902587890625\n",
            "Train_StdReturn : 77.7641830444336\n",
            "Train_MaxReturn : 267.1009826660156\n",
            "Train_MinReturn : -59.922393798828125\n",
            "Train_AverageEpLen : 887.0\n",
            "Train_EnvstepsSoFar : 1811888\n",
            "TimeSinceStart : 4933.8479697704315\n",
            "Training Loss : -13.833213806152344\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 127.21504211425781\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 127.21504211425781\n",
            "Eval_MinReturn : 127.21504211425781\n",
            "Eval_AverageEpLen : 737.0\n",
            "Train_AverageReturn : 128.24029541015625\n",
            "Train_StdReturn : 75.52079010009766\n",
            "Train_MaxReturn : 252.5177764892578\n",
            "Train_MinReturn : -12.915878295898438\n",
            "Train_AverageEpLen : 888.3913043478261\n",
            "Train_EnvstepsSoFar : 1852754\n",
            "TimeSinceStart : 5087.189076662064\n",
            "Training Loss : 173.41656494140625\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 15.715232849121094\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 15.715232849121094\n",
            "Eval_MinReturn : 15.715232849121094\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 121.10140228271484\n",
            "Train_StdReturn : 86.42118835449219\n",
            "Train_MaxReturn : 266.83270263671875\n",
            "Train_MinReturn : -157.48023986816406\n",
            "Train_AverageEpLen : 876.0652173913044\n",
            "Train_EnvstepsSoFar : 1893053\n",
            "TimeSinceStart : 5240.036780357361\n",
            "Training Loss : -134.1785430908203\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 141.7734832763672\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 141.7734832763672\n",
            "Eval_MinReturn : 141.7734832763672\n",
            "Eval_AverageEpLen : 956.0\n",
            "Train_AverageReturn : 130.64498901367188\n",
            "Train_StdReturn : 80.23343658447266\n",
            "Train_MaxReturn : 277.493408203125\n",
            "Train_MinReturn : 10.477322578430176\n",
            "Train_AverageEpLen : 828.2857142857143\n",
            "Train_EnvstepsSoFar : 1933639\n",
            "TimeSinceStart : 5385.930480718613\n",
            "Training Loss : 0.18424224853515625\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.79747772216797\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 33.79747772216797\n",
            "Eval_MinReturn : 33.79747772216797\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 112.14498138427734\n",
            "Train_StdReturn : 109.3267822265625\n",
            "Train_MaxReturn : 282.536376953125\n",
            "Train_MinReturn : -182.0859375\n",
            "Train_AverageEpLen : 745.0185185185185\n",
            "Train_EnvstepsSoFar : 1973870\n",
            "TimeSinceStart : 5520.468509197235\n",
            "Training Loss : -14.322265625\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 244.5029296875\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 244.5029296875\n",
            "Eval_MinReturn : 244.5029296875\n",
            "Eval_AverageEpLen : 436.0\n",
            "Train_AverageReturn : 147.0963592529297\n",
            "Train_StdReturn : 98.57914733886719\n",
            "Train_MaxReturn : 283.79638671875\n",
            "Train_MinReturn : -98.45585632324219\n",
            "Train_AverageEpLen : 671.3666666666667\n",
            "Train_EnvstepsSoFar : 2014152\n",
            "TimeSinceStart : 5645.043370246887\n",
            "Training Loss : 379.345947265625\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 127.4092025756836\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 127.4092025756836\n",
            "Eval_MinReturn : 127.4092025756836\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 131.38882446289062\n",
            "Train_StdReturn : 104.63048553466797\n",
            "Train_MaxReturn : 286.38372802734375\n",
            "Train_MinReturn : -114.3756103515625\n",
            "Train_AverageEpLen : 682.0847457627119\n",
            "Train_EnvstepsSoFar : 2054395\n",
            "TimeSinceStart : 5773.277674913406\n",
            "Training Loss : 181.720458984375\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -112.11328887939453\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : -112.11328887939453\n",
            "Eval_MinReturn : -112.11328887939453\n",
            "Eval_AverageEpLen : 819.0\n",
            "Train_AverageReturn : 102.46349334716797\n",
            "Train_StdReturn : 117.51477813720703\n",
            "Train_MaxReturn : 280.9493408203125\n",
            "Train_MinReturn : -202.7613525390625\n",
            "Train_AverageEpLen : 691.3103448275862\n",
            "Train_EnvstepsSoFar : 2094491\n",
            "TimeSinceStart : 5904.373704195023\n",
            "Training Loss : 54.153709411621094\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 127.44515991210938\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 127.44515991210938\n",
            "Eval_MinReturn : 127.44515991210938\n",
            "Eval_AverageEpLen : 611.0\n",
            "Train_AverageReturn : 102.85680389404297\n",
            "Train_StdReturn : 112.30530548095703\n",
            "Train_MaxReturn : 266.8987731933594\n",
            "Train_MinReturn : -310.2667541503906\n",
            "Train_AverageEpLen : 717.2280701754386\n",
            "Train_EnvstepsSoFar : 2135373\n",
            "TimeSinceStart : 6033.102813959122\n",
            "Training Loss : -50.45703125\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -176.95542907714844\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : -176.95542907714844\n",
            "Eval_MinReturn : -176.95542907714844\n",
            "Eval_AverageEpLen : 631.0\n",
            "Train_AverageReturn : 97.49931335449219\n",
            "Train_StdReturn : 98.44403076171875\n",
            "Train_MaxReturn : 269.64794921875\n",
            "Train_MinReturn : -115.14495849609375\n",
            "Train_AverageEpLen : 700.1034482758621\n",
            "Train_EnvstepsSoFar : 2175979\n",
            "TimeSinceStart : 6163.966959476471\n",
            "Training Loss : -73.52163696289062\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 22.744028091430664\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 22.744028091430664\n",
            "Eval_MinReturn : 22.744028091430664\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 109.99454498291016\n",
            "Train_StdReturn : 125.5518798828125\n",
            "Train_MaxReturn : 292.59832763671875\n",
            "Train_MinReturn : -177.1087188720703\n",
            "Train_AverageEpLen : 711.140350877193\n",
            "Train_EnvstepsSoFar : 2216514\n",
            "TimeSinceStart : 6293.947399139404\n",
            "Training Loss : 83.05921936035156\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 135.5264892578125\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 135.5264892578125\n",
            "Eval_MinReturn : 135.5264892578125\n",
            "Eval_AverageEpLen : 826.0\n",
            "Train_AverageReturn : 81.2566146850586\n",
            "Train_StdReturn : 129.9957275390625\n",
            "Train_MaxReturn : 274.658935546875\n",
            "Train_MinReturn : -250.75299072265625\n",
            "Train_AverageEpLen : 741.5090909090909\n",
            "Train_EnvstepsSoFar : 2257297\n",
            "TimeSinceStart : 6427.689009666443\n",
            "Training Loss : -64.19354248046875\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 195.5763397216797\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 195.5763397216797\n",
            "Eval_MinReturn : 195.5763397216797\n",
            "Eval_AverageEpLen : 812.0\n",
            "Train_AverageReturn : 122.64095306396484\n",
            "Train_StdReturn : 111.07144927978516\n",
            "Train_MaxReturn : 276.9958190917969\n",
            "Train_MinReturn : -166.73858642578125\n",
            "Train_AverageEpLen : 708.438596491228\n",
            "Train_EnvstepsSoFar : 2297678\n",
            "TimeSinceStart : 6562.41770362854\n",
            "Training Loss : 219.1219940185547\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 252.78868103027344\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 252.78868103027344\n",
            "Eval_MinReturn : 252.78868103027344\n",
            "Eval_AverageEpLen : 420.0\n",
            "Train_AverageReturn : 101.73345184326172\n",
            "Train_StdReturn : 127.3064193725586\n",
            "Train_MaxReturn : 264.73248291015625\n",
            "Train_MinReturn : -191.16433715820312\n",
            "Train_AverageEpLen : 715.0\n",
            "Train_EnvstepsSoFar : 2337718\n",
            "TimeSinceStart : 6691.08399105072\n",
            "Training Loss : 550.3270263671875\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 21.6124267578125\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 21.6124267578125\n",
            "Eval_MinReturn : 21.6124267578125\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 128.32337951660156\n",
            "Train_StdReturn : 122.55879211425781\n",
            "Train_MaxReturn : 297.70343017578125\n",
            "Train_MinReturn : -207.505615234375\n",
            "Train_AverageEpLen : 625.0\n",
            "Train_EnvstepsSoFar : 2377718\n",
            "TimeSinceStart : 6812.2879140377045\n",
            "Training Loss : 91.17192077636719\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 220.6578369140625\n",
            "Eval_StdReturn : 8.07586669921875\n",
            "Eval_MaxReturn : 228.73370361328125\n",
            "Eval_MinReturn : 212.58197021484375\n",
            "Eval_AverageEpLen : 359.0\n",
            "Train_AverageReturn : 120.55291748046875\n",
            "Train_StdReturn : 135.84634399414062\n",
            "Train_MaxReturn : 291.00946044921875\n",
            "Train_MinReturn : -305.3316955566406\n",
            "Train_AverageEpLen : 602.820895522388\n",
            "Train_EnvstepsSoFar : 2418107\n",
            "TimeSinceStart : 6932.9315066337585\n",
            "Training Loss : -295.0166931152344\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 213.740234375\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 213.740234375\n",
            "Eval_MinReturn : 213.740234375\n",
            "Eval_AverageEpLen : 493.0\n",
            "Train_AverageReturn : 137.68360900878906\n",
            "Train_StdReturn : 136.53395080566406\n",
            "Train_MaxReturn : 277.35443115234375\n",
            "Train_MinReturn : -186.12832641601562\n",
            "Train_AverageEpLen : 545.0135135135135\n",
            "Train_EnvstepsSoFar : 2458438\n",
            "TimeSinceStart : 7044.551762342453\n",
            "Training Loss : -205.87911987304688\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 153.27883911132812\n",
            "Eval_StdReturn : 63.980709075927734\n",
            "Eval_MaxReturn : 217.25955200195312\n",
            "Eval_MinReturn : 89.29813385009766\n",
            "Eval_AverageEpLen : 660.5\n",
            "Train_AverageReturn : 131.45741271972656\n",
            "Train_StdReturn : 134.97120666503906\n",
            "Train_MaxReturn : 281.44256591796875\n",
            "Train_MinReturn : -170.5372772216797\n",
            "Train_AverageEpLen : 515.6923076923077\n",
            "Train_EnvstepsSoFar : 2498662\n",
            "TimeSinceStart : 7152.915504455566\n",
            "Training Loss : -244.74758911132812\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 182.37054443359375\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 182.37054443359375\n",
            "Eval_MinReturn : 182.37054443359375\n",
            "Eval_AverageEpLen : 965.0\n",
            "Train_AverageReturn : 131.20236206054688\n",
            "Train_StdReturn : 123.57099151611328\n",
            "Train_MaxReturn : 288.87744140625\n",
            "Train_MinReturn : -182.25433349609375\n",
            "Train_AverageEpLen : 508.1898734177215\n",
            "Train_EnvstepsSoFar : 2538809\n",
            "TimeSinceStart : 7259.962915182114\n",
            "Training Loss : 290.023681640625\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 143.6219024658203\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 143.6219024658203\n",
            "Eval_MinReturn : 143.6219024658203\n",
            "Eval_AverageEpLen : 432.0\n",
            "Train_AverageReturn : 138.3161163330078\n",
            "Train_StdReturn : 134.92376708984375\n",
            "Train_MaxReturn : 287.17901611328125\n",
            "Train_MinReturn : -328.6415100097656\n",
            "Train_AverageEpLen : 364.25\n",
            "Train_EnvstepsSoFar : 2579605\n",
            "TimeSinceStart : 7348.008614063263\n",
            "Training Loss : 95.88748931884766\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.775524139404297\n",
            "Eval_StdReturn : 18.24380874633789\n",
            "Eval_MaxReturn : 2.4682846069335938\n",
            "Eval_MinReturn : -34.01933288574219\n",
            "Eval_AverageEpLen : 290.0\n",
            "Train_AverageReturn : 144.22129821777344\n",
            "Train_StdReturn : 115.4340591430664\n",
            "Train_MaxReturn : 283.07769775390625\n",
            "Train_MinReturn : -140.38494873046875\n",
            "Train_AverageEpLen : 462.60227272727275\n",
            "Train_EnvstepsSoFar : 2620314\n",
            "TimeSinceStart : 7447.899277925491\n",
            "Training Loss : -24.828201293945312\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 149.2423858642578\n",
            "Eval_StdReturn : 122.41814422607422\n",
            "Eval_MaxReturn : 271.6605224609375\n",
            "Eval_MinReturn : 26.824237823486328\n",
            "Eval_AverageEpLen : 220.5\n",
            "Train_AverageReturn : 130.88601684570312\n",
            "Train_StdReturn : 122.35768127441406\n",
            "Train_MaxReturn : 280.65777587890625\n",
            "Train_MinReturn : -178.15524291992188\n",
            "Train_AverageEpLen : 515.3974358974359\n",
            "Train_EnvstepsSoFar : 2660515\n",
            "TimeSinceStart : 7556.17774772644\n",
            "Training Loss : -217.74200439453125\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 233.3327178955078\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 233.3327178955078\n",
            "Eval_MinReturn : 233.3327178955078\n",
            "Eval_AverageEpLen : 428.0\n",
            "Train_AverageReturn : 152.47422790527344\n",
            "Train_StdReturn : 117.92295837402344\n",
            "Train_MaxReturn : 281.2868347167969\n",
            "Train_MinReturn : -178.71043395996094\n",
            "Train_AverageEpLen : 441.2391304347826\n",
            "Train_EnvstepsSoFar : 2701109\n",
            "TimeSinceStart : 7656.761449098587\n",
            "Training Loss : -113.47682189941406\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 53.8704833984375\n",
            "Eval_StdReturn : 210.60977172851562\n",
            "Eval_MaxReturn : 264.4802551269531\n",
            "Eval_MinReturn : -156.73928833007812\n",
            "Eval_AverageEpLen : 279.5\n",
            "Train_AverageReturn : 153.50650024414062\n",
            "Train_StdReturn : 115.8738021850586\n",
            "Train_MaxReturn : 284.75457763671875\n",
            "Train_MinReturn : -139.9807586669922\n",
            "Train_AverageEpLen : 409.88775510204084\n",
            "Train_EnvstepsSoFar : 2741278\n",
            "TimeSinceStart : 7748.509573459625\n",
            "Training Loss : -23.9765625\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 233.36216735839844\n",
            "Eval_StdReturn : 24.501052856445312\n",
            "Eval_MaxReturn : 257.86322021484375\n",
            "Eval_MinReturn : 208.86111450195312\n",
            "Eval_AverageEpLen : 336.0\n",
            "Train_AverageReturn : 152.1938934326172\n",
            "Train_StdReturn : 111.39578247070312\n",
            "Train_MaxReturn : 281.79461669921875\n",
            "Train_MinReturn : -165.2374267578125\n",
            "Train_AverageEpLen : 402.25\n",
            "Train_EnvstepsSoFar : 2781503\n",
            "TimeSinceStart : 7838.157968521118\n",
            "Training Loss : -199.2786865234375\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 95.65419006347656\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 95.65419006347656\n",
            "Eval_MinReturn : 95.65419006347656\n",
            "Eval_AverageEpLen : 545.0\n",
            "Train_AverageReturn : 129.84547424316406\n",
            "Train_StdReturn : 124.61006164550781\n",
            "Train_MaxReturn : 278.2618713378906\n",
            "Train_MinReturn : -190.29547119140625\n",
            "Train_AverageEpLen : 442.94505494505495\n",
            "Train_EnvstepsSoFar : 2821811\n",
            "TimeSinceStart : 7937.909622192383\n",
            "Training Loss : -88.8249740600586\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 238.66856384277344\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 238.66856384277344\n",
            "Eval_MinReturn : 238.66856384277344\n",
            "Eval_AverageEpLen : 615.0\n",
            "Train_AverageReturn : 167.0755615234375\n",
            "Train_StdReturn : 119.47013854980469\n",
            "Train_MaxReturn : 286.2551574707031\n",
            "Train_MinReturn : -167.44259643554688\n",
            "Train_AverageEpLen : 456.2022471910112\n",
            "Train_EnvstepsSoFar : 2862413\n",
            "TimeSinceStart : 8036.548818349838\n",
            "Training Loss : -25.67755889892578\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 211.86871337890625\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 211.86871337890625\n",
            "Eval_MinReturn : 211.86871337890625\n",
            "Eval_AverageEpLen : 625.0\n",
            "Train_AverageReturn : 139.8453369140625\n",
            "Train_StdReturn : 122.33212280273438\n",
            "Train_MaxReturn : 285.5076904296875\n",
            "Train_MinReturn : -214.73818969726562\n",
            "Train_AverageEpLen : 522.1410256410256\n",
            "Train_EnvstepsSoFar : 2903140\n",
            "TimeSinceStart : 8144.045930624008\n",
            "Training Loss : -168.88540649414062\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 210.5714569091797\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 210.5714569091797\n",
            "Eval_MinReturn : 210.5714569091797\n",
            "Eval_AverageEpLen : 435.0\n",
            "Train_AverageReturn : 167.3472137451172\n",
            "Train_StdReturn : 91.11344146728516\n",
            "Train_MaxReturn : 274.2931823730469\n",
            "Train_MinReturn : -118.49087524414062\n",
            "Train_AverageEpLen : 485.855421686747\n",
            "Train_EnvstepsSoFar : 2943466\n",
            "TimeSinceStart : 8247.102708101273\n",
            "Training Loss : 325.29254150390625\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 241.865966796875\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 241.865966796875\n",
            "Eval_MinReturn : 241.865966796875\n",
            "Eval_AverageEpLen : 403.0\n",
            "Train_AverageReturn : 183.69615173339844\n",
            "Train_StdReturn : 85.66996002197266\n",
            "Train_MaxReturn : 270.02197265625\n",
            "Train_MinReturn : -86.94709014892578\n",
            "Train_AverageEpLen : 485.60714285714283\n",
            "Train_EnvstepsSoFar : 2984257\n",
            "TimeSinceStart : 8350.511014699936\n",
            "Training Loss : 207.94528198242188\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 229.07716369628906\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 229.07716369628906\n",
            "Eval_MinReturn : 229.07716369628906\n",
            "Eval_AverageEpLen : 643.0\n",
            "Train_AverageReturn : 151.38111877441406\n",
            "Train_StdReturn : 94.53138732910156\n",
            "Train_MaxReturn : 266.207275390625\n",
            "Train_MinReturn : -142.07699584960938\n",
            "Train_AverageEpLen : 581.3571428571429\n",
            "Train_EnvstepsSoFar : 3024952\n",
            "TimeSinceStart : 8464.052181482315\n",
            "Training Loss : -487.681640625\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 215.5882568359375\n",
            "Eval_StdReturn : 31.02520751953125\n",
            "Eval_MaxReturn : 246.61346435546875\n",
            "Eval_MinReturn : 184.56304931640625\n",
            "Eval_AverageEpLen : 431.5\n",
            "Train_AverageReturn : 156.9320831298828\n",
            "Train_StdReturn : 94.00239562988281\n",
            "Train_MaxReturn : 277.777587890625\n",
            "Train_MinReturn : -13.728796005249023\n",
            "Train_AverageEpLen : 659.2459016393443\n",
            "Train_EnvstepsSoFar : 3065166\n",
            "TimeSinceStart : 8588.941388368607\n",
            "Training Loss : -178.0194091796875\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.97698974609375\n",
            "Eval_StdReturn : 9.862548828125\n",
            "Eval_MaxReturn : 234.83953857421875\n",
            "Eval_MinReturn : 215.11444091796875\n",
            "Eval_AverageEpLen : 469.5\n",
            "Train_AverageReturn : 155.4761199951172\n",
            "Train_StdReturn : 102.14307403564453\n",
            "Train_MaxReturn : 284.11480712890625\n",
            "Train_MinReturn : -220.87039184570312\n",
            "Train_AverageEpLen : 668.0\n",
            "Train_EnvstepsSoFar : 3105246\n",
            "TimeSinceStart : 8708.324708938599\n",
            "Training Loss : -371.6977233886719\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.5755615234375\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 234.5755615234375\n",
            "Eval_MinReturn : 234.5755615234375\n",
            "Eval_AverageEpLen : 586.0\n",
            "Train_AverageReturn : 173.6013641357422\n",
            "Train_StdReturn : 86.66890716552734\n",
            "Train_MaxReturn : 284.72491455078125\n",
            "Train_MinReturn : -59.68135070800781\n",
            "Train_AverageEpLen : 663.8688524590164\n",
            "Train_EnvstepsSoFar : 3145742\n",
            "TimeSinceStart : 8826.362259626389\n",
            "Training Loss : -265.1875\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 102.10173034667969\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 102.10173034667969\n",
            "Eval_MinReturn : 102.10173034667969\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 162.058837890625\n",
            "Train_StdReturn : 74.1329574584961\n",
            "Train_MaxReturn : 266.940673828125\n",
            "Train_MinReturn : 40.7163200378418\n",
            "Train_AverageEpLen : 731.1636363636363\n",
            "Train_EnvstepsSoFar : 3185956\n",
            "TimeSinceStart : 8949.530787706375\n",
            "Training Loss : -335.85394287109375\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 122.40252685546875\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 122.40252685546875\n",
            "Eval_MinReturn : 122.40252685546875\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 162.5794677734375\n",
            "Train_StdReturn : 86.60589599609375\n",
            "Train_MaxReturn : 283.43212890625\n",
            "Train_MinReturn : -120.44369506835938\n",
            "Train_AverageEpLen : 698.0862068965517\n",
            "Train_EnvstepsSoFar : 3226445\n",
            "TimeSinceStart : 9071.040506601334\n",
            "Training Loss : 160.04440307617188\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 128.38685607910156\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 128.38685607910156\n",
            "Eval_MinReturn : 128.38685607910156\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 165.36273193359375\n",
            "Train_StdReturn : 72.24849700927734\n",
            "Train_MaxReturn : 276.61798095703125\n",
            "Train_MinReturn : 43.52970504760742\n",
            "Train_AverageEpLen : 757.8301886792453\n",
            "Train_EnvstepsSoFar : 3266610\n",
            "TimeSinceStart : 9190.11890745163\n",
            "Training Loss : -303.038818359375\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 266.91766357421875\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 266.91766357421875\n",
            "Eval_MinReturn : 266.91766357421875\n",
            "Eval_AverageEpLen : 879.0\n",
            "Train_AverageReturn : 170.3387908935547\n",
            "Train_StdReturn : 73.135986328125\n",
            "Train_MaxReturn : 287.293212890625\n",
            "Train_MinReturn : -64.58683776855469\n",
            "Train_AverageEpLen : 799.7058823529412\n",
            "Train_EnvstepsSoFar : 3307395\n",
            "TimeSinceStart : 9310.943220853806\n",
            "Training Loss : -62.44843673706055\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 195.01092529296875\n",
            "Eval_StdReturn : 71.19425201416016\n",
            "Eval_MaxReturn : 266.2051696777344\n",
            "Eval_MinReturn : 123.8166732788086\n",
            "Eval_AverageEpLen : 631.5\n",
            "Train_AverageReturn : 159.90675354003906\n",
            "Train_StdReturn : 57.3271598815918\n",
            "Train_MaxReturn : 290.071533203125\n",
            "Train_MinReturn : 60.80132293701172\n",
            "Train_AverageEpLen : 881.3260869565217\n",
            "Train_EnvstepsSoFar : 3347936\n",
            "TimeSinceStart : 9442.613320589066\n",
            "Training Loss : -262.91937255859375\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 144.57054138183594\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 144.57054138183594\n",
            "Eval_MinReturn : 144.57054138183594\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 154.74002075195312\n",
            "Train_StdReturn : 55.17633056640625\n",
            "Train_MaxReturn : 285.84912109375\n",
            "Train_MinReturn : 28.249488830566406\n",
            "Train_AverageEpLen : 867.9574468085107\n",
            "Train_EnvstepsSoFar : 3388730\n",
            "TimeSinceStart : 9570.958992958069\n",
            "Training Loss : -249.02232360839844\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 170.150390625\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 170.150390625\n",
            "Eval_MinReturn : 170.150390625\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 148.28289794921875\n",
            "Train_StdReturn : 55.7103271484375\n",
            "Train_MaxReturn : 281.48199462890625\n",
            "Train_MinReturn : 40.07746124267578\n",
            "Train_AverageEpLen : 815.52\n",
            "Train_EnvstepsSoFar : 3429506\n",
            "TimeSinceStart : 9691.702492952347\n",
            "Training Loss : -270.77667236328125\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 111.05294799804688\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 111.05294799804688\n",
            "Eval_MinReturn : 111.05294799804688\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 154.5822296142578\n",
            "Train_StdReturn : 38.1113166809082\n",
            "Train_MaxReturn : 277.0050354003906\n",
            "Train_MinReturn : 53.34879684448242\n",
            "Train_AverageEpLen : 935.2325581395348\n",
            "Train_EnvstepsSoFar : 3469721\n",
            "TimeSinceStart : 9812.183913230896\n",
            "Training Loss : 40.40243911743164\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 136.947998046875\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 136.947998046875\n",
            "Eval_MinReturn : 136.947998046875\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 145.21641540527344\n",
            "Train_StdReturn : 47.10079574584961\n",
            "Train_MaxReturn : 290.42657470703125\n",
            "Train_MinReturn : 25.499252319335938\n",
            "Train_AverageEpLen : 860.1276595744681\n",
            "Train_EnvstepsSoFar : 3510147\n",
            "TimeSinceStart : 9931.528761148453\n",
            "Training Loss : 8.740310668945312\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 186.5458221435547\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 186.5458221435547\n",
            "Eval_MinReturn : 186.5458221435547\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 153.90870666503906\n",
            "Train_StdReturn : 36.15946578979492\n",
            "Train_MaxReturn : 260.29949951171875\n",
            "Train_MinReturn : 46.13642120361328\n",
            "Train_AverageEpLen : 910.5333333333333\n",
            "Train_EnvstepsSoFar : 3551121\n",
            "TimeSinceStart : 10053.407588481903\n",
            "Training Loss : -172.89007568359375\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 136.51292419433594\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 136.51292419433594\n",
            "Eval_MinReturn : 136.51292419433594\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 151.68646240234375\n",
            "Train_StdReturn : 30.96660804748535\n",
            "Train_MaxReturn : 193.3594512939453\n",
            "Train_MinReturn : 58.96520233154297\n",
            "Train_AverageEpLen : 940.3953488372093\n",
            "Train_EnvstepsSoFar : 3591558\n",
            "TimeSinceStart : 10174.682295560837\n",
            "Training Loss : 80.49827575683594\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 157.12208557128906\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 157.12208557128906\n",
            "Eval_MinReturn : 157.12208557128906\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 164.8189697265625\n",
            "Train_StdReturn : 26.534847259521484\n",
            "Train_MaxReturn : 268.2198791503906\n",
            "Train_MinReturn : 70.73501586914062\n",
            "Train_AverageEpLen : 974.2857142857143\n",
            "Train_EnvstepsSoFar : 3632478\n",
            "TimeSinceStart : 10296.62826013565\n",
            "Training Loss : 109.07949829101562\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 161.4851531982422\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 161.4851531982422\n",
            "Eval_MinReturn : 161.4851531982422\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 160.1879119873047\n",
            "Train_StdReturn : 30.780073165893555\n",
            "Train_MaxReturn : 228.16656494140625\n",
            "Train_MinReturn : 35.44872283935547\n",
            "Train_AverageEpLen : 942.2093023255813\n",
            "Train_EnvstepsSoFar : 3672993\n",
            "TimeSinceStart : 10422.007741212845\n",
            "Training Loss : 15.762840270996094\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.18402099609375\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 107.18402099609375\n",
            "Eval_MinReturn : 107.18402099609375\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 147.07835388183594\n",
            "Train_StdReturn : 43.85512161254883\n",
            "Train_MaxReturn : 263.7637939453125\n",
            "Train_MinReturn : 4.774024963378906\n",
            "Train_AverageEpLen : 929.5454545454545\n",
            "Train_EnvstepsSoFar : 3713893\n",
            "TimeSinceStart : 10548.816361665726\n",
            "Training Loss : 48.83279800415039\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 106.80584716796875\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 106.80584716796875\n",
            "Eval_MinReturn : 106.80584716796875\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 134.79872131347656\n",
            "Train_StdReturn : 47.69014358520508\n",
            "Train_MaxReturn : 267.02606201171875\n",
            "Train_MinReturn : -2.5232925415039062\n",
            "Train_AverageEpLen : 896.2444444444444\n",
            "Train_EnvstepsSoFar : 3754224\n",
            "TimeSinceStart : 10686.06361413002\n",
            "Training Loss : -481.05694580078125\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 147.1660919189453\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 147.1660919189453\n",
            "Eval_MinReturn : 147.1660919189453\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 144.31753540039062\n",
            "Train_StdReturn : 44.71713638305664\n",
            "Train_MaxReturn : 284.1854248046875\n",
            "Train_MinReturn : 39.5808219909668\n",
            "Train_AverageEpLen : 944.7906976744187\n",
            "Train_EnvstepsSoFar : 3794850\n",
            "TimeSinceStart : 10818.893727302551\n",
            "Training Loss : 134.06832885742188\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 119.23963928222656\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 119.23963928222656\n",
            "Eval_MinReturn : 119.23963928222656\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 146.79400634765625\n",
            "Train_StdReturn : 45.20397186279297\n",
            "Train_MaxReturn : 276.491943359375\n",
            "Train_MinReturn : 25.580581665039062\n",
            "Train_AverageEpLen : 922.2727272727273\n",
            "Train_EnvstepsSoFar : 3835430\n",
            "TimeSinceStart : 10951.29117679596\n",
            "Training Loss : -39.64531707763672\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 176.1136932373047\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 176.1136932373047\n",
            "Eval_MinReturn : 176.1136932373047\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 149.6871795654297\n",
            "Train_StdReturn : 46.2299690246582\n",
            "Train_MaxReturn : 283.98583984375\n",
            "Train_MinReturn : 30.422561645507812\n",
            "Train_AverageEpLen : 909.3181818181819\n",
            "Train_EnvstepsSoFar : 3875440\n",
            "TimeSinceStart : 11082.147010326385\n",
            "Training Loss : -414.4808349609375\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 140.0716552734375\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 140.0716552734375\n",
            "Eval_MinReturn : 140.0716552734375\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 136.61439514160156\n",
            "Train_StdReturn : 37.39499282836914\n",
            "Train_MaxReturn : 261.8418884277344\n",
            "Train_MinReturn : 25.217369079589844\n",
            "Train_AverageEpLen : 949.046511627907\n",
            "Train_EnvstepsSoFar : 3916249\n",
            "TimeSinceStart : 11218.342480659485\n",
            "Training Loss : -195.04718017578125\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 162.5585479736328\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 162.5585479736328\n",
            "Eval_MinReturn : 162.5585479736328\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 144.15121459960938\n",
            "Train_StdReturn : 36.7049674987793\n",
            "Train_MaxReturn : 280.0279541015625\n",
            "Train_MinReturn : 33.219642639160156\n",
            "Train_AverageEpLen : 955.5\n",
            "Train_EnvstepsSoFar : 3956380\n",
            "TimeSinceStart : 11352.769087791443\n",
            "Training Loss : 154.02008056640625\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 171.22824096679688\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 171.22824096679688\n",
            "Eval_MinReturn : 171.22824096679688\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 159.750244140625\n",
            "Train_StdReturn : 32.29533004760742\n",
            "Train_MaxReturn : 274.50421142578125\n",
            "Train_MinReturn : 120.23625183105469\n",
            "Train_AverageEpLen : 976.780487804878\n",
            "Train_EnvstepsSoFar : 3996428\n",
            "TimeSinceStart : 11476.616807699203\n",
            "Training Loss : -445.568115234375\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 169.43553161621094\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 169.43553161621094\n",
            "Eval_MinReturn : 169.43553161621094\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 151.9038848876953\n",
            "Train_StdReturn : 34.14383316040039\n",
            "Train_MaxReturn : 197.5133819580078\n",
            "Train_MinReturn : -10.642662048339844\n",
            "Train_AverageEpLen : 960.7142857142857\n",
            "Train_EnvstepsSoFar : 4036778\n",
            "TimeSinceStart : 11599.454854249954\n",
            "Training Loss : 22.449237823486328\n",
            "Initial_DataCollection_AverageReturn : -312.86669921875\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name LunarLanderContinuous-v2 --ep_len 1000 \\\n",
        "    --discount 0.99 -n 100 -l 2 -s 64 -b 40000 -lr 0.005 \\\n",
        "    --reward_to_go --nn_baseline --exp_name q3_b40000_r0.005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPxNrIeH-sUa"
      },
      "source": [
        "#HalfCheetah"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1c8wyjwAmN5",
        "outputId": "f4ffd235-89ee-4d7d-c4d4-ddefa85ef305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q4_search_b10000_lr0005_rtg_nnbaseline_HalfCheetah-v2_08-05-2022_19-28-50\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -109.93585205078125\n",
            "Eval_StdReturn : 28.696123123168945\n",
            "Eval_MaxReturn : -84.45085144042969\n",
            "Eval_MinReturn : -150.029541015625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -89.69666290283203\n",
            "Train_StdReturn : 40.17568588256836\n",
            "Train_MaxReturn : 11.764884948730469\n",
            "Train_MinReturn : -178.39559936523438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 10050\n",
            "TimeSinceStart : 11.21988558769226\n",
            "Training Loss : -594.497802734375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -76.0262680053711\n",
            "Eval_StdReturn : 17.410524368286133\n",
            "Eval_MaxReturn : -56.84567642211914\n",
            "Eval_MinReturn : -98.98698425292969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -91.4492416381836\n",
            "Train_StdReturn : 34.832763671875\n",
            "Train_MaxReturn : -9.281532287597656\n",
            "Train_MinReturn : -196.26231384277344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 20100\n",
            "TimeSinceStart : 22.40818214416504\n",
            "Training Loss : -790.5743408203125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -127.92074584960938\n",
            "Eval_StdReturn : 35.554359436035156\n",
            "Eval_MaxReturn : -90.490478515625\n",
            "Eval_MinReturn : -175.71163940429688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -87.39057922363281\n",
            "Train_StdReturn : 38.77783203125\n",
            "Train_MaxReturn : 11.486871719360352\n",
            "Train_MinReturn : -186.36941528320312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 30150\n",
            "TimeSinceStart : 34.0995454788208\n",
            "Training Loss : -772.0904541015625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -94.68631744384766\n",
            "Eval_StdReturn : 31.485275268554688\n",
            "Eval_MaxReturn : -53.942623138427734\n",
            "Eval_MinReturn : -130.61282348632812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -84.3447265625\n",
            "Train_StdReturn : 35.974327087402344\n",
            "Train_MaxReturn : -3.8416919708251953\n",
            "Train_MinReturn : -165.24893188476562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 40200\n",
            "TimeSinceStart : 45.239386558532715\n",
            "Training Loss : -928.1629028320312\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -83.1507797241211\n",
            "Eval_StdReturn : 3.04738187789917\n",
            "Eval_MaxReturn : -79.32483673095703\n",
            "Eval_MinReturn : -86.78172302246094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -85.84059143066406\n",
            "Train_StdReturn : 37.05912399291992\n",
            "Train_MaxReturn : -0.9085664749145508\n",
            "Train_MinReturn : -191.39483642578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50250\n",
            "TimeSinceStart : 56.33263158798218\n",
            "Training Loss : -504.3857421875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -108.64761352539062\n",
            "Eval_StdReturn : 34.41657257080078\n",
            "Eval_MaxReturn : -63.09326934814453\n",
            "Eval_MinReturn : -146.26904296875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -87.1074447631836\n",
            "Train_StdReturn : 39.624488830566406\n",
            "Train_MaxReturn : -13.392494201660156\n",
            "Train_MinReturn : -188.46182250976562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 60300\n",
            "TimeSinceStart : 67.44551253318787\n",
            "Training Loss : -550.963134765625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -82.03079986572266\n",
            "Eval_StdReturn : 17.604190826416016\n",
            "Eval_MaxReturn : -69.196533203125\n",
            "Eval_MinReturn : -106.92284393310547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -83.09355926513672\n",
            "Train_StdReturn : 39.58574295043945\n",
            "Train_MaxReturn : -18.959840774536133\n",
            "Train_MinReturn : -213.1837615966797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 70350\n",
            "TimeSinceStart : 78.53900671005249\n",
            "Training Loss : -943.23291015625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -80.27570343017578\n",
            "Eval_StdReturn : 39.392333984375\n",
            "Eval_MaxReturn : -31.765090942382812\n",
            "Eval_MinReturn : -128.25177001953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -76.48530578613281\n",
            "Train_StdReturn : 44.06564712524414\n",
            "Train_MaxReturn : 32.7755126953125\n",
            "Train_MinReturn : -200.31832885742188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 80400\n",
            "TimeSinceStart : 89.65295720100403\n",
            "Training Loss : -586.5796508789062\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -58.977630615234375\n",
            "Eval_StdReturn : 30.642261505126953\n",
            "Eval_MaxReturn : -22.801288604736328\n",
            "Eval_MinReturn : -97.72679138183594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -73.06816864013672\n",
            "Train_StdReturn : 33.52214813232422\n",
            "Train_MaxReturn : 5.699337482452393\n",
            "Train_MinReturn : -166.042236328125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 90450\n",
            "TimeSinceStart : 100.78236198425293\n",
            "Training Loss : -498.8280029296875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -86.890869140625\n",
            "Eval_StdReturn : 5.380568027496338\n",
            "Eval_MaxReturn : -80.42738342285156\n",
            "Eval_MinReturn : -93.60015106201172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -78.2951889038086\n",
            "Train_StdReturn : 29.961811065673828\n",
            "Train_MaxReturn : -6.937883377075195\n",
            "Train_MinReturn : -159.39035034179688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100500\n",
            "TimeSinceStart : 111.98120975494385\n",
            "Training Loss : -710.968994140625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -73.8011474609375\n",
            "Eval_StdReturn : 21.26218032836914\n",
            "Eval_MaxReturn : -45.22837448120117\n",
            "Eval_MinReturn : -96.20036315917969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -76.7349853515625\n",
            "Train_StdReturn : 32.86245346069336\n",
            "Train_MaxReturn : -8.832087516784668\n",
            "Train_MinReturn : -152.6584014892578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 110550\n",
            "TimeSinceStart : 123.0911157131195\n",
            "Training Loss : -979.3428955078125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -89.74832153320312\n",
            "Eval_StdReturn : 18.514692306518555\n",
            "Eval_MaxReturn : -73.2552261352539\n",
            "Eval_MinReturn : -115.60662841796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -74.3985595703125\n",
            "Train_StdReturn : 41.329872131347656\n",
            "Train_MaxReturn : -8.343355178833008\n",
            "Train_MinReturn : -200.09744262695312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 120600\n",
            "TimeSinceStart : 134.19172978401184\n",
            "Training Loss : -618.4567260742188\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.72684097290039\n",
            "Eval_StdReturn : 2.675712823867798\n",
            "Eval_MaxReturn : -57.52734375\n",
            "Eval_MinReturn : -64.07632446289062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -73.63104248046875\n",
            "Train_StdReturn : 29.176671981811523\n",
            "Train_MaxReturn : -9.15896224975586\n",
            "Train_MinReturn : -162.2747039794922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 130650\n",
            "TimeSinceStart : 145.41577291488647\n",
            "Training Loss : -756.5451049804688\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -95.11811065673828\n",
            "Eval_StdReturn : 14.6112060546875\n",
            "Eval_MaxReturn : -78.8897933959961\n",
            "Eval_MinReturn : -114.30982971191406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -67.72683715820312\n",
            "Train_StdReturn : 33.44994354248047\n",
            "Train_MaxReturn : 17.44020652770996\n",
            "Train_MinReturn : -146.49835205078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 140700\n",
            "TimeSinceStart : 156.51906871795654\n",
            "Training Loss : -525.287109375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -57.34754943847656\n",
            "Eval_StdReturn : 11.233145713806152\n",
            "Eval_MaxReturn : -41.586669921875\n",
            "Eval_MinReturn : -66.95174407958984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -67.11063385009766\n",
            "Train_StdReturn : 30.65034294128418\n",
            "Train_MaxReturn : -7.19975471496582\n",
            "Train_MinReturn : -145.7237091064453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150750\n",
            "TimeSinceStart : 167.6806936264038\n",
            "Training Loss : -672.71337890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -63.71388244628906\n",
            "Eval_StdReturn : 14.572257041931152\n",
            "Eval_MaxReturn : -43.19767761230469\n",
            "Eval_MinReturn : -75.65719604492188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -69.10037231445312\n",
            "Train_StdReturn : 35.155601501464844\n",
            "Train_MaxReturn : 35.30580520629883\n",
            "Train_MinReturn : -146.36526489257812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 160800\n",
            "TimeSinceStart : 178.89528918266296\n",
            "Training Loss : -907.277587890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.45907974243164\n",
            "Eval_StdReturn : 4.617094993591309\n",
            "Eval_MaxReturn : -53.9874153137207\n",
            "Eval_MinReturn : -64.44624328613281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -62.93974304199219\n",
            "Train_StdReturn : 36.377952575683594\n",
            "Train_MaxReturn : 1.4154725074768066\n",
            "Train_MinReturn : -264.9469909667969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 170850\n",
            "TimeSinceStart : 190.08194828033447\n",
            "Training Loss : -981.571533203125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.7334098815918\n",
            "Eval_StdReturn : 22.805431365966797\n",
            "Eval_MaxReturn : -28.26323699951172\n",
            "Eval_MinReturn : -84.1031723022461\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -61.1399040222168\n",
            "Train_StdReturn : 28.066341400146484\n",
            "Train_MaxReturn : 0.9238119125366211\n",
            "Train_MinReturn : -127.1011962890625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 180900\n",
            "TimeSinceStart : 201.27135491371155\n",
            "Training Loss : -673.4058837890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -74.6897964477539\n",
            "Eval_StdReturn : 63.18547439575195\n",
            "Eval_MaxReturn : -12.640146255493164\n",
            "Eval_MinReturn : -161.401123046875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -61.22383499145508\n",
            "Train_StdReturn : 26.991653442382812\n",
            "Train_MaxReturn : -8.06292724609375\n",
            "Train_MinReturn : -135.96438598632812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 190950\n",
            "TimeSinceStart : 212.391131401062\n",
            "Training Loss : -785.6578369140625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -59.204620361328125\n",
            "Eval_StdReturn : 32.6316032409668\n",
            "Eval_MaxReturn : -13.063833236694336\n",
            "Eval_MinReturn : -82.98438262939453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -54.50385665893555\n",
            "Train_StdReturn : 29.2785587310791\n",
            "Train_MaxReturn : 15.530704498291016\n",
            "Train_MinReturn : -134.98324584960938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 201000\n",
            "TimeSinceStart : 223.6042082309723\n",
            "Training Loss : -590.2191162109375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.11750411987305\n",
            "Eval_StdReturn : 6.312065124511719\n",
            "Eval_MaxReturn : -51.72502136230469\n",
            "Eval_MinReturn : -66.94773864746094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -56.67873764038086\n",
            "Train_StdReturn : 31.673673629760742\n",
            "Train_MaxReturn : 40.28327178955078\n",
            "Train_MinReturn : -125.12155151367188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 211050\n",
            "TimeSinceStart : 234.8788161277771\n",
            "Training Loss : -398.616455078125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.89372253417969\n",
            "Eval_StdReturn : 30.760597229003906\n",
            "Eval_MaxReturn : -20.908939361572266\n",
            "Eval_MinReturn : -96.05550384521484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -56.872005462646484\n",
            "Train_StdReturn : 27.157798767089844\n",
            "Train_MaxReturn : 16.819900512695312\n",
            "Train_MinReturn : -149.275634765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 221100\n",
            "TimeSinceStart : 246.18556880950928\n",
            "Training Loss : -1037.7255859375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -5.56080961227417\n",
            "Eval_StdReturn : 22.3707275390625\n",
            "Eval_MaxReturn : 24.08281135559082\n",
            "Eval_MinReturn : -29.95424461364746\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -61.298099517822266\n",
            "Train_StdReturn : 26.89995574951172\n",
            "Train_MaxReturn : -6.60453987121582\n",
            "Train_MinReturn : -130.2169189453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 231150\n",
            "TimeSinceStart : 257.3208932876587\n",
            "Training Loss : -728.464599609375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -74.56952667236328\n",
            "Eval_StdReturn : 1.4620699882507324\n",
            "Eval_MaxReturn : -73.0767822265625\n",
            "Eval_MinReturn : -76.5549545288086\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -55.907440185546875\n",
            "Train_StdReturn : 27.742780685424805\n",
            "Train_MaxReturn : 1.2462701797485352\n",
            "Train_MinReturn : -125.75847625732422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 241200\n",
            "TimeSinceStart : 268.53298902511597\n",
            "Training Loss : -656.7396240234375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -54.4824333190918\n",
            "Eval_StdReturn : 31.3464298248291\n",
            "Eval_MaxReturn : -20.80015754699707\n",
            "Eval_MinReturn : -96.28406524658203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -54.849082946777344\n",
            "Train_StdReturn : 22.640748977661133\n",
            "Train_MaxReturn : -8.014871597290039\n",
            "Train_MinReturn : -109.0977783203125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 251250\n",
            "TimeSinceStart : 279.655633687973\n",
            "Training Loss : -652.732666015625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.550201416015625\n",
            "Eval_StdReturn : 27.41400718688965\n",
            "Eval_MaxReturn : -0.5422395467758179\n",
            "Eval_MinReturn : -66.99852752685547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -59.29603576660156\n",
            "Train_StdReturn : 24.857885360717773\n",
            "Train_MaxReturn : -11.857392311096191\n",
            "Train_MinReturn : -129.57797241210938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 261300\n",
            "TimeSinceStart : 290.88336634635925\n",
            "Training Loss : -775.0698852539062\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.92477798461914\n",
            "Eval_StdReturn : 14.087299346923828\n",
            "Eval_MaxReturn : -24.419837951660156\n",
            "Eval_MinReturn : -55.76288604736328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -47.057674407958984\n",
            "Train_StdReturn : 27.64733123779297\n",
            "Train_MaxReturn : 28.022781372070312\n",
            "Train_MinReturn : -109.49799346923828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 271350\n",
            "TimeSinceStart : 302.0545802116394\n",
            "Training Loss : -421.07281494140625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.76999282836914\n",
            "Eval_StdReturn : 35.64567565917969\n",
            "Eval_MaxReturn : -27.59273338317871\n",
            "Eval_MinReturn : -110.95001220703125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -55.02385711669922\n",
            "Train_StdReturn : 29.63568687438965\n",
            "Train_MaxReturn : 8.720518112182617\n",
            "Train_MinReturn : -122.04849243164062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 281400\n",
            "TimeSinceStart : 313.25865483283997\n",
            "Training Loss : -633.739501953125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.917724609375\n",
            "Eval_StdReturn : 4.856295108795166\n",
            "Eval_MaxReturn : -54.17896270751953\n",
            "Eval_MinReturn : -65.43480682373047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.16931915283203\n",
            "Train_StdReturn : 29.08896255493164\n",
            "Train_MaxReturn : 12.042778968811035\n",
            "Train_MinReturn : -142.63497924804688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 291450\n",
            "TimeSinceStart : 324.4382040500641\n",
            "Training Loss : -467.1969299316406\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.100284576416016\n",
            "Eval_StdReturn : 26.08272933959961\n",
            "Eval_MaxReturn : -8.720142364501953\n",
            "Eval_MinReturn : -69.26262664794922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.1545295715332\n",
            "Train_StdReturn : 23.5613956451416\n",
            "Train_MaxReturn : -2.6100568771362305\n",
            "Train_MinReturn : -103.80879211425781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 301500\n",
            "TimeSinceStart : 335.63144397735596\n",
            "Training Loss : -752.2435302734375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.6325569152832\n",
            "Eval_StdReturn : 12.479619026184082\n",
            "Eval_MaxReturn : -21.792924880981445\n",
            "Eval_MinReturn : -52.037086486816406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -56.666725158691406\n",
            "Train_StdReturn : 34.121742248535156\n",
            "Train_MaxReturn : -1.0290679931640625\n",
            "Train_MinReturn : -226.25741577148438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 311550\n",
            "TimeSinceStart : 346.8096139431\n",
            "Training Loss : -373.25244140625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -64.50467681884766\n",
            "Eval_StdReturn : 9.388771057128906\n",
            "Eval_MaxReturn : -57.351619720458984\n",
            "Eval_MinReturn : -77.76876831054688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.35468673706055\n",
            "Train_StdReturn : 29.11703109741211\n",
            "Train_MaxReturn : 0.7055339813232422\n",
            "Train_MinReturn : -119.15565490722656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 321600\n",
            "TimeSinceStart : 358.00824785232544\n",
            "Training Loss : -667.339599609375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -73.99170684814453\n",
            "Eval_StdReturn : 24.641132354736328\n",
            "Eval_MaxReturn : -52.45646667480469\n",
            "Eval_MinReturn : -108.4859619140625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.978511810302734\n",
            "Train_StdReturn : 29.320707321166992\n",
            "Train_MaxReturn : 19.21038246154785\n",
            "Train_MinReturn : -155.9505615234375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 331650\n",
            "TimeSinceStart : 369.1101543903351\n",
            "Training Loss : -386.2683410644531\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -62.85084915161133\n",
            "Eval_StdReturn : 20.707061767578125\n",
            "Eval_MaxReturn : -47.47774887084961\n",
            "Eval_MinReturn : -92.1226806640625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -57.75224685668945\n",
            "Train_StdReturn : 28.343618392944336\n",
            "Train_MaxReturn : -2.9181156158447266\n",
            "Train_MinReturn : -142.71827697753906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 341700\n",
            "TimeSinceStart : 380.20115542411804\n",
            "Training Loss : -858.7710571289062\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -78.98487091064453\n",
            "Eval_StdReturn : 16.902538299560547\n",
            "Eval_MaxReturn : -65.04200744628906\n",
            "Eval_MinReturn : -102.77120971679688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.040199279785156\n",
            "Train_StdReturn : 27.533546447753906\n",
            "Train_MaxReturn : 17.64371109008789\n",
            "Train_MinReturn : -112.45431518554688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 351750\n",
            "TimeSinceStart : 391.4089183807373\n",
            "Training Loss : -768.5400390625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.17461585998535\n",
            "Eval_StdReturn : 14.342996597290039\n",
            "Eval_MaxReturn : -5.133238792419434\n",
            "Eval_MinReturn : -38.14982604980469\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -48.58920669555664\n",
            "Train_StdReturn : 29.695858001708984\n",
            "Train_MaxReturn : 1.5478696823120117\n",
            "Train_MinReturn : -146.29403686523438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 361800\n",
            "TimeSinceStart : 402.5317144393921\n",
            "Training Loss : -578.0440673828125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.47773742675781\n",
            "Eval_StdReturn : 4.92881965637207\n",
            "Eval_MaxReturn : -53.97323989868164\n",
            "Eval_MinReturn : -65.89990234375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.701194763183594\n",
            "Train_StdReturn : 30.216089248657227\n",
            "Train_MaxReturn : 30.378080368041992\n",
            "Train_MinReturn : -143.17860412597656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 371850\n",
            "TimeSinceStart : 413.78270196914673\n",
            "Training Loss : -534.6089477539062\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.21565246582031\n",
            "Eval_StdReturn : 10.840435981750488\n",
            "Eval_MaxReturn : -40.195377349853516\n",
            "Eval_MinReturn : -65.38399505615234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.48476791381836\n",
            "Train_StdReturn : 28.21965217590332\n",
            "Train_MaxReturn : 31.079204559326172\n",
            "Train_MinReturn : -112.54005432128906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 381900\n",
            "TimeSinceStart : 424.96326208114624\n",
            "Training Loss : -957.644287109375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.06834411621094\n",
            "Eval_StdReturn : 14.943394660949707\n",
            "Eval_MaxReturn : -31.37027359008789\n",
            "Eval_MinReturn : -66.56776428222656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.11164093017578\n",
            "Train_StdReturn : 26.712112426757812\n",
            "Train_MaxReturn : 12.862884521484375\n",
            "Train_MinReturn : -117.34593200683594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 391950\n",
            "TimeSinceStart : 436.05137395858765\n",
            "Training Loss : -522.35400390625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.64347839355469\n",
            "Eval_StdReturn : 17.034034729003906\n",
            "Eval_MaxReturn : -16.70134735107422\n",
            "Eval_MinReturn : -56.945613861083984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.784053802490234\n",
            "Train_StdReturn : 24.82539176940918\n",
            "Train_MaxReturn : 15.331310272216797\n",
            "Train_MinReturn : -109.13078308105469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 402000\n",
            "TimeSinceStart : 447.92720770835876\n",
            "Training Loss : -921.080078125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -68.58613586425781\n",
            "Eval_StdReturn : 17.52140998840332\n",
            "Eval_MaxReturn : -43.808494567871094\n",
            "Eval_MinReturn : -81.20096588134766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.84385681152344\n",
            "Train_StdReturn : 24.732423782348633\n",
            "Train_MaxReturn : 13.939506530761719\n",
            "Train_MinReturn : -135.57901000976562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 412050\n",
            "TimeSinceStart : 459.0848641395569\n",
            "Training Loss : -486.8341064453125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.241122245788574\n",
            "Eval_StdReturn : 16.556169509887695\n",
            "Eval_MaxReturn : 10.836005210876465\n",
            "Eval_MinReturn : -27.206748962402344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -47.19465637207031\n",
            "Train_StdReturn : 24.856966018676758\n",
            "Train_MaxReturn : 4.619266986846924\n",
            "Train_MinReturn : -99.99119567871094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 422100\n",
            "TimeSinceStart : 470.1859657764435\n",
            "Training Loss : -960.8161010742188\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.3484992980957\n",
            "Eval_StdReturn : 14.006142616271973\n",
            "Eval_MaxReturn : -35.288421630859375\n",
            "Eval_MinReturn : -66.98640441894531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.122066497802734\n",
            "Train_StdReturn : 27.90115737915039\n",
            "Train_MaxReturn : 12.125251770019531\n",
            "Train_MinReturn : -123.50349426269531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 432150\n",
            "TimeSinceStart : 481.36814880371094\n",
            "Training Loss : -556.4846801757812\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.44143295288086\n",
            "Eval_StdReturn : 10.096508026123047\n",
            "Eval_MaxReturn : -31.509876251220703\n",
            "Eval_MinReturn : -55.86240005493164\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -42.76089859008789\n",
            "Train_StdReturn : 23.103622436523438\n",
            "Train_MaxReturn : 14.410652160644531\n",
            "Train_MinReturn : -110.87995910644531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 442200\n",
            "TimeSinceStart : 492.5777962207794\n",
            "Training Loss : -687.51171875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -51.9191780090332\n",
            "Eval_StdReturn : 5.395246505737305\n",
            "Eval_MaxReturn : -45.0255126953125\n",
            "Eval_MinReturn : -58.198158264160156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.4996337890625\n",
            "Train_StdReturn : 22.784276962280273\n",
            "Train_MaxReturn : 4.298460006713867\n",
            "Train_MinReturn : -114.93854522705078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 452250\n",
            "TimeSinceStart : 503.75137186050415\n",
            "Training Loss : -365.600830078125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.453369140625\n",
            "Eval_StdReturn : 12.257240295410156\n",
            "Eval_MaxReturn : -30.571062088012695\n",
            "Eval_MinReturn : -59.300498962402344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -38.766536712646484\n",
            "Train_StdReturn : 28.65084457397461\n",
            "Train_MaxReturn : 19.943954467773438\n",
            "Train_MinReturn : -154.78890991210938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 462300\n",
            "TimeSinceStart : 514.9605565071106\n",
            "Training Loss : -681.1080932617188\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.81138038635254\n",
            "Eval_StdReturn : 28.78388214111328\n",
            "Eval_MaxReturn : 1.0474882125854492\n",
            "Eval_MinReturn : -68.68453979492188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -42.2320556640625\n",
            "Train_StdReturn : 29.36178207397461\n",
            "Train_MaxReturn : 6.194156646728516\n",
            "Train_MinReturn : -141.78977966308594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 472350\n",
            "TimeSinceStart : 526.1674590110779\n",
            "Training Loss : -625.8134765625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.37628746032715\n",
            "Eval_StdReturn : 6.750000476837158\n",
            "Eval_MaxReturn : -22.098751068115234\n",
            "Eval_MinReturn : -37.96165466308594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.82204818725586\n",
            "Train_StdReturn : 22.7003116607666\n",
            "Train_MaxReturn : -0.606266975402832\n",
            "Train_MinReturn : -113.71253204345703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 482400\n",
            "TimeSinceStart : 537.3591859340668\n",
            "Training Loss : -359.73974609375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -67.90635681152344\n",
            "Eval_StdReturn : 4.002956390380859\n",
            "Eval_MaxReturn : -62.258602142333984\n",
            "Eval_MinReturn : -71.06587219238281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.82126998901367\n",
            "Train_StdReturn : 25.233501434326172\n",
            "Train_MaxReturn : 25.16976547241211\n",
            "Train_MinReturn : -117.44540405273438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 492450\n",
            "TimeSinceStart : 548.6274101734161\n",
            "Training Loss : -665.8515014648438\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.1154899597168\n",
            "Eval_StdReturn : 2.210963487625122\n",
            "Eval_MaxReturn : -37.23768997192383\n",
            "Eval_MinReturn : -42.21955490112305\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.28273010253906\n",
            "Train_StdReturn : 21.97345733642578\n",
            "Train_MaxReturn : 7.365322589874268\n",
            "Train_MinReturn : -97.97064971923828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 502500\n",
            "TimeSinceStart : 559.736159324646\n",
            "Training Loss : -530.9801635742188\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.584745407104492\n",
            "Eval_StdReturn : 29.88889503479004\n",
            "Eval_MaxReturn : 21.298583984375\n",
            "Eval_MinReturn : -49.323402404785156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.1334228515625\n",
            "Train_StdReturn : 19.01548957824707\n",
            "Train_MaxReturn : 9.522115707397461\n",
            "Train_MinReturn : -105.49897766113281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 512550\n",
            "TimeSinceStart : 570.9757554531097\n",
            "Training Loss : -748.4495849609375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.405996322631836\n",
            "Eval_StdReturn : 21.542755126953125\n",
            "Eval_MaxReturn : -10.564730644226074\n",
            "Eval_MinReturn : -61.07154083251953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.11360168457031\n",
            "Train_StdReturn : 22.617286682128906\n",
            "Train_MaxReturn : 36.51298904418945\n",
            "Train_MinReturn : -96.64213562011719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 522600\n",
            "TimeSinceStart : 582.1488935947418\n",
            "Training Loss : -475.281005859375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -72.11093139648438\n",
            "Eval_StdReturn : 6.587162017822266\n",
            "Eval_MaxReturn : -63.98576354980469\n",
            "Eval_MinReturn : -80.11968994140625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.28800582885742\n",
            "Train_StdReturn : 22.33155632019043\n",
            "Train_MaxReturn : 8.844583511352539\n",
            "Train_MinReturn : -113.64492797851562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 532650\n",
            "TimeSinceStart : 593.3533699512482\n",
            "Training Loss : -454.8165283203125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.4124755859375\n",
            "Eval_StdReturn : 7.17169713973999\n",
            "Eval_MaxReturn : -30.149261474609375\n",
            "Eval_MinReturn : -45.552330017089844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.230125427246094\n",
            "Train_StdReturn : 23.821325302124023\n",
            "Train_MaxReturn : 6.512899398803711\n",
            "Train_MinReturn : -120.1529541015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 542700\n",
            "TimeSinceStart : 604.5772466659546\n",
            "Training Loss : -554.6689453125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -66.46251678466797\n",
            "Eval_StdReturn : 12.433098793029785\n",
            "Eval_MaxReturn : -50.89439392089844\n",
            "Eval_MinReturn : -81.32457733154297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.11054992675781\n",
            "Train_StdReturn : 26.093868255615234\n",
            "Train_MaxReturn : 31.776674270629883\n",
            "Train_MinReturn : -95.67637634277344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 552750\n",
            "TimeSinceStart : 615.6751592159271\n",
            "Training Loss : -512.8168334960938\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.138086318969727\n",
            "Eval_StdReturn : 28.234296798706055\n",
            "Eval_MaxReturn : 11.08843994140625\n",
            "Eval_MinReturn : -58.060672760009766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.74087142944336\n",
            "Train_StdReturn : 23.902645111083984\n",
            "Train_MaxReturn : 2.4931435585021973\n",
            "Train_MinReturn : -139.81759643554688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 562800\n",
            "TimeSinceStart : 626.802571773529\n",
            "Training Loss : -386.825439453125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.32908821105957\n",
            "Eval_StdReturn : 8.714503288269043\n",
            "Eval_MaxReturn : -17.909645080566406\n",
            "Eval_MinReturn : -39.05267333984375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.686655044555664\n",
            "Train_StdReturn : 20.993629455566406\n",
            "Train_MaxReturn : 28.729219436645508\n",
            "Train_MinReturn : -75.90325927734375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 572850\n",
            "TimeSinceStart : 638.011937379837\n",
            "Training Loss : -617.559814453125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.086965560913086\n",
            "Eval_StdReturn : 7.178427696228027\n",
            "Eval_MaxReturn : -16.180774688720703\n",
            "Eval_MinReturn : -33.554935455322266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -38.24219512939453\n",
            "Train_StdReturn : 25.34207534790039\n",
            "Train_MaxReturn : 18.308815002441406\n",
            "Train_MinReturn : -101.43978881835938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 582900\n",
            "TimeSinceStart : 649.2621347904205\n",
            "Training Loss : -573.15673828125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.963960647583008\n",
            "Eval_StdReturn : 6.108028411865234\n",
            "Eval_MaxReturn : -21.549564361572266\n",
            "Eval_MinReturn : -36.181514739990234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.26211166381836\n",
            "Train_StdReturn : 21.6205997467041\n",
            "Train_MaxReturn : 7.400765419006348\n",
            "Train_MinReturn : -105.22821807861328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 592950\n",
            "TimeSinceStart : 660.4446537494659\n",
            "Training Loss : -279.2119140625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.3163948059082\n",
            "Eval_StdReturn : 5.673444747924805\n",
            "Eval_MaxReturn : -54.052703857421875\n",
            "Eval_MinReturn : -67.89968872070312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.10356521606445\n",
            "Train_StdReturn : 21.95646858215332\n",
            "Train_MaxReturn : 23.237953186035156\n",
            "Train_MinReturn : -76.2237548828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 603000\n",
            "TimeSinceStart : 671.7322950363159\n",
            "Training Loss : -303.666748046875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.51580810546875\n",
            "Eval_StdReturn : 6.37857723236084\n",
            "Eval_MaxReturn : -24.39868927001953\n",
            "Eval_MinReturn : -39.31588363647461\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.0479850769043\n",
            "Train_StdReturn : 19.902982711791992\n",
            "Train_MaxReturn : 32.82141876220703\n",
            "Train_MinReturn : -83.43986511230469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 613050\n",
            "TimeSinceStart : 683.0695898532867\n",
            "Training Loss : -487.94677734375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.65159034729004\n",
            "Eval_StdReturn : 26.50309944152832\n",
            "Eval_MaxReturn : 13.296222686767578\n",
            "Eval_MinReturn : -49.81447982788086\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.018699645996094\n",
            "Train_StdReturn : 21.232194900512695\n",
            "Train_MaxReturn : 12.254171371459961\n",
            "Train_MinReturn : -113.03002166748047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 623100\n",
            "TimeSinceStart : 694.4628055095673\n",
            "Training Loss : -552.3762817382812\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -57.82088851928711\n",
            "Eval_StdReturn : 45.001060485839844\n",
            "Eval_MaxReturn : -25.746179580688477\n",
            "Eval_MinReturn : -121.46131896972656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.56825637817383\n",
            "Train_StdReturn : 22.066730499267578\n",
            "Train_MaxReturn : 9.171146392822266\n",
            "Train_MinReturn : -98.80686950683594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 633150\n",
            "TimeSinceStart : 705.8072369098663\n",
            "Training Loss : -244.3062744140625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.42897415161133\n",
            "Eval_StdReturn : 27.4659366607666\n",
            "Eval_MaxReturn : -8.039825439453125\n",
            "Eval_MinReturn : -70.74909973144531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.83584976196289\n",
            "Train_StdReturn : 23.31336212158203\n",
            "Train_MaxReturn : 20.439756393432617\n",
            "Train_MinReturn : -99.11543273925781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 643200\n",
            "TimeSinceStart : 717.0771653652191\n",
            "Training Loss : -638.39892578125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.52546691894531\n",
            "Eval_StdReturn : 10.241524696350098\n",
            "Eval_MaxReturn : -26.750219345092773\n",
            "Eval_MinReturn : -51.716575622558594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.20248794555664\n",
            "Train_StdReturn : 23.01065444946289\n",
            "Train_MaxReturn : 10.812108993530273\n",
            "Train_MinReturn : -108.48360443115234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 653250\n",
            "TimeSinceStart : 728.4943156242371\n",
            "Training Loss : -600.0736694335938\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -43.90547561645508\n",
            "Eval_StdReturn : 24.63330078125\n",
            "Eval_MaxReturn : -14.127653121948242\n",
            "Eval_MinReturn : -74.45198059082031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.53236770629883\n",
            "Train_StdReturn : 29.911344528198242\n",
            "Train_MaxReturn : 23.368099212646484\n",
            "Train_MinReturn : -122.69373321533203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 663300\n",
            "TimeSinceStart : 739.8000593185425\n",
            "Training Loss : -519.8245849609375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.59573745727539\n",
            "Eval_StdReturn : 9.778072357177734\n",
            "Eval_MaxReturn : -19.413047790527344\n",
            "Eval_MinReturn : -42.80351257324219\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.32500076293945\n",
            "Train_StdReturn : 24.84697914123535\n",
            "Train_MaxReturn : 39.00493621826172\n",
            "Train_MinReturn : -104.28742218017578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 673350\n",
            "TimeSinceStart : 751.129599571228\n",
            "Training Loss : -124.1427001953125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.367657661437988\n",
            "Eval_StdReturn : 12.858463287353516\n",
            "Eval_MaxReturn : 2.743990182876587\n",
            "Eval_MinReturn : -25.832843780517578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.617698669433594\n",
            "Train_StdReturn : 26.973161697387695\n",
            "Train_MaxReturn : 50.68516540527344\n",
            "Train_MinReturn : -90.56977844238281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 683400\n",
            "TimeSinceStart : 762.3490686416626\n",
            "Training Loss : -321.74188232421875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.70365524291992\n",
            "Eval_StdReturn : 22.56507110595703\n",
            "Eval_MaxReturn : -6.202343463897705\n",
            "Eval_MinReturn : -57.8729248046875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.223970413208008\n",
            "Train_StdReturn : 27.00776481628418\n",
            "Train_MaxReturn : 27.841415405273438\n",
            "Train_MinReturn : -139.928466796875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 693450\n",
            "TimeSinceStart : 774.5814354419708\n",
            "Training Loss : -440.4884033203125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.96860694885254\n",
            "Eval_StdReturn : 21.862680435180664\n",
            "Eval_MaxReturn : 5.0813188552856445\n",
            "Eval_MinReturn : -46.29568099975586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.36732482910156\n",
            "Train_StdReturn : 22.892465591430664\n",
            "Train_MaxReturn : 15.088293075561523\n",
            "Train_MinReturn : -103.43965148925781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 703500\n",
            "TimeSinceStart : 786.5974593162537\n",
            "Training Loss : -281.824951171875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.621441602706909\n",
            "Eval_StdReturn : 5.024414539337158\n",
            "Eval_MaxReturn : 8.5712890625\n",
            "Eval_MinReturn : -3.2683849334716797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.22688674926758\n",
            "Train_StdReturn : 30.555927276611328\n",
            "Train_MaxReturn : 44.90399169921875\n",
            "Train_MinReturn : -132.87962341308594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 713550\n",
            "TimeSinceStart : 797.9248070716858\n",
            "Training Loss : -857.418701171875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.441131591796875\n",
            "Eval_StdReturn : 6.586406707763672\n",
            "Eval_MaxReturn : -35.51678466796875\n",
            "Eval_MinReturn : -51.21375274658203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.95231628417969\n",
            "Train_StdReturn : 26.6473445892334\n",
            "Train_MaxReturn : 29.504180908203125\n",
            "Train_MinReturn : -119.5429916381836\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 723600\n",
            "TimeSinceStart : 809.1089317798615\n",
            "Training Loss : -130.0172119140625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -64.17969512939453\n",
            "Eval_StdReturn : 41.853511810302734\n",
            "Eval_MaxReturn : -21.672183990478516\n",
            "Eval_MinReturn : -121.10428619384766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.582733154296875\n",
            "Train_StdReturn : 23.606151580810547\n",
            "Train_MaxReturn : 12.020391464233398\n",
            "Train_MinReturn : -95.90640258789062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 733650\n",
            "TimeSinceStart : 820.4823293685913\n",
            "Training Loss : -305.45745849609375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.81694030761719\n",
            "Eval_StdReturn : 21.519590377807617\n",
            "Eval_MaxReturn : -20.591087341308594\n",
            "Eval_MinReturn : -67.22740936279297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.67182731628418\n",
            "Train_StdReturn : 28.296131134033203\n",
            "Train_MaxReturn : 30.373533248901367\n",
            "Train_MinReturn : -93.76555633544922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 743700\n",
            "TimeSinceStart : 831.8035109043121\n",
            "Training Loss : -637.0107421875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.3226203918457\n",
            "Eval_StdReturn : 42.68242263793945\n",
            "Eval_MaxReturn : 15.473227500915527\n",
            "Eval_MinReturn : -88.16549682617188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.53215980529785\n",
            "Train_StdReturn : 30.094451904296875\n",
            "Train_MaxReturn : 31.480567932128906\n",
            "Train_MinReturn : -127.76773834228516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 753750\n",
            "TimeSinceStart : 844.7283091545105\n",
            "Training Loss : -469.4132080078125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.84876823425293\n",
            "Eval_StdReturn : 25.168752670288086\n",
            "Eval_MaxReturn : 8.56850814819336\n",
            "Eval_MinReturn : -47.625247955322266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.093902587890625\n",
            "Train_StdReturn : 26.66154670715332\n",
            "Train_MaxReturn : 38.79605484008789\n",
            "Train_MinReturn : -106.4204330444336\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 763800\n",
            "TimeSinceStart : 857.1885831356049\n",
            "Training Loss : -145.211669921875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.121784210205078\n",
            "Eval_StdReturn : 16.4256591796875\n",
            "Eval_MaxReturn : 0.664860725402832\n",
            "Eval_MinReturn : -37.77281188964844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.59844207763672\n",
            "Train_StdReturn : 30.147207260131836\n",
            "Train_MaxReturn : 28.602373123168945\n",
            "Train_MinReturn : -126.44007110595703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 773850\n",
            "TimeSinceStart : 869.7504169940948\n",
            "Training Loss : -502.084716796875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.270438194274902\n",
            "Eval_StdReturn : 17.76589584350586\n",
            "Eval_MaxReturn : 14.294557571411133\n",
            "Eval_MinReturn : -28.60004425048828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.787302017211914\n",
            "Train_StdReturn : 24.57518768310547\n",
            "Train_MaxReturn : 31.861486434936523\n",
            "Train_MinReturn : -78.07756805419922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 783900\n",
            "TimeSinceStart : 882.2379679679871\n",
            "Training Loss : -288.7564697265625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.141387939453125\n",
            "Eval_StdReturn : 24.406770706176758\n",
            "Eval_MaxReturn : 15.35262680053711\n",
            "Eval_MinReturn : -37.464508056640625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.930091857910156\n",
            "Train_StdReturn : 29.75264549255371\n",
            "Train_MaxReturn : 29.825618743896484\n",
            "Train_MinReturn : -131.377685546875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 793950\n",
            "TimeSinceStart : 895.630063533783\n",
            "Training Loss : -318.1958312988281\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.64817237854004\n",
            "Eval_StdReturn : 10.054457664489746\n",
            "Eval_MaxReturn : -16.97576904296875\n",
            "Eval_MinReturn : -40.866268157958984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.861658096313477\n",
            "Train_StdReturn : 26.745643615722656\n",
            "Train_MaxReturn : 44.66259765625\n",
            "Train_MinReturn : -100.47542572021484\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 804000\n",
            "TimeSinceStart : 907.7779552936554\n",
            "Training Loss : -576.5880126953125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.121009826660156\n",
            "Eval_StdReturn : 28.8873348236084\n",
            "Eval_MaxReturn : -5.441102027893066\n",
            "Eval_MinReturn : -76.1924819946289\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.57082748413086\n",
            "Train_StdReturn : 24.48186492919922\n",
            "Train_MaxReturn : 25.912195205688477\n",
            "Train_MinReturn : -90.49858093261719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 814050\n",
            "TimeSinceStart : 919.6909894943237\n",
            "Training Loss : -379.2724609375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.260574340820312\n",
            "Eval_StdReturn : 14.136645317077637\n",
            "Eval_MaxReturn : -2.381937026977539\n",
            "Eval_MinReturn : -34.04297637939453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.955963134765625\n",
            "Train_StdReturn : 30.319581985473633\n",
            "Train_MaxReturn : 22.52548599243164\n",
            "Train_MinReturn : -144.73837280273438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 824100\n",
            "TimeSinceStart : 931.2729406356812\n",
            "Training Loss : -171.041259765625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.072343826293945\n",
            "Eval_StdReturn : 18.629796981811523\n",
            "Eval_MaxReturn : -4.004741191864014\n",
            "Eval_MinReturn : -49.30727767944336\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.87714958190918\n",
            "Train_StdReturn : 28.27754783630371\n",
            "Train_MaxReturn : 37.8999137878418\n",
            "Train_MinReturn : -128.36688232421875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 834150\n",
            "TimeSinceStart : 942.4960014820099\n",
            "Training Loss : -299.67822265625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -6.87156867980957\n",
            "Eval_StdReturn : 23.087562561035156\n",
            "Eval_MaxReturn : 20.35941505432129\n",
            "Eval_MinReturn : -36.0886116027832\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.793901443481445\n",
            "Train_StdReturn : 29.661800384521484\n",
            "Train_MaxReturn : 45.844398498535156\n",
            "Train_MinReturn : -114.59215545654297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 844200\n",
            "TimeSinceStart : 953.7081043720245\n",
            "Training Loss : -351.9665222167969\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.6595344543457\n",
            "Eval_StdReturn : 19.24005699157715\n",
            "Eval_MaxReturn : -12.114456176757812\n",
            "Eval_MinReturn : -58.547271728515625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.59857940673828\n",
            "Train_StdReturn : 28.224266052246094\n",
            "Train_MaxReturn : 40.70801544189453\n",
            "Train_MinReturn : -112.99352264404297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 854250\n",
            "TimeSinceStart : 965.0106046199799\n",
            "Training Loss : 24.2340087890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.473187446594238\n",
            "Eval_StdReturn : 9.705228805541992\n",
            "Eval_MaxReturn : 1.2548017501831055\n",
            "Eval_MinReturn : -21.72239875793457\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.111879348754883\n",
            "Train_StdReturn : 23.827531814575195\n",
            "Train_MaxReturn : 17.67504119873047\n",
            "Train_MinReturn : -117.46293640136719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 864300\n",
            "TimeSinceStart : 976.2299509048462\n",
            "Training Loss : -265.1798400878906\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.5678200721740723\n",
            "Eval_StdReturn : 6.067152976989746\n",
            "Eval_MaxReturn : 6.672956466674805\n",
            "Eval_MinReturn : -6.957076072692871\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.94670295715332\n",
            "Train_StdReturn : 25.26302146911621\n",
            "Train_MaxReturn : 40.94290542602539\n",
            "Train_MinReturn : -90.01292419433594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 874350\n",
            "TimeSinceStart : 987.4770276546478\n",
            "Training Loss : -584.3751220703125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.802331924438477\n",
            "Eval_StdReturn : 6.195310115814209\n",
            "Eval_MaxReturn : -19.59477996826172\n",
            "Eval_MinReturn : -33.50806427001953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.373563766479492\n",
            "Train_StdReturn : 27.909183502197266\n",
            "Train_MaxReturn : 19.2559871673584\n",
            "Train_MinReturn : -101.96548461914062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 884400\n",
            "TimeSinceStart : 999.5417051315308\n",
            "Training Loss : -220.490478515625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.540194511413574\n",
            "Eval_StdReturn : 18.944536209106445\n",
            "Eval_MaxReturn : 9.674077033996582\n",
            "Eval_MinReturn : -36.61798095703125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.385995864868164\n",
            "Train_StdReturn : 29.767009735107422\n",
            "Train_MaxReturn : 46.27586364746094\n",
            "Train_MinReturn : -118.1898193359375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 894450\n",
            "TimeSinceStart : 1010.7248766422272\n",
            "Training Loss : -249.8551025390625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.3682746887207\n",
            "Eval_StdReturn : 51.06887435913086\n",
            "Eval_MaxReturn : 4.223832130432129\n",
            "Eval_MinReturn : -119.90564727783203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.07723045349121\n",
            "Train_StdReturn : 29.917762756347656\n",
            "Train_MaxReturn : 55.73033905029297\n",
            "Train_MinReturn : -107.85514831542969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 904500\n",
            "TimeSinceStart : 1021.995908498764\n",
            "Training Loss : -297.3880615234375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -1.1153602600097656\n",
            "Eval_StdReturn : 18.751220703125\n",
            "Eval_MaxReturn : 21.84539794921875\n",
            "Eval_MinReturn : -24.085519790649414\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.49774169921875\n",
            "Train_StdReturn : 22.496780395507812\n",
            "Train_MaxReturn : 26.018970489501953\n",
            "Train_MinReturn : -85.83457946777344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 914550\n",
            "TimeSinceStart : 1033.1874511241913\n",
            "Training Loss : -550.20556640625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.303653717041016\n",
            "Eval_StdReturn : 11.666465759277344\n",
            "Eval_MaxReturn : -22.056381225585938\n",
            "Eval_MinReturn : -50.3862419128418\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.738176345825195\n",
            "Train_StdReturn : 25.814464569091797\n",
            "Train_MaxReturn : 31.834096908569336\n",
            "Train_MinReturn : -101.53853607177734\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 924600\n",
            "TimeSinceStart : 1044.4617249965668\n",
            "Training Loss : -27.728759765625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.12369728088379\n",
            "Eval_StdReturn : 13.235209465026855\n",
            "Eval_MaxReturn : -12.487675666809082\n",
            "Eval_MinReturn : -41.95172119140625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.62078094482422\n",
            "Train_StdReturn : 23.527997970581055\n",
            "Train_MaxReturn : 27.702747344970703\n",
            "Train_MinReturn : -80.50686645507812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 934650\n",
            "TimeSinceStart : 1055.6991715431213\n",
            "Training Loss : -246.7235107421875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.3539772033691406\n",
            "Eval_StdReturn : 20.736169815063477\n",
            "Eval_MaxReturn : 22.69352912902832\n",
            "Eval_MinReturn : -26.110881805419922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.7083797454834\n",
            "Train_StdReturn : 24.464679718017578\n",
            "Train_MaxReturn : 17.905986785888672\n",
            "Train_MinReturn : -113.82181549072266\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 944700\n",
            "TimeSinceStart : 1067.0790150165558\n",
            "Training Loss : -325.71435546875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.43230152130127\n",
            "Eval_StdReturn : 11.075360298156738\n",
            "Eval_MaxReturn : 1.7314825057983398\n",
            "Eval_MinReturn : -24.411270141601562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.988113403320312\n",
            "Train_StdReturn : 20.649755477905273\n",
            "Train_MaxReturn : 28.842166900634766\n",
            "Train_MinReturn : -54.014564514160156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 954750\n",
            "TimeSinceStart : 1078.3805994987488\n",
            "Training Loss : -377.26715087890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.590744018554688\n",
            "Eval_StdReturn : 14.583602905273438\n",
            "Eval_MaxReturn : -2.187715530395508\n",
            "Eval_MinReturn : -35.40176773071289\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.449674606323242\n",
            "Train_StdReturn : 30.487600326538086\n",
            "Train_MaxReturn : 69.48457336425781\n",
            "Train_MinReturn : -82.43817901611328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 964800\n",
            "TimeSinceStart : 1089.6244101524353\n",
            "Training Loss : -394.41748046875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -5.81785249710083\n",
            "Eval_StdReturn : 6.423649311065674\n",
            "Eval_MaxReturn : 2.0159332752227783\n",
            "Eval_MinReturn : -13.718305587768555\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.392107009887695\n",
            "Train_StdReturn : 26.992475509643555\n",
            "Train_MaxReturn : 42.383392333984375\n",
            "Train_MinReturn : -113.51248931884766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 974850\n",
            "TimeSinceStart : 1100.8160498142242\n",
            "Training Loss : -157.65771484375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.9090576171875\n",
            "Eval_StdReturn : 12.614840507507324\n",
            "Eval_MaxReturn : -33.01041793823242\n",
            "Eval_MinReturn : -63.031715393066406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.57535743713379\n",
            "Train_StdReturn : 25.658763885498047\n",
            "Train_MaxReturn : 34.59477996826172\n",
            "Train_MinReturn : -81.45733642578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 984900\n",
            "TimeSinceStart : 1112.0429155826569\n",
            "Training Loss : -308.72589111328125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.21088790893555\n",
            "Eval_StdReturn : 27.172542572021484\n",
            "Eval_MaxReturn : 2.3392744064331055\n",
            "Eval_MinReturn : -61.057708740234375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.521141052246094\n",
            "Train_StdReturn : 26.583629608154297\n",
            "Train_MaxReturn : 17.105701446533203\n",
            "Train_MinReturn : -129.7442626953125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 994950\n",
            "TimeSinceStart : 1123.2970237731934\n",
            "Training Loss : -175.2423095703125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.556416511535645\n",
            "Eval_StdReturn : 21.795866012573242\n",
            "Eval_MaxReturn : 20.56189727783203\n",
            "Eval_MinReturn : -30.29493522644043\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.604188919067383\n",
            "Train_StdReturn : 24.034351348876953\n",
            "Train_MaxReturn : 37.57486343383789\n",
            "Train_MinReturn : -83.0820541381836\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1005000\n",
            "TimeSinceStart : 1134.5981850624084\n",
            "Training Loss : -338.738037109375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "    --discount 0.95 -n 100 -l 2 -s 32 \\\n",
        "    -b 10000 -lr 0.005 -rtg --nn_baseline \\\n",
        "    --exp_name q4_search_b10000_lr0005_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZjWLxb_PQ8b",
        "outputId": "cc32ec6d-868f-40e5-85c2-d782280c75e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q4_search_b10000_lr0.01_rtg_nnbaseline_HalfCheetah-v2_08-05-2022_19-55-15\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -72.73572540283203\n",
            "Eval_StdReturn : 21.75385856628418\n",
            "Eval_MaxReturn : -43.327781677246094\n",
            "Eval_MinReturn : -95.26435089111328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -89.69666290283203\n",
            "Train_StdReturn : 40.17568588256836\n",
            "Train_MaxReturn : 11.764884948730469\n",
            "Train_MinReturn : -178.39559936523438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 10050\n",
            "TimeSinceStart : 11.108069658279419\n",
            "Training Loss : -594.497802734375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -95.35165405273438\n",
            "Eval_StdReturn : 61.713741302490234\n",
            "Eval_MaxReturn : -35.701663970947266\n",
            "Eval_MinReturn : -180.35171508789062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -85.73645782470703\n",
            "Train_StdReturn : 35.6266975402832\n",
            "Train_MaxReturn : -4.120784759521484\n",
            "Train_MinReturn : -176.25816345214844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 20100\n",
            "TimeSinceStart : 22.131297826766968\n",
            "Training Loss : -800.195556640625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -87.4935302734375\n",
            "Eval_StdReturn : 52.132503509521484\n",
            "Eval_MaxReturn : -50.00199890136719\n",
            "Eval_MinReturn : -161.2164306640625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -80.23383331298828\n",
            "Train_StdReturn : 37.9964485168457\n",
            "Train_MaxReturn : 7.254712104797363\n",
            "Train_MinReturn : -168.55490112304688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 30150\n",
            "TimeSinceStart : 34.03262186050415\n",
            "Training Loss : -726.760986328125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -69.81610870361328\n",
            "Eval_StdReturn : 8.206768035888672\n",
            "Eval_MaxReturn : -63.01698303222656\n",
            "Eval_MinReturn : -81.36155700683594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -74.48127746582031\n",
            "Train_StdReturn : 37.99134826660156\n",
            "Train_MaxReturn : -11.382469177246094\n",
            "Train_MinReturn : -173.03298950195312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 40200\n",
            "TimeSinceStart : 46.066182374954224\n",
            "Training Loss : -762.4384765625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -70.22513580322266\n",
            "Eval_StdReturn : 19.35980987548828\n",
            "Eval_MaxReturn : -45.186561584472656\n",
            "Eval_MinReturn : -92.33638000488281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -83.13900756835938\n",
            "Train_StdReturn : 32.38508605957031\n",
            "Train_MaxReturn : -9.559446334838867\n",
            "Train_MinReturn : -149.76661682128906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50250\n",
            "TimeSinceStart : 58.35699653625488\n",
            "Training Loss : -641.6790771484375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -71.21239471435547\n",
            "Eval_StdReturn : 49.40984344482422\n",
            "Eval_MaxReturn : -30.6042423248291\n",
            "Eval_MinReturn : -140.76312255859375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -85.80929565429688\n",
            "Train_StdReturn : 31.995943069458008\n",
            "Train_MaxReturn : -15.747190475463867\n",
            "Train_MinReturn : -189.6061248779297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 60300\n",
            "TimeSinceStart : 70.48032832145691\n",
            "Training Loss : -614.6835327148438\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.98158264160156\n",
            "Eval_StdReturn : 26.870647430419922\n",
            "Eval_MaxReturn : -39.502506256103516\n",
            "Eval_MinReturn : -98.86949920654297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -73.23147583007812\n",
            "Train_StdReturn : 32.210994720458984\n",
            "Train_MaxReturn : -3.0500292778015137\n",
            "Train_MinReturn : -169.2998046875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 70350\n",
            "TimeSinceStart : 82.75687265396118\n",
            "Training Loss : -682.0318603515625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -80.45281219482422\n",
            "Eval_StdReturn : 37.74751663208008\n",
            "Eval_MaxReturn : -27.939929962158203\n",
            "Eval_MinReturn : -115.02252197265625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -66.1253662109375\n",
            "Train_StdReturn : 33.46888732910156\n",
            "Train_MaxReturn : -6.055882453918457\n",
            "Train_MinReturn : -181.52481079101562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 80400\n",
            "TimeSinceStart : 95.00839519500732\n",
            "Training Loss : -773.9697265625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -73.38822937011719\n",
            "Eval_StdReturn : 24.021724700927734\n",
            "Eval_MaxReturn : -50.621280670166016\n",
            "Eval_MinReturn : -106.6077880859375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -74.30213928222656\n",
            "Train_StdReturn : 32.7768440246582\n",
            "Train_MaxReturn : 13.385478973388672\n",
            "Train_MinReturn : -185.43438720703125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 90450\n",
            "TimeSinceStart : 107.13680243492126\n",
            "Training Loss : -506.053466796875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -94.2370376586914\n",
            "Eval_StdReturn : 21.92368507385254\n",
            "Eval_MaxReturn : -75.09954071044922\n",
            "Eval_MinReturn : -124.93134307861328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -68.8402099609375\n",
            "Train_StdReturn : 29.354280471801758\n",
            "Train_MaxReturn : -11.48534870147705\n",
            "Train_MinReturn : -168.30462646484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100500\n",
            "TimeSinceStart : 119.76581287384033\n",
            "Training Loss : -721.911865234375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.63649368286133\n",
            "Eval_StdReturn : 33.03647994995117\n",
            "Eval_MaxReturn : -10.519474029541016\n",
            "Eval_MinReturn : -90.7772216796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -58.97908401489258\n",
            "Train_StdReturn : 28.281143188476562\n",
            "Train_MaxReturn : 16.411584854125977\n",
            "Train_MinReturn : -114.05081176757812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 110550\n",
            "TimeSinceStart : 131.12939882278442\n",
            "Training Loss : -748.515380859375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -86.37345123291016\n",
            "Eval_StdReturn : 18.678272247314453\n",
            "Eval_MaxReturn : -68.91795349121094\n",
            "Eval_MinReturn : -112.27082824707031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -61.503482818603516\n",
            "Train_StdReturn : 30.071107864379883\n",
            "Train_MaxReturn : 16.952091217041016\n",
            "Train_MinReturn : -153.2393798828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 120600\n",
            "TimeSinceStart : 143.14209723472595\n",
            "Training Loss : -815.5404052734375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -69.91509246826172\n",
            "Eval_StdReturn : 18.118907928466797\n",
            "Eval_MaxReturn : -55.89633560180664\n",
            "Eval_MinReturn : -95.49993896484375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -60.19501876831055\n",
            "Train_StdReturn : 32.53670883178711\n",
            "Train_MaxReturn : 36.638980865478516\n",
            "Train_MinReturn : -139.79608154296875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 130650\n",
            "TimeSinceStart : 154.49945044517517\n",
            "Training Loss : -648.5099487304688\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -57.817874908447266\n",
            "Eval_StdReturn : 23.538860321044922\n",
            "Eval_MaxReturn : -35.24477005004883\n",
            "Eval_MinReturn : -90.29306030273438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -64.13095092773438\n",
            "Train_StdReturn : 31.858922958374023\n",
            "Train_MaxReturn : 16.475317001342773\n",
            "Train_MinReturn : -135.26376342773438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 140700\n",
            "TimeSinceStart : 165.55156707763672\n",
            "Training Loss : -764.00537109375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -77.21027374267578\n",
            "Eval_StdReturn : 9.38501262664795\n",
            "Eval_MaxReturn : -68.14810943603516\n",
            "Eval_MinReturn : -90.13931274414062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -58.69081497192383\n",
            "Train_StdReturn : 28.793132781982422\n",
            "Train_MaxReturn : 11.446619033813477\n",
            "Train_MinReturn : -158.81423950195312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150750\n",
            "TimeSinceStart : 176.50937819480896\n",
            "Training Loss : -645.8775634765625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -59.767086029052734\n",
            "Eval_StdReturn : 27.465194702148438\n",
            "Eval_MaxReturn : -34.52130889892578\n",
            "Eval_MinReturn : -97.9534912109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -54.034523010253906\n",
            "Train_StdReturn : 29.40131187438965\n",
            "Train_MaxReturn : 45.36736297607422\n",
            "Train_MinReturn : -117.75344848632812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 160800\n",
            "TimeSinceStart : 187.61142444610596\n",
            "Training Loss : -670.237060546875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.875640869140625\n",
            "Eval_StdReturn : 11.704269409179688\n",
            "Eval_MaxReturn : -21.92555046081543\n",
            "Eval_MinReturn : -49.68224334716797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -57.82722091674805\n",
            "Train_StdReturn : 33.434967041015625\n",
            "Train_MaxReturn : 64.82599639892578\n",
            "Train_MinReturn : -140.81712341308594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 170850\n",
            "TimeSinceStart : 201.07099318504333\n",
            "Training Loss : -356.12933349609375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.6121940612793\n",
            "Eval_StdReturn : 11.449040412902832\n",
            "Eval_MaxReturn : -27.566829681396484\n",
            "Eval_MinReturn : -55.316436767578125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -47.9141845703125\n",
            "Train_StdReturn : 31.835046768188477\n",
            "Train_MaxReturn : 14.488752365112305\n",
            "Train_MinReturn : -134.64324951171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 180900\n",
            "TimeSinceStart : 212.68382573127747\n",
            "Training Loss : -608.7667236328125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.558746337890625\n",
            "Eval_StdReturn : 49.83916091918945\n",
            "Eval_MaxReturn : 11.39228630065918\n",
            "Eval_MinReturn : -106.5991439819336\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.13291549682617\n",
            "Train_StdReturn : 31.972681045532227\n",
            "Train_MaxReturn : 21.362594604492188\n",
            "Train_MinReturn : -115.51376342773438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 190950\n",
            "TimeSinceStart : 224.63450694084167\n",
            "Training Loss : -366.0010986328125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.65644454956055\n",
            "Eval_StdReturn : 13.841567039489746\n",
            "Eval_MaxReturn : -16.084440231323242\n",
            "Eval_MinReturn : -45.735782623291016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -54.8868293762207\n",
            "Train_StdReturn : 31.29109764099121\n",
            "Train_MaxReturn : 7.840527534484863\n",
            "Train_MinReturn : -144.18582153320312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 201000\n",
            "TimeSinceStart : 237.7570674419403\n",
            "Training Loss : -369.82958984375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -75.97421264648438\n",
            "Eval_StdReturn : 19.58222007751465\n",
            "Eval_MaxReturn : -48.610008239746094\n",
            "Eval_MinReturn : -93.34349822998047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -59.43598556518555\n",
            "Train_StdReturn : 32.40591812133789\n",
            "Train_MaxReturn : -10.306190490722656\n",
            "Train_MinReturn : -166.36135864257812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 211050\n",
            "TimeSinceStart : 249.74642968177795\n",
            "Training Loss : -603.40478515625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -54.25973129272461\n",
            "Eval_StdReturn : 13.704864501953125\n",
            "Eval_MaxReturn : -35.0201530456543\n",
            "Eval_MinReturn : -65.9078140258789\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.41896057128906\n",
            "Train_StdReturn : 27.405651092529297\n",
            "Train_MaxReturn : -5.114140510559082\n",
            "Train_MinReturn : -166.73825073242188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 221100\n",
            "TimeSinceStart : 260.88303995132446\n",
            "Training Loss : -537.715576171875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.33957862854004\n",
            "Eval_StdReturn : 22.08193016052246\n",
            "Eval_MaxReturn : 3.3255324363708496\n",
            "Eval_MinReturn : -50.402976989746094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -58.272430419921875\n",
            "Train_StdReturn : 32.92831802368164\n",
            "Train_MaxReturn : 14.191364288330078\n",
            "Train_MinReturn : -155.84005737304688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 231150\n",
            "TimeSinceStart : 271.9838535785675\n",
            "Training Loss : -434.80029296875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.65726089477539\n",
            "Eval_StdReturn : 24.441387176513672\n",
            "Eval_MaxReturn : -20.077672958374023\n",
            "Eval_MinReturn : -73.1893081665039\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.176727294921875\n",
            "Train_StdReturn : 26.84471321105957\n",
            "Train_MaxReturn : 7.232210159301758\n",
            "Train_MinReturn : -120.96580505371094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 241200\n",
            "TimeSinceStart : 283.0781123638153\n",
            "Training Loss : -779.16162109375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.91758346557617\n",
            "Eval_StdReturn : 25.393171310424805\n",
            "Eval_MaxReturn : -25.655803680419922\n",
            "Eval_MinReturn : -84.97758483886719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.1032600402832\n",
            "Train_StdReturn : 29.219791412353516\n",
            "Train_MaxReturn : 41.86130905151367\n",
            "Train_MinReturn : -126.00021362304688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 251250\n",
            "TimeSinceStart : 294.18121576309204\n",
            "Training Loss : -491.5908203125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.81390380859375\n",
            "Eval_StdReturn : 6.807002544403076\n",
            "Eval_MaxReturn : -55.526641845703125\n",
            "Eval_MinReturn : -71.27066802978516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.95524597167969\n",
            "Train_StdReturn : 26.62990379333496\n",
            "Train_MaxReturn : 4.478955268859863\n",
            "Train_MinReturn : -146.1715545654297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 261300\n",
            "TimeSinceStart : 305.21908140182495\n",
            "Training Loss : -209.947021484375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -59.09309005737305\n",
            "Eval_StdReturn : 38.06846618652344\n",
            "Eval_MaxReturn : -27.988773345947266\n",
            "Eval_MinReturn : -112.70051574707031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.74413299560547\n",
            "Train_StdReturn : 29.70844268798828\n",
            "Train_MaxReturn : 8.542524337768555\n",
            "Train_MinReturn : -147.37191772460938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 271350\n",
            "TimeSinceStart : 316.2641613483429\n",
            "Training Loss : -277.543212890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.70139694213867\n",
            "Eval_StdReturn : 11.224720001220703\n",
            "Eval_MaxReturn : -30.81578254699707\n",
            "Eval_MinReturn : -57.15015411376953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.9287109375\n",
            "Train_StdReturn : 27.069190979003906\n",
            "Train_MaxReturn : 18.778085708618164\n",
            "Train_MinReturn : -137.66952514648438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 281400\n",
            "TimeSinceStart : 327.2720944881439\n",
            "Training Loss : -472.3165283203125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.90211868286133\n",
            "Eval_StdReturn : 31.090436935424805\n",
            "Eval_MaxReturn : -21.19200325012207\n",
            "Eval_MinReturn : -96.97234344482422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.31694793701172\n",
            "Train_StdReturn : 26.493122100830078\n",
            "Train_MaxReturn : 20.44605255126953\n",
            "Train_MinReturn : -123.30900573730469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 291450\n",
            "TimeSinceStart : 339.0997769832611\n",
            "Training Loss : -377.33795166015625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.32887649536133\n",
            "Eval_StdReturn : 11.382833480834961\n",
            "Eval_MaxReturn : -17.118450164794922\n",
            "Eval_MinReturn : -44.49868392944336\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.55807876586914\n",
            "Train_StdReturn : 23.436172485351562\n",
            "Train_MaxReturn : 10.537585258483887\n",
            "Train_MinReturn : -124.16144561767578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 301500\n",
            "TimeSinceStart : 350.2870464324951\n",
            "Training Loss : -631.2113647460938\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.853118896484375\n",
            "Eval_StdReturn : 6.846157073974609\n",
            "Eval_MaxReturn : -35.330116271972656\n",
            "Eval_MinReturn : -51.8927001953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.02032470703125\n",
            "Train_StdReturn : 25.316204071044922\n",
            "Train_MaxReturn : 7.573053359985352\n",
            "Train_MinReturn : -102.44505310058594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 311550\n",
            "TimeSinceStart : 361.4029371738434\n",
            "Training Loss : -194.08642578125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.304080963134766\n",
            "Eval_StdReturn : 13.286690711975098\n",
            "Eval_MaxReturn : -25.778352737426758\n",
            "Eval_MinReturn : -57.88957214355469\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.62839126586914\n",
            "Train_StdReturn : 24.30445671081543\n",
            "Train_MaxReturn : 21.379352569580078\n",
            "Train_MinReturn : -107.11601257324219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 321600\n",
            "TimeSinceStart : 372.64826226234436\n",
            "Training Loss : -668.1434326171875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.771357536315918\n",
            "Eval_StdReturn : 26.145307540893555\n",
            "Eval_MaxReturn : 25.17934226989746\n",
            "Eval_MinReturn : -31.408676147460938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.706417083740234\n",
            "Train_StdReturn : 23.36972427368164\n",
            "Train_MaxReturn : 17.725589752197266\n",
            "Train_MinReturn : -129.78436279296875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 331650\n",
            "TimeSinceStart : 383.7691156864166\n",
            "Training Loss : -233.15673828125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.854122161865234\n",
            "Eval_StdReturn : 36.76789093017578\n",
            "Eval_MaxReturn : 1.632537841796875\n",
            "Eval_MinReturn : -87.3541259765625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.75143051147461\n",
            "Train_StdReturn : 20.557876586914062\n",
            "Train_MaxReturn : -0.8829655647277832\n",
            "Train_MinReturn : -105.11602783203125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 341700\n",
            "TimeSinceStart : 394.824875831604\n",
            "Training Loss : -463.762939453125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.154510498046875\n",
            "Eval_StdReturn : 42.91868209838867\n",
            "Eval_MaxReturn : 8.449230194091797\n",
            "Eval_MinReturn : -95.56669616699219\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.066768646240234\n",
            "Train_StdReturn : 25.846176147460938\n",
            "Train_MaxReturn : 21.673084259033203\n",
            "Train_MinReturn : -107.04438781738281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 351750\n",
            "TimeSinceStart : 405.87731194496155\n",
            "Training Loss : -727.361328125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.18608474731445\n",
            "Eval_StdReturn : 11.327197074890137\n",
            "Eval_MaxReturn : -44.30332946777344\n",
            "Eval_MinReturn : -69.93345642089844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.21477127075195\n",
            "Train_StdReturn : 25.73703956604004\n",
            "Train_MaxReturn : 30.49485969543457\n",
            "Train_MinReturn : -125.79078674316406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 361800\n",
            "TimeSinceStart : 416.8598463535309\n",
            "Training Loss : -629.92333984375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.517112731933594\n",
            "Eval_StdReturn : 10.079887390136719\n",
            "Eval_MaxReturn : -3.3922243118286133\n",
            "Eval_MinReturn : -26.244434356689453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.651737213134766\n",
            "Train_StdReturn : 25.964744567871094\n",
            "Train_MaxReturn : 27.60624885559082\n",
            "Train_MinReturn : -109.85079193115234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 371850\n",
            "TimeSinceStart : 427.9764127731323\n",
            "Training Loss : -379.470947265625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.538726806640625\n",
            "Eval_StdReturn : 15.918328285217285\n",
            "Eval_MaxReturn : -16.029335021972656\n",
            "Eval_MinReturn : -50.08527755737305\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.318599700927734\n",
            "Train_StdReturn : 26.63442611694336\n",
            "Train_MaxReturn : 16.447996139526367\n",
            "Train_MinReturn : -153.1623992919922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 381900\n",
            "TimeSinceStart : 439.1345181465149\n",
            "Training Loss : -336.7137451171875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.236169815063477\n",
            "Eval_StdReturn : 19.146961212158203\n",
            "Eval_MaxReturn : -1.4146537780761719\n",
            "Eval_MinReturn : -47.12315368652344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.74691390991211\n",
            "Train_StdReturn : 24.320005416870117\n",
            "Train_MaxReturn : 19.39845085144043\n",
            "Train_MinReturn : -108.08453369140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 391950\n",
            "TimeSinceStart : 450.1814205646515\n",
            "Training Loss : -308.5566711425781\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.17674255371094\n",
            "Eval_StdReturn : 22.1978816986084\n",
            "Eval_MaxReturn : -12.987955093383789\n",
            "Eval_MinReturn : -63.287681579589844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.170719146728516\n",
            "Train_StdReturn : 22.46530532836914\n",
            "Train_MaxReturn : 16.399091720581055\n",
            "Train_MinReturn : -88.2833023071289\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 402000\n",
            "TimeSinceStart : 461.35939025878906\n",
            "Training Loss : -516.9796142578125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.31132888793945\n",
            "Eval_StdReturn : 10.834312438964844\n",
            "Eval_MaxReturn : -34.51387023925781\n",
            "Eval_MinReturn : -60.15242385864258\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.28104782104492\n",
            "Train_StdReturn : 23.781707763671875\n",
            "Train_MaxReturn : 30.889400482177734\n",
            "Train_MinReturn : -95.19679260253906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 412050\n",
            "TimeSinceStart : 472.3786871433258\n",
            "Training Loss : -363.1303405761719\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -43.43696594238281\n",
            "Eval_StdReturn : 4.032754421234131\n",
            "Eval_MaxReturn : -37.734466552734375\n",
            "Eval_MinReturn : -46.36423873901367\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.87882995605469\n",
            "Train_StdReturn : 23.215055465698242\n",
            "Train_MaxReturn : 20.78600311279297\n",
            "Train_MinReturn : -98.8391342163086\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 422100\n",
            "TimeSinceStart : 483.386931180954\n",
            "Training Loss : -689.0902099609375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -63.2808837890625\n",
            "Eval_StdReturn : 50.569480895996094\n",
            "Eval_MaxReturn : -25.297670364379883\n",
            "Eval_MinReturn : -134.74977111816406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.442792892456055\n",
            "Train_StdReturn : 25.598764419555664\n",
            "Train_MaxReturn : 62.998722076416016\n",
            "Train_MinReturn : -142.48471069335938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 432150\n",
            "TimeSinceStart : 494.55460929870605\n",
            "Training Loss : -413.1396484375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -48.25163269042969\n",
            "Eval_StdReturn : 14.796862602233887\n",
            "Eval_MaxReturn : -36.43948745727539\n",
            "Eval_MinReturn : -69.11683654785156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.79633331298828\n",
            "Train_StdReturn : 28.893510818481445\n",
            "Train_MaxReturn : 78.50135040283203\n",
            "Train_MinReturn : -107.94352722167969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 442200\n",
            "TimeSinceStart : 505.64980721473694\n",
            "Training Loss : -241.26611328125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.801450729370117\n",
            "Eval_StdReturn : 11.978968620300293\n",
            "Eval_MaxReturn : -15.426782608032227\n",
            "Eval_MinReturn : -43.361053466796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.057308197021484\n",
            "Train_StdReturn : 20.871212005615234\n",
            "Train_MaxReturn : 13.798707962036133\n",
            "Train_MinReturn : -91.367919921875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 452250\n",
            "TimeSinceStart : 516.842609167099\n",
            "Training Loss : -180.377197265625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -54.91389083862305\n",
            "Eval_StdReturn : 44.04994201660156\n",
            "Eval_MaxReturn : -0.2366943359375\n",
            "Eval_MinReturn : -108.10591125488281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.519060134887695\n",
            "Train_StdReturn : 28.713594436645508\n",
            "Train_MaxReturn : 58.27046203613281\n",
            "Train_MinReturn : -116.94634246826172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 462300\n",
            "TimeSinceStart : 527.9104795455933\n",
            "Training Loss : -288.2974853515625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.168880462646484\n",
            "Eval_StdReturn : 13.271275520324707\n",
            "Eval_MaxReturn : -27.15245819091797\n",
            "Eval_MinReturn : -58.98657989501953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.0358943939209\n",
            "Train_StdReturn : 23.176118850708008\n",
            "Train_MaxReturn : 29.249282836914062\n",
            "Train_MinReturn : -100.22400665283203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 472350\n",
            "TimeSinceStart : 538.9354159832001\n",
            "Training Loss : -185.5704345703125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.781639099121094\n",
            "Eval_StdReturn : 10.433195114135742\n",
            "Eval_MaxReturn : -4.664281845092773\n",
            "Eval_MinReturn : -29.55548858642578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.762428283691406\n",
            "Train_StdReturn : 22.8797550201416\n",
            "Train_MaxReturn : 27.542383193969727\n",
            "Train_MinReturn : -95.75023651123047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 482400\n",
            "TimeSinceStart : 550.0494561195374\n",
            "Training Loss : -312.010009765625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -10.722338676452637\n",
            "Eval_StdReturn : 20.970422744750977\n",
            "Eval_MaxReturn : 16.485916137695312\n",
            "Eval_MinReturn : -34.54513168334961\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.947418212890625\n",
            "Train_StdReturn : 22.774139404296875\n",
            "Train_MaxReturn : 11.271583557128906\n",
            "Train_MinReturn : -103.89087677001953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 492450\n",
            "TimeSinceStart : 561.153115272522\n",
            "Training Loss : -500.42132568359375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.30290699005127\n",
            "Eval_StdReturn : 1.8727556467056274\n",
            "Eval_MaxReturn : -12.944372177124023\n",
            "Eval_MinReturn : -17.525632858276367\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.520938873291016\n",
            "Train_StdReturn : 28.929574966430664\n",
            "Train_MaxReturn : 23.48661231994629\n",
            "Train_MinReturn : -124.16776275634766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 502500\n",
            "TimeSinceStart : 572.2200078964233\n",
            "Training Loss : -381.5133056640625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -51.69184494018555\n",
            "Eval_StdReturn : 19.858476638793945\n",
            "Eval_MaxReturn : -31.836158752441406\n",
            "Eval_MinReturn : -78.82005310058594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.17854118347168\n",
            "Train_StdReturn : 21.568235397338867\n",
            "Train_MaxReturn : 25.4155330657959\n",
            "Train_MinReturn : -86.19914245605469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 512550\n",
            "TimeSinceStart : 583.3389608860016\n",
            "Training Loss : -459.5859680175781\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.2640788555145264\n",
            "Eval_StdReturn : 19.910131454467773\n",
            "Eval_MaxReturn : 28.163055419921875\n",
            "Eval_MinReturn : -20.253707885742188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.479990005493164\n",
            "Train_StdReturn : 21.971595764160156\n",
            "Train_MaxReturn : 45.61919021606445\n",
            "Train_MinReturn : -77.36854553222656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 522600\n",
            "TimeSinceStart : 594.3904888629913\n",
            "Training Loss : -425.4404296875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.460365295410156\n",
            "Eval_StdReturn : 20.245302200317383\n",
            "Eval_MaxReturn : -14.720962524414062\n",
            "Eval_MinReturn : -62.29045104980469\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.359769821166992\n",
            "Train_StdReturn : 23.82781982421875\n",
            "Train_MaxReturn : 46.10308837890625\n",
            "Train_MinReturn : -91.07524871826172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 532650\n",
            "TimeSinceStart : 605.4972093105316\n",
            "Training Loss : -157.111572265625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.11696243286133\n",
            "Eval_StdReturn : 32.110782623291016\n",
            "Eval_MaxReturn : -5.152505874633789\n",
            "Eval_MinReturn : -83.77498626708984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.50832176208496\n",
            "Train_StdReturn : 21.124465942382812\n",
            "Train_MaxReturn : 16.137922286987305\n",
            "Train_MinReturn : -119.12198638916016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 542700\n",
            "TimeSinceStart : 616.612943649292\n",
            "Training Loss : -173.840576171875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.905059814453125\n",
            "Eval_StdReturn : 67.11075592041016\n",
            "Eval_MaxReturn : 1.961961269378662\n",
            "Eval_MinReturn : -148.2835693359375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.56987190246582\n",
            "Train_StdReturn : 17.654165267944336\n",
            "Train_MaxReturn : 28.39212417602539\n",
            "Train_MinReturn : -60.20140075683594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 552750\n",
            "TimeSinceStart : 627.7094373703003\n",
            "Training Loss : -229.964599609375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.880030632019043\n",
            "Eval_StdReturn : 14.158309936523438\n",
            "Eval_MaxReturn : 9.022956848144531\n",
            "Eval_MinReturn : -25.596759796142578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.34819221496582\n",
            "Train_StdReturn : 24.599063873291016\n",
            "Train_MaxReturn : 28.895809173583984\n",
            "Train_MinReturn : -112.21556854248047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 562800\n",
            "TimeSinceStart : 638.6947717666626\n",
            "Training Loss : -146.1162109375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.716012954711914\n",
            "Eval_StdReturn : 14.278568267822266\n",
            "Eval_MaxReturn : -13.290122985839844\n",
            "Eval_MinReturn : -43.905338287353516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.03321075439453\n",
            "Train_StdReturn : 23.645742416381836\n",
            "Train_MaxReturn : 14.181537628173828\n",
            "Train_MinReturn : -128.9253387451172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 572850\n",
            "TimeSinceStart : 649.7229428291321\n",
            "Training Loss : -292.38409423828125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.606399536132812\n",
            "Eval_StdReturn : 16.26309585571289\n",
            "Eval_MaxReturn : -11.345579147338867\n",
            "Eval_MinReturn : -46.58871078491211\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.90479278564453\n",
            "Train_StdReturn : 26.7767333984375\n",
            "Train_MaxReturn : 16.343719482421875\n",
            "Train_MinReturn : -122.95221710205078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 582900\n",
            "TimeSinceStart : 660.7485661506653\n",
            "Training Loss : -256.54193115234375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.830297470092773\n",
            "Eval_StdReturn : 29.064861297607422\n",
            "Eval_MaxReturn : 12.809243202209473\n",
            "Eval_MinReturn : -57.290443420410156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.65468406677246\n",
            "Train_StdReturn : 19.10034942626953\n",
            "Train_MaxReturn : 25.061534881591797\n",
            "Train_MinReturn : -62.72241973876953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 592950\n",
            "TimeSinceStart : 671.827241897583\n",
            "Training Loss : -460.4771728515625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.00252342224121\n",
            "Eval_StdReturn : 11.658770561218262\n",
            "Eval_MaxReturn : -7.753782272338867\n",
            "Eval_MinReturn : -34.312278747558594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.121843338012695\n",
            "Train_StdReturn : 20.666837692260742\n",
            "Train_MaxReturn : 21.715133666992188\n",
            "Train_MinReturn : -77.8202133178711\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 603000\n",
            "TimeSinceStart : 682.910441160202\n",
            "Training Loss : -129.98037719726562\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.333106994628906\n",
            "Eval_StdReturn : 6.663449764251709\n",
            "Eval_MaxReturn : -5.628392696380615\n",
            "Eval_MinReturn : -21.81169319152832\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.780807495117188\n",
            "Train_StdReturn : 21.458139419555664\n",
            "Train_MaxReturn : 13.206883430480957\n",
            "Train_MinReturn : -78.05075073242188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 613050\n",
            "TimeSinceStart : 693.9262595176697\n",
            "Training Loss : -293.2187194824219\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.609970092773438\n",
            "Eval_StdReturn : 15.017030715942383\n",
            "Eval_MaxReturn : -7.296411514282227\n",
            "Eval_MinReturn : -43.54247283935547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.784351348876953\n",
            "Train_StdReturn : 22.805496215820312\n",
            "Train_MaxReturn : 2.7170896530151367\n",
            "Train_MinReturn : -117.60938262939453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 623100\n",
            "TimeSinceStart : 705.0402767658234\n",
            "Training Loss : -242.00743103027344\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.056270599365234\n",
            "Eval_StdReturn : 4.74627161026001\n",
            "Eval_MaxReturn : -41.84186935424805\n",
            "Eval_MinReturn : -52.68782043457031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.507373809814453\n",
            "Train_StdReturn : 22.32496452331543\n",
            "Train_MaxReturn : 39.810916900634766\n",
            "Train_MinReturn : -99.97247314453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 633150\n",
            "TimeSinceStart : 716.0063302516937\n",
            "Training Loss : -350.7887878417969\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.818490982055664\n",
            "Eval_StdReturn : 11.609040260314941\n",
            "Eval_MaxReturn : -0.6016391515731812\n",
            "Eval_MinReturn : -27.143892288208008\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.169300079345703\n",
            "Train_StdReturn : 17.329458236694336\n",
            "Train_MaxReturn : 8.0034761428833\n",
            "Train_MinReturn : -67.45668029785156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 643200\n",
            "TimeSinceStart : 726.9943408966064\n",
            "Training Loss : -358.6823425292969\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.348787307739258\n",
            "Eval_StdReturn : 2.8831746578216553\n",
            "Eval_MaxReturn : -18.110254287719727\n",
            "Eval_MinReturn : -25.113508224487305\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.74574851989746\n",
            "Train_StdReturn : 20.15227508544922\n",
            "Train_MaxReturn : 40.474998474121094\n",
            "Train_MinReturn : -61.919776916503906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 653250\n",
            "TimeSinceStart : 738.1495735645294\n",
            "Training Loss : -479.23193359375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.338302612304688\n",
            "Eval_StdReturn : 6.489475727081299\n",
            "Eval_MaxReturn : -19.945266723632812\n",
            "Eval_MinReturn : -35.75004196166992\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.6651611328125\n",
            "Train_StdReturn : 24.156675338745117\n",
            "Train_MaxReturn : 19.919078826904297\n",
            "Train_MinReturn : -80.71577453613281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 663300\n",
            "TimeSinceStart : 749.1796772480011\n",
            "Training Loss : -436.3665771484375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.36481857299805\n",
            "Eval_StdReturn : 8.470512390136719\n",
            "Eval_MaxReturn : -25.307384490966797\n",
            "Eval_MinReturn : -45.682979583740234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -15.210467338562012\n",
            "Train_StdReturn : 18.62265968322754\n",
            "Train_MaxReturn : 25.6544189453125\n",
            "Train_MinReturn : -56.949241638183594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 673350\n",
            "TimeSinceStart : 760.1811645030975\n",
            "Training Loss : -286.4739990234375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.6418514251709\n",
            "Eval_StdReturn : 20.47412109375\n",
            "Eval_MaxReturn : -9.2202787399292\n",
            "Eval_MinReturn : -54.50532150268555\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -15.391091346740723\n",
            "Train_StdReturn : 16.760103225708008\n",
            "Train_MaxReturn : 31.074987411499023\n",
            "Train_MinReturn : -74.77079772949219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 683400\n",
            "TimeSinceStart : 771.1826605796814\n",
            "Training Loss : -404.5950927734375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.397544860839844\n",
            "Eval_StdReturn : 5.89511775970459\n",
            "Eval_MaxReturn : -22.02446174621582\n",
            "Eval_MinReturn : -35.6046028137207\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.30532455444336\n",
            "Train_StdReturn : 17.923816680908203\n",
            "Train_MaxReturn : 26.29413414001465\n",
            "Train_MinReturn : -65.71788024902344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 693450\n",
            "TimeSinceStart : 782.1388494968414\n",
            "Training Loss : -237.85498046875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -1.1555742025375366\n",
            "Eval_StdReturn : 15.240594863891602\n",
            "Eval_MaxReturn : 15.957611083984375\n",
            "Eval_MinReturn : -21.059755325317383\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.96107006072998\n",
            "Train_StdReturn : 23.04347038269043\n",
            "Train_MaxReturn : 28.46307945251465\n",
            "Train_MinReturn : -79.46923828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 703500\n",
            "TimeSinceStart : 793.1536831855774\n",
            "Training Loss : -265.7105712890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.879247665405273\n",
            "Eval_StdReturn : 15.023119926452637\n",
            "Eval_MaxReturn : -5.803766250610352\n",
            "Eval_MinReturn : -39.91923141479492\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.968600273132324\n",
            "Train_StdReturn : 20.124696731567383\n",
            "Train_MaxReturn : 38.901039123535156\n",
            "Train_MinReturn : -50.05793762207031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 713550\n",
            "TimeSinceStart : 804.2066025733948\n",
            "Training Loss : -499.145751953125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.559165954589844\n",
            "Eval_StdReturn : 25.828100204467773\n",
            "Eval_MaxReturn : 2.197352409362793\n",
            "Eval_MinReturn : -58.867034912109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.082569122314453\n",
            "Train_StdReturn : 21.858474731445312\n",
            "Train_MaxReturn : 33.20669937133789\n",
            "Train_MinReturn : -64.78046417236328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 723600\n",
            "TimeSinceStart : 815.297869682312\n",
            "Training Loss : -139.1484375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.554330825805664\n",
            "Eval_StdReturn : 21.89618682861328\n",
            "Eval_MaxReturn : 4.3008880615234375\n",
            "Eval_MinReturn : -48.713165283203125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.797298431396484\n",
            "Train_StdReturn : 23.941905975341797\n",
            "Train_MaxReturn : 52.93552780151367\n",
            "Train_MinReturn : -92.07276916503906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 733650\n",
            "TimeSinceStart : 826.3664741516113\n",
            "Training Loss : 33.4974365234375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.638773918151855\n",
            "Eval_StdReturn : 18.901235580444336\n",
            "Eval_MaxReturn : 14.932092666625977\n",
            "Eval_MinReturn : -27.449459075927734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.14892578125\n",
            "Train_StdReturn : 23.524213790893555\n",
            "Train_MaxReturn : 39.30232620239258\n",
            "Train_MinReturn : -68.52902221679688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 743700\n",
            "TimeSinceStart : 837.3146743774414\n",
            "Training Loss : -347.52655029296875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -10.070515632629395\n",
            "Eval_StdReturn : 19.14773178100586\n",
            "Eval_MaxReturn : 16.901355743408203\n",
            "Eval_MinReturn : -25.640209197998047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.701067924499512\n",
            "Train_StdReturn : 20.79119110107422\n",
            "Train_MaxReturn : 29.88555908203125\n",
            "Train_MinReturn : -62.163692474365234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 753750\n",
            "TimeSinceStart : 848.3224353790283\n",
            "Training Loss : -372.95404052734375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.765308380126953\n",
            "Eval_StdReturn : 18.93885040283203\n",
            "Eval_MaxReturn : 5.480532646179199\n",
            "Eval_MinReturn : -40.743408203125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.513211250305176\n",
            "Train_StdReturn : 20.917083740234375\n",
            "Train_MaxReturn : 26.983509063720703\n",
            "Train_MinReturn : -73.15151977539062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 763800\n",
            "TimeSinceStart : 859.3828113079071\n",
            "Training Loss : -424.8636474609375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.173540115356445\n",
            "Eval_StdReturn : 14.214837074279785\n",
            "Eval_MaxReturn : -8.126730918884277\n",
            "Eval_MinReturn : -40.134239196777344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.573578834533691\n",
            "Train_StdReturn : 21.134479522705078\n",
            "Train_MaxReturn : 22.32027816772461\n",
            "Train_MinReturn : -88.48792266845703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 773850\n",
            "TimeSinceStart : 870.4117217063904\n",
            "Training Loss : -93.86669921875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.446578979492188\n",
            "Eval_StdReturn : 4.8463134765625\n",
            "Eval_MaxReturn : -23.93811798095703\n",
            "Eval_MinReturn : -35.73249053955078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.035951614379883\n",
            "Train_StdReturn : 23.740158081054688\n",
            "Train_MaxReturn : 61.8887939453125\n",
            "Train_MinReturn : -107.95974731445312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 783900\n",
            "TimeSinceStart : 881.4209370613098\n",
            "Training Loss : -282.04248046875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -5.481530666351318\n",
            "Eval_StdReturn : 10.728693008422852\n",
            "Eval_MaxReturn : 9.585611343383789\n",
            "Eval_MinReturn : -14.56209659576416\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.450218200683594\n",
            "Train_StdReturn : 22.598024368286133\n",
            "Train_MaxReturn : 27.294109344482422\n",
            "Train_MinReturn : -86.54885864257812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 793950\n",
            "TimeSinceStart : 892.4668357372284\n",
            "Training Loss : -176.68994140625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.738082885742188\n",
            "Eval_StdReturn : 29.036266326904297\n",
            "Eval_MaxReturn : 14.971490859985352\n",
            "Eval_MinReturn : -50.751739501953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.719316482543945\n",
            "Train_StdReturn : 21.793922424316406\n",
            "Train_MaxReturn : 40.886112213134766\n",
            "Train_MinReturn : -66.3118667602539\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 804000\n",
            "TimeSinceStart : 903.40691614151\n",
            "Training Loss : -384.162353515625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -2.9243290424346924\n",
            "Eval_StdReturn : 13.106499671936035\n",
            "Eval_MaxReturn : 12.650169372558594\n",
            "Eval_MinReturn : -19.414840698242188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.472911834716797\n",
            "Train_StdReturn : 18.16254425048828\n",
            "Train_MaxReturn : 29.613605499267578\n",
            "Train_MinReturn : -56.916290283203125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 814050\n",
            "TimeSinceStart : 914.4271531105042\n",
            "Training Loss : -556.7864990234375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.26678466796875\n",
            "Eval_StdReturn : 14.496304512023926\n",
            "Eval_MaxReturn : 6.8512043952941895\n",
            "Eval_MinReturn : -28.236019134521484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.1954345703125\n",
            "Train_StdReturn : 20.09455680847168\n",
            "Train_MaxReturn : 29.66067886352539\n",
            "Train_MinReturn : -96.80540466308594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 824100\n",
            "TimeSinceStart : 925.4818065166473\n",
            "Training Loss : -194.851318359375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.858622550964355\n",
            "Eval_StdReturn : 9.767329216003418\n",
            "Eval_MaxReturn : -0.4610309600830078\n",
            "Eval_MinReturn : -24.332441329956055\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.5330810546875\n",
            "Train_StdReturn : 18.131528854370117\n",
            "Train_MaxReturn : 26.197017669677734\n",
            "Train_MinReturn : -57.33379364013672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 834150\n",
            "TimeSinceStart : 936.5459280014038\n",
            "Training Loss : -425.962890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.624841690063477\n",
            "Eval_StdReturn : 13.119507789611816\n",
            "Eval_MaxReturn : -4.083237648010254\n",
            "Eval_MinReturn : -32.47781753540039\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.021529197692871\n",
            "Train_StdReturn : 20.195837020874023\n",
            "Train_MaxReturn : 41.19812774658203\n",
            "Train_MinReturn : -61.18902587890625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 844200\n",
            "TimeSinceStart : 947.519832611084\n",
            "Training Loss : -266.206787109375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.419355392456055\n",
            "Eval_StdReturn : 3.9217629432678223\n",
            "Eval_MaxReturn : -16.259057998657227\n",
            "Eval_MinReturn : -25.759855270385742\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.858826637268066\n",
            "Train_StdReturn : 24.872859954833984\n",
            "Train_MaxReturn : 46.535911560058594\n",
            "Train_MinReturn : -79.13349914550781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 854250\n",
            "TimeSinceStart : 958.4429311752319\n",
            "Training Loss : -33.138275146484375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.50536346435547\n",
            "Eval_StdReturn : 31.110851287841797\n",
            "Eval_MaxReturn : 14.073175430297852\n",
            "Eval_MinReturn : -61.968570709228516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.93903923034668\n",
            "Train_StdReturn : 23.59741973876953\n",
            "Train_MaxReturn : 29.219615936279297\n",
            "Train_MinReturn : -82.51119232177734\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 864300\n",
            "TimeSinceStart : 969.409698009491\n",
            "Training Loss : -560.9947509765625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -6.608467102050781\n",
            "Eval_StdReturn : 4.832760810852051\n",
            "Eval_MaxReturn : -0.04210245609283447\n",
            "Eval_MinReturn : -11.533449172973633\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.552520751953125\n",
            "Train_StdReturn : 20.121124267578125\n",
            "Train_MaxReturn : 33.64421844482422\n",
            "Train_MinReturn : -84.15909576416016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 874350\n",
            "TimeSinceStart : 980.4296629428864\n",
            "Training Loss : -384.2169189453125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.472848892211914\n",
            "Eval_StdReturn : 10.958381652832031\n",
            "Eval_MaxReturn : -3.927931785583496\n",
            "Eval_MinReturn : -30.766857147216797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.863898277282715\n",
            "Train_StdReturn : 20.999420166015625\n",
            "Train_MaxReturn : 45.52891159057617\n",
            "Train_MinReturn : -56.213157653808594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 884400\n",
            "TimeSinceStart : 991.4735703468323\n",
            "Training Loss : -11.621337890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -3.4107940196990967\n",
            "Eval_StdReturn : 23.56330680847168\n",
            "Eval_MaxReturn : 27.471084594726562\n",
            "Eval_MinReturn : -29.694992065429688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.665814399719238\n",
            "Train_StdReturn : 21.087574005126953\n",
            "Train_MaxReturn : 31.5885009765625\n",
            "Train_MinReturn : -72.03947448730469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 894450\n",
            "TimeSinceStart : 1002.4875266551971\n",
            "Training Loss : -558.4429321289062\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.3188812732696533\n",
            "Eval_StdReturn : 2.1337456703186035\n",
            "Eval_MaxReturn : 5.765434741973877\n",
            "Eval_MinReturn : 0.5658700466156006\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.016583442687988\n",
            "Train_StdReturn : 20.31294059753418\n",
            "Train_MaxReturn : 40.12790298461914\n",
            "Train_MinReturn : -79.56413269042969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 904500\n",
            "TimeSinceStart : 1013.4915289878845\n",
            "Training Loss : -157.78665161132812\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.789799213409424\n",
            "Eval_StdReturn : 3.7330780029296875\n",
            "Eval_MaxReturn : -1.4845943450927734\n",
            "Eval_MinReturn : -10.007583618164062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.61670970916748\n",
            "Train_StdReturn : 22.775911331176758\n",
            "Train_MaxReturn : 33.2144775390625\n",
            "Train_MinReturn : -60.668609619140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 914550\n",
            "TimeSinceStart : 1024.432963848114\n",
            "Training Loss : 25.881591796875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.594635009765625\n",
            "Eval_StdReturn : 7.649935245513916\n",
            "Eval_MaxReturn : -28.044944763183594\n",
            "Eval_MinReturn : -45.94560623168945\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -7.204541206359863\n",
            "Train_StdReturn : 22.951828002929688\n",
            "Train_MaxReturn : 50.191436767578125\n",
            "Train_MinReturn : -61.42890930175781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 924600\n",
            "TimeSinceStart : 1035.3966610431671\n",
            "Training Loss : -209.841552734375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.1354261636734009\n",
            "Eval_StdReturn : 19.248075485229492\n",
            "Eval_MaxReturn : 27.085494995117188\n",
            "Eval_MinReturn : -18.958463668823242\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.337693214416504\n",
            "Train_StdReturn : 20.194114685058594\n",
            "Train_MaxReturn : 27.795286178588867\n",
            "Train_MinReturn : -81.60664367675781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 934650\n",
            "TimeSinceStart : 1046.4120998382568\n",
            "Training Loss : -274.0804443359375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.225418090820312\n",
            "Eval_StdReturn : 1.4289005994796753\n",
            "Eval_MaxReturn : -9.460891723632812\n",
            "Eval_MinReturn : -12.960599899291992\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -6.51415491104126\n",
            "Train_StdReturn : 15.905716896057129\n",
            "Train_MaxReturn : 27.998138427734375\n",
            "Train_MinReturn : -52.817283630371094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 944700\n",
            "TimeSinceStart : 1057.4043292999268\n",
            "Training Loss : -155.45263671875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -3.3048441410064697\n",
            "Eval_StdReturn : 9.148971557617188\n",
            "Eval_MaxReturn : 8.26105785369873\n",
            "Eval_MinReturn : -14.1105375289917\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -5.520517349243164\n",
            "Train_StdReturn : 20.866764068603516\n",
            "Train_MaxReturn : 31.365095138549805\n",
            "Train_MinReturn : -54.64640426635742\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 954750\n",
            "TimeSinceStart : 1068.3946726322174\n",
            "Training Loss : -114.892578125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.03652572631836\n",
            "Eval_StdReturn : 23.408884048461914\n",
            "Eval_MaxReturn : -8.088186264038086\n",
            "Eval_MinReturn : -65.37726593017578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.408302307128906\n",
            "Train_StdReturn : 22.63493537902832\n",
            "Train_MaxReturn : 35.870662689208984\n",
            "Train_MinReturn : -67.67787170410156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 964800\n",
            "TimeSinceStart : 1079.4686439037323\n",
            "Training Loss : -7.2113037109375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.76687240600586\n",
            "Eval_StdReturn : 4.744922637939453\n",
            "Eval_MaxReturn : -32.07004165649414\n",
            "Eval_MinReturn : -42.483768463134766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.107442855834961\n",
            "Train_StdReturn : 19.169292449951172\n",
            "Train_MaxReturn : 21.409353256225586\n",
            "Train_MinReturn : -70.0940170288086\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 974850\n",
            "TimeSinceStart : 1090.4469068050385\n",
            "Training Loss : 50.16387939453125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.342639923095703\n",
            "Eval_StdReturn : 29.649728775024414\n",
            "Eval_MaxReturn : 56.035606384277344\n",
            "Eval_MinReturn : -10.368057250976562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.719139099121094\n",
            "Train_StdReturn : 21.357717514038086\n",
            "Train_MaxReturn : 50.964988708496094\n",
            "Train_MinReturn : -68.31231689453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 984900\n",
            "TimeSinceStart : 1101.5094799995422\n",
            "Training Loss : -247.27178955078125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.19044303894043\n",
            "Eval_StdReturn : 27.523679733276367\n",
            "Eval_MaxReturn : 18.22365379333496\n",
            "Eval_MinReturn : -47.196327209472656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.487607955932617\n",
            "Train_StdReturn : 27.92308807373047\n",
            "Train_MaxReturn : 36.411865234375\n",
            "Train_MinReturn : -97.09986877441406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 994950\n",
            "TimeSinceStart : 1112.4833822250366\n",
            "Training Loss : 24.8968505859375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 23.164369583129883\n",
            "Eval_StdReturn : 23.70033836364746\n",
            "Eval_MaxReturn : 47.82086181640625\n",
            "Eval_MinReturn : -8.826072692871094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -15.096661567687988\n",
            "Train_StdReturn : 25.05755043029785\n",
            "Train_MaxReturn : 28.763193130493164\n",
            "Train_MinReturn : -95.96675872802734\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1005000\n",
            "TimeSinceStart : 1123.5326025485992\n",
            "Training Loss : 49.5146484375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "    --discount 0.95 -n 100 -l 2 -s 32 \\\n",
        "    -b 10000 -lr 0.01 -rtg --nn_baseline \\\n",
        "    --exp_name q4_search_b10000_lr0.01_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHB-xlYzPRK3",
        "outputId": "80235234-d8a5-4b9f-80d9-1af8e771d757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q4_search_b10000_lr0.02_rtg_nnbaseline_HalfCheetah-v2_08-05-2022_20-14-06\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -126.7088851928711\n",
            "Eval_StdReturn : 13.824382781982422\n",
            "Eval_MaxReturn : -110.81553649902344\n",
            "Eval_MinReturn : -144.51565551757812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -89.69666290283203\n",
            "Train_StdReturn : 40.17568588256836\n",
            "Train_MaxReturn : 11.764884948730469\n",
            "Train_MinReturn : -178.39559936523438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 10050\n",
            "TimeSinceStart : 10.955688953399658\n",
            "Training Loss : -594.497802734375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -83.4251480102539\n",
            "Eval_StdReturn : 42.37925720214844\n",
            "Eval_MaxReturn : -48.661888122558594\n",
            "Eval_MinReturn : -143.08726501464844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -95.77449035644531\n",
            "Train_StdReturn : 38.1460075378418\n",
            "Train_MaxReturn : -11.555405616760254\n",
            "Train_MinReturn : -178.0684814453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 20100\n",
            "TimeSinceStart : 21.81291151046753\n",
            "Training Loss : -742.626708984375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -51.4468994140625\n",
            "Eval_StdReturn : 10.643753051757812\n",
            "Eval_MaxReturn : -41.18898391723633\n",
            "Eval_MinReturn : -66.1160659790039\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -84.25623321533203\n",
            "Train_StdReturn : 31.326400756835938\n",
            "Train_MaxReturn : -30.9055118560791\n",
            "Train_MinReturn : -163.94789123535156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 30150\n",
            "TimeSinceStart : 32.723681688308716\n",
            "Training Loss : -889.6669921875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -85.89300537109375\n",
            "Eval_StdReturn : 48.93783187866211\n",
            "Eval_MaxReturn : -48.39056396484375\n",
            "Eval_MinReturn : -155.01824951171875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -77.2768325805664\n",
            "Train_StdReturn : 29.734907150268555\n",
            "Train_MaxReturn : -3.1090316772460938\n",
            "Train_MinReturn : -141.26736450195312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 40200\n",
            "TimeSinceStart : 43.690449953079224\n",
            "Training Loss : -638.990234375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -114.37316131591797\n",
            "Eval_StdReturn : 22.232288360595703\n",
            "Eval_MaxReturn : -90.93241119384766\n",
            "Eval_MinReturn : -144.24044799804688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -72.59554290771484\n",
            "Train_StdReturn : 31.431142807006836\n",
            "Train_MaxReturn : 5.646683692932129\n",
            "Train_MinReturn : -182.41555786132812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50250\n",
            "TimeSinceStart : 54.65705633163452\n",
            "Training Loss : -712.750244140625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -62.609806060791016\n",
            "Eval_StdReturn : 11.99024486541748\n",
            "Eval_MaxReturn : -49.554630279541016\n",
            "Eval_MinReturn : -78.5086669921875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -73.26036071777344\n",
            "Train_StdReturn : 30.63409996032715\n",
            "Train_MaxReturn : -11.50638198852539\n",
            "Train_MinReturn : -182.47018432617188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 60300\n",
            "TimeSinceStart : 65.68543028831482\n",
            "Training Loss : -616.8878173828125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.8748664855957\n",
            "Eval_StdReturn : 11.707289695739746\n",
            "Eval_MaxReturn : -32.59812545776367\n",
            "Eval_MinReturn : -61.04106140136719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -71.40825653076172\n",
            "Train_StdReturn : 30.76011848449707\n",
            "Train_MaxReturn : 6.369926452636719\n",
            "Train_MinReturn : -170.55357360839844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 70350\n",
            "TimeSinceStart : 76.56258654594421\n",
            "Training Loss : -916.9287109375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -57.12397766113281\n",
            "Eval_StdReturn : 22.906963348388672\n",
            "Eval_MaxReturn : -25.654857635498047\n",
            "Eval_MinReturn : -79.51919555664062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -65.52487182617188\n",
            "Train_StdReturn : 31.08083724975586\n",
            "Train_MaxReturn : -16.92013931274414\n",
            "Train_MinReturn : -148.75802612304688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 80400\n",
            "TimeSinceStart : 87.5333263874054\n",
            "Training Loss : -891.955078125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -76.46233367919922\n",
            "Eval_StdReturn : 19.903949737548828\n",
            "Eval_MaxReturn : -56.79804229736328\n",
            "Eval_MinReturn : -103.73688507080078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -63.75426483154297\n",
            "Train_StdReturn : 32.36934280395508\n",
            "Train_MaxReturn : -13.799888610839844\n",
            "Train_MinReturn : -173.34024047851562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 90450\n",
            "TimeSinceStart : 98.56667804718018\n",
            "Training Loss : -764.9451904296875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.15739059448242\n",
            "Eval_StdReturn : 14.248607635498047\n",
            "Eval_MaxReturn : -28.8807430267334\n",
            "Eval_MinReturn : -61.13396453857422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -66.35037994384766\n",
            "Train_StdReturn : 28.72787857055664\n",
            "Train_MaxReturn : -18.278526306152344\n",
            "Train_MinReturn : -158.01583862304688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100500\n",
            "TimeSinceStart : 109.60752058029175\n",
            "Training Loss : -785.747314453125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.572269439697266\n",
            "Eval_StdReturn : 13.675941467285156\n",
            "Eval_MaxReturn : -27.91956329345703\n",
            "Eval_MinReturn : -59.566646575927734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -58.091346740722656\n",
            "Train_StdReturn : 25.81679344177246\n",
            "Train_MaxReturn : -5.820111274719238\n",
            "Train_MinReturn : -145.61764526367188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 110550\n",
            "TimeSinceStart : 120.54760599136353\n",
            "Training Loss : -868.84375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -54.3850212097168\n",
            "Eval_StdReturn : 11.481715202331543\n",
            "Eval_MaxReturn : -38.294410705566406\n",
            "Eval_MinReturn : -64.31815338134766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -53.559722900390625\n",
            "Train_StdReturn : 21.699249267578125\n",
            "Train_MaxReturn : -12.347146034240723\n",
            "Train_MinReturn : -108.59098815917969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 120600\n",
            "TimeSinceStart : 131.62430119514465\n",
            "Training Loss : -652.5889282226562\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.42710494995117\n",
            "Eval_StdReturn : 22.24776268005371\n",
            "Eval_MaxReturn : -31.123455047607422\n",
            "Eval_MinReturn : -84.88337707519531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.25799560546875\n",
            "Train_StdReturn : 23.625045776367188\n",
            "Train_MaxReturn : 21.233015060424805\n",
            "Train_MinReturn : -105.67744445800781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 130650\n",
            "TimeSinceStart : 142.53515529632568\n",
            "Training Loss : -524.490478515625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -43.45444107055664\n",
            "Eval_StdReturn : 16.29139518737793\n",
            "Eval_MaxReturn : -28.834903717041016\n",
            "Eval_MinReturn : -66.18550109863281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -47.111724853515625\n",
            "Train_StdReturn : 21.293689727783203\n",
            "Train_MaxReturn : 7.669222354888916\n",
            "Train_MinReturn : -100.63525390625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 140700\n",
            "TimeSinceStart : 153.45920538902283\n",
            "Training Loss : -773.2991943359375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -57.28889465332031\n",
            "Eval_StdReturn : 18.621286392211914\n",
            "Eval_MaxReturn : -31.659746170043945\n",
            "Eval_MinReturn : -75.3464126586914\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.95389938354492\n",
            "Train_StdReturn : 20.31081199645996\n",
            "Train_MaxReturn : -4.953121185302734\n",
            "Train_MinReturn : -84.91143798828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150750\n",
            "TimeSinceStart : 164.48052406311035\n",
            "Training Loss : -637.3282470703125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.89118957519531\n",
            "Eval_StdReturn : 34.1931266784668\n",
            "Eval_MaxReturn : -4.266727447509766\n",
            "Eval_MinReturn : -86.5800552368164\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.4182243347168\n",
            "Train_StdReturn : 27.682296752929688\n",
            "Train_MaxReturn : 17.711559295654297\n",
            "Train_MinReturn : -124.04788208007812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 160800\n",
            "TimeSinceStart : 175.45085883140564\n",
            "Training Loss : -538.1280517578125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -6.271653652191162\n",
            "Eval_StdReturn : 25.821414947509766\n",
            "Eval_MaxReturn : 19.673931121826172\n",
            "Eval_MinReturn : -41.498390197753906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.23373794555664\n",
            "Train_StdReturn : 26.060985565185547\n",
            "Train_MaxReturn : 31.304357528686523\n",
            "Train_MinReturn : -105.66343688964844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 170850\n",
            "TimeSinceStart : 186.39425539970398\n",
            "Training Loss : -860.6170654296875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.295238971710205\n",
            "Eval_StdReturn : 17.03789710998535\n",
            "Eval_MaxReturn : 14.720056533813477\n",
            "Eval_MinReturn : -26.618846893310547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.003456115722656\n",
            "Train_StdReturn : 30.97953224182129\n",
            "Train_MaxReturn : 25.817672729492188\n",
            "Train_MinReturn : -102.27705383300781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 180900\n",
            "TimeSinceStart : 197.45853400230408\n",
            "Training Loss : -538.1461181640625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -59.70859909057617\n",
            "Eval_StdReturn : 65.5448226928711\n",
            "Eval_MaxReturn : 7.270885467529297\n",
            "Eval_MinReturn : -148.69155883789062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.305055618286133\n",
            "Train_StdReturn : 30.494117736816406\n",
            "Train_MaxReturn : 36.32183837890625\n",
            "Train_MinReturn : -137.30484008789062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 190950\n",
            "TimeSinceStart : 208.5235857963562\n",
            "Training Loss : -620.1349487304688\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.018243232741951942\n",
            "Eval_StdReturn : 20.44532585144043\n",
            "Eval_MaxReturn : 23.039684295654297\n",
            "Eval_MinReturn : -26.655685424804688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.79250144958496\n",
            "Train_StdReturn : 29.651975631713867\n",
            "Train_MaxReturn : 47.368892669677734\n",
            "Train_MinReturn : -101.90228271484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 201000\n",
            "TimeSinceStart : 219.56582379341125\n",
            "Training Loss : -102.763916015625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.738995313644409\n",
            "Eval_StdReturn : 21.768451690673828\n",
            "Eval_MaxReturn : 31.853511810302734\n",
            "Eval_MinReturn : -20.4818058013916\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.447547912597656\n",
            "Train_StdReturn : 28.45505142211914\n",
            "Train_MaxReturn : 23.184595108032227\n",
            "Train_MinReturn : -110.70503997802734\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 211050\n",
            "TimeSinceStart : 230.4843544960022\n",
            "Training Loss : -488.73272705078125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.97951889038086\n",
            "Eval_StdReturn : 32.50989532470703\n",
            "Eval_MaxReturn : 9.660490036010742\n",
            "Eval_MinReturn : -60.914878845214844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.98282241821289\n",
            "Train_StdReturn : 24.6472110748291\n",
            "Train_MaxReturn : 30.14655113220215\n",
            "Train_MinReturn : -82.41376495361328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 221100\n",
            "TimeSinceStart : 241.43183159828186\n",
            "Training Loss : -231.16702270507812\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.506908416748047\n",
            "Eval_StdReturn : 34.36140441894531\n",
            "Eval_MaxReturn : 52.875511169433594\n",
            "Eval_MinReturn : -23.729284286499023\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.022300720214844\n",
            "Train_StdReturn : 29.832679748535156\n",
            "Train_MaxReturn : 32.87486267089844\n",
            "Train_MinReturn : -142.96189880371094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 231150\n",
            "TimeSinceStart : 252.42868494987488\n",
            "Training Loss : -196.1109619140625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -48.4793815612793\n",
            "Eval_StdReturn : 38.53536605834961\n",
            "Eval_MaxReturn : -1.684885025024414\n",
            "Eval_MinReturn : -96.06687927246094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.54608154296875\n",
            "Train_StdReturn : 23.965181350708008\n",
            "Train_MaxReturn : 26.928918838500977\n",
            "Train_MinReturn : -77.15754699707031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 241200\n",
            "TimeSinceStart : 263.38045048713684\n",
            "Training Loss : -662.2893676757812\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.5130696296691895\n",
            "Eval_StdReturn : 6.44730806350708\n",
            "Eval_MaxReturn : -1.0966014862060547\n",
            "Eval_MinReturn : -16.331417083740234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.66792869567871\n",
            "Train_StdReturn : 26.678133010864258\n",
            "Train_MaxReturn : 66.82957458496094\n",
            "Train_MinReturn : -124.4635009765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 251250\n",
            "TimeSinceStart : 274.3855073451996\n",
            "Training Loss : -294.80584716796875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.554317474365234\n",
            "Eval_StdReturn : 8.414444923400879\n",
            "Eval_MaxReturn : -24.043073654174805\n",
            "Eval_MinReturn : -44.64105224609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.428098678588867\n",
            "Train_StdReturn : 27.123661041259766\n",
            "Train_MaxReturn : 57.266990661621094\n",
            "Train_MinReturn : -98.20254516601562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 261300\n",
            "TimeSinceStart : 285.46438670158386\n",
            "Training Loss : -393.898681640625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -3.9260880947113037\n",
            "Eval_StdReturn : 2.554837942123413\n",
            "Eval_MaxReturn : -0.3137702941894531\n",
            "Eval_MinReturn : -5.7967939376831055\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.527379989624023\n",
            "Train_StdReturn : 23.601903915405273\n",
            "Train_MaxReturn : 29.060285568237305\n",
            "Train_MinReturn : -78.07493591308594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 271350\n",
            "TimeSinceStart : 296.4640443325043\n",
            "Training Loss : -171.01904296875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.552339553833008\n",
            "Eval_StdReturn : 6.986714839935303\n",
            "Eval_MaxReturn : -7.957665920257568\n",
            "Eval_MinReturn : -25.071046829223633\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.797985076904297\n",
            "Train_StdReturn : 27.361345291137695\n",
            "Train_MaxReturn : 54.3944091796875\n",
            "Train_MinReturn : -117.5749282836914\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 281400\n",
            "TimeSinceStart : 307.4421708583832\n",
            "Training Loss : -108.98788452148438\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.901013374328613\n",
            "Eval_StdReturn : 36.227535247802734\n",
            "Eval_MaxReturn : 62.51935958862305\n",
            "Eval_MinReturn : -22.96105194091797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.435188293457031\n",
            "Train_StdReturn : 22.437145233154297\n",
            "Train_MaxReturn : 35.56938171386719\n",
            "Train_MinReturn : -76.82821655273438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 291450\n",
            "TimeSinceStart : 318.51176285743713\n",
            "Training Loss : -263.3720703125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.6913480758667\n",
            "Eval_StdReturn : 20.064435958862305\n",
            "Eval_MaxReturn : 17.873228073120117\n",
            "Eval_MinReturn : -29.30613136291504\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.186674118041992\n",
            "Train_StdReturn : 24.566068649291992\n",
            "Train_MaxReturn : 22.51689910888672\n",
            "Train_MinReturn : -132.12249755859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 301500\n",
            "TimeSinceStart : 329.3987994194031\n",
            "Training Loss : -508.26495361328125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.446737289428711\n",
            "Eval_StdReturn : 17.810630798339844\n",
            "Eval_MaxReturn : 17.72389793395996\n",
            "Eval_MinReturn : -25.88459014892578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.98599910736084\n",
            "Train_StdReturn : 30.818185806274414\n",
            "Train_MaxReturn : 41.15327072143555\n",
            "Train_MinReturn : -118.28507995605469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 311550\n",
            "TimeSinceStart : 340.32216334342957\n",
            "Training Loss : 89.040771484375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.332414150238037\n",
            "Eval_StdReturn : 3.2913107872009277\n",
            "Eval_MaxReturn : 11.220417022705078\n",
            "Eval_MinReturn : 3.172184944152832\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.832052230834961\n",
            "Train_StdReturn : 23.542633056640625\n",
            "Train_MaxReturn : 33.68971252441406\n",
            "Train_MinReturn : -85.18734741210938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 321600\n",
            "TimeSinceStart : 351.26653480529785\n",
            "Training Loss : -359.41015625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.40330696105957\n",
            "Eval_StdReturn : 26.445837020874023\n",
            "Eval_MaxReturn : 0.7520589828491211\n",
            "Eval_MinReturn : -57.69075012207031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.794428825378418\n",
            "Train_StdReturn : 29.80646514892578\n",
            "Train_MaxReturn : 44.77552795410156\n",
            "Train_MinReturn : -108.3469009399414\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 331650\n",
            "TimeSinceStart : 362.20321464538574\n",
            "Training Loss : -97.80230712890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.4006261825561523\n",
            "Eval_StdReturn : 13.265405654907227\n",
            "Eval_MaxReturn : 20.526748657226562\n",
            "Eval_MinReturn : -10.850424766540527\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.441516876220703\n",
            "Train_StdReturn : 21.813716888427734\n",
            "Train_MaxReturn : 43.65543746948242\n",
            "Train_MinReturn : -84.40428161621094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 341700\n",
            "TimeSinceStart : 373.1726849079132\n",
            "Training Loss : -94.23052978515625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.354957580566406\n",
            "Eval_StdReturn : 23.479612350463867\n",
            "Eval_MaxReturn : 7.388618469238281\n",
            "Eval_MinReturn : -44.463783264160156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.092281341552734\n",
            "Train_StdReturn : 29.63365364074707\n",
            "Train_MaxReturn : 62.060569763183594\n",
            "Train_MinReturn : -107.559814453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 351750\n",
            "TimeSinceStart : 384.1052944660187\n",
            "Training Loss : -348.49365234375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -43.99555969238281\n",
            "Eval_StdReturn : 22.114301681518555\n",
            "Eval_MaxReturn : -14.00488567352295\n",
            "Eval_MinReturn : -66.67094421386719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.717787742614746\n",
            "Train_StdReturn : 23.10759162902832\n",
            "Train_MaxReturn : 38.37455749511719\n",
            "Train_MinReturn : -63.102481842041016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 361800\n",
            "TimeSinceStart : 395.0595328807831\n",
            "Training Loss : -95.0809326171875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.16853904724121\n",
            "Eval_StdReturn : 13.582210540771484\n",
            "Eval_MaxReturn : -10.848363876342773\n",
            "Eval_MinReturn : -43.86275863647461\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.72513198852539\n",
            "Train_StdReturn : 24.412187576293945\n",
            "Train_MaxReturn : 60.32628631591797\n",
            "Train_MinReturn : -87.37860870361328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 371850\n",
            "TimeSinceStart : 406.1252439022064\n",
            "Training Loss : -104.35284423828125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.58819007873535\n",
            "Eval_StdReturn : 15.00993537902832\n",
            "Eval_MaxReturn : -9.085028648376465\n",
            "Eval_MinReturn : -43.52412033081055\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.627153396606445\n",
            "Train_StdReturn : 27.13973617553711\n",
            "Train_MaxReturn : 27.07176971435547\n",
            "Train_MinReturn : -99.76579284667969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 381900\n",
            "TimeSinceStart : 417.02423000335693\n",
            "Training Loss : -19.066604614257812\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.82610321044922\n",
            "Eval_StdReturn : 2.388723373413086\n",
            "Eval_MaxReturn : -36.99382019042969\n",
            "Eval_MinReturn : -42.83680725097656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.25107192993164\n",
            "Train_StdReturn : 27.230985641479492\n",
            "Train_MaxReturn : 40.798309326171875\n",
            "Train_MinReturn : -110.77723693847656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 391950\n",
            "TimeSinceStart : 427.90699076652527\n",
            "Training Loss : -339.03607177734375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.89087677001953\n",
            "Eval_StdReturn : 20.160810470581055\n",
            "Eval_MaxReturn : -15.306641578674316\n",
            "Eval_MinReturn : -61.11964416503906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.24385070800781\n",
            "Train_StdReturn : 25.20794677734375\n",
            "Train_MaxReturn : 16.248531341552734\n",
            "Train_MinReturn : -105.16572570800781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 402000\n",
            "TimeSinceStart : 439.0496573448181\n",
            "Training Loss : -500.20416259765625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -48.32450485229492\n",
            "Eval_StdReturn : 30.036439895629883\n",
            "Eval_MaxReturn : -9.742794036865234\n",
            "Eval_MinReturn : -83.00595092773438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.84107971191406\n",
            "Train_StdReturn : 20.38396453857422\n",
            "Train_MaxReturn : 6.406946182250977\n",
            "Train_MinReturn : -88.43853759765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 412050\n",
            "TimeSinceStart : 449.9780058860779\n",
            "Training Loss : -312.6148986816406\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.67312240600586\n",
            "Eval_StdReturn : 15.0137939453125\n",
            "Eval_MaxReturn : -31.58545684814453\n",
            "Eval_MinReturn : -65.69644927978516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.413230895996094\n",
            "Train_StdReturn : 24.807518005371094\n",
            "Train_MaxReturn : 5.663944244384766\n",
            "Train_MinReturn : -146.12078857421875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 422100\n",
            "TimeSinceStart : 460.87043142318726\n",
            "Training Loss : -439.534912109375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.90537643432617\n",
            "Eval_StdReturn : 10.933987617492676\n",
            "Eval_MaxReturn : -18.635297775268555\n",
            "Eval_MinReturn : -43.64912414550781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.435794830322266\n",
            "Train_StdReturn : 24.544816970825195\n",
            "Train_MaxReturn : 43.18218231201172\n",
            "Train_MinReturn : -114.93595886230469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 432150\n",
            "TimeSinceStart : 471.83628964424133\n",
            "Training Loss : -373.6766052246094\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.96550750732422\n",
            "Eval_StdReturn : 34.2960319519043\n",
            "Eval_MaxReturn : 6.294869422912598\n",
            "Eval_MinReturn : -76.48574829101562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.63920211791992\n",
            "Train_StdReturn : 25.51121711730957\n",
            "Train_MaxReturn : 45.008323669433594\n",
            "Train_MinReturn : -106.52978515625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 442200\n",
            "TimeSinceStart : 482.71319937705994\n",
            "Training Loss : -618.2421875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.148757934570312\n",
            "Eval_StdReturn : 7.346389293670654\n",
            "Eval_MaxReturn : -13.861223220825195\n",
            "Eval_MinReturn : -30.54916000366211\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.449321746826172\n",
            "Train_StdReturn : 23.0329532623291\n",
            "Train_MaxReturn : 19.10194969177246\n",
            "Train_MinReturn : -131.45147705078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 452250\n",
            "TimeSinceStart : 493.70640444755554\n",
            "Training Loss : -455.30621337890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.1363525390625\n",
            "Eval_StdReturn : 18.423044204711914\n",
            "Eval_MaxReturn : -8.720222473144531\n",
            "Eval_MinReturn : -50.03425216674805\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.11318588256836\n",
            "Train_StdReturn : 22.7570858001709\n",
            "Train_MaxReturn : 34.20586395263672\n",
            "Train_MinReturn : -93.10572814941406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 462300\n",
            "TimeSinceStart : 504.6713101863861\n",
            "Training Loss : -527.636474609375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.4186885356903076\n",
            "Eval_StdReturn : 15.296944618225098\n",
            "Eval_MaxReturn : 18.059900283813477\n",
            "Eval_MinReturn : -18.344449996948242\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.74510383605957\n",
            "Train_StdReturn : 21.739425659179688\n",
            "Train_MaxReturn : 29.931928634643555\n",
            "Train_MinReturn : -84.8438491821289\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 472350\n",
            "TimeSinceStart : 515.582977771759\n",
            "Training Loss : 134.9561767578125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.0482466220855713\n",
            "Eval_StdReturn : 14.958601951599121\n",
            "Eval_MaxReturn : 20.021928787231445\n",
            "Eval_MinReturn : -16.372955322265625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -15.40419864654541\n",
            "Train_StdReturn : 24.303125381469727\n",
            "Train_MaxReturn : 38.206886291503906\n",
            "Train_MinReturn : -80.53315734863281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 482400\n",
            "TimeSinceStart : 526.5697796344757\n",
            "Training Loss : 84.156494140625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.029922485351562\n",
            "Eval_StdReturn : 21.12811279296875\n",
            "Eval_MaxReturn : 35.17572021484375\n",
            "Eval_MinReturn : -10.816367149353027\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.607351303100586\n",
            "Train_StdReturn : 33.396095275878906\n",
            "Train_MaxReturn : 63.21240234375\n",
            "Train_MinReturn : -83.94866943359375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 492450\n",
            "TimeSinceStart : 537.5766708850861\n",
            "Training Loss : -279.1302185058594\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.903763473033905\n",
            "Eval_StdReturn : 20.064340591430664\n",
            "Eval_MaxReturn : 27.046239852905273\n",
            "Eval_MinReturn : -19.11724853515625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -5.109408378601074\n",
            "Train_StdReturn : 29.884765625\n",
            "Train_MaxReturn : 53.68855285644531\n",
            "Train_MinReturn : -79.49057006835938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 502500\n",
            "TimeSinceStart : 548.3930780887604\n",
            "Training Loss : -335.7205505371094\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 18.629161834716797\n",
            "Eval_StdReturn : 19.420896530151367\n",
            "Eval_MaxReturn : 44.938453674316406\n",
            "Eval_MinReturn : -1.3535714149475098\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 1.408810019493103\n",
            "Train_StdReturn : 29.038326263427734\n",
            "Train_MaxReturn : 61.62769317626953\n",
            "Train_MinReturn : -99.58572387695312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 512550\n",
            "TimeSinceStart : 559.37384557724\n",
            "Training Loss : -237.060791015625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -3.599226713180542\n",
            "Eval_StdReturn : 22.898998260498047\n",
            "Eval_MaxReturn : 28.55535125732422\n",
            "Eval_MinReturn : -23.00945281982422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.541832208633423\n",
            "Train_StdReturn : 32.4086799621582\n",
            "Train_MaxReturn : 60.201072692871094\n",
            "Train_MinReturn : -105.25308227539062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 522600\n",
            "TimeSinceStart : 570.2778794765472\n",
            "Training Loss : -328.1134033203125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.110180854797363\n",
            "Eval_StdReturn : 39.92396545410156\n",
            "Eval_MaxReturn : 16.008211135864258\n",
            "Eval_MinReturn : -70.52812957763672\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 10.458093643188477\n",
            "Train_StdReturn : 31.497047424316406\n",
            "Train_MaxReturn : 77.57145690917969\n",
            "Train_MinReturn : -85.67933654785156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 532650\n",
            "TimeSinceStart : 581.1323540210724\n",
            "Training Loss : -430.5809326171875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 37.714107513427734\n",
            "Eval_StdReturn : 22.45940399169922\n",
            "Eval_MaxReturn : 69.23979187011719\n",
            "Eval_MinReturn : 18.599319458007812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 13.106386184692383\n",
            "Train_StdReturn : 29.13918685913086\n",
            "Train_MaxReturn : 71.54960632324219\n",
            "Train_MinReturn : -91.49285888671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 542700\n",
            "TimeSinceStart : 592.1551029682159\n",
            "Training Loss : -310.7403564453125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 21.794538497924805\n",
            "Eval_StdReturn : 30.916154861450195\n",
            "Eval_MaxReturn : 50.74219512939453\n",
            "Eval_MinReturn : -21.056005477905273\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 25.789165496826172\n",
            "Train_StdReturn : 34.92344665527344\n",
            "Train_MaxReturn : 121.94639587402344\n",
            "Train_MinReturn : -48.393646240234375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 552750\n",
            "TimeSinceStart : 603.1221973896027\n",
            "Training Loss : -183.41702270507812\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.09552764892578\n",
            "Eval_StdReturn : 51.51868438720703\n",
            "Eval_MaxReturn : 88.640380859375\n",
            "Eval_MinReturn : -26.02458381652832\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 16.561519622802734\n",
            "Train_StdReturn : 42.61299514770508\n",
            "Train_MaxReturn : 110.54087829589844\n",
            "Train_MinReturn : -85.2955093383789\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 562800\n",
            "TimeSinceStart : 614.0539238452911\n",
            "Training Loss : -98.407470703125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.2310662269592285\n",
            "Eval_StdReturn : 50.0247688293457\n",
            "Eval_MaxReturn : 75.9482650756836\n",
            "Eval_MinReturn : -31.866676330566406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 12.776143074035645\n",
            "Train_StdReturn : 41.22244644165039\n",
            "Train_MaxReturn : 116.02810668945312\n",
            "Train_MinReturn : -89.0338363647461\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 572850\n",
            "TimeSinceStart : 625.0595092773438\n",
            "Training Loss : -65.9041748046875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 66.94642639160156\n",
            "Eval_StdReturn : 32.458614349365234\n",
            "Eval_MaxReturn : 111.03247833251953\n",
            "Eval_MinReturn : 33.82832717895508\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 11.337928771972656\n",
            "Train_StdReturn : 38.880069732666016\n",
            "Train_MaxReturn : 78.97449493408203\n",
            "Train_MinReturn : -87.27041625976562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 582900\n",
            "TimeSinceStart : 636.0019116401672\n",
            "Training Loss : -167.2037353515625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.559406757354736\n",
            "Eval_StdReturn : 11.02186393737793\n",
            "Eval_MaxReturn : 21.744945526123047\n",
            "Eval_MinReturn : -4.078325271606445\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 5.498197078704834\n",
            "Train_StdReturn : 38.511356353759766\n",
            "Train_MaxReturn : 87.06625366210938\n",
            "Train_MinReturn : -83.86632537841797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 592950\n",
            "TimeSinceStart : 646.878429889679\n",
            "Training Loss : -166.1290283203125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 15.582230567932129\n",
            "Eval_StdReturn : 8.886573791503906\n",
            "Eval_MaxReturn : 23.770099639892578\n",
            "Eval_MinReturn : 3.23142671585083\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 13.666348457336426\n",
            "Train_StdReturn : 35.81463623046875\n",
            "Train_MaxReturn : 77.94723510742188\n",
            "Train_MinReturn : -100.85796356201172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 603000\n",
            "TimeSinceStart : 657.8604879379272\n",
            "Training Loss : -438.754150390625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.159451484680176\n",
            "Eval_StdReturn : 17.28567123413086\n",
            "Eval_MaxReturn : 29.409618377685547\n",
            "Eval_MinReturn : -10.011503219604492\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 3.5992207527160645\n",
            "Train_StdReturn : 47.10050964355469\n",
            "Train_MaxReturn : 93.55628967285156\n",
            "Train_MinReturn : -108.81895446777344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 613050\n",
            "TimeSinceStart : 668.651563167572\n",
            "Training Loss : -8.859283447265625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.855693817138672\n",
            "Eval_StdReturn : 11.816449165344238\n",
            "Eval_MaxReturn : -0.350067138671875\n",
            "Eval_MinReturn : -25.565771102905273\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 8.942872047424316\n",
            "Train_StdReturn : 39.86074447631836\n",
            "Train_MaxReturn : 77.10176086425781\n",
            "Train_MinReturn : -104.17787170410156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 623100\n",
            "TimeSinceStart : 679.575924873352\n",
            "Training Loss : -346.83837890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 15.089881896972656\n",
            "Eval_StdReturn : 25.009319305419922\n",
            "Eval_MaxReturn : 50.455467224121094\n",
            "Eval_MinReturn : -2.9874558448791504\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 15.995661735534668\n",
            "Train_StdReturn : 30.384754180908203\n",
            "Train_MaxReturn : 80.45818328857422\n",
            "Train_MinReturn : -76.50606536865234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 633150\n",
            "TimeSinceStart : 690.5562973022461\n",
            "Training Loss : -469.00408935546875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.00379753112793\n",
            "Eval_StdReturn : 18.376361846923828\n",
            "Eval_MaxReturn : 40.02518081665039\n",
            "Eval_MinReturn : -4.595603942871094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 10.461577415466309\n",
            "Train_StdReturn : 18.238975524902344\n",
            "Train_MaxReturn : 44.154022216796875\n",
            "Train_MinReturn : -55.41809844970703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 643200\n",
            "TimeSinceStart : 701.5040709972382\n",
            "Training Loss : -689.7080688476562\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.1125664710998535\n",
            "Eval_StdReturn : 13.416487693786621\n",
            "Eval_MaxReturn : 20.7401123046875\n",
            "Eval_MinReturn : -11.134520530700684\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 15.225621223449707\n",
            "Train_StdReturn : 20.90665054321289\n",
            "Train_MaxReturn : 63.78636932373047\n",
            "Train_MinReturn : -54.040523529052734\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 653250\n",
            "TimeSinceStart : 712.4630105495453\n",
            "Training Loss : -446.4715576171875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.342141628265381\n",
            "Eval_StdReturn : 27.295562744140625\n",
            "Eval_MaxReturn : 37.25069808959961\n",
            "Eval_MinReturn : -28.746952056884766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 19.476465225219727\n",
            "Train_StdReturn : 22.569433212280273\n",
            "Train_MaxReturn : 85.28459167480469\n",
            "Train_MinReturn : -44.788536071777344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 663300\n",
            "TimeSinceStart : 723.2995066642761\n",
            "Training Loss : -510.92401123046875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.765275001525879\n",
            "Eval_StdReturn : 25.680747985839844\n",
            "Eval_MaxReturn : 46.42186737060547\n",
            "Eval_MinReturn : -16.478803634643555\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 20.025596618652344\n",
            "Train_StdReturn : 27.45697021484375\n",
            "Train_MaxReturn : 63.95043182373047\n",
            "Train_MinReturn : -50.428428649902344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 673350\n",
            "TimeSinceStart : 734.2107434272766\n",
            "Training Loss : -151.69683837890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 44.713836669921875\n",
            "Eval_StdReturn : 22.815227508544922\n",
            "Eval_MaxReturn : 70.63114166259766\n",
            "Eval_MinReturn : 15.11120891571045\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 11.682049751281738\n",
            "Train_StdReturn : 38.071781158447266\n",
            "Train_MaxReturn : 80.05413818359375\n",
            "Train_MinReturn : -115.16390991210938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 683400\n",
            "TimeSinceStart : 745.1178495883942\n",
            "Training Loss : -468.36627197265625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.509882926940918\n",
            "Eval_StdReturn : 71.08221435546875\n",
            "Eval_MaxReturn : 85.15548706054688\n",
            "Eval_MinReturn : -86.14328002929688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 25.284353256225586\n",
            "Train_StdReturn : 41.256561279296875\n",
            "Train_MaxReturn : 101.16073608398438\n",
            "Train_MinReturn : -128.23561096191406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 693450\n",
            "TimeSinceStart : 756.0401592254639\n",
            "Training Loss : -212.84130859375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 11.99820613861084\n",
            "Eval_StdReturn : 28.50217056274414\n",
            "Eval_MaxReturn : 51.275691986083984\n",
            "Eval_MinReturn : -15.484001159667969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 24.292774200439453\n",
            "Train_StdReturn : 40.82585525512695\n",
            "Train_MaxReturn : 91.51129150390625\n",
            "Train_MinReturn : -71.04651641845703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 703500\n",
            "TimeSinceStart : 766.9329998493195\n",
            "Training Loss : 114.68580627441406\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.751909255981445\n",
            "Eval_StdReturn : 7.637901306152344\n",
            "Eval_MaxReturn : 42.54559326171875\n",
            "Eval_MinReturn : 25.9964656829834\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 21.656173706054688\n",
            "Train_StdReturn : 48.892555236816406\n",
            "Train_MaxReturn : 105.90766906738281\n",
            "Train_MinReturn : -176.72354125976562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 713550\n",
            "TimeSinceStart : 777.8748269081116\n",
            "Training Loss : -80.32032775878906\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 28.02373695373535\n",
            "Eval_StdReturn : 37.52359390258789\n",
            "Eval_MaxReturn : 79.7939453125\n",
            "Eval_MinReturn : -7.956630706787109\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 14.471822738647461\n",
            "Train_StdReturn : 49.0124626159668\n",
            "Train_MaxReturn : 108.40225982666016\n",
            "Train_MinReturn : -87.61679077148438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 723600\n",
            "TimeSinceStart : 788.7381088733673\n",
            "Training Loss : 2.58453369140625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 74.751220703125\n",
            "Eval_StdReturn : 51.5682487487793\n",
            "Eval_MaxReturn : 146.67727661132812\n",
            "Eval_MinReturn : 28.352266311645508\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 34.22329330444336\n",
            "Train_StdReturn : 46.15589904785156\n",
            "Train_MaxReturn : 150.00949096679688\n",
            "Train_MinReturn : -51.364715576171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 733650\n",
            "TimeSinceStart : 799.6261632442474\n",
            "Training Loss : -76.66796875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.492384910583496\n",
            "Eval_StdReturn : 17.717857360839844\n",
            "Eval_MaxReturn : 27.49451446533203\n",
            "Eval_MinReturn : -12.389293670654297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 24.11863136291504\n",
            "Train_StdReturn : 49.09718322753906\n",
            "Train_MaxReturn : 135.43455505371094\n",
            "Train_MinReturn : -91.26316833496094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 743700\n",
            "TimeSinceStart : 810.6550207138062\n",
            "Training Loss : -163.78970336914062\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.3603630065918\n",
            "Eval_StdReturn : 59.005924224853516\n",
            "Eval_MaxReturn : 128.78265380859375\n",
            "Eval_MinReturn : -15.723108291625977\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 44.05952835083008\n",
            "Train_StdReturn : 46.77394485473633\n",
            "Train_MaxReturn : 166.29739379882812\n",
            "Train_MinReturn : -124.32064056396484\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 753750\n",
            "TimeSinceStart : 821.4877531528473\n",
            "Training Loss : -378.26519775390625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 24.87029457092285\n",
            "Eval_StdReturn : 27.002685546875\n",
            "Eval_MaxReturn : 44.799346923828125\n",
            "Eval_MinReturn : -13.304906845092773\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 47.935882568359375\n",
            "Train_StdReturn : 46.21656799316406\n",
            "Train_MaxReturn : 128.7193603515625\n",
            "Train_MinReturn : -59.979190826416016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 763800\n",
            "TimeSinceStart : 832.3727312088013\n",
            "Training Loss : -432.3514099121094\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.496493339538574\n",
            "Eval_StdReturn : 114.22590637207031\n",
            "Eval_MaxReturn : 91.60816955566406\n",
            "Eval_MinReturn : -152.03585815429688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 43.65476608276367\n",
            "Train_StdReturn : 38.77937698364258\n",
            "Train_MaxReturn : 152.19163513183594\n",
            "Train_MinReturn : -106.84727478027344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 773850\n",
            "TimeSinceStart : 843.3228991031647\n",
            "Training Loss : -134.13714599609375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.643645763397217\n",
            "Eval_StdReturn : 26.809141159057617\n",
            "Eval_MaxReturn : 39.82099914550781\n",
            "Eval_MinReturn : -25.658634185791016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 32.541072845458984\n",
            "Train_StdReturn : 43.444862365722656\n",
            "Train_MaxReturn : 121.75823974609375\n",
            "Train_MinReturn : -57.690853118896484\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 783900\n",
            "TimeSinceStart : 854.2287621498108\n",
            "Training Loss : -513.2294311523438\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 35.32583236694336\n",
            "Eval_StdReturn : 25.725360870361328\n",
            "Eval_MaxReturn : 58.280338287353516\n",
            "Eval_MinReturn : -0.5954246520996094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 17.572519302368164\n",
            "Train_StdReturn : 34.077606201171875\n",
            "Train_MaxReturn : 90.45374298095703\n",
            "Train_MinReturn : -81.14519500732422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 793950\n",
            "TimeSinceStart : 865.145307302475\n",
            "Training Loss : -321.8837890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 18.6169490814209\n",
            "Eval_StdReturn : 23.115880966186523\n",
            "Eval_MaxReturn : 37.96803665161133\n",
            "Eval_MinReturn : -13.87673568725586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 20.381954193115234\n",
            "Train_StdReturn : 40.41389083862305\n",
            "Train_MaxReturn : 88.0459976196289\n",
            "Train_MinReturn : -74.8519287109375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 804000\n",
            "TimeSinceStart : 876.1403098106384\n",
            "Training Loss : -349.7518310546875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.16754150390625\n",
            "Eval_StdReturn : 30.465869903564453\n",
            "Eval_MaxReturn : 85.78874206542969\n",
            "Eval_MinReturn : 21.0823917388916\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 38.34745407104492\n",
            "Train_StdReturn : 24.769411087036133\n",
            "Train_MaxReturn : 95.17259979248047\n",
            "Train_MinReturn : -20.17782211303711\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 814050\n",
            "TimeSinceStart : 887.08629155159\n",
            "Training Loss : -544.9002685546875\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.4971809387207\n",
            "Eval_StdReturn : 22.09900665283203\n",
            "Eval_MaxReturn : 81.05851745605469\n",
            "Eval_MinReturn : 29.12364387512207\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 59.23963928222656\n",
            "Train_StdReturn : 30.99291229248047\n",
            "Train_MaxReturn : 123.9330825805664\n",
            "Train_MinReturn : 1.944300651550293\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 824100\n",
            "TimeSinceStart : 898.09157538414\n",
            "Training Loss : -245.85147094726562\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 75.09584045410156\n",
            "Eval_StdReturn : 15.693954467773438\n",
            "Eval_MaxReturn : 96.34864807128906\n",
            "Eval_MinReturn : 58.92967987060547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 73.2923583984375\n",
            "Train_StdReturn : 31.570375442504883\n",
            "Train_MaxReturn : 150.10409545898438\n",
            "Train_MinReturn : 13.637857437133789\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 834150\n",
            "TimeSinceStart : 908.9907402992249\n",
            "Training Loss : -83.46633911132812\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 98.07720947265625\n",
            "Eval_StdReturn : 33.24665069580078\n",
            "Eval_MaxReturn : 125.34379577636719\n",
            "Eval_MinReturn : 51.27149963378906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 67.86273193359375\n",
            "Train_StdReturn : 32.36418151855469\n",
            "Train_MaxReturn : 171.38534545898438\n",
            "Train_MinReturn : -42.042816162109375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 844200\n",
            "TimeSinceStart : 919.9507579803467\n",
            "Training Loss : -469.429931640625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.92402648925781\n",
            "Eval_StdReturn : 36.681243896484375\n",
            "Eval_MaxReturn : 101.2083740234375\n",
            "Eval_MinReturn : 14.741758346557617\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 48.43232727050781\n",
            "Train_StdReturn : 42.648292541503906\n",
            "Train_MaxReturn : 134.870361328125\n",
            "Train_MinReturn : -47.537899017333984\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 854250\n",
            "TimeSinceStart : 931.0134932994843\n",
            "Training Loss : -477.21783447265625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 47.64622497558594\n",
            "Eval_StdReturn : 46.640987396240234\n",
            "Eval_MaxReturn : 107.75965118408203\n",
            "Eval_MinReturn : -5.923342704772949\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 46.56834411621094\n",
            "Train_StdReturn : 44.88633346557617\n",
            "Train_MaxReturn : 130.34986877441406\n",
            "Train_MinReturn : -70.6773452758789\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 864300\n",
            "TimeSinceStart : 941.9615404605865\n",
            "Training Loss : -355.57806396484375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 48.7982063293457\n",
            "Eval_StdReturn : 41.11582946777344\n",
            "Eval_MaxReturn : 103.66088104248047\n",
            "Eval_MinReturn : 4.6835784912109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 46.09660339355469\n",
            "Train_StdReturn : 38.59961700439453\n",
            "Train_MaxReturn : 132.48797607421875\n",
            "Train_MinReturn : -56.5311279296875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 874350\n",
            "TimeSinceStart : 952.8398041725159\n",
            "Training Loss : -414.62652587890625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 87.15345001220703\n",
            "Eval_StdReturn : 2.876068353652954\n",
            "Eval_MaxReturn : 91.14138793945312\n",
            "Eval_MinReturn : 84.46670532226562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 49.174957275390625\n",
            "Train_StdReturn : 43.14777755737305\n",
            "Train_MaxReturn : 123.29315948486328\n",
            "Train_MinReturn : -55.1447639465332\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 884400\n",
            "TimeSinceStart : 963.7789072990417\n",
            "Training Loss : -185.51791381835938\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 66.84174346923828\n",
            "Eval_StdReturn : 13.144909858703613\n",
            "Eval_MaxReturn : 79.93598175048828\n",
            "Eval_MinReturn : 48.86708068847656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 63.8923454284668\n",
            "Train_StdReturn : 42.93008804321289\n",
            "Train_MaxReturn : 131.00660705566406\n",
            "Train_MinReturn : -41.66095733642578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 894450\n",
            "TimeSinceStart : 974.599586725235\n",
            "Training Loss : -204.87353515625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 91.7206039428711\n",
            "Eval_StdReturn : 29.260589599609375\n",
            "Eval_MaxReturn : 131.462158203125\n",
            "Eval_MinReturn : 61.86334991455078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 71.62580871582031\n",
            "Train_StdReturn : 35.53367233276367\n",
            "Train_MaxReturn : 132.0952606201172\n",
            "Train_MinReturn : -55.60669708251953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 904500\n",
            "TimeSinceStart : 985.4625000953674\n",
            "Training Loss : -175.5238037109375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 81.65522766113281\n",
            "Eval_StdReturn : 17.37112045288086\n",
            "Eval_MaxReturn : 105.95602416992188\n",
            "Eval_MinReturn : 66.38438415527344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 72.21658325195312\n",
            "Train_StdReturn : 43.67281723022461\n",
            "Train_MaxReturn : 147.52880859375\n",
            "Train_MinReturn : -124.82044982910156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 914550\n",
            "TimeSinceStart : 996.3767347335815\n",
            "Training Loss : -173.9329376220703\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 72.66776275634766\n",
            "Eval_StdReturn : 59.23137283325195\n",
            "Eval_MaxReturn : 125.37773895263672\n",
            "Eval_MinReturn : -10.067873001098633\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 68.9111328125\n",
            "Train_StdReturn : 72.91564178466797\n",
            "Train_MaxReturn : 179.77590942382812\n",
            "Train_MinReturn : -156.5870819091797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 924600\n",
            "TimeSinceStart : 1007.2812216281891\n",
            "Training Loss : -169.4307861328125\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 26.115585327148438\n",
            "Eval_StdReturn : 109.85919952392578\n",
            "Eval_MaxReturn : 142.49464416503906\n",
            "Eval_MinReturn : -121.21148681640625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 61.200443267822266\n",
            "Train_StdReturn : 57.35980224609375\n",
            "Train_MaxReturn : 139.71055603027344\n",
            "Train_MinReturn : -127.4559326171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 934650\n",
            "TimeSinceStart : 1018.1787190437317\n",
            "Training Loss : 10.468818664550781\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.80256175994873\n",
            "Eval_StdReturn : 93.1921615600586\n",
            "Eval_MaxReturn : 88.87626647949219\n",
            "Eval_MinReturn : -117.54324340820312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 58.01673126220703\n",
            "Train_StdReturn : 79.42630767822266\n",
            "Train_MaxReturn : 172.27801513671875\n",
            "Train_MinReturn : -144.79147338867188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 944700\n",
            "TimeSinceStart : 1028.9800553321838\n",
            "Training Loss : -246.35939025878906\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 113.3381118774414\n",
            "Eval_StdReturn : 34.67935562133789\n",
            "Eval_MaxReturn : 151.5719451904297\n",
            "Eval_MinReturn : 67.6201171875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 22.854389190673828\n",
            "Train_StdReturn : 91.06575012207031\n",
            "Train_MaxReturn : 144.40696716308594\n",
            "Train_MinReturn : -182.87994384765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 954750\n",
            "TimeSinceStart : 1039.816998243332\n",
            "Training Loss : -170.9419708251953\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.392313957214355\n",
            "Eval_StdReturn : 57.57331085205078\n",
            "Eval_MaxReturn : 78.14617919921875\n",
            "Eval_MinReturn : -62.75642395019531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 31.004085540771484\n",
            "Train_StdReturn : 90.2292251586914\n",
            "Train_MaxReturn : 163.57443237304688\n",
            "Train_MinReturn : -162.81900024414062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 964800\n",
            "TimeSinceStart : 1050.6771473884583\n",
            "Training Loss : 152.23501586914062\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 15.195228576660156\n",
            "Eval_StdReturn : 136.8672332763672\n",
            "Eval_MaxReturn : 130.30807495117188\n",
            "Eval_MinReturn : -177.12295532226562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 41.02448272705078\n",
            "Train_StdReturn : 98.41920471191406\n",
            "Train_MaxReturn : 175.82736206054688\n",
            "Train_MinReturn : -173.62001037597656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 974850\n",
            "TimeSinceStart : 1061.5628554821014\n",
            "Training Loss : -124.48919677734375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.769378662109375\n",
            "Eval_StdReturn : 28.531387329101562\n",
            "Eval_MaxReturn : 81.40415954589844\n",
            "Eval_MinReturn : 17.630477905273438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 66.47285461425781\n",
            "Train_StdReturn : 69.74757385253906\n",
            "Train_MaxReturn : 145.43043518066406\n",
            "Train_MinReturn : -158.37246704101562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 984900\n",
            "TimeSinceStart : 1072.4781830310822\n",
            "Training Loss : 219.1392822265625\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.73004150390625\n",
            "Eval_StdReturn : 39.64228057861328\n",
            "Eval_MaxReturn : 50.30461120605469\n",
            "Eval_MinReturn : -42.090274810791016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 59.76290512084961\n",
            "Train_StdReturn : 67.59819030761719\n",
            "Train_MaxReturn : 154.8407440185547\n",
            "Train_MinReturn : -141.8435516357422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 994950\n",
            "TimeSinceStart : 1083.4109556674957\n",
            "Training Loss : -380.570068359375\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 43.42671203613281\n",
            "Eval_StdReturn : 19.50218391418457\n",
            "Eval_MaxReturn : 61.5203857421875\n",
            "Eval_MinReturn : 16.353036880493164\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 49.601261138916016\n",
            "Train_StdReturn : 55.81999969482422\n",
            "Train_MaxReturn : 181.739501953125\n",
            "Train_MinReturn : -145.19509887695312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1005000\n",
            "TimeSinceStart : 1094.351128578186\n",
            "Training Loss : -123.71224975585938\n",
            "Initial_DataCollection_AverageReturn : -89.69666290283203\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "    --discount 0.95 -n 100 -l 2 -s 32 \\\n",
        "    -b 10000 -lr 0.02 -rtg --nn_baseline \\\n",
        "    --exp_name q4_search_b10000_lr0.02_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKDLdM7EPRV7",
        "outputId": "adf0672d-4920-432c-b66c-836fc07611f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q4_search_b30000_lr0.005_rtg_nnbaseline_HalfCheetah-v2_09-05-2022_08-19-46\n",
            "########################\n",
            "GPU not detected. Defaulting to CPU.\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -95.7751235961914\n",
            "Eval_StdReturn : 29.627788543701172\n",
            "Eval_MaxReturn : -54.66142272949219\n",
            "Eval_MinReturn : -123.32884216308594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -95.93110656738281\n",
            "Train_StdReturn : 40.167728424072266\n",
            "Train_MaxReturn : 1.7286391258239746\n",
            "Train_MinReturn : -209.38143920898438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 30000\n",
            "TimeSinceStart : 25.610349416732788\n",
            "Training Loss : -2342.963623046875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -103.648193359375\n",
            "Eval_StdReturn : 30.617198944091797\n",
            "Eval_MaxReturn : -79.45094299316406\n",
            "Eval_MinReturn : -146.84326171875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -88.14118957519531\n",
            "Train_StdReturn : 38.789424896240234\n",
            "Train_MaxReturn : 10.799810409545898\n",
            "Train_MinReturn : -212.19825744628906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 60000\n",
            "TimeSinceStart : 48.48898196220398\n",
            "Training Loss : -2463.899169921875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -86.24471282958984\n",
            "Eval_StdReturn : 29.528364181518555\n",
            "Eval_MaxReturn : -60.39523696899414\n",
            "Eval_MinReturn : -127.57261657714844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -81.94127655029297\n",
            "Train_StdReturn : 32.324764251708984\n",
            "Train_MaxReturn : 9.6873197555542\n",
            "Train_MinReturn : -196.8123321533203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 90000\n",
            "TimeSinceStart : 71.70542669296265\n",
            "Training Loss : -2565.299560546875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -97.45294189453125\n",
            "Eval_StdReturn : 32.281070709228516\n",
            "Eval_MaxReturn : -55.958961486816406\n",
            "Eval_MinReturn : -134.68594360351562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -82.4278335571289\n",
            "Train_StdReturn : 36.8380241394043\n",
            "Train_MaxReturn : -0.6612091064453125\n",
            "Train_MinReturn : -188.39111328125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 120000\n",
            "TimeSinceStart : 95.64666771888733\n",
            "Training Loss : -2423.416015625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.33652877807617\n",
            "Eval_StdReturn : 4.93971061706543\n",
            "Eval_MaxReturn : -38.2567138671875\n",
            "Eval_MinReturn : -50.35603332519531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -74.32819366455078\n",
            "Train_StdReturn : 33.969398498535156\n",
            "Train_MaxReturn : 13.961021423339844\n",
            "Train_MinReturn : -172.36569213867188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150000\n",
            "TimeSinceStart : 118.55557417869568\n",
            "Training Loss : -2059.75244140625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -75.71623992919922\n",
            "Eval_StdReturn : 12.761014938354492\n",
            "Eval_MaxReturn : -58.89601135253906\n",
            "Eval_MinReturn : -89.78984832763672\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -71.85033416748047\n",
            "Train_StdReturn : 32.52754211425781\n",
            "Train_MaxReturn : 7.408069610595703\n",
            "Train_MinReturn : -174.7384490966797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 180000\n",
            "TimeSinceStart : 141.50831532478333\n",
            "Training Loss : -2219.489501953125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -73.58133697509766\n",
            "Eval_StdReturn : 27.791015625\n",
            "Eval_MaxReturn : -41.089298248291016\n",
            "Eval_MinReturn : -108.97706604003906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -74.84937286376953\n",
            "Train_StdReturn : 34.430511474609375\n",
            "Train_MaxReturn : 15.536502838134766\n",
            "Train_MinReturn : -189.9884490966797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 210000\n",
            "TimeSinceStart : 164.36341977119446\n",
            "Training Loss : -2270.073974609375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -79.25798797607422\n",
            "Eval_StdReturn : 24.909282684326172\n",
            "Eval_MaxReturn : -47.78587341308594\n",
            "Eval_MinReturn : -108.69944763183594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -70.48393249511719\n",
            "Train_StdReturn : 34.57160568237305\n",
            "Train_MaxReturn : 34.229244232177734\n",
            "Train_MinReturn : -179.67324829101562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 240000\n",
            "TimeSinceStart : 187.29128098487854\n",
            "Training Loss : -2218.4931640625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -79.65953063964844\n",
            "Eval_StdReturn : 35.96688461303711\n",
            "Eval_MaxReturn : -38.391292572021484\n",
            "Eval_MinReturn : -126.04485321044922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -72.53614044189453\n",
            "Train_StdReturn : 29.972911834716797\n",
            "Train_MaxReturn : 3.2635202407836914\n",
            "Train_MinReturn : -157.27444458007812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 270000\n",
            "TimeSinceStart : 210.17937350273132\n",
            "Training Loss : -1997.7401123046875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.91929626464844\n",
            "Eval_StdReturn : 6.022052764892578\n",
            "Eval_MaxReturn : -56.80891418457031\n",
            "Eval_MinReturn : -70.37454223632812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -68.36996459960938\n",
            "Train_StdReturn : 33.99187088012695\n",
            "Train_MaxReturn : 30.18625259399414\n",
            "Train_MinReturn : -175.54476928710938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300000\n",
            "TimeSinceStart : 233.2184178829193\n",
            "Training Loss : -2261.987060546875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -82.07074737548828\n",
            "Eval_StdReturn : 26.822200775146484\n",
            "Eval_MaxReturn : -47.84295654296875\n",
            "Eval_MinReturn : -113.34407043457031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -71.56906127929688\n",
            "Train_StdReturn : 34.36994171142578\n",
            "Train_MaxReturn : 9.927654266357422\n",
            "Train_MinReturn : -190.597900390625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 330000\n",
            "TimeSinceStart : 256.27080845832825\n",
            "Training Loss : -2342.41552734375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -74.69782257080078\n",
            "Eval_StdReturn : 24.40528678894043\n",
            "Eval_MaxReturn : -51.914756774902344\n",
            "Eval_MinReturn : -108.54210662841797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -69.38675689697266\n",
            "Train_StdReturn : 35.6569709777832\n",
            "Train_MaxReturn : 29.145809173583984\n",
            "Train_MinReturn : -203.12167358398438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 360000\n",
            "TimeSinceStart : 279.258624792099\n",
            "Training Loss : -2212.77197265625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -71.03749084472656\n",
            "Eval_StdReturn : 16.134126663208008\n",
            "Eval_MaxReturn : -58.86767578125\n",
            "Eval_MinReturn : -93.83726501464844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -65.8082275390625\n",
            "Train_StdReturn : 32.462982177734375\n",
            "Train_MaxReturn : 23.72580909729004\n",
            "Train_MinReturn : -199.9788055419922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 390000\n",
            "TimeSinceStart : 302.3900384902954\n",
            "Training Loss : -2365.630859375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -68.31934356689453\n",
            "Eval_StdReturn : 29.272104263305664\n",
            "Eval_MaxReturn : -31.873023986816406\n",
            "Eval_MinReturn : -103.54348754882812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -61.16557693481445\n",
            "Train_StdReturn : 32.70226287841797\n",
            "Train_MaxReturn : 50.27409744262695\n",
            "Train_MinReturn : -172.81124877929688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 420000\n",
            "TimeSinceStart : 325.7843933105469\n",
            "Training Loss : -2280.284423828125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -76.39358520507812\n",
            "Eval_StdReturn : 13.775527000427246\n",
            "Eval_MaxReturn : -56.99470520019531\n",
            "Eval_MinReturn : -87.6455307006836\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -65.96098327636719\n",
            "Train_StdReturn : 30.35675048828125\n",
            "Train_MaxReturn : 4.425207138061523\n",
            "Train_MinReturn : -175.4967498779297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450000\n",
            "TimeSinceStart : 350.52857303619385\n",
            "Training Loss : -2381.40185546875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -84.4675064086914\n",
            "Eval_StdReturn : 49.39593505859375\n",
            "Eval_MaxReturn : -23.66161346435547\n",
            "Eval_MinReturn : -144.6516571044922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -61.26016616821289\n",
            "Train_StdReturn : 27.051755905151367\n",
            "Train_MaxReturn : 23.876476287841797\n",
            "Train_MinReturn : -152.40721130371094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 480000\n",
            "TimeSinceStart : 373.67030572891235\n",
            "Training Loss : -1849.526611328125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.6577262878418\n",
            "Eval_StdReturn : 19.760576248168945\n",
            "Eval_MaxReturn : -36.983184814453125\n",
            "Eval_MinReturn : -85.35414123535156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -57.566959381103516\n",
            "Train_StdReturn : 28.061832427978516\n",
            "Train_MaxReturn : 17.030685424804688\n",
            "Train_MinReturn : -144.38864135742188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 510000\n",
            "TimeSinceStart : 397.00490617752075\n",
            "Training Loss : -2586.07568359375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -57.997222900390625\n",
            "Eval_StdReturn : 13.277048110961914\n",
            "Eval_MaxReturn : -39.933563232421875\n",
            "Eval_MinReturn : -71.46731567382812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -54.211082458496094\n",
            "Train_StdReturn : 31.697555541992188\n",
            "Train_MaxReturn : 40.0955810546875\n",
            "Train_MinReturn : -167.2388916015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 540000\n",
            "TimeSinceStart : 420.17388439178467\n",
            "Training Loss : -2704.989013671875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -86.53006744384766\n",
            "Eval_StdReturn : 17.777982711791992\n",
            "Eval_MaxReturn : -72.64399719238281\n",
            "Eval_MinReturn : -111.62435150146484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -56.99787139892578\n",
            "Train_StdReturn : 29.35330581665039\n",
            "Train_MaxReturn : 46.522613525390625\n",
            "Train_MinReturn : -157.62643432617188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 570000\n",
            "TimeSinceStart : 443.3466284275055\n",
            "Training Loss : -2066.10888671875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.452117919921875\n",
            "Eval_StdReturn : 36.030067443847656\n",
            "Eval_MaxReturn : -2.5701522827148438\n",
            "Eval_MinReturn : -81.24212646484375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -58.12247085571289\n",
            "Train_StdReturn : 29.74583625793457\n",
            "Train_MaxReturn : 17.77752685546875\n",
            "Train_MinReturn : -153.00025939941406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 600000\n",
            "TimeSinceStart : 466.7059361934662\n",
            "Training Loss : -1894.3385009765625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -52.482975006103516\n",
            "Eval_StdReturn : 24.55522918701172\n",
            "Eval_MaxReturn : -23.648052215576172\n",
            "Eval_MinReturn : -83.65899658203125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -53.321048736572266\n",
            "Train_StdReturn : 27.133697509765625\n",
            "Train_MaxReturn : 50.716068267822266\n",
            "Train_MinReturn : -131.302978515625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 630000\n",
            "TimeSinceStart : 489.92917370796204\n",
            "Training Loss : -2023.220703125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.71393966674805\n",
            "Eval_StdReturn : 19.88077163696289\n",
            "Eval_MaxReturn : -28.407638549804688\n",
            "Eval_MinReturn : -76.97657012939453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.785430908203125\n",
            "Train_StdReturn : 29.81329917907715\n",
            "Train_MaxReturn : 38.790382385253906\n",
            "Train_MinReturn : -159.44740295410156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 660000\n",
            "TimeSinceStart : 513.0882384777069\n",
            "Training Loss : -1973.3470458984375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -67.16024780273438\n",
            "Eval_StdReturn : 52.19968795776367\n",
            "Eval_MaxReturn : -23.61030387878418\n",
            "Eval_MinReturn : -140.5565643310547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -53.083492279052734\n",
            "Train_StdReturn : 29.858728408813477\n",
            "Train_MaxReturn : 24.138391494750977\n",
            "Train_MinReturn : -168.42266845703125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 690000\n",
            "TimeSinceStart : 536.4848787784576\n",
            "Training Loss : -1540.5677490234375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.597361087799072\n",
            "Eval_StdReturn : 41.94905471801758\n",
            "Eval_MaxReturn : 43.715614318847656\n",
            "Eval_MinReturn : -58.5695686340332\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.00816345214844\n",
            "Train_StdReturn : 30.412160873413086\n",
            "Train_MaxReturn : 17.224361419677734\n",
            "Train_MinReturn : -167.1864776611328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 720000\n",
            "TimeSinceStart : 559.8135480880737\n",
            "Training Loss : -1809.02001953125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.35151290893555\n",
            "Eval_StdReturn : 6.012782096862793\n",
            "Eval_MaxReturn : -50.060821533203125\n",
            "Eval_MinReturn : -64.45172882080078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.53242111206055\n",
            "Train_StdReturn : 26.843629837036133\n",
            "Train_MaxReturn : 40.747676849365234\n",
            "Train_MinReturn : -123.72844696044922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 750000\n",
            "TimeSinceStart : 583.4345450401306\n",
            "Training Loss : -1891.724853515625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -73.48265838623047\n",
            "Eval_StdReturn : 12.040791511535645\n",
            "Eval_MaxReturn : -57.06155776977539\n",
            "Eval_MinReturn : -85.59597778320312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.23519515991211\n",
            "Train_StdReturn : 27.834287643432617\n",
            "Train_MaxReturn : 42.360084533691406\n",
            "Train_MinReturn : -129.5837860107422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 780000\n",
            "TimeSinceStart : 606.7572679519653\n",
            "Training Loss : -1779.4490966796875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.66203689575195\n",
            "Eval_StdReturn : 11.498729705810547\n",
            "Eval_MaxReturn : -29.469297409057617\n",
            "Eval_MinReturn : -57.28002166748047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -48.607627868652344\n",
            "Train_StdReturn : 26.31568145751953\n",
            "Train_MaxReturn : 17.756755828857422\n",
            "Train_MinReturn : -132.1570281982422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 810000\n",
            "TimeSinceStart : 630.4789569377899\n",
            "Training Loss : -2270.667236328125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -54.94816207885742\n",
            "Eval_StdReturn : 27.620994567871094\n",
            "Eval_MaxReturn : -17.257143020629883\n",
            "Eval_MinReturn : -82.67733764648438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.89680099487305\n",
            "Train_StdReturn : 26.49964141845703\n",
            "Train_MaxReturn : 26.820438385009766\n",
            "Train_MinReturn : -124.67816162109375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 840000\n",
            "TimeSinceStart : 654.0523152351379\n",
            "Training Loss : -1609.6424560546875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.148950576782227\n",
            "Eval_StdReturn : 15.49996280670166\n",
            "Eval_MaxReturn : 2.4212093353271484\n",
            "Eval_MinReturn : -33.31329345703125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.653167724609375\n",
            "Train_StdReturn : 29.831151962280273\n",
            "Train_MaxReturn : 70.89340209960938\n",
            "Train_MinReturn : -147.3101806640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 870000\n",
            "TimeSinceStart : 677.3218810558319\n",
            "Training Loss : -1361.7220458984375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.71016311645508\n",
            "Eval_StdReturn : 62.62668228149414\n",
            "Eval_MaxReturn : 2.2141475677490234\n",
            "Eval_MinReturn : -141.1492462158203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.66694259643555\n",
            "Train_StdReturn : 27.506488800048828\n",
            "Train_MaxReturn : 23.964500427246094\n",
            "Train_MinReturn : -151.6700897216797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 900000\n",
            "TimeSinceStart : 700.3822321891785\n",
            "Training Loss : -2032.562744140625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -63.6417350769043\n",
            "Eval_StdReturn : 32.239070892333984\n",
            "Eval_MaxReturn : -38.05796432495117\n",
            "Eval_MinReturn : -109.11602783203125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.78702163696289\n",
            "Train_StdReturn : 26.165077209472656\n",
            "Train_MaxReturn : 44.21910858154297\n",
            "Train_MinReturn : -116.2715835571289\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 930000\n",
            "TimeSinceStart : 723.5515923500061\n",
            "Training Loss : -2155.17431640625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.4501960277557373\n",
            "Eval_StdReturn : 4.8163580894470215\n",
            "Eval_MaxReturn : 9.785982131958008\n",
            "Eval_MinReturn : -1.8831806182861328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -42.708595275878906\n",
            "Train_StdReturn : 29.586841583251953\n",
            "Train_MaxReturn : 30.581172943115234\n",
            "Train_MinReturn : -142.46652221679688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 960000\n",
            "TimeSinceStart : 746.7095239162445\n",
            "Training Loss : -1861.9403076171875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.747737884521484\n",
            "Eval_StdReturn : 21.0259952545166\n",
            "Eval_MaxReturn : -25.32317352294922\n",
            "Eval_MinReturn : -75.31722259521484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.92829895019531\n",
            "Train_StdReturn : 31.4968318939209\n",
            "Train_MaxReturn : 47.68714141845703\n",
            "Train_MinReturn : -140.49124145507812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 990000\n",
            "TimeSinceStart : 769.8914525508881\n",
            "Training Loss : -1876.1121826171875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.340824127197266\n",
            "Eval_StdReturn : 8.310124397277832\n",
            "Eval_MaxReturn : -29.4982852935791\n",
            "Eval_MinReturn : -49.68851089477539\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.86992263793945\n",
            "Train_StdReturn : 32.9903678894043\n",
            "Train_MaxReturn : 37.66130828857422\n",
            "Train_MinReturn : -156.75250244140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1020000\n",
            "TimeSinceStart : 793.348283290863\n",
            "Training Loss : -1838.373046875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.501583099365234\n",
            "Eval_StdReturn : 13.212321281433105\n",
            "Eval_MaxReturn : -22.403779983520508\n",
            "Eval_MinReturn : -54.577125549316406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -42.423580169677734\n",
            "Train_StdReturn : 32.51015090942383\n",
            "Train_MaxReturn : 48.66728210449219\n",
            "Train_MinReturn : -143.41334533691406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1050000\n",
            "TimeSinceStart : 816.5653200149536\n",
            "Training Loss : -1610.81591796875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.17308044433594\n",
            "Eval_StdReturn : 10.111676216125488\n",
            "Eval_MaxReturn : -31.072406768798828\n",
            "Eval_MinReturn : -53.42897033691406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.627716064453125\n",
            "Train_StdReturn : 33.76807403564453\n",
            "Train_MaxReturn : 48.26289367675781\n",
            "Train_MinReturn : -167.53323364257812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1080000\n",
            "TimeSinceStart : 839.9505000114441\n",
            "Training Loss : -1645.945556640625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.8046989440918\n",
            "Eval_StdReturn : 23.45296859741211\n",
            "Eval_MaxReturn : -5.406089782714844\n",
            "Eval_MinReturn : -62.843204498291016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.21226119995117\n",
            "Train_StdReturn : 34.4036979675293\n",
            "Train_MaxReturn : 55.18051528930664\n",
            "Train_MinReturn : -147.5151824951172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1110000\n",
            "TimeSinceStart : 863.2248911857605\n",
            "Training Loss : -1548.895751953125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -50.66709899902344\n",
            "Eval_StdReturn : 22.22761344909668\n",
            "Eval_MaxReturn : -20.801406860351562\n",
            "Eval_MinReturn : -74.09291076660156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -38.779815673828125\n",
            "Train_StdReturn : 32.16222381591797\n",
            "Train_MaxReturn : 42.41575622558594\n",
            "Train_MinReturn : -130.27719116210938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1140000\n",
            "TimeSinceStart : 886.5618152618408\n",
            "Training Loss : -988.5917358398438\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.074766159057617\n",
            "Eval_StdReturn : 14.71359920501709\n",
            "Eval_MaxReturn : -0.35384178161621094\n",
            "Eval_MinReturn : -33.083702087402344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.31037139892578\n",
            "Train_StdReturn : 30.46460723876953\n",
            "Train_MaxReturn : 56.89752197265625\n",
            "Train_MinReturn : -117.89469146728516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1170000\n",
            "TimeSinceStart : 909.757465839386\n",
            "Training Loss : -1370.072509765625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.70233154296875\n",
            "Eval_StdReturn : 15.892328262329102\n",
            "Eval_MaxReturn : -3.7885570526123047\n",
            "Eval_MinReturn : -40.982303619384766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.477230072021484\n",
            "Train_StdReturn : 28.403867721557617\n",
            "Train_MaxReturn : 24.38463020324707\n",
            "Train_MinReturn : -120.43682098388672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1200000\n",
            "TimeSinceStart : 932.9705057144165\n",
            "Training Loss : -1386.4813232421875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.7345027923584\n",
            "Eval_StdReturn : 25.1491641998291\n",
            "Eval_MaxReturn : 11.685465812683105\n",
            "Eval_MinReturn : -49.6105842590332\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.430416107177734\n",
            "Train_StdReturn : 31.62660789489746\n",
            "Train_MaxReturn : 55.071685791015625\n",
            "Train_MinReturn : -112.17848205566406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1230000\n",
            "TimeSinceStart : 956.5378923416138\n",
            "Training Loss : -1612.583740234375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.70293617248535\n",
            "Eval_StdReturn : 32.52931594848633\n",
            "Eval_MaxReturn : 17.134506225585938\n",
            "Eval_MinReturn : -55.00267028808594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.81679153442383\n",
            "Train_StdReturn : 30.557893753051758\n",
            "Train_MaxReturn : 48.9691162109375\n",
            "Train_MinReturn : -119.51406860351562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1260000\n",
            "TimeSinceStart : 980.1275913715363\n",
            "Training Loss : -1271.345703125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.164512634277344\n",
            "Eval_StdReturn : 10.486882209777832\n",
            "Eval_MaxReturn : -5.575266361236572\n",
            "Eval_MinReturn : -27.993833541870117\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.694122314453125\n",
            "Train_StdReturn : 28.457637786865234\n",
            "Train_MaxReturn : 46.60452651977539\n",
            "Train_MinReturn : -137.7283477783203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1290000\n",
            "TimeSinceStart : 1003.4634871482849\n",
            "Training Loss : -1412.7003173828125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.824771881103516\n",
            "Eval_StdReturn : 19.58429718017578\n",
            "Eval_MaxReturn : -15.771270751953125\n",
            "Eval_MinReturn : -62.989601135253906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.58155822753906\n",
            "Train_StdReturn : 30.67635154724121\n",
            "Train_MaxReturn : 54.78059387207031\n",
            "Train_MinReturn : -136.9505157470703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1320000\n",
            "TimeSinceStart : 1026.981595993042\n",
            "Training Loss : -830.6343383789062\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.559296607971191\n",
            "Eval_StdReturn : 29.956180572509766\n",
            "Eval_MaxReturn : 26.190906524658203\n",
            "Eval_MinReturn : -42.65930938720703\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.968360900878906\n",
            "Train_StdReturn : 27.754898071289062\n",
            "Train_MaxReturn : 29.025833129882812\n",
            "Train_MinReturn : -107.62598419189453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1350000\n",
            "TimeSinceStart : 1050.2173438072205\n",
            "Training Loss : -1297.14990234375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -68.64453887939453\n",
            "Eval_StdReturn : 29.894399642944336\n",
            "Eval_MaxReturn : -36.297481536865234\n",
            "Eval_MinReturn : -108.39270782470703\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.05818176269531\n",
            "Train_StdReturn : 25.66642189025879\n",
            "Train_MaxReturn : 47.31415557861328\n",
            "Train_MinReturn : -97.26759338378906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1380000\n",
            "TimeSinceStart : 1073.7473335266113\n",
            "Training Loss : -1580.284423828125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -50.087825775146484\n",
            "Eval_StdReturn : 11.6819429397583\n",
            "Eval_MaxReturn : -37.51708221435547\n",
            "Eval_MinReturn : -65.65673065185547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.29270935058594\n",
            "Train_StdReturn : 29.00811195373535\n",
            "Train_MaxReturn : 26.683422088623047\n",
            "Train_MinReturn : -133.62753295898438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1410000\n",
            "TimeSinceStart : 1097.3555135726929\n",
            "Training Loss : -1117.950439453125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.89469909667969\n",
            "Eval_StdReturn : 22.345298767089844\n",
            "Eval_MaxReturn : -18.43476676940918\n",
            "Eval_MinReturn : -68.20789337158203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.891094207763672\n",
            "Train_StdReturn : 23.735536575317383\n",
            "Train_MaxReturn : 54.270545959472656\n",
            "Train_MinReturn : -99.28211212158203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1440000\n",
            "TimeSinceStart : 1120.9107468128204\n",
            "Training Loss : -1210.0877685546875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.74000549316406\n",
            "Eval_StdReturn : 12.818658828735352\n",
            "Eval_MaxReturn : -22.164199829101562\n",
            "Eval_MinReturn : -52.37437438964844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.207656860351562\n",
            "Train_StdReturn : 27.468828201293945\n",
            "Train_MaxReturn : 68.17518615722656\n",
            "Train_MinReturn : -115.99604034423828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1470000\n",
            "TimeSinceStart : 1144.5976145267487\n",
            "Training Loss : -1744.9884033203125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.18477249145508\n",
            "Eval_StdReturn : 14.412308692932129\n",
            "Eval_MaxReturn : -15.005706787109375\n",
            "Eval_MinReturn : -47.75944137573242\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.621131896972656\n",
            "Train_StdReturn : 27.556737899780273\n",
            "Train_MaxReturn : 39.09894561767578\n",
            "Train_MinReturn : -109.77826690673828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1500000\n",
            "TimeSinceStart : 1167.751045703888\n",
            "Training Loss : -913.1797485351562\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.097410202026367\n",
            "Eval_StdReturn : 15.54462718963623\n",
            "Eval_MaxReturn : 0.7443239688873291\n",
            "Eval_MinReturn : -34.17631912231445\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.067113876342773\n",
            "Train_StdReturn : 26.82600212097168\n",
            "Train_MaxReturn : 37.645973205566406\n",
            "Train_MinReturn : -120.36038208007812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1530000\n",
            "TimeSinceStart : 1191.2470710277557\n",
            "Training Loss : -1313.536865234375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.83612060546875\n",
            "Eval_StdReturn : 13.296029090881348\n",
            "Eval_MaxReturn : -18.05794906616211\n",
            "Eval_MinReturn : -50.57682418823242\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.748485565185547\n",
            "Train_StdReturn : 29.21756362915039\n",
            "Train_MaxReturn : 60.1131477355957\n",
            "Train_MinReturn : -127.05062866210938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1560000\n",
            "TimeSinceStart : 1214.5345513820648\n",
            "Training Loss : -1226.506591796875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.878259658813477\n",
            "Eval_StdReturn : 4.6967549324035645\n",
            "Eval_MaxReturn : -22.26291275024414\n",
            "Eval_MinReturn : -33.3227424621582\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.688095092773438\n",
            "Train_StdReturn : 28.816225051879883\n",
            "Train_MaxReturn : 45.027713775634766\n",
            "Train_MinReturn : -134.28131103515625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1590000\n",
            "TimeSinceStart : 1238.0013303756714\n",
            "Training Loss : -1014.645263671875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.176944732666016\n",
            "Eval_StdReturn : 26.149927139282227\n",
            "Eval_MaxReturn : 0.794283390045166\n",
            "Eval_MinReturn : -55.42042922973633\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.7640323638916\n",
            "Train_StdReturn : 28.553354263305664\n",
            "Train_MaxReturn : 52.703006744384766\n",
            "Train_MinReturn : -138.93482971191406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1620000\n",
            "TimeSinceStart : 1262.0414016246796\n",
            "Training Loss : -1655.5286865234375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.28401756286621\n",
            "Eval_StdReturn : 9.458590507507324\n",
            "Eval_MaxReturn : -7.275535583496094\n",
            "Eval_MinReturn : -29.48676872253418\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.743749618530273\n",
            "Train_StdReturn : 26.974605560302734\n",
            "Train_MaxReturn : 66.03022003173828\n",
            "Train_MinReturn : -88.94816589355469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1650000\n",
            "TimeSinceStart : 1286.7604141235352\n",
            "Training Loss : -1124.7373046875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.130924224853516\n",
            "Eval_StdReturn : 23.446815490722656\n",
            "Eval_MaxReturn : -13.704179763793945\n",
            "Eval_MinReturn : -70.27633666992188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.374988555908203\n",
            "Train_StdReturn : 28.193037033081055\n",
            "Train_MaxReturn : 37.34245300292969\n",
            "Train_MinReturn : -157.78390502929688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1680000\n",
            "TimeSinceStart : 1310.513798236847\n",
            "Training Loss : -1303.496337890625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.926148414611816\n",
            "Eval_StdReturn : 32.5621452331543\n",
            "Eval_MaxReturn : 27.935646057128906\n",
            "Eval_MinReturn : -51.2598876953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.71310043334961\n",
            "Train_StdReturn : 29.811861038208008\n",
            "Train_MaxReturn : 31.515779495239258\n",
            "Train_MinReturn : -125.70388793945312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1710000\n",
            "TimeSinceStart : 1333.97145485878\n",
            "Training Loss : -1160.89306640625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.96821975708008\n",
            "Eval_StdReturn : 7.52207612991333\n",
            "Eval_MaxReturn : -35.540794372558594\n",
            "Eval_MinReturn : -53.00513458251953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.284799575805664\n",
            "Train_StdReturn : 27.7728271484375\n",
            "Train_MaxReturn : 67.49986267089844\n",
            "Train_MinReturn : -140.78451538085938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1740000\n",
            "TimeSinceStart : 1357.5253882408142\n",
            "Training Loss : -1047.40478515625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.03132629394531\n",
            "Eval_StdReturn : 2.715367555618286\n",
            "Eval_MaxReturn : -32.0680046081543\n",
            "Eval_MinReturn : -38.62813949584961\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.11090850830078\n",
            "Train_StdReturn : 28.54585075378418\n",
            "Train_MaxReturn : 35.7323112487793\n",
            "Train_MinReturn : -137.13783264160156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1770000\n",
            "TimeSinceStart : 1380.77450633049\n",
            "Training Loss : -619.405517578125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.80193519592285\n",
            "Eval_StdReturn : 18.23382568359375\n",
            "Eval_MaxReturn : -6.016117572784424\n",
            "Eval_MinReturn : -44.86005783081055\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.16721725463867\n",
            "Train_StdReturn : 28.293987274169922\n",
            "Train_MaxReturn : 84.54468536376953\n",
            "Train_MinReturn : -116.24064636230469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1800000\n",
            "TimeSinceStart : 1404.0522320270538\n",
            "Training Loss : -851.997314453125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.90590286254883\n",
            "Eval_StdReturn : 18.900320053100586\n",
            "Eval_MaxReturn : -6.687046527862549\n",
            "Eval_MinReturn : -50.51665115356445\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.32706069946289\n",
            "Train_StdReturn : 26.533124923706055\n",
            "Train_MaxReturn : 44.53840637207031\n",
            "Train_MinReturn : -98.26419067382812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1830000\n",
            "TimeSinceStart : 1427.6436760425568\n",
            "Training Loss : -1327.047119140625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.62843322753906\n",
            "Eval_StdReturn : 17.87437629699707\n",
            "Eval_MaxReturn : -14.624385833740234\n",
            "Eval_MinReturn : -57.492984771728516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.89513397216797\n",
            "Train_StdReturn : 30.679683685302734\n",
            "Train_MaxReturn : 38.18583679199219\n",
            "Train_MinReturn : -125.78498077392578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1860000\n",
            "TimeSinceStart : 1451.2567775249481\n",
            "Training Loss : -1054.784912109375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.767318725585938\n",
            "Eval_StdReturn : 4.532387733459473\n",
            "Eval_MaxReturn : -8.358711242675781\n",
            "Eval_MinReturn : -18.07703971862793\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.289947509765625\n",
            "Train_StdReturn : 26.947471618652344\n",
            "Train_MaxReturn : 37.775936126708984\n",
            "Train_MinReturn : -128.19952392578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1890000\n",
            "TimeSinceStart : 1474.5338835716248\n",
            "Training Loss : -1396.2076416015625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.597375869750977\n",
            "Eval_StdReturn : 13.80435848236084\n",
            "Eval_MaxReturn : -8.456217765808105\n",
            "Eval_MinReturn : -41.32390594482422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.12267303466797\n",
            "Train_StdReturn : 27.983144760131836\n",
            "Train_MaxReturn : 35.19480895996094\n",
            "Train_MinReturn : -109.70868682861328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1920000\n",
            "TimeSinceStart : 1497.9990408420563\n",
            "Training Loss : -1493.334228515625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.84163284301758\n",
            "Eval_StdReturn : 13.415786743164062\n",
            "Eval_MaxReturn : -25.259891510009766\n",
            "Eval_MinReturn : -58.007041931152344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.452295303344727\n",
            "Train_StdReturn : 28.03725814819336\n",
            "Train_MaxReturn : 41.409202575683594\n",
            "Train_MinReturn : -121.3736343383789\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1950000\n",
            "TimeSinceStart : 1521.5277190208435\n",
            "Training Loss : -1113.58154296875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.19575119018555\n",
            "Eval_StdReturn : 14.559548377990723\n",
            "Eval_MaxReturn : -26.778072357177734\n",
            "Eval_MinReturn : -62.377201080322266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.7356014251709\n",
            "Train_StdReturn : 28.925859451293945\n",
            "Train_MaxReturn : 95.82366180419922\n",
            "Train_MinReturn : -140.74530029296875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1980000\n",
            "TimeSinceStart : 1544.7395813465118\n",
            "Training Loss : -723.6757202148438\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.957656860351562\n",
            "Eval_StdReturn : 14.904252052307129\n",
            "Eval_MaxReturn : -8.414073944091797\n",
            "Eval_MinReturn : -42.71635818481445\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.69302749633789\n",
            "Train_StdReturn : 26.388111114501953\n",
            "Train_MaxReturn : 22.64928436279297\n",
            "Train_MinReturn : -145.91275024414062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2010000\n",
            "TimeSinceStart : 1568.2422225475311\n",
            "Training Loss : -1083.5577392578125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.142969131469727\n",
            "Eval_StdReturn : 19.38739585876465\n",
            "Eval_MaxReturn : -0.5111541748046875\n",
            "Eval_MinReturn : -44.33594512939453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.684141159057617\n",
            "Train_StdReturn : 24.364377975463867\n",
            "Train_MaxReturn : 32.765296936035156\n",
            "Train_MinReturn : -91.01531219482422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2040000\n",
            "TimeSinceStart : 1591.8918268680573\n",
            "Training Loss : -1042.677001953125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.031518936157227\n",
            "Eval_StdReturn : 19.446678161621094\n",
            "Eval_MaxReturn : -14.973567962646484\n",
            "Eval_MinReturn : -58.39612579345703\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.20846176147461\n",
            "Train_StdReturn : 26.001554489135742\n",
            "Train_MaxReturn : 37.033287048339844\n",
            "Train_MinReturn : -157.69479370117188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2070000\n",
            "TimeSinceStart : 1615.4738459587097\n",
            "Training Loss : -949.1129760742188\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.90387725830078\n",
            "Eval_StdReturn : 9.337102890014648\n",
            "Eval_MaxReturn : -15.368367195129395\n",
            "Eval_MinReturn : -37.76579284667969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.535297393798828\n",
            "Train_StdReturn : 23.730443954467773\n",
            "Train_MaxReturn : 36.605735778808594\n",
            "Train_MinReturn : -114.14178466796875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2100000\n",
            "TimeSinceStart : 1638.6884751319885\n",
            "Training Loss : -920.1890869140625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.97310733795166\n",
            "Eval_StdReturn : 37.133583068847656\n",
            "Eval_MaxReturn : 16.828170776367188\n",
            "Eval_MinReturn : -67.89010620117188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.76636505126953\n",
            "Train_StdReturn : 25.448875427246094\n",
            "Train_MaxReturn : 33.51392364501953\n",
            "Train_MinReturn : -121.8482666015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2130000\n",
            "TimeSinceStart : 1662.041894197464\n",
            "Training Loss : -1433.896240234375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.801382064819336\n",
            "Eval_StdReturn : 26.08734130859375\n",
            "Eval_MaxReturn : 2.7868270874023438\n",
            "Eval_MinReturn : -60.21150207519531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.382831573486328\n",
            "Train_StdReturn : 21.756847381591797\n",
            "Train_MaxReturn : 36.17041778564453\n",
            "Train_MinReturn : -94.3660888671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2160000\n",
            "TimeSinceStart : 1685.5159842967987\n",
            "Training Loss : -1056.591796875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.32831573486328\n",
            "Eval_StdReturn : 17.867246627807617\n",
            "Eval_MaxReturn : -4.107956886291504\n",
            "Eval_MinReturn : -43.28307342529297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.244569778442383\n",
            "Train_StdReturn : 22.74954605102539\n",
            "Train_MaxReturn : 31.522113800048828\n",
            "Train_MinReturn : -101.69416809082031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2190000\n",
            "TimeSinceStart : 1708.8367323875427\n",
            "Training Loss : -1086.757568359375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.591073989868164\n",
            "Eval_StdReturn : 21.216825485229492\n",
            "Eval_MaxReturn : -9.736860275268555\n",
            "Eval_MinReturn : -58.23251724243164\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.492666244506836\n",
            "Train_StdReturn : 20.786785125732422\n",
            "Train_MaxReturn : 34.610836029052734\n",
            "Train_MinReturn : -89.48855590820312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2220000\n",
            "TimeSinceStart : 1732.4525792598724\n",
            "Training Loss : -998.6405639648438\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.92647361755371\n",
            "Eval_StdReturn : 31.517534255981445\n",
            "Eval_MaxReturn : -0.702730655670166\n",
            "Eval_MinReturn : -68.48566436767578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.802621841430664\n",
            "Train_StdReturn : 27.679054260253906\n",
            "Train_MaxReturn : 47.47515869140625\n",
            "Train_MinReturn : -142.61024475097656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2250000\n",
            "TimeSinceStart : 1756.1706252098083\n",
            "Training Loss : -845.44873046875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.169553756713867\n",
            "Eval_StdReturn : 5.6374735832214355\n",
            "Eval_MaxReturn : -15.648862838745117\n",
            "Eval_MinReturn : -29.402568817138672\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.5292911529541\n",
            "Train_StdReturn : 22.37894058227539\n",
            "Train_MaxReturn : 41.519691467285156\n",
            "Train_MinReturn : -97.06553649902344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2280000\n",
            "TimeSinceStart : 1779.6798212528229\n",
            "Training Loss : -1388.8634033203125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.475497245788574\n",
            "Eval_StdReturn : 20.171707153320312\n",
            "Eval_MaxReturn : 10.493766784667969\n",
            "Eval_MinReturn : -38.68484115600586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.956525802612305\n",
            "Train_StdReturn : 24.004180908203125\n",
            "Train_MaxReturn : 38.527183532714844\n",
            "Train_MinReturn : -127.16928100585938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2310000\n",
            "TimeSinceStart : 1803.236358165741\n",
            "Training Loss : -953.74951171875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.305946350097656\n",
            "Eval_StdReturn : 31.225332260131836\n",
            "Eval_MaxReturn : 31.685802459716797\n",
            "Eval_MinReturn : -37.629974365234375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.673974990844727\n",
            "Train_StdReturn : 24.820377349853516\n",
            "Train_MaxReturn : 20.28777313232422\n",
            "Train_MinReturn : -115.75650787353516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2340000\n",
            "TimeSinceStart : 1826.7043511867523\n",
            "Training Loss : -1494.7178955078125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.234403610229492\n",
            "Eval_StdReturn : 29.329206466674805\n",
            "Eval_MaxReturn : 20.89196014404297\n",
            "Eval_MinReturn : -50.4428596496582\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.338720321655273\n",
            "Train_StdReturn : 20.097593307495117\n",
            "Train_MaxReturn : 31.301380157470703\n",
            "Train_MinReturn : -83.6397933959961\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2370000\n",
            "TimeSinceStart : 1850.229168176651\n",
            "Training Loss : -1422.791748046875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.288726806640625\n",
            "Eval_StdReturn : 27.089176177978516\n",
            "Eval_MaxReturn : -16.290966033935547\n",
            "Eval_MinReturn : -81.468994140625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.730552673339844\n",
            "Train_StdReturn : 24.44236946105957\n",
            "Train_MaxReturn : 33.1214599609375\n",
            "Train_MinReturn : -105.79217529296875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2400000\n",
            "TimeSinceStart : 1873.6300003528595\n",
            "Training Loss : -1298.824951171875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.592622756958008\n",
            "Eval_StdReturn : 14.027591705322266\n",
            "Eval_MaxReturn : -3.5459821224212646\n",
            "Eval_MinReturn : -37.750301361083984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.931978225708008\n",
            "Train_StdReturn : 21.854360580444336\n",
            "Train_MaxReturn : 34.75331115722656\n",
            "Train_MinReturn : -115.82316589355469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2430000\n",
            "TimeSinceStart : 1896.9683451652527\n",
            "Training Loss : -832.3477172851562\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.268239974975586\n",
            "Eval_StdReturn : 12.200374603271484\n",
            "Eval_MaxReturn : -8.548284530639648\n",
            "Eval_MinReturn : -38.18889236450195\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.288158416748047\n",
            "Train_StdReturn : 19.11665916442871\n",
            "Train_MaxReturn : 25.431049346923828\n",
            "Train_MinReturn : -89.20919799804688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2460000\n",
            "TimeSinceStart : 1920.5394995212555\n",
            "Training Loss : -1090.450439453125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.34684181213379\n",
            "Eval_StdReturn : 9.391338348388672\n",
            "Eval_MaxReturn : -17.466278076171875\n",
            "Eval_MinReturn : -39.59143829345703\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.006675720214844\n",
            "Train_StdReturn : 21.48206329345703\n",
            "Train_MaxReturn : 44.56844711303711\n",
            "Train_MinReturn : -106.80233764648438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2490000\n",
            "TimeSinceStart : 1944.2869408130646\n",
            "Training Loss : -935.1402587890625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -1.8897451162338257\n",
            "Eval_StdReturn : 27.322635650634766\n",
            "Eval_MaxReturn : 33.62586975097656\n",
            "Eval_MinReturn : -32.82975769042969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.08160972595215\n",
            "Train_StdReturn : 20.817663192749023\n",
            "Train_MaxReturn : 29.059709548950195\n",
            "Train_MinReturn : -102.89564514160156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2520000\n",
            "TimeSinceStart : 1967.6233689785004\n",
            "Training Loss : -1651.0242919921875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.37190246582031\n",
            "Eval_StdReturn : 7.898614406585693\n",
            "Eval_MaxReturn : -27.179222106933594\n",
            "Eval_MinReturn : -45.36967468261719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.07317352294922\n",
            "Train_StdReturn : 22.03374481201172\n",
            "Train_MaxReturn : 43.762847900390625\n",
            "Train_MinReturn : -105.646728515625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2550000\n",
            "TimeSinceStart : 1990.9879086017609\n",
            "Training Loss : -1146.490234375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.19603157043457\n",
            "Eval_StdReturn : 23.907251358032227\n",
            "Eval_MaxReturn : 8.00448989868164\n",
            "Eval_MinReturn : -48.743446350097656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.452383041381836\n",
            "Train_StdReturn : 22.051504135131836\n",
            "Train_MaxReturn : 32.03081512451172\n",
            "Train_MinReturn : -127.86393737792969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2580000\n",
            "TimeSinceStart : 2014.1995086669922\n",
            "Training Loss : -812.3900146484375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.97404670715332\n",
            "Eval_StdReturn : 11.153510093688965\n",
            "Eval_MaxReturn : -10.136236190795898\n",
            "Eval_MinReturn : -37.329837799072266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.020042419433594\n",
            "Train_StdReturn : 22.418630599975586\n",
            "Train_MaxReturn : 34.15699005126953\n",
            "Train_MinReturn : -108.52017211914062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2610000\n",
            "TimeSinceStart : 2037.5047354698181\n",
            "Training Loss : -1025.1610107421875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.213211059570312\n",
            "Eval_StdReturn : 7.984685897827148\n",
            "Eval_MaxReturn : -16.930492401123047\n",
            "Eval_MinReturn : -36.00139236450195\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.457860946655273\n",
            "Train_StdReturn : 23.212114334106445\n",
            "Train_MaxReturn : 56.71615219116211\n",
            "Train_MinReturn : -84.76890563964844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2640000\n",
            "TimeSinceStart : 2060.647335290909\n",
            "Training Loss : -1195.192138671875\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.856446266174316\n",
            "Eval_StdReturn : 36.30716323852539\n",
            "Eval_MaxReturn : 41.296695709228516\n",
            "Eval_MinReturn : -43.462547302246094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.244604110717773\n",
            "Train_StdReturn : 20.18375015258789\n",
            "Train_MaxReturn : 30.48860740661621\n",
            "Train_MinReturn : -96.41751861572266\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2670000\n",
            "TimeSinceStart : 2083.780481815338\n",
            "Training Loss : -817.332275390625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.866867065429688\n",
            "Eval_StdReturn : 11.36864185333252\n",
            "Eval_MaxReturn : -10.259576797485352\n",
            "Eval_MinReturn : -34.930824279785156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.203664779663086\n",
            "Train_StdReturn : 21.356075286865234\n",
            "Train_MaxReturn : 25.481369018554688\n",
            "Train_MinReturn : -84.91692352294922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2700000\n",
            "TimeSinceStart : 2107.1969709396362\n",
            "Training Loss : -461.8017578125\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.26953411102295\n",
            "Eval_StdReturn : 19.123397827148438\n",
            "Eval_MaxReturn : 6.360045433044434\n",
            "Eval_MinReturn : -35.28300857543945\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.535642623901367\n",
            "Train_StdReturn : 20.60430335998535\n",
            "Train_MaxReturn : 38.221466064453125\n",
            "Train_MinReturn : -96.18199157714844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2730000\n",
            "TimeSinceStart : 2130.6084656715393\n",
            "Training Loss : -776.191650390625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.450528144836426\n",
            "Eval_StdReturn : 22.2543888092041\n",
            "Eval_MaxReturn : 18.020673751831055\n",
            "Eval_MinReturn : -29.429359436035156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.56390953063965\n",
            "Train_StdReturn : 18.827754974365234\n",
            "Train_MaxReturn : 38.27375793457031\n",
            "Train_MinReturn : -72.7908935546875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2760000\n",
            "TimeSinceStart : 2153.8887491226196\n",
            "Training Loss : -1468.46484375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.61302947998047\n",
            "Eval_StdReturn : 21.592971801757812\n",
            "Eval_MaxReturn : 8.328510284423828\n",
            "Eval_MinReturn : -44.342384338378906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.98522186279297\n",
            "Train_StdReturn : 20.2210750579834\n",
            "Train_MaxReturn : 53.80995559692383\n",
            "Train_MinReturn : -87.73812103271484\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2790000\n",
            "TimeSinceStart : 2177.1936597824097\n",
            "Training Loss : -545.7958984375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.49774169921875\n",
            "Eval_StdReturn : 7.455788612365723\n",
            "Eval_MaxReturn : -19.701696395874023\n",
            "Eval_MinReturn : -37.543888092041016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.73477554321289\n",
            "Train_StdReturn : 19.345802307128906\n",
            "Train_MaxReturn : 37.06285858154297\n",
            "Train_MinReturn : -77.58753204345703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2820000\n",
            "TimeSinceStart : 2200.4457342624664\n",
            "Training Loss : -895.837646484375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.980133056640625\n",
            "Eval_StdReturn : 9.375041007995605\n",
            "Eval_MaxReturn : -12.856592178344727\n",
            "Eval_MinReturn : -34.17488479614258\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.958641052246094\n",
            "Train_StdReturn : 19.833282470703125\n",
            "Train_MaxReturn : 47.41875457763672\n",
            "Train_MinReturn : -89.5289306640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2850000\n",
            "TimeSinceStart : 2223.9653034210205\n",
            "Training Loss : -688.9911499023438\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.260396003723145\n",
            "Eval_StdReturn : 12.98473072052002\n",
            "Eval_MaxReturn : 9.265652656555176\n",
            "Eval_MinReturn : -21.770320892333984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.300521850585938\n",
            "Train_StdReturn : 19.90644645690918\n",
            "Train_MaxReturn : 28.272056579589844\n",
            "Train_MinReturn : -95.12388610839844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2880000\n",
            "TimeSinceStart : 2247.268483400345\n",
            "Training Loss : -750.5347290039062\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.524662017822266\n",
            "Eval_StdReturn : 4.016414165496826\n",
            "Eval_MaxReturn : -31.542572021484375\n",
            "Eval_MinReturn : -41.02349853515625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.882387161254883\n",
            "Train_StdReturn : 19.94087028503418\n",
            "Train_MaxReturn : 55.250404357910156\n",
            "Train_MinReturn : -72.66101837158203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2910000\n",
            "TimeSinceStart : 2270.495620250702\n",
            "Training Loss : -1005.8355712890625\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.987838745117188\n",
            "Eval_StdReturn : 16.295326232910156\n",
            "Eval_MaxReturn : -11.618491172790527\n",
            "Eval_MinReturn : -51.48582458496094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.0377254486084\n",
            "Train_StdReturn : 20.396854400634766\n",
            "Train_MaxReturn : 30.012069702148438\n",
            "Train_MinReturn : -94.85800170898438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2940000\n",
            "TimeSinceStart : 2293.940327644348\n",
            "Training Loss : -793.2849731445312\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.04777717590332\n",
            "Eval_StdReturn : 25.673137664794922\n",
            "Eval_MaxReturn : 27.246997833251953\n",
            "Eval_MinReturn : -28.02102279663086\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.447185516357422\n",
            "Train_StdReturn : 17.90625762939453\n",
            "Train_MaxReturn : 31.786972045898438\n",
            "Train_MinReturn : -77.13557434082031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2970000\n",
            "TimeSinceStart : 2317.6730937957764\n",
            "Training Loss : -1061.26708984375\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.32927703857422\n",
            "Eval_StdReturn : 34.46062088012695\n",
            "Eval_MaxReturn : 30.898330688476562\n",
            "Eval_MinReturn : -47.51555633544922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.35183334350586\n",
            "Train_StdReturn : 17.574399948120117\n",
            "Train_MaxReturn : 44.536163330078125\n",
            "Train_MinReturn : -66.22369384765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3000000\n",
            "TimeSinceStart : 2341.088659763336\n",
            "Training Loss : -963.5365600585938\n",
            "Initial_DataCollection_AverageReturn : -95.93110656738281\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "    --discount 0.95 -n 100 -l 2 -s 32 \\\n",
        "    -b 30000 -lr 0.005 -rtg --nn_baseline \\\n",
        "    --exp_name q4_search_b30000_lr0.005_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji24Xu4-PRdu",
        "outputId": "d16742b2-db19-41f6-d05c-8991cf20aada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q4_search_b30000_lr0.01_rtg_nnbaseline_HalfCheetah-v2_08-05-2022_20-46-02\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -84.32534790039062\n",
            "Eval_StdReturn : 19.448017120361328\n",
            "Eval_MaxReturn : -59.814178466796875\n",
            "Eval_MinReturn : -107.38555908203125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -88.56880950927734\n",
            "Train_StdReturn : 36.4640007019043\n",
            "Train_MaxReturn : 11.764884948730469\n",
            "Train_MinReturn : -178.39559936523438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 30000\n",
            "TimeSinceStart : 31.062530994415283\n",
            "Training Loss : -1876.564208984375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -80.07642364501953\n",
            "Eval_StdReturn : 65.33696746826172\n",
            "Eval_MaxReturn : -6.356746673583984\n",
            "Eval_MinReturn : -165.1797637939453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -86.01199340820312\n",
            "Train_StdReturn : 36.042030334472656\n",
            "Train_MaxReturn : 16.945676803588867\n",
            "Train_MinReturn : -213.38748168945312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 60000\n",
            "TimeSinceStart : 62.438366174697876\n",
            "Training Loss : -2674.191650390625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -73.25232696533203\n",
            "Eval_StdReturn : 36.625221252441406\n",
            "Eval_MaxReturn : -26.467529296875\n",
            "Eval_MinReturn : -115.89303588867188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -77.80892944335938\n",
            "Train_StdReturn : 35.78786087036133\n",
            "Train_MaxReturn : 11.511127471923828\n",
            "Train_MinReturn : -179.0921630859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 90000\n",
            "TimeSinceStart : 93.80858492851257\n",
            "Training Loss : -1975.83447265625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -83.74202728271484\n",
            "Eval_StdReturn : 23.36210823059082\n",
            "Eval_MaxReturn : -58.52918243408203\n",
            "Eval_MinReturn : -114.83943176269531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -72.60015869140625\n",
            "Train_StdReturn : 35.39597702026367\n",
            "Train_MaxReturn : 30.671573638916016\n",
            "Train_MinReturn : -211.88543701171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 120000\n",
            "TimeSinceStart : 125.41544580459595\n",
            "Training Loss : -2381.533203125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -58.3531494140625\n",
            "Eval_StdReturn : 6.190606594085693\n",
            "Eval_MaxReturn : -49.64122772216797\n",
            "Eval_MinReturn : -63.45893859863281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -70.8793716430664\n",
            "Train_StdReturn : 35.016929626464844\n",
            "Train_MaxReturn : 15.260515213012695\n",
            "Train_MinReturn : -172.86390686035156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150000\n",
            "TimeSinceStart : 156.7298765182495\n",
            "Training Loss : -2645.838134765625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.857391357421875\n",
            "Eval_StdReturn : 17.060623168945312\n",
            "Eval_MaxReturn : -15.451539039611816\n",
            "Eval_MinReturn : -55.631988525390625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -67.14691162109375\n",
            "Train_StdReturn : 29.447677612304688\n",
            "Train_MaxReturn : 12.062154769897461\n",
            "Train_MinReturn : -158.9652557373047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 180000\n",
            "TimeSinceStart : 187.89632892608643\n",
            "Training Loss : -2333.408203125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -80.70881652832031\n",
            "Eval_StdReturn : 5.513556480407715\n",
            "Eval_MaxReturn : -72.97453308105469\n",
            "Eval_MinReturn : -85.43305969238281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -68.26123809814453\n",
            "Train_StdReturn : 30.86604881286621\n",
            "Train_MaxReturn : 16.264095306396484\n",
            "Train_MinReturn : -197.3482208251953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 210000\n",
            "TimeSinceStart : 219.08698201179504\n",
            "Training Loss : -2035.533203125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -68.1929702758789\n",
            "Eval_StdReturn : 30.31983184814453\n",
            "Eval_MaxReturn : -25.319761276245117\n",
            "Eval_MinReturn : -90.22451782226562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -65.5389175415039\n",
            "Train_StdReturn : 30.6890869140625\n",
            "Train_MaxReturn : -1.6565775871276855\n",
            "Train_MinReturn : -197.90655517578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 240000\n",
            "TimeSinceStart : 250.3363664150238\n",
            "Training Loss : -2668.82470703125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -109.2626724243164\n",
            "Eval_StdReturn : 65.17276763916016\n",
            "Eval_MaxReturn : -17.30835723876953\n",
            "Eval_MinReturn : -160.67465209960938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -62.45676803588867\n",
            "Train_StdReturn : 30.826204299926758\n",
            "Train_MaxReturn : 19.722679138183594\n",
            "Train_MinReturn : -153.9091339111328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 270000\n",
            "TimeSinceStart : 281.75013160705566\n",
            "Training Loss : -2754.84912109375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -10.25239372253418\n",
            "Eval_StdReturn : 20.23589515686035\n",
            "Eval_MaxReturn : 12.880970001220703\n",
            "Eval_MinReturn : -36.409236907958984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -59.921756744384766\n",
            "Train_StdReturn : 26.98344612121582\n",
            "Train_MaxReturn : 46.318416595458984\n",
            "Train_MinReturn : -147.9867401123047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300000\n",
            "TimeSinceStart : 313.2432255744934\n",
            "Training Loss : -2464.73291015625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.57201385498047\n",
            "Eval_StdReturn : 34.254783630371094\n",
            "Eval_MaxReturn : 22.576324462890625\n",
            "Eval_MinReturn : -59.40680694580078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -59.58504867553711\n",
            "Train_StdReturn : 26.71690559387207\n",
            "Train_MaxReturn : -4.043464660644531\n",
            "Train_MinReturn : -148.2194061279297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 330000\n",
            "TimeSinceStart : 344.38349080085754\n",
            "Training Loss : -2101.41015625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.06478500366211\n",
            "Eval_StdReturn : 17.257715225219727\n",
            "Eval_MaxReturn : -23.8364200592041\n",
            "Eval_MinReturn : -66.00491333007812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.986900329589844\n",
            "Train_StdReturn : 27.042938232421875\n",
            "Train_MaxReturn : 32.57075119018555\n",
            "Train_MinReturn : -148.42604064941406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 360000\n",
            "TimeSinceStart : 375.4432978630066\n",
            "Training Loss : -2622.2568359375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -64.78975677490234\n",
            "Eval_StdReturn : 8.078741073608398\n",
            "Eval_MaxReturn : -53.98932647705078\n",
            "Eval_MinReturn : -73.41675567626953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -52.2458610534668\n",
            "Train_StdReturn : 29.50537109375\n",
            "Train_MaxReturn : 32.25286102294922\n",
            "Train_MinReturn : -140.68060302734375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 390000\n",
            "TimeSinceStart : 406.7500419616699\n",
            "Training Loss : -2459.64453125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.71794128417969\n",
            "Eval_StdReturn : 28.78014373779297\n",
            "Eval_MaxReturn : -17.367374420166016\n",
            "Eval_MinReturn : -82.13738250732422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -52.54717254638672\n",
            "Train_StdReturn : 30.655593872070312\n",
            "Train_MaxReturn : 27.48080825805664\n",
            "Train_MinReturn : -185.79010009765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 420000\n",
            "TimeSinceStart : 437.97787952423096\n",
            "Training Loss : -2668.927978515625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.95517921447754\n",
            "Eval_StdReturn : 20.457063674926758\n",
            "Eval_MaxReturn : -0.046445369720458984\n",
            "Eval_MinReturn : -50.05810546875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.18889617919922\n",
            "Train_StdReturn : 28.56855583190918\n",
            "Train_MaxReturn : 12.711751937866211\n",
            "Train_MinReturn : -128.2277069091797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450000\n",
            "TimeSinceStart : 469.1364812850952\n",
            "Training Loss : -2684.400634765625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.890201568603516\n",
            "Eval_StdReturn : 9.204821586608887\n",
            "Eval_MaxReturn : -24.181241989135742\n",
            "Eval_MinReturn : -45.68494415283203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -47.22748565673828\n",
            "Train_StdReturn : 29.315935134887695\n",
            "Train_MaxReturn : 59.35768127441406\n",
            "Train_MinReturn : -148.99435424804688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 480000\n",
            "TimeSinceStart : 500.4040458202362\n",
            "Training Loss : -2026.98779296875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -69.38839721679688\n",
            "Eval_StdReturn : 10.337674140930176\n",
            "Eval_MaxReturn : -55.745033264160156\n",
            "Eval_MinReturn : -80.75927734375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.1041145324707\n",
            "Train_StdReturn : 29.975297927856445\n",
            "Train_MaxReturn : 22.271495819091797\n",
            "Train_MinReturn : -161.05966186523438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 510000\n",
            "TimeSinceStart : 531.509761095047\n",
            "Training Loss : -2034.768798828125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.23794937133789\n",
            "Eval_StdReturn : 21.647903442382812\n",
            "Eval_MaxReturn : -9.653797149658203\n",
            "Eval_MinReturn : -62.025146484375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -42.462276458740234\n",
            "Train_StdReturn : 30.245769500732422\n",
            "Train_MaxReturn : 27.843059539794922\n",
            "Train_MinReturn : -148.29971313476562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 540000\n",
            "TimeSinceStart : 562.8200287818909\n",
            "Training Loss : -2214.213623046875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.399757385253906\n",
            "Eval_StdReturn : 4.045846462249756\n",
            "Eval_MaxReturn : -21.86612892150879\n",
            "Eval_MinReturn : -31.06380271911621\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.623260498046875\n",
            "Train_StdReturn : 31.1484432220459\n",
            "Train_MaxReturn : 50.74607849121094\n",
            "Train_MinReturn : -201.9454803466797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 570000\n",
            "TimeSinceStart : 594.0186195373535\n",
            "Training Loss : -1630.906494140625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.7665901184082\n",
            "Eval_StdReturn : 17.871244430541992\n",
            "Eval_MaxReturn : -26.194656372070312\n",
            "Eval_MinReturn : -68.89791107177734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.64488220214844\n",
            "Train_StdReturn : 31.367916107177734\n",
            "Train_MaxReturn : 37.80793762207031\n",
            "Train_MinReturn : -142.53741455078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 600000\n",
            "TimeSinceStart : 625.1554350852966\n",
            "Training Loss : -1627.861572265625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.907981872558594\n",
            "Eval_StdReturn : 4.281543254852295\n",
            "Eval_MaxReturn : 0.6159992218017578\n",
            "Eval_MinReturn : -9.8174467086792\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.57231140136719\n",
            "Train_StdReturn : 27.590011596679688\n",
            "Train_MaxReturn : 51.151336669921875\n",
            "Train_MinReturn : -133.52423095703125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 630000\n",
            "TimeSinceStart : 656.3931436538696\n",
            "Training Loss : -1787.2418212890625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.161415100097656\n",
            "Eval_StdReturn : 1.774718165397644\n",
            "Eval_MaxReturn : -25.72817611694336\n",
            "Eval_MinReturn : -29.91090202331543\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.759437561035156\n",
            "Train_StdReturn : 25.045202255249023\n",
            "Train_MaxReturn : 22.3470401763916\n",
            "Train_MinReturn : -116.82990264892578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 660000\n",
            "TimeSinceStart : 687.6102576255798\n",
            "Training Loss : -1618.011962890625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.058990478515625\n",
            "Eval_StdReturn : 22.913864135742188\n",
            "Eval_MaxReturn : -17.237606048583984\n",
            "Eval_MinReturn : -71.39344024658203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.680137634277344\n",
            "Train_StdReturn : 27.748994827270508\n",
            "Train_MaxReturn : 35.27641296386719\n",
            "Train_MinReturn : -119.95952606201172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 690000\n",
            "TimeSinceStart : 718.9970605373383\n",
            "Training Loss : -1909.720458984375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.94362258911133\n",
            "Eval_StdReturn : 10.542852401733398\n",
            "Eval_MaxReturn : -33.51036071777344\n",
            "Eval_MinReturn : -57.659645080566406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.85590744018555\n",
            "Train_StdReturn : 31.216358184814453\n",
            "Train_MaxReturn : 57.16136169433594\n",
            "Train_MinReturn : -152.91378784179688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 720000\n",
            "TimeSinceStart : 750.2635750770569\n",
            "Training Loss : -1351.786376953125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.29887008666992\n",
            "Eval_StdReturn : 40.45820617675781\n",
            "Eval_MaxReturn : -5.839755058288574\n",
            "Eval_MinReturn : -100.2159194946289\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.43448257446289\n",
            "Train_StdReturn : 23.840900421142578\n",
            "Train_MaxReturn : 21.62890625\n",
            "Train_MinReturn : -116.87052917480469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 750000\n",
            "TimeSinceStart : 781.6444778442383\n",
            "Training Loss : -1725.8623046875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -43.87626266479492\n",
            "Eval_StdReturn : 14.147727966308594\n",
            "Eval_MaxReturn : -27.460615158081055\n",
            "Eval_MinReturn : -61.990257263183594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.669286727905273\n",
            "Train_StdReturn : 28.345857620239258\n",
            "Train_MaxReturn : 37.66005325317383\n",
            "Train_MinReturn : -118.7358627319336\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 780000\n",
            "TimeSinceStart : 812.823882818222\n",
            "Training Loss : -2194.5517578125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.454131126403809\n",
            "Eval_StdReturn : 7.2086381912231445\n",
            "Eval_MaxReturn : -0.37049055099487305\n",
            "Eval_MinReturn : -17.875333786010742\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.591562271118164\n",
            "Train_StdReturn : 25.80504035949707\n",
            "Train_MaxReturn : 39.368133544921875\n",
            "Train_MinReturn : -108.31625366210938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 810000\n",
            "TimeSinceStart : 844.3148522377014\n",
            "Training Loss : -1505.7933349609375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.710864067077637\n",
            "Eval_StdReturn : 14.700897216796875\n",
            "Eval_MaxReturn : 7.499011993408203\n",
            "Eval_MinReturn : -28.201297760009766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.639175415039062\n",
            "Train_StdReturn : 26.370752334594727\n",
            "Train_MaxReturn : 45.59698486328125\n",
            "Train_MinReturn : -119.16622924804688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 840000\n",
            "TimeSinceStart : 875.7649176120758\n",
            "Training Loss : -1470.2978515625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.285640716552734\n",
            "Eval_StdReturn : 14.250118255615234\n",
            "Eval_MaxReturn : -15.322599411010742\n",
            "Eval_MinReturn : -47.65601348876953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.394933700561523\n",
            "Train_StdReturn : 26.240245819091797\n",
            "Train_MaxReturn : 33.159385681152344\n",
            "Train_MinReturn : -136.8338165283203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 870000\n",
            "TimeSinceStart : 907.2481408119202\n",
            "Training Loss : -1051.762939453125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 11.0120210647583\n",
            "Eval_StdReturn : 15.67265510559082\n",
            "Eval_MaxReturn : 30.734909057617188\n",
            "Eval_MinReturn : -7.607501983642578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.24273681640625\n",
            "Train_StdReturn : 28.998634338378906\n",
            "Train_MaxReturn : 74.27862548828125\n",
            "Train_MinReturn : -115.00434875488281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 900000\n",
            "TimeSinceStart : 938.505539894104\n",
            "Training Loss : -1142.6748046875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.941593170166016\n",
            "Eval_StdReturn : 10.079985618591309\n",
            "Eval_MaxReturn : -22.598833084106445\n",
            "Eval_MinReturn : -46.60883331298828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.893667221069336\n",
            "Train_StdReturn : 30.078367233276367\n",
            "Train_MaxReturn : 45.73988342285156\n",
            "Train_MinReturn : -115.73564910888672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 930000\n",
            "TimeSinceStart : 969.7172508239746\n",
            "Training Loss : -1408.43896484375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.26909065246582\n",
            "Eval_StdReturn : 4.742417335510254\n",
            "Eval_MaxReturn : -16.15353012084961\n",
            "Eval_MinReturn : -27.711345672607422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.30292510986328\n",
            "Train_StdReturn : 30.254186630249023\n",
            "Train_MaxReturn : 42.73756408691406\n",
            "Train_MinReturn : -118.55686950683594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 960000\n",
            "TimeSinceStart : 1000.8940966129303\n",
            "Training Loss : -951.6502685546875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.74609375\n",
            "Eval_StdReturn : 5.991118431091309\n",
            "Eval_MaxReturn : -11.603216171264648\n",
            "Eval_MinReturn : -25.844947814941406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.241016387939453\n",
            "Train_StdReturn : 30.45283317565918\n",
            "Train_MaxReturn : 43.60266876220703\n",
            "Train_MinReturn : -136.89822387695312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 990000\n",
            "TimeSinceStart : 1032.128469467163\n",
            "Training Loss : -767.3759765625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.5971245765686035\n",
            "Eval_StdReturn : 19.24265480041504\n",
            "Eval_MaxReturn : 34.75175476074219\n",
            "Eval_MinReturn : -7.52589225769043\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.407888412475586\n",
            "Train_StdReturn : 28.570289611816406\n",
            "Train_MaxReturn : 44.90938186645508\n",
            "Train_MinReturn : -136.69296264648438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1020000\n",
            "TimeSinceStart : 1063.3592636585236\n",
            "Training Loss : -906.19873046875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.237479209899902\n",
            "Eval_StdReturn : 40.589935302734375\n",
            "Eval_MaxReturn : 19.90799331665039\n",
            "Eval_MinReturn : -70.39774322509766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.255287170410156\n",
            "Train_StdReturn : 32.28660583496094\n",
            "Train_MaxReturn : 48.775699615478516\n",
            "Train_MinReturn : -144.65541076660156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1050000\n",
            "TimeSinceStart : 1094.41907787323\n",
            "Training Loss : -937.09765625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.200709342956543\n",
            "Eval_StdReturn : 10.95859146118164\n",
            "Eval_MaxReturn : 2.493284225463867\n",
            "Eval_MinReturn : -24.33197021484375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.955673217773438\n",
            "Train_StdReturn : 30.457321166992188\n",
            "Train_MaxReturn : 43.944610595703125\n",
            "Train_MinReturn : -129.44757080078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1080000\n",
            "TimeSinceStart : 1125.5113897323608\n",
            "Training Loss : -986.076904296875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.750580787658691\n",
            "Eval_StdReturn : 11.663145065307617\n",
            "Eval_MaxReturn : 3.7243895530700684\n",
            "Eval_MinReturn : -24.725923538208008\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.596338272094727\n",
            "Train_StdReturn : 31.597370147705078\n",
            "Train_MaxReturn : 51.71971893310547\n",
            "Train_MinReturn : -141.63648986816406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1110000\n",
            "TimeSinceStart : 1156.7154204845428\n",
            "Training Loss : -889.256103515625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.8371718525886536\n",
            "Eval_StdReturn : 13.385272026062012\n",
            "Eval_MaxReturn : 9.716361999511719\n",
            "Eval_MinReturn : -19.72332763671875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -15.377738952636719\n",
            "Train_StdReturn : 25.560791015625\n",
            "Train_MaxReturn : 47.948631286621094\n",
            "Train_MinReturn : -86.80809783935547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1140000\n",
            "TimeSinceStart : 1187.8460166454315\n",
            "Training Loss : -1149.63671875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.487701416015625\n",
            "Eval_StdReturn : 47.55475616455078\n",
            "Eval_MaxReturn : 9.17535400390625\n",
            "Eval_MinReturn : -93.69829559326172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.296045303344727\n",
            "Train_StdReturn : 31.346769332885742\n",
            "Train_MaxReturn : 50.759342193603516\n",
            "Train_MinReturn : -122.36480712890625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1170000\n",
            "TimeSinceStart : 1219.083646774292\n",
            "Training Loss : -709.8876953125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.538055419921875\n",
            "Eval_StdReturn : 32.834877014160156\n",
            "Eval_MaxReturn : 37.21578598022461\n",
            "Eval_MinReturn : -43.012027740478516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.123872756958008\n",
            "Train_StdReturn : 33.9920768737793\n",
            "Train_MaxReturn : 62.58607864379883\n",
            "Train_MinReturn : -177.39523315429688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1200000\n",
            "TimeSinceStart : 1250.1988229751587\n",
            "Training Loss : -484.26318359375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.694364547729492\n",
            "Eval_StdReturn : 31.620853424072266\n",
            "Eval_MaxReturn : 26.88462257385254\n",
            "Eval_MinReturn : -43.04216003417969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.58526039123535\n",
            "Train_StdReturn : 33.3115234375\n",
            "Train_MaxReturn : 55.24110412597656\n",
            "Train_MinReturn : -133.22999572753906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1230000\n",
            "TimeSinceStart : 1281.4483749866486\n",
            "Training Loss : -475.20849609375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.2188663482666\n",
            "Eval_StdReturn : 33.449954986572266\n",
            "Eval_MaxReturn : 23.21906852722168\n",
            "Eval_MinReturn : -56.3349609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.388178825378418\n",
            "Train_StdReturn : 32.93500900268555\n",
            "Train_MaxReturn : 67.97268676757812\n",
            "Train_MinReturn : -139.00357055664062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1260000\n",
            "TimeSinceStart : 1312.6412439346313\n",
            "Training Loss : -589.7412109375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.834875583648682\n",
            "Eval_StdReturn : 17.25728416442871\n",
            "Eval_MaxReturn : 31.064456939697266\n",
            "Eval_MinReturn : -7.812962532043457\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -15.68677043914795\n",
            "Train_StdReturn : 33.43115234375\n",
            "Train_MaxReturn : 83.99090576171875\n",
            "Train_MinReturn : -142.6241455078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1290000\n",
            "TimeSinceStart : 1343.62358212471\n",
            "Training Loss : -672.0830078125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.513132095336914\n",
            "Eval_StdReturn : 6.650628089904785\n",
            "Eval_MaxReturn : -10.115772247314453\n",
            "Eval_MinReturn : -24.548715591430664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.437963485717773\n",
            "Train_StdReturn : 32.27101516723633\n",
            "Train_MaxReturn : 68.28826904296875\n",
            "Train_MinReturn : -120.75531768798828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1320000\n",
            "TimeSinceStart : 1374.852022409439\n",
            "Training Loss : -655.21484375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.819327354431152\n",
            "Eval_StdReturn : 33.48188400268555\n",
            "Eval_MaxReturn : 49.329959869384766\n",
            "Eval_MinReturn : -32.53548812866211\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.678747177124023\n",
            "Train_StdReturn : 32.72898483276367\n",
            "Train_MaxReturn : 73.42423248291016\n",
            "Train_MinReturn : -106.26948547363281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1350000\n",
            "TimeSinceStart : 1406.1288442611694\n",
            "Training Loss : -807.78369140625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.81865406036377\n",
            "Eval_StdReturn : 11.613962173461914\n",
            "Eval_MaxReturn : 1.6029186248779297\n",
            "Eval_MinReturn : -23.303470611572266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -7.2523698806762695\n",
            "Train_StdReturn : 30.340286254882812\n",
            "Train_MaxReturn : 53.84557342529297\n",
            "Train_MinReturn : -138.05429077148438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1380000\n",
            "TimeSinceStart : 1437.4103677272797\n",
            "Training Loss : 136.48095703125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.327476978302002\n",
            "Eval_StdReturn : 22.39421844482422\n",
            "Eval_MaxReturn : 12.637922286987305\n",
            "Eval_MinReturn : -35.97011947631836\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.034114837646484\n",
            "Train_StdReturn : 33.63960647583008\n",
            "Train_MaxReturn : 100.26947021484375\n",
            "Train_MinReturn : -114.90089416503906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1410000\n",
            "TimeSinceStart : 1468.5988988876343\n",
            "Training Loss : -236.0947265625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.411061763763428\n",
            "Eval_StdReturn : 13.440546035766602\n",
            "Eval_MaxReturn : 24.065372467041016\n",
            "Eval_MinReturn : -7.075989246368408\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -6.686321258544922\n",
            "Train_StdReturn : 32.93519592285156\n",
            "Train_MaxReturn : 68.61373138427734\n",
            "Train_MinReturn : -88.04254150390625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1440000\n",
            "TimeSinceStart : 1500.0438513755798\n",
            "Training Loss : -406.412841796875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.463946342468262\n",
            "Eval_StdReturn : 25.658342361450195\n",
            "Eval_MaxReturn : 18.507509231567383\n",
            "Eval_MinReturn : -44.323509216308594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -7.637836456298828\n",
            "Train_StdReturn : 32.265830993652344\n",
            "Train_MaxReturn : 81.61631774902344\n",
            "Train_MinReturn : -81.20183563232422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1470000\n",
            "TimeSinceStart : 1531.3082466125488\n",
            "Training Loss : -548.1183471679688\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.51164722442627\n",
            "Eval_StdReturn : 16.67007064819336\n",
            "Eval_MaxReturn : 14.954559326171875\n",
            "Eval_MinReturn : -22.20427894592285\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.908594131469727\n",
            "Train_StdReturn : 30.465877532958984\n",
            "Train_MaxReturn : 74.82373046875\n",
            "Train_MinReturn : -129.47872924804688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1500000\n",
            "TimeSinceStart : 1562.5059690475464\n",
            "Training Loss : -458.09423828125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.046968460083008\n",
            "Eval_StdReturn : 23.262619018554688\n",
            "Eval_MaxReturn : 10.850749969482422\n",
            "Eval_MinReturn : -38.666507720947266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.48159408569336\n",
            "Train_StdReturn : 30.818811416625977\n",
            "Train_MaxReturn : 77.68257141113281\n",
            "Train_MinReturn : -121.50696563720703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1530000\n",
            "TimeSinceStart : 1593.643304824829\n",
            "Training Loss : 497.9957580566406\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.172831535339355\n",
            "Eval_StdReturn : 9.448460578918457\n",
            "Eval_MaxReturn : -5.188026428222656\n",
            "Eval_MinReturn : -27.230575561523438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.911747932434082\n",
            "Train_StdReturn : 28.343576431274414\n",
            "Train_MaxReturn : 64.6265640258789\n",
            "Train_MinReturn : -111.56304931640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1560000\n",
            "TimeSinceStart : 1624.7350075244904\n",
            "Training Loss : -270.84765625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.72571563720703\n",
            "Eval_StdReturn : 18.403074264526367\n",
            "Eval_MaxReturn : -13.605615615844727\n",
            "Eval_MinReturn : -56.261817932128906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.27094078063965\n",
            "Train_StdReturn : 28.617830276489258\n",
            "Train_MaxReturn : 48.96617889404297\n",
            "Train_MinReturn : -141.89785766601562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1590000\n",
            "TimeSinceStart : 1656.029844045639\n",
            "Training Loss : -972.6971435546875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.333267211914062\n",
            "Eval_StdReturn : 19.298921585083008\n",
            "Eval_MaxReturn : 0.689640998840332\n",
            "Eval_MinReturn : -46.30596160888672\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.073949813842773\n",
            "Train_StdReturn : 28.744958877563477\n",
            "Train_MaxReturn : 50.741546630859375\n",
            "Train_MinReturn : -157.71023559570312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1620000\n",
            "TimeSinceStart : 1687.2631673812866\n",
            "Training Loss : -582.63134765625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -2.5054538249969482\n",
            "Eval_StdReturn : 18.37623405456543\n",
            "Eval_MaxReturn : 21.05876350402832\n",
            "Eval_MinReturn : -23.778335571289062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.046586990356445\n",
            "Train_StdReturn : 24.762109756469727\n",
            "Train_MaxReturn : 30.191387176513672\n",
            "Train_MinReturn : -110.28482055664062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1650000\n",
            "TimeSinceStart : 1718.3876025676727\n",
            "Training Loss : -593.6093139648438\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.257766723632812\n",
            "Eval_StdReturn : 11.915277481079102\n",
            "Eval_MaxReturn : -15.779834747314453\n",
            "Eval_MinReturn : -44.755714416503906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.420320510864258\n",
            "Train_StdReturn : 24.106388092041016\n",
            "Train_MaxReturn : 58.251434326171875\n",
            "Train_MinReturn : -122.80435943603516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1680000\n",
            "TimeSinceStart : 1749.8157782554626\n",
            "Training Loss : 15.4468994140625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.608306884765625\n",
            "Eval_StdReturn : 14.779377937316895\n",
            "Eval_MaxReturn : -16.169795989990234\n",
            "Eval_MinReturn : -50.615108489990234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.346664428710938\n",
            "Train_StdReturn : 23.537826538085938\n",
            "Train_MaxReturn : 41.191654205322266\n",
            "Train_MinReturn : -87.16922760009766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1710000\n",
            "TimeSinceStart : 1781.0222432613373\n",
            "Training Loss : -580.45556640625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.703676223754883\n",
            "Eval_StdReturn : 18.073741912841797\n",
            "Eval_MaxReturn : -2.3673782348632812\n",
            "Eval_MinReturn : -46.28139114379883\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.967737197875977\n",
            "Train_StdReturn : 23.894512176513672\n",
            "Train_MaxReturn : 45.352012634277344\n",
            "Train_MinReturn : -163.04103088378906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1740000\n",
            "TimeSinceStart : 1812.407057762146\n",
            "Training Loss : -645.4990234375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.06940269470215\n",
            "Eval_StdReturn : 13.875995635986328\n",
            "Eval_MaxReturn : -4.416911602020264\n",
            "Eval_MinReturn : -37.67564392089844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.918079376220703\n",
            "Train_StdReturn : 24.471946716308594\n",
            "Train_MaxReturn : 22.912519454956055\n",
            "Train_MinReturn : -144.6946563720703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1770000\n",
            "TimeSinceStart : 1843.7531206607819\n",
            "Training Loss : -461.68280029296875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.00716233253479\n",
            "Eval_StdReturn : 10.354937553405762\n",
            "Eval_MaxReturn : 13.754140853881836\n",
            "Eval_MinReturn : -11.438874244689941\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.398164749145508\n",
            "Train_StdReturn : 21.034719467163086\n",
            "Train_MaxReturn : 31.545297622680664\n",
            "Train_MinReturn : -122.33184051513672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1800000\n",
            "TimeSinceStart : 1874.8507452011108\n",
            "Training Loss : -671.4027099609375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.318343162536621\n",
            "Eval_StdReturn : 28.826005935668945\n",
            "Eval_MaxReturn : 17.316387176513672\n",
            "Eval_MinReturn : -52.793182373046875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.044841766357422\n",
            "Train_StdReturn : 22.85651969909668\n",
            "Train_MaxReturn : 49.99835205078125\n",
            "Train_MinReturn : -109.42475128173828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1830000\n",
            "TimeSinceStart : 1906.0760571956635\n",
            "Training Loss : -622.9153442382812\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.866207122802734\n",
            "Eval_StdReturn : 4.463590145111084\n",
            "Eval_MaxReturn : -29.565540313720703\n",
            "Eval_MinReturn : -40.018245697021484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.67345428466797\n",
            "Train_StdReturn : 20.91498565673828\n",
            "Train_MaxReturn : 18.2451229095459\n",
            "Train_MinReturn : -141.73904418945312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1860000\n",
            "TimeSinceStart : 1937.3231961727142\n",
            "Training Loss : -868.5086669921875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.435928344726562\n",
            "Eval_StdReturn : 13.909955978393555\n",
            "Eval_MaxReturn : -8.095407485961914\n",
            "Eval_MinReturn : -42.15044403076172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.157005310058594\n",
            "Train_StdReturn : 18.34111976623535\n",
            "Train_MaxReturn : 38.51053237915039\n",
            "Train_MinReturn : -96.12934875488281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1890000\n",
            "TimeSinceStart : 1968.4463498592377\n",
            "Training Loss : -1311.0703125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.22662925720215\n",
            "Eval_StdReturn : 23.02517318725586\n",
            "Eval_MaxReturn : -4.77479362487793\n",
            "Eval_MinReturn : -58.16815185546875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.559484481811523\n",
            "Train_StdReturn : 19.535667419433594\n",
            "Train_MaxReturn : 18.02230453491211\n",
            "Train_MinReturn : -93.50325012207031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1920000\n",
            "TimeSinceStart : 1999.7222590446472\n",
            "Training Loss : -548.54345703125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.378692626953125\n",
            "Eval_StdReturn : 14.913036346435547\n",
            "Eval_MaxReturn : -9.42814826965332\n",
            "Eval_MinReturn : -44.05194854736328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.379636764526367\n",
            "Train_StdReturn : 20.128679275512695\n",
            "Train_MaxReturn : 28.205732345581055\n",
            "Train_MinReturn : -101.34426879882812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1950000\n",
            "TimeSinceStart : 2030.8937020301819\n",
            "Training Loss : -899.5809326171875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.134910583496094\n",
            "Eval_StdReturn : 11.664341926574707\n",
            "Eval_MaxReturn : -21.96933364868164\n",
            "Eval_MinReturn : -49.06214904785156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.513042449951172\n",
            "Train_StdReturn : 22.927438735961914\n",
            "Train_MaxReturn : 47.1774787902832\n",
            "Train_MinReturn : -113.30400085449219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1980000\n",
            "TimeSinceStart : 2061.9953713417053\n",
            "Training Loss : -1239.610107421875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.67540168762207\n",
            "Eval_StdReturn : 10.30727481842041\n",
            "Eval_MaxReturn : -17.395055770874023\n",
            "Eval_MinReturn : -40.204837799072266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.626802444458008\n",
            "Train_StdReturn : 23.772785186767578\n",
            "Train_MaxReturn : 63.37567138671875\n",
            "Train_MinReturn : -130.9266357421875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2010000\n",
            "TimeSinceStart : 2093.2835409641266\n",
            "Training Loss : -1590.43310546875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.66240692138672\n",
            "Eval_StdReturn : 4.9556684494018555\n",
            "Eval_MaxReturn : -14.731135368347168\n",
            "Eval_MinReturn : -26.86115074157715\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.575223922729492\n",
            "Train_StdReturn : 17.87192153930664\n",
            "Train_MaxReturn : 66.29711151123047\n",
            "Train_MinReturn : -68.5672378540039\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2040000\n",
            "TimeSinceStart : 2124.6350133419037\n",
            "Training Loss : -968.566162109375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.69706916809082\n",
            "Eval_StdReturn : 11.525996208190918\n",
            "Eval_MaxReturn : -8.180910110473633\n",
            "Eval_MinReturn : -35.99850082397461\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.253908157348633\n",
            "Train_StdReturn : 18.13918685913086\n",
            "Train_MaxReturn : 60.959327697753906\n",
            "Train_MinReturn : -64.31724548339844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2070000\n",
            "TimeSinceStart : 2155.8273396492004\n",
            "Training Loss : -1195.5709228515625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.7560977935791\n",
            "Eval_StdReturn : 27.052276611328125\n",
            "Eval_MaxReturn : 9.411526679992676\n",
            "Eval_MinReturn : -56.74522399902344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.2158203125\n",
            "Train_StdReturn : 17.119224548339844\n",
            "Train_MaxReturn : 26.650074005126953\n",
            "Train_MinReturn : -59.97288513183594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2100000\n",
            "TimeSinceStart : 2186.9313156604767\n",
            "Training Loss : -1229.970703125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.07265853881836\n",
            "Eval_StdReturn : 14.498011589050293\n",
            "Eval_MaxReturn : 3.771167516708374\n",
            "Eval_MinReturn : -30.46172332763672\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.60706329345703\n",
            "Train_StdReturn : 16.325057983398438\n",
            "Train_MaxReturn : 21.968219757080078\n",
            "Train_MinReturn : -81.00755310058594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2130000\n",
            "TimeSinceStart : 2218.2028200626373\n",
            "Training Loss : -1849.505615234375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.7773706912994385\n",
            "Eval_StdReturn : 6.441644191741943\n",
            "Eval_MaxReturn : 12.64383316040039\n",
            "Eval_MinReturn : -2.467367172241211\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.089092254638672\n",
            "Train_StdReturn : 16.02886199951172\n",
            "Train_MaxReturn : 39.384063720703125\n",
            "Train_MinReturn : -60.32835388183594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2160000\n",
            "TimeSinceStart : 2249.5380907058716\n",
            "Training Loss : -1824.244140625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.095831871032715\n",
            "Eval_StdReturn : 11.935809135437012\n",
            "Eval_MaxReturn : 5.778918266296387\n",
            "Eval_MinReturn : -19.890169143676758\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.067176818847656\n",
            "Train_StdReturn : 15.948957443237305\n",
            "Train_MaxReturn : 44.342041015625\n",
            "Train_MinReturn : -78.88874816894531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2190000\n",
            "TimeSinceStart : 2280.74325799942\n",
            "Training Loss : -1671.84130859375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.7045698165893555\n",
            "Eval_StdReturn : 14.997903823852539\n",
            "Eval_MaxReturn : 14.648527145385742\n",
            "Eval_MinReturn : -18.446739196777344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.489516258239746\n",
            "Train_StdReturn : 16.74544906616211\n",
            "Train_MaxReturn : 31.548372268676758\n",
            "Train_MinReturn : -62.704044342041016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2220000\n",
            "TimeSinceStart : 2311.94114112854\n",
            "Training Loss : -1142.5205078125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.867318153381348\n",
            "Eval_StdReturn : 9.822611808776855\n",
            "Eval_MaxReturn : -1.2350744009017944\n",
            "Eval_MinReturn : -22.735166549682617\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.682106971740723\n",
            "Train_StdReturn : 16.45938491821289\n",
            "Train_MaxReturn : 27.49765396118164\n",
            "Train_MinReturn : -85.31256866455078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2250000\n",
            "TimeSinceStart : 2343.095771789551\n",
            "Training Loss : -1476.1983642578125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.66373634338379\n",
            "Eval_StdReturn : 5.845478534698486\n",
            "Eval_MaxReturn : -9.90794563293457\n",
            "Eval_MinReturn : -24.019575119018555\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.634549140930176\n",
            "Train_StdReturn : 16.319639205932617\n",
            "Train_MaxReturn : 38.81768035888672\n",
            "Train_MinReturn : -62.509735107421875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2280000\n",
            "TimeSinceStart : 2374.3176057338715\n",
            "Training Loss : -1538.092529296875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.2779258191585541\n",
            "Eval_StdReturn : 16.2423095703125\n",
            "Eval_MaxReturn : 16.528718948364258\n",
            "Eval_MinReturn : -22.241168975830078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.095502853393555\n",
            "Train_StdReturn : 17.426300048828125\n",
            "Train_MaxReturn : 58.589820861816406\n",
            "Train_MinReturn : -63.62263870239258\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2310000\n",
            "TimeSinceStart : 2405.859087228775\n",
            "Training Loss : -1080.590576171875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.140144348144531\n",
            "Eval_StdReturn : 1.0772428512573242\n",
            "Eval_MaxReturn : -12.702051162719727\n",
            "Eval_MinReturn : -15.294614791870117\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -7.9523844718933105\n",
            "Train_StdReturn : 14.949398040771484\n",
            "Train_MaxReturn : 25.68524932861328\n",
            "Train_MinReturn : -51.35693359375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2340000\n",
            "TimeSinceStart : 2437.1529598236084\n",
            "Training Loss : -1306.9443359375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.641538619995117\n",
            "Eval_StdReturn : 2.387819290161133\n",
            "Eval_MaxReturn : -1.4196996688842773\n",
            "Eval_MinReturn : -7.1284356117248535\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -5.643033504486084\n",
            "Train_StdReturn : 14.3485689163208\n",
            "Train_MaxReturn : 43.19451141357422\n",
            "Train_MinReturn : -42.8250846862793\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2370000\n",
            "TimeSinceStart : 2468.1802604198456\n",
            "Training Loss : -1103.1376953125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 0.2564045488834381\n",
            "Eval_StdReturn : 9.219738960266113\n",
            "Eval_MaxReturn : 12.542258262634277\n",
            "Eval_MinReturn : -9.667886734008789\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -4.655010223388672\n",
            "Train_StdReturn : 13.723533630371094\n",
            "Train_MaxReturn : 25.514225006103516\n",
            "Train_MinReturn : -42.00094985961914\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2400000\n",
            "TimeSinceStart : 2499.4132277965546\n",
            "Training Loss : -1205.482177734375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.143424987792969\n",
            "Eval_StdReturn : 14.614518165588379\n",
            "Eval_MaxReturn : 7.751479148864746\n",
            "Eval_MinReturn : -26.999849319458008\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -4.316760063171387\n",
            "Train_StdReturn : 14.397830963134766\n",
            "Train_MaxReturn : 38.85014343261719\n",
            "Train_MinReturn : -41.117706298828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2430000\n",
            "TimeSinceStart : 2530.612030506134\n",
            "Training Loss : -1598.310791015625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.69471549987793\n",
            "Eval_StdReturn : 11.02251148223877\n",
            "Eval_MaxReturn : -14.754097938537598\n",
            "Eval_MinReturn : -39.22362518310547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -3.504817008972168\n",
            "Train_StdReturn : 14.49397087097168\n",
            "Train_MaxReturn : 51.910003662109375\n",
            "Train_MinReturn : -45.242008209228516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2460000\n",
            "TimeSinceStart : 2561.728093147278\n",
            "Training Loss : -1009.4534912109375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.445378065109253\n",
            "Eval_StdReturn : 4.3936309814453125\n",
            "Eval_MaxReturn : 8.599748611450195\n",
            "Eval_MinReturn : -1.3726096153259277\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -3.1137800216674805\n",
            "Train_StdReturn : 14.026839256286621\n",
            "Train_MaxReturn : 29.707630157470703\n",
            "Train_MinReturn : -59.206180572509766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2490000\n",
            "TimeSinceStart : 2592.8155171871185\n",
            "Training Loss : -1427.6793212890625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.775337219238281\n",
            "Eval_StdReturn : 1.1482586860656738\n",
            "Eval_MaxReturn : -3.2848711013793945\n",
            "Eval_MinReturn : -6.078808784484863\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -0.2788677215576172\n",
            "Train_StdReturn : 13.660568237304688\n",
            "Train_MaxReturn : 34.01344299316406\n",
            "Train_MinReturn : -41.35348129272461\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2520000\n",
            "TimeSinceStart : 2623.965984582901\n",
            "Training Loss : -1173.737548828125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.078120231628418\n",
            "Eval_StdReturn : 12.22568130493164\n",
            "Eval_MaxReturn : 25.016733169555664\n",
            "Eval_MinReturn : -4.693891525268555\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -1.2849678993225098\n",
            "Train_StdReturn : 13.455179214477539\n",
            "Train_MaxReturn : 39.392330169677734\n",
            "Train_MinReturn : -58.94737243652344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2550000\n",
            "TimeSinceStart : 2655.851527452469\n",
            "Training Loss : -1477.7025146484375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.466015338897705\n",
            "Eval_StdReturn : 18.236669540405273\n",
            "Eval_MaxReturn : 29.005617141723633\n",
            "Eval_MinReturn : -15.587854385375977\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.148700475692749\n",
            "Train_StdReturn : 14.923235893249512\n",
            "Train_MaxReturn : 36.38235092163086\n",
            "Train_MinReturn : -43.20777130126953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2580000\n",
            "TimeSinceStart : 2687.1606974601746\n",
            "Training Loss : -1457.3157958984375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.5322136878967285\n",
            "Eval_StdReturn : 2.2385292053222656\n",
            "Eval_MaxReturn : 7.425678253173828\n",
            "Eval_MinReturn : 1.9730887413024902\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 4.099873065948486\n",
            "Train_StdReturn : 14.663049697875977\n",
            "Train_MaxReturn : 50.59050750732422\n",
            "Train_MinReturn : -45.80942916870117\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2610000\n",
            "TimeSinceStart : 2718.2957146167755\n",
            "Training Loss : -1010.4034423828125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.0827054977417\n",
            "Eval_StdReturn : 6.957119941711426\n",
            "Eval_MaxReturn : 22.920730590820312\n",
            "Eval_MinReturn : 8.05312728881836\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 4.501284599304199\n",
            "Train_StdReturn : 15.148188591003418\n",
            "Train_MaxReturn : 37.07292175292969\n",
            "Train_MinReturn : -41.12998580932617\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2640000\n",
            "TimeSinceStart : 2749.7550773620605\n",
            "Training Loss : -854.9857177734375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.637542724609375\n",
            "Eval_StdReturn : 9.990686416625977\n",
            "Eval_MaxReturn : 5.017671585083008\n",
            "Eval_MinReturn : -19.406187057495117\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 6.220144271850586\n",
            "Train_StdReturn : 16.73680877685547\n",
            "Train_MaxReturn : 49.311317443847656\n",
            "Train_MinReturn : -38.75957107543945\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2670000\n",
            "TimeSinceStart : 2781.3503320217133\n",
            "Training Loss : -970.4835815429688\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -1.731414794921875\n",
            "Eval_StdReturn : 21.600698471069336\n",
            "Eval_MaxReturn : 28.114883422851562\n",
            "Eval_MinReturn : -22.29231071472168\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 5.262725830078125\n",
            "Train_StdReturn : 14.753771781921387\n",
            "Train_MaxReturn : 44.570777893066406\n",
            "Train_MinReturn : -43.93120193481445\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2700000\n",
            "TimeSinceStart : 2814.0955290794373\n",
            "Training Loss : -529.514404296875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.6317138671875\n",
            "Eval_StdReturn : 6.160081386566162\n",
            "Eval_MaxReturn : -1.4667749404907227\n",
            "Eval_MinReturn : -16.344816207885742\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.492845058441162\n",
            "Train_StdReturn : 15.074718475341797\n",
            "Train_MaxReturn : 40.665122985839844\n",
            "Train_MinReturn : -42.99897766113281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2730000\n",
            "TimeSinceStart : 2845.9748668670654\n",
            "Training Loss : -1025.839599609375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.853367805480957\n",
            "Eval_StdReturn : 16.373069763183594\n",
            "Eval_MaxReturn : 5.103190898895264\n",
            "Eval_MinReturn : -35.0011100769043\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.9934330582618713\n",
            "Train_StdReturn : 15.190617561340332\n",
            "Train_MaxReturn : 39.27125549316406\n",
            "Train_MinReturn : -38.72238540649414\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2760000\n",
            "TimeSinceStart : 2877.3802864551544\n",
            "Training Loss : -598.4990234375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.705289363861084\n",
            "Eval_StdReturn : 10.364073753356934\n",
            "Eval_MaxReturn : 20.629615783691406\n",
            "Eval_MinReturn : -4.743725299835205\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 4.0699005126953125\n",
            "Train_StdReturn : 15.578572273254395\n",
            "Train_MaxReturn : 48.90582275390625\n",
            "Train_MinReturn : -60.69575119018555\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2790000\n",
            "TimeSinceStart : 2908.883815765381\n",
            "Training Loss : -902.5977783203125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.896329402923584\n",
            "Eval_StdReturn : 10.787402153015137\n",
            "Eval_MaxReturn : 19.874242782592773\n",
            "Eval_MinReturn : -5.102341651916504\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 5.894199848175049\n",
            "Train_StdReturn : 15.699392318725586\n",
            "Train_MaxReturn : 49.205238342285156\n",
            "Train_MinReturn : -43.451393127441406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2820000\n",
            "TimeSinceStart : 2940.33891248703\n",
            "Training Loss : -1186.073974609375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 35.15740966796875\n",
            "Eval_StdReturn : 15.831178665161133\n",
            "Eval_MaxReturn : 54.57373809814453\n",
            "Eval_MinReturn : 15.795541763305664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 11.408038139343262\n",
            "Train_StdReturn : 16.787979125976562\n",
            "Train_MaxReturn : 54.65028381347656\n",
            "Train_MinReturn : -38.50416564941406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2850000\n",
            "TimeSinceStart : 2971.6357929706573\n",
            "Training Loss : -611.01318359375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 35.17938232421875\n",
            "Eval_StdReturn : 16.281652450561523\n",
            "Eval_MaxReturn : 49.66798400878906\n",
            "Eval_MinReturn : 12.436738967895508\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 13.4523286819458\n",
            "Train_StdReturn : 17.42123031616211\n",
            "Train_MaxReturn : 51.937767028808594\n",
            "Train_MinReturn : -25.130048751831055\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2880000\n",
            "TimeSinceStart : 3002.916067123413\n",
            "Training Loss : -1073.3863525390625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.720741271972656\n",
            "Eval_StdReturn : 3.3290555477142334\n",
            "Eval_MaxReturn : 17.437721252441406\n",
            "Eval_MinReturn : 10.032472610473633\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 18.277698516845703\n",
            "Train_StdReturn : 18.169458389282227\n",
            "Train_MaxReturn : 64.810791015625\n",
            "Train_MinReturn : -41.57769012451172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2910000\n",
            "TimeSinceStart : 3034.184450864792\n",
            "Training Loss : -601.4022827148438\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 18.50299835205078\n",
            "Eval_StdReturn : 21.10235595703125\n",
            "Eval_MaxReturn : 37.72892761230469\n",
            "Eval_MinReturn : -10.877031326293945\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 21.309402465820312\n",
            "Train_StdReturn : 20.854398727416992\n",
            "Train_MaxReturn : 81.80804443359375\n",
            "Train_MinReturn : -37.19353103637695\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2940000\n",
            "TimeSinceStart : 3065.6240191459656\n",
            "Training Loss : -1120.0950927734375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 32.60082244873047\n",
            "Eval_StdReturn : 9.539900779724121\n",
            "Eval_MaxReturn : 45.97920227050781\n",
            "Eval_MinReturn : 24.402076721191406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 21.72372817993164\n",
            "Train_StdReturn : 20.198781967163086\n",
            "Train_MaxReturn : 71.2672119140625\n",
            "Train_MinReturn : -60.29045104980469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2970000\n",
            "TimeSinceStart : 3096.931074619293\n",
            "Training Loss : -1133.7255859375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.933985710144043\n",
            "Eval_StdReturn : 20.306594848632812\n",
            "Eval_MaxReturn : 28.063474655151367\n",
            "Eval_MinReturn : -15.769838333129883\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 21.73900604248047\n",
            "Train_StdReturn : 21.102214813232422\n",
            "Train_MaxReturn : 92.09784698486328\n",
            "Train_MinReturn : -83.94593811035156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3000000\n",
            "TimeSinceStart : 3128.156980276108\n",
            "Training Loss : -1394.59375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "    --discount 0.95 -n 100 -l 2 -s 32 \\\n",
        "    -b 30000 -lr 0.01 -rtg --nn_baseline \\\n",
        "    --exp_name q4_search_b30000_lr0.01_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2kHJ1vHPRmR",
        "outputId": "85cbe84d-9084-41f7-c35c-7720ff58baa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q4_search_b30000_lr0.02_rtg_nnbaseline_HalfCheetah-v2_08-05-2022_22-46-21\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -77.61477661132812\n",
            "Eval_StdReturn : 18.0219783782959\n",
            "Eval_MaxReturn : -52.5893440246582\n",
            "Eval_MinReturn : -94.30880737304688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -88.56880950927734\n",
            "Train_StdReturn : 36.4640007019043\n",
            "Train_MaxReturn : 11.764884948730469\n",
            "Train_MinReturn : -178.39559936523438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 30000\n",
            "TimeSinceStart : 33.02404427528381\n",
            "Training Loss : -1876.564208984375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -91.0204086303711\n",
            "Eval_StdReturn : 32.067588806152344\n",
            "Eval_MaxReturn : -47.725669860839844\n",
            "Eval_MinReturn : -124.35836029052734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -81.52295684814453\n",
            "Train_StdReturn : 36.62186813354492\n",
            "Train_MaxReturn : 3.0298919677734375\n",
            "Train_MinReturn : -201.528076171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 60000\n",
            "TimeSinceStart : 66.89031386375427\n",
            "Training Loss : -1685.50927734375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -85.7428970336914\n",
            "Eval_StdReturn : 39.20172119140625\n",
            "Eval_MaxReturn : -56.27777099609375\n",
            "Eval_MinReturn : -141.14508056640625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -69.95453643798828\n",
            "Train_StdReturn : 36.06737518310547\n",
            "Train_MaxReturn : 24.475486755371094\n",
            "Train_MinReturn : -171.18569946289062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 90000\n",
            "TimeSinceStart : 99.84952449798584\n",
            "Training Loss : -2151.66845703125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -67.7029800415039\n",
            "Eval_StdReturn : 7.208848476409912\n",
            "Eval_MaxReturn : -61.84013366699219\n",
            "Eval_MinReturn : -77.85739135742188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -72.21687316894531\n",
            "Train_StdReturn : 30.496122360229492\n",
            "Train_MaxReturn : -0.1988515853881836\n",
            "Train_MinReturn : -169.98806762695312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 120000\n",
            "TimeSinceStart : 132.94011116027832\n",
            "Training Loss : -2854.28515625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.63401222229004\n",
            "Eval_StdReturn : 26.058082580566406\n",
            "Eval_MaxReturn : -1.5372915267944336\n",
            "Eval_MinReturn : -63.812469482421875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -60.26576614379883\n",
            "Train_StdReturn : 31.02254295349121\n",
            "Train_MaxReturn : 12.34134292602539\n",
            "Train_MinReturn : -188.1354522705078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150000\n",
            "TimeSinceStart : 165.9920723438263\n",
            "Training Loss : -1957.7843017578125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.04985427856445\n",
            "Eval_StdReturn : 7.741281986236572\n",
            "Eval_MaxReturn : -29.210792541503906\n",
            "Eval_MinReturn : -45.98937225341797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -58.133026123046875\n",
            "Train_StdReturn : 30.113466262817383\n",
            "Train_MaxReturn : 6.697846412658691\n",
            "Train_MinReturn : -173.11325073242188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 180000\n",
            "TimeSinceStart : 199.25428819656372\n",
            "Training Loss : -2022.525390625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -52.26359939575195\n",
            "Eval_StdReturn : 2.5185179710388184\n",
            "Eval_MaxReturn : -49.26768112182617\n",
            "Eval_MinReturn : -55.429718017578125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -52.680870056152344\n",
            "Train_StdReturn : 30.282957077026367\n",
            "Train_MaxReturn : 24.78516960144043\n",
            "Train_MinReturn : -157.39743041992188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 210000\n",
            "TimeSinceStart : 232.61767292022705\n",
            "Training Loss : -1861.5660400390625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.337385177612305\n",
            "Eval_StdReturn : 9.700095176696777\n",
            "Eval_MaxReturn : -13.100441932678223\n",
            "Eval_MinReturn : -36.825279235839844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -48.47749328613281\n",
            "Train_StdReturn : 27.649555206298828\n",
            "Train_MaxReturn : 43.10425567626953\n",
            "Train_MinReturn : -142.85284423828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 240000\n",
            "TimeSinceStart : 265.932434797287\n",
            "Training Loss : -2699.744384765625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.052547454833984\n",
            "Eval_StdReturn : 19.475818634033203\n",
            "Eval_MaxReturn : -14.857938766479492\n",
            "Eval_MinReturn : -61.521629333496094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.376609802246094\n",
            "Train_StdReturn : 25.172502517700195\n",
            "Train_MaxReturn : 24.129779815673828\n",
            "Train_MinReturn : -111.37345123291016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 270000\n",
            "TimeSinceStart : 299.2738380432129\n",
            "Training Loss : -2405.33447265625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.88469123840332\n",
            "Eval_StdReturn : 18.127527236938477\n",
            "Eval_MaxReturn : 0.010335922241210938\n",
            "Eval_MinReturn : -43.87469482421875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.777565002441406\n",
            "Train_StdReturn : 24.581043243408203\n",
            "Train_MaxReturn : 27.408859252929688\n",
            "Train_MinReturn : -126.16836547851562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300000\n",
            "TimeSinceStart : 332.26822876930237\n",
            "Training Loss : -2139.7529296875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.11879348754883\n",
            "Eval_StdReturn : 32.715980529785156\n",
            "Eval_MaxReturn : 1.4950571060180664\n",
            "Eval_MinReturn : -73.63656616210938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.49205017089844\n",
            "Train_StdReturn : 25.671358108520508\n",
            "Train_MaxReturn : 30.513864517211914\n",
            "Train_MinReturn : -126.07417297363281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 330000\n",
            "TimeSinceStart : 365.39719462394714\n",
            "Training Loss : -2778.689697265625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.337684631347656\n",
            "Eval_StdReturn : 7.956539154052734\n",
            "Eval_MaxReturn : -19.083993911743164\n",
            "Eval_MinReturn : -36.56565856933594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.88309860229492\n",
            "Train_StdReturn : 29.288896560668945\n",
            "Train_MaxReturn : 30.962255477905273\n",
            "Train_MinReturn : -129.84283447265625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 360000\n",
            "TimeSinceStart : 398.3196313381195\n",
            "Training Loss : -2309.858642578125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.7252140045166\n",
            "Eval_StdReturn : 15.597024917602539\n",
            "Eval_MaxReturn : -4.759422302246094\n",
            "Eval_MinReturn : -42.14337921142578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.414052963256836\n",
            "Train_StdReturn : 26.380382537841797\n",
            "Train_MaxReturn : 58.99376678466797\n",
            "Train_MinReturn : -143.61968994140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 390000\n",
            "TimeSinceStart : 431.1748421192169\n",
            "Training Loss : -2051.60888671875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.032347679138184\n",
            "Eval_StdReturn : 4.661983966827393\n",
            "Eval_MaxReturn : -7.7418670654296875\n",
            "Eval_MinReturn : -18.51290512084961\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.38471221923828\n",
            "Train_StdReturn : 25.41449737548828\n",
            "Train_MaxReturn : 31.480953216552734\n",
            "Train_MinReturn : -132.11558532714844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 420000\n",
            "TimeSinceStart : 463.96947407722473\n",
            "Training Loss : -1538.522705078125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.734025955200195\n",
            "Eval_StdReturn : 35.631256103515625\n",
            "Eval_MaxReturn : 25.354469299316406\n",
            "Eval_MinReturn : -61.76288604736328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.955766677856445\n",
            "Train_StdReturn : 26.382946014404297\n",
            "Train_MaxReturn : 59.910118103027344\n",
            "Train_MinReturn : -113.86270904541016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450000\n",
            "TimeSinceStart : 496.962171792984\n",
            "Training Loss : -1315.95068359375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.07664108276367\n",
            "Eval_StdReturn : 21.264299392700195\n",
            "Eval_MaxReturn : -9.144770622253418\n",
            "Eval_MinReturn : -60.3905029296875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.865673065185547\n",
            "Train_StdReturn : 27.259323120117188\n",
            "Train_MaxReturn : 61.369056701660156\n",
            "Train_MinReturn : -105.65432739257812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 480000\n",
            "TimeSinceStart : 529.6139874458313\n",
            "Training Loss : -1399.1826171875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -66.68733978271484\n",
            "Eval_StdReturn : 13.864500045776367\n",
            "Eval_MaxReturn : -51.9392204284668\n",
            "Eval_MinReturn : -85.25096130371094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.1474494934082\n",
            "Train_StdReturn : 32.55413055419922\n",
            "Train_MaxReturn : 78.12288665771484\n",
            "Train_MinReturn : -139.982666015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 510000\n",
            "TimeSinceStart : 562.2597055435181\n",
            "Training Loss : -946.380615234375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.94279861450195\n",
            "Eval_StdReturn : 17.37883758544922\n",
            "Eval_MaxReturn : -22.74185562133789\n",
            "Eval_MinReturn : -62.754310607910156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.0069694519043\n",
            "Train_StdReturn : 34.362701416015625\n",
            "Train_MaxReturn : 74.10006713867188\n",
            "Train_MinReturn : -127.41129302978516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 540000\n",
            "TimeSinceStart : 594.8846473693848\n",
            "Training Loss : -907.49609375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.17128562927246\n",
            "Eval_StdReturn : 18.46403694152832\n",
            "Eval_MaxReturn : 3.5337753295898438\n",
            "Eval_MinReturn : -41.69257354736328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.55660629272461\n",
            "Train_StdReturn : 29.982046127319336\n",
            "Train_MaxReturn : 57.541263580322266\n",
            "Train_MinReturn : -120.80377960205078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 570000\n",
            "TimeSinceStart : 627.5352449417114\n",
            "Training Loss : -597.71240234375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.92298889160156\n",
            "Eval_StdReturn : 20.318605422973633\n",
            "Eval_MaxReturn : -22.69300651550293\n",
            "Eval_MinReturn : -71.485595703125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.216976165771484\n",
            "Train_StdReturn : 33.01277542114258\n",
            "Train_MaxReturn : 61.20103454589844\n",
            "Train_MinReturn : -144.2144012451172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 600000\n",
            "TimeSinceStart : 660.0798721313477\n",
            "Training Loss : -389.85736083984375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.52066421508789\n",
            "Eval_StdReturn : 14.640453338623047\n",
            "Eval_MaxReturn : -1.585322380065918\n",
            "Eval_MinReturn : -33.2142333984375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.315574645996094\n",
            "Train_StdReturn : 32.799530029296875\n",
            "Train_MaxReturn : 61.33198547363281\n",
            "Train_MinReturn : -144.74002075195312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 630000\n",
            "TimeSinceStart : 692.627701997757\n",
            "Training Loss : -1152.9560546875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -43.87810134887695\n",
            "Eval_StdReturn : 35.03803253173828\n",
            "Eval_MaxReturn : -1.3724431991577148\n",
            "Eval_MinReturn : -87.18648529052734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.845806121826172\n",
            "Train_StdReturn : 30.66712188720703\n",
            "Train_MaxReturn : 71.77928161621094\n",
            "Train_MinReturn : -171.89144897460938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 660000\n",
            "TimeSinceStart : 725.531280040741\n",
            "Training Loss : -998.6123046875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.552154541015625\n",
            "Eval_StdReturn : 23.203567504882812\n",
            "Eval_MaxReturn : 14.382184982299805\n",
            "Eval_MinReturn : -42.42497253417969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.729297637939453\n",
            "Train_StdReturn : 26.208984375\n",
            "Train_MaxReturn : 35.71501922607422\n",
            "Train_MinReturn : -120.26286315917969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 690000\n",
            "TimeSinceStart : 758.461362361908\n",
            "Training Loss : -977.859619140625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.65010452270508\n",
            "Eval_StdReturn : 13.064029693603516\n",
            "Eval_MaxReturn : -27.866024017333984\n",
            "Eval_MinReturn : -58.87783432006836\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.208694458007812\n",
            "Train_StdReturn : 29.298307418823242\n",
            "Train_MaxReturn : 43.224002838134766\n",
            "Train_MinReturn : -114.638916015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 720000\n",
            "TimeSinceStart : 791.2854061126709\n",
            "Training Loss : -1043.4639892578125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.805392265319824\n",
            "Eval_StdReturn : 33.268978118896484\n",
            "Eval_MaxReturn : 30.952606201171875\n",
            "Eval_MinReturn : -47.16550827026367\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.435575485229492\n",
            "Train_StdReturn : 26.391210556030273\n",
            "Train_MaxReturn : 46.24993133544922\n",
            "Train_MinReturn : -116.48910522460938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 750000\n",
            "TimeSinceStart : 824.268577337265\n",
            "Training Loss : -660.0703125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.770988464355469\n",
            "Eval_StdReturn : 5.96029806137085\n",
            "Eval_MaxReturn : -9.549148559570312\n",
            "Eval_MinReturn : -22.200119018554688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.564382553100586\n",
            "Train_StdReturn : 26.74131965637207\n",
            "Train_MaxReturn : 70.19696044921875\n",
            "Train_MinReturn : -117.97518920898438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 780000\n",
            "TimeSinceStart : 856.7915458679199\n",
            "Training Loss : -1440.475341796875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -3.7104930877685547\n",
            "Eval_StdReturn : 16.247529983520508\n",
            "Eval_MaxReturn : 14.927645683288574\n",
            "Eval_MinReturn : -24.6673526763916\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -15.573293685913086\n",
            "Train_StdReturn : 25.70230484008789\n",
            "Train_MaxReturn : 46.432891845703125\n",
            "Train_MinReturn : -102.91195678710938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 810000\n",
            "TimeSinceStart : 889.466269493103\n",
            "Training Loss : -1405.01318359375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -1.7127857208251953\n",
            "Eval_StdReturn : 22.42844009399414\n",
            "Eval_MaxReturn : 29.664779663085938\n",
            "Eval_MinReturn : -21.418869018554688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.22928237915039\n",
            "Train_StdReturn : 24.90826988220215\n",
            "Train_MaxReturn : 36.73611831665039\n",
            "Train_MinReturn : -95.67950439453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 840000\n",
            "TimeSinceStart : 921.981659412384\n",
            "Training Loss : -403.671142578125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -10.063323020935059\n",
            "Eval_StdReturn : 22.2784366607666\n",
            "Eval_MaxReturn : 18.808555603027344\n",
            "Eval_MinReturn : -35.421905517578125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.400814056396484\n",
            "Train_StdReturn : 23.3940372467041\n",
            "Train_MaxReturn : 32.058349609375\n",
            "Train_MinReturn : -112.10675048828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 870000\n",
            "TimeSinceStart : 954.7745978832245\n",
            "Training Loss : -287.33148193359375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.438919067382812\n",
            "Eval_StdReturn : 19.953170776367188\n",
            "Eval_MaxReturn : -12.501410484313965\n",
            "Eval_MinReturn : -57.453369140625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.946457862854004\n",
            "Train_StdReturn : 23.12195587158203\n",
            "Train_MaxReturn : 74.12247467041016\n",
            "Train_MinReturn : -87.06782531738281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 900000\n",
            "TimeSinceStart : 987.5823152065277\n",
            "Training Loss : -743.3810424804688\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.81800079345703\n",
            "Eval_StdReturn : 4.954331874847412\n",
            "Eval_MaxReturn : -29.14887046813965\n",
            "Eval_MinReturn : -41.01271057128906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.45037841796875\n",
            "Train_StdReturn : 20.23442840576172\n",
            "Train_MaxReturn : 28.388343811035156\n",
            "Train_MinReturn : -75.18147277832031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 930000\n",
            "TimeSinceStart : 1020.2610409259796\n",
            "Training Loss : -962.0787353515625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.984986305236816\n",
            "Eval_StdReturn : 40.26306915283203\n",
            "Eval_MaxReturn : 43.85651397705078\n",
            "Eval_MinReturn : -44.31342697143555\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.873680114746094\n",
            "Train_StdReturn : 20.371625900268555\n",
            "Train_MaxReturn : 32.07113265991211\n",
            "Train_MinReturn : -88.86463928222656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 960000\n",
            "TimeSinceStart : 1052.8977885246277\n",
            "Training Loss : -103.94635009765625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 0.13879840075969696\n",
            "Eval_StdReturn : 24.228513717651367\n",
            "Eval_MaxReturn : 34.31134796142578\n",
            "Eval_MinReturn : -19.11749267578125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.107929229736328\n",
            "Train_StdReturn : 20.241254806518555\n",
            "Train_MaxReturn : 28.77644157409668\n",
            "Train_MinReturn : -91.00216674804688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 990000\n",
            "TimeSinceStart : 1085.8203341960907\n",
            "Training Loss : -586.9791259765625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.513976097106934\n",
            "Eval_StdReturn : 17.65770149230957\n",
            "Eval_MaxReturn : 9.232872009277344\n",
            "Eval_MinReturn : -34.017433166503906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.033300399780273\n",
            "Train_StdReturn : 16.767854690551758\n",
            "Train_MaxReturn : 24.052133560180664\n",
            "Train_MinReturn : -66.25355529785156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1020000\n",
            "TimeSinceStart : 1118.4363424777985\n",
            "Training Loss : -195.8720703125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -1.1134281158447266\n",
            "Eval_StdReturn : 8.703753471374512\n",
            "Eval_MaxReturn : 7.56121301651001\n",
            "Eval_MinReturn : -13.013547897338867\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.87155532836914\n",
            "Train_StdReturn : 16.828039169311523\n",
            "Train_MaxReturn : 29.452152252197266\n",
            "Train_MinReturn : -68.8846435546875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1050000\n",
            "TimeSinceStart : 1151.0345208644867\n",
            "Training Loss : -663.48291015625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.19129259884357452\n",
            "Eval_StdReturn : 5.274871826171875\n",
            "Eval_MaxReturn : 5.596287250518799\n",
            "Eval_MinReturn : -7.1611528396606445\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.775616645812988\n",
            "Train_StdReturn : 15.603788375854492\n",
            "Train_MaxReturn : 26.99722671508789\n",
            "Train_MinReturn : -104.5067138671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1080000\n",
            "TimeSinceStart : 1183.8003749847412\n",
            "Training Loss : -1233.28564453125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -5.451810836791992\n",
            "Eval_StdReturn : 9.773594856262207\n",
            "Eval_MaxReturn : 5.124562740325928\n",
            "Eval_MinReturn : -18.446487426757812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.154794692993164\n",
            "Train_StdReturn : 15.023455619812012\n",
            "Train_MaxReturn : 31.373775482177734\n",
            "Train_MinReturn : -64.21414184570312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1110000\n",
            "TimeSinceStart : 1216.4181542396545\n",
            "Training Loss : -1369.209716796875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.043057441711426\n",
            "Eval_StdReturn : 7.051297187805176\n",
            "Eval_MaxReturn : -1.898122787475586\n",
            "Eval_MinReturn : -19.059188842773438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.658411979675293\n",
            "Train_StdReturn : 17.086889266967773\n",
            "Train_MaxReturn : 30.22223472595215\n",
            "Train_MinReturn : -74.2760009765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1140000\n",
            "TimeSinceStart : 1248.9616348743439\n",
            "Training Loss : -1198.7222900390625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -10.852660179138184\n",
            "Eval_StdReturn : 4.94727087020874\n",
            "Eval_MaxReturn : -5.896712303161621\n",
            "Eval_MinReturn : -17.607568740844727\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.618399620056152\n",
            "Train_StdReturn : 15.855561256408691\n",
            "Train_MaxReturn : 29.668163299560547\n",
            "Train_MinReturn : -58.588260650634766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1170000\n",
            "TimeSinceStart : 1281.589108467102\n",
            "Training Loss : -1083.641357421875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.608774185180664\n",
            "Eval_StdReturn : 9.801450729370117\n",
            "Eval_MaxReturn : -12.056661605834961\n",
            "Eval_MinReturn : -34.90630340576172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.83859634399414\n",
            "Train_StdReturn : 15.903190612792969\n",
            "Train_MaxReturn : 40.758365631103516\n",
            "Train_MinReturn : -84.60020446777344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1200000\n",
            "TimeSinceStart : 1314.3007209300995\n",
            "Training Loss : -755.4013671875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.786401748657227\n",
            "Eval_StdReturn : 2.735670328140259\n",
            "Eval_MaxReturn : -4.500097751617432\n",
            "Eval_MinReturn : -11.197601318359375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -8.052604675292969\n",
            "Train_StdReturn : 16.6746883392334\n",
            "Train_MaxReturn : 26.876676559448242\n",
            "Train_MinReturn : -85.03334045410156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1230000\n",
            "TimeSinceStart : 1347.0848333835602\n",
            "Training Loss : -100.32879638671875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.06940460205078\n",
            "Eval_StdReturn : 6.3894944190979\n",
            "Eval_MaxReturn : -8.477919578552246\n",
            "Eval_MinReturn : -23.789657592773438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -4.763493537902832\n",
            "Train_StdReturn : 15.410737991333008\n",
            "Train_MaxReturn : 30.00821876525879\n",
            "Train_MinReturn : -55.27644729614258\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1260000\n",
            "TimeSinceStart : 1380.212718963623\n",
            "Training Loss : -686.647705078125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -2.2694356441497803\n",
            "Eval_StdReturn : 24.381847381591797\n",
            "Eval_MaxReturn : 29.32114601135254\n",
            "Eval_MinReturn : -30.032939910888672\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -5.787195205688477\n",
            "Train_StdReturn : 16.426950454711914\n",
            "Train_MaxReturn : 33.777339935302734\n",
            "Train_MinReturn : -68.16542053222656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1290000\n",
            "TimeSinceStart : 1412.7517530918121\n",
            "Training Loss : -451.9935302734375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.699794769287109\n",
            "Eval_StdReturn : 12.687479019165039\n",
            "Eval_MaxReturn : 9.628389358520508\n",
            "Eval_MinReturn : -20.396095275878906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -5.319515228271484\n",
            "Train_StdReturn : 15.722308158874512\n",
            "Train_MaxReturn : 36.46635818481445\n",
            "Train_MinReturn : -68.4854507446289\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1320000\n",
            "TimeSinceStart : 1445.2036139965057\n",
            "Training Loss : -305.59320068359375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -3.666024923324585\n",
            "Eval_StdReturn : 16.301332473754883\n",
            "Eval_MaxReturn : 9.774614334106445\n",
            "Eval_MinReturn : -26.607074737548828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -4.550142288208008\n",
            "Train_StdReturn : 14.3374662399292\n",
            "Train_MaxReturn : 32.35928726196289\n",
            "Train_MinReturn : -39.08235168457031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1350000\n",
            "TimeSinceStart : 1477.8414425849915\n",
            "Training Loss : -493.752685546875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.000237941741943\n",
            "Eval_StdReturn : 10.884586334228516\n",
            "Eval_MaxReturn : 5.12786865234375\n",
            "Eval_MinReturn : -21.27362060546875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -4.103071212768555\n",
            "Train_StdReturn : 15.623626708984375\n",
            "Train_MaxReturn : 31.145465850830078\n",
            "Train_MinReturn : -47.90350341796875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1380000\n",
            "TimeSinceStart : 1510.3860230445862\n",
            "Training Loss : 192.647705078125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 0.7897433638572693\n",
            "Eval_StdReturn : 8.51058578491211\n",
            "Eval_MaxReturn : 12.10746955871582\n",
            "Eval_MinReturn : -8.415512084960938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -3.745316743850708\n",
            "Train_StdReturn : 14.815417289733887\n",
            "Train_MaxReturn : 38.19083786010742\n",
            "Train_MinReturn : -44.7789421081543\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1410000\n",
            "TimeSinceStart : 1542.9035568237305\n",
            "Training Loss : -373.45526123046875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.010859489440918\n",
            "Eval_StdReturn : 5.692514419555664\n",
            "Eval_MaxReturn : 17.339916229248047\n",
            "Eval_MinReturn : 3.4617557525634766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -3.524275541305542\n",
            "Train_StdReturn : 15.377147674560547\n",
            "Train_MaxReturn : 31.485464096069336\n",
            "Train_MinReturn : -59.51126480102539\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1440000\n",
            "TimeSinceStart : 1575.6441452503204\n",
            "Training Loss : -376.346435546875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.931415557861328\n",
            "Eval_StdReturn : 13.560426712036133\n",
            "Eval_MaxReturn : 33.69666290283203\n",
            "Eval_MinReturn : 2.1243386268615723\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -2.184187650680542\n",
            "Train_StdReturn : 16.70867919921875\n",
            "Train_MaxReturn : 35.44709777832031\n",
            "Train_MinReturn : -92.73173522949219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1470000\n",
            "TimeSinceStart : 1608.4411787986755\n",
            "Training Loss : -666.6395874023438\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 0.9199149012565613\n",
            "Eval_StdReturn : 13.485597610473633\n",
            "Eval_MaxReturn : 19.392311096191406\n",
            "Eval_MinReturn : -12.423585891723633\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -1.1460096836090088\n",
            "Train_StdReturn : 16.24527931213379\n",
            "Train_MaxReturn : 35.590797424316406\n",
            "Train_MinReturn : -71.87083435058594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1500000\n",
            "TimeSinceStart : 1641.1354222297668\n",
            "Training Loss : -423.0885009765625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.9153470993042\n",
            "Eval_StdReturn : 19.48630142211914\n",
            "Eval_MaxReturn : 0.4305342435836792\n",
            "Eval_MinReturn : -41.46525192260742\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.6343188285827637\n",
            "Train_StdReturn : 15.495491981506348\n",
            "Train_MaxReturn : 36.86473083496094\n",
            "Train_MinReturn : -56.041282653808594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1530000\n",
            "TimeSinceStart : 1673.9831936359406\n",
            "Training Loss : -104.8221435546875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.616800546646118\n",
            "Eval_StdReturn : 15.876483917236328\n",
            "Eval_MaxReturn : 25.522754669189453\n",
            "Eval_MinReturn : -11.601264953613281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 1.6239683628082275\n",
            "Train_StdReturn : 17.144243240356445\n",
            "Train_MaxReturn : 49.41046142578125\n",
            "Train_MinReturn : -57.20105743408203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1560000\n",
            "TimeSinceStart : 1706.590235710144\n",
            "Training Loss : 91.46926879882812\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.783931255340576\n",
            "Eval_StdReturn : 11.589953422546387\n",
            "Eval_MaxReturn : 4.283607482910156\n",
            "Eval_MinReturn : -23.42350196838379\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -2.837115526199341\n",
            "Train_StdReturn : 16.638280868530273\n",
            "Train_MaxReturn : 33.52363967895508\n",
            "Train_MinReturn : -62.25825881958008\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1590000\n",
            "TimeSinceStart : 1739.481098651886\n",
            "Training Loss : -915.7220458984375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.640777587890625\n",
            "Eval_StdReturn : 10.70954418182373\n",
            "Eval_MaxReturn : -19.400310516357422\n",
            "Eval_MinReturn : -45.629608154296875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -8.203182220458984\n",
            "Train_StdReturn : 20.970497131347656\n",
            "Train_MaxReturn : 37.724098205566406\n",
            "Train_MinReturn : -100.19281005859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1620000\n",
            "TimeSinceStart : 1772.1699833869934\n",
            "Training Loss : -222.1900634765625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -10.651298522949219\n",
            "Eval_StdReturn : 31.043807983398438\n",
            "Eval_MaxReturn : 27.66020965576172\n",
            "Eval_MinReturn : -48.374446868896484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.583505630493164\n",
            "Train_StdReturn : 20.85968017578125\n",
            "Train_MaxReturn : 40.978614807128906\n",
            "Train_MinReturn : -75.06401824951172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1650000\n",
            "TimeSinceStart : 1804.7614696025848\n",
            "Training Loss : -731.35400390625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.845184326171875\n",
            "Eval_StdReturn : 18.455537796020508\n",
            "Eval_MaxReturn : 1.2187714576721191\n",
            "Eval_MinReturn : -43.629581451416016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.394905090332031\n",
            "Train_StdReturn : 26.883398056030273\n",
            "Train_MaxReturn : 85.57240295410156\n",
            "Train_MinReturn : -115.32440948486328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1680000\n",
            "TimeSinceStart : 1836.9795308113098\n",
            "Training Loss : -644.307373046875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -5.351642608642578\n",
            "Eval_StdReturn : 13.594724655151367\n",
            "Eval_MaxReturn : 13.072380065917969\n",
            "Eval_MinReturn : -19.32194709777832\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.158357620239258\n",
            "Train_StdReturn : 25.89716148376465\n",
            "Train_MaxReturn : 38.699947357177734\n",
            "Train_MinReturn : -158.85789489746094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1710000\n",
            "TimeSinceStart : 1869.288016319275\n",
            "Training Loss : 400.61468505859375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.88694190979004\n",
            "Eval_StdReturn : 15.34616470336914\n",
            "Eval_MaxReturn : -8.847719192504883\n",
            "Eval_MinReturn : -45.0185432434082\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.415538787841797\n",
            "Train_StdReturn : 25.766864776611328\n",
            "Train_MaxReturn : 42.80398941040039\n",
            "Train_MinReturn : -140.2986602783203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1740000\n",
            "TimeSinceStart : 1901.5828695297241\n",
            "Training Loss : -743.4990844726562\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -6.7170090675354\n",
            "Eval_StdReturn : 4.870096683502197\n",
            "Eval_MaxReturn : -0.09096169471740723\n",
            "Eval_MinReturn : -11.657418251037598\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.565996170043945\n",
            "Train_StdReturn : 25.044588088989258\n",
            "Train_MaxReturn : 27.25326156616211\n",
            "Train_MinReturn : -100.48650360107422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1770000\n",
            "TimeSinceStart : 1933.848578453064\n",
            "Training Loss : -843.4906005859375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.3168830871582\n",
            "Eval_StdReturn : 15.087431907653809\n",
            "Eval_MaxReturn : -28.461692810058594\n",
            "Eval_MinReturn : -62.49249267578125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.4883918762207\n",
            "Train_StdReturn : 28.39911651611328\n",
            "Train_MaxReturn : 30.029224395751953\n",
            "Train_MinReturn : -184.74057006835938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1800000\n",
            "TimeSinceStart : 1966.411060810089\n",
            "Training Loss : -484.98590087890625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.883487701416016\n",
            "Eval_StdReturn : 17.5531005859375\n",
            "Eval_MaxReturn : -16.668136596679688\n",
            "Eval_MinReturn : -57.72187805175781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.72785568237305\n",
            "Train_StdReturn : 19.72771644592285\n",
            "Train_MaxReturn : 6.685481071472168\n",
            "Train_MinReturn : -101.90829467773438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1830000\n",
            "TimeSinceStart : 1998.7946870326996\n",
            "Training Loss : -61.1370849609375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.32453536987305\n",
            "Eval_StdReturn : 44.03556442260742\n",
            "Eval_MaxReturn : -9.891395568847656\n",
            "Eval_MinReturn : -115.48090362548828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.17325210571289\n",
            "Train_StdReturn : 18.72486114501953\n",
            "Train_MaxReturn : 3.3415231704711914\n",
            "Train_MinReturn : -145.79563903808594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1860000\n",
            "TimeSinceStart : 2031.3543791770935\n",
            "Training Loss : -411.01123046875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.948448181152344\n",
            "Eval_StdReturn : 16.574819564819336\n",
            "Eval_MaxReturn : -5.721621990203857\n",
            "Eval_MinReturn : -43.99542236328125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.46318435668945\n",
            "Train_StdReturn : 20.833168029785156\n",
            "Train_MaxReturn : 16.0020751953125\n",
            "Train_MinReturn : -140.5732879638672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1890000\n",
            "TimeSinceStart : 2063.881117105484\n",
            "Training Loss : -546.1707763671875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.6085205078125\n",
            "Eval_StdReturn : 25.412092208862305\n",
            "Eval_MaxReturn : 20.893354415893555\n",
            "Eval_MinReturn : -40.623558044433594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.122421264648438\n",
            "Train_StdReturn : 24.378480911254883\n",
            "Train_MaxReturn : 17.564123153686523\n",
            "Train_MinReturn : -114.23886108398438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1920000\n",
            "TimeSinceStart : 2096.3070783615112\n",
            "Training Loss : -682.9437255859375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.279739379882812\n",
            "Eval_StdReturn : 12.659576416015625\n",
            "Eval_MaxReturn : 21.460418701171875\n",
            "Eval_MinReturn : -5.621636390686035\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.668305397033691\n",
            "Train_StdReturn : 20.713136672973633\n",
            "Train_MaxReturn : 27.50295639038086\n",
            "Train_MinReturn : -82.56588745117188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1950000\n",
            "TimeSinceStart : 2128.702079296112\n",
            "Training Loss : -348.2711181640625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.402484893798828\n",
            "Eval_StdReturn : 28.444564819335938\n",
            "Eval_MaxReturn : 38.59934997558594\n",
            "Eval_MinReturn : -31.041812896728516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -6.034867763519287\n",
            "Train_StdReturn : 25.337724685668945\n",
            "Train_MaxReturn : 68.61702728271484\n",
            "Train_MinReturn : -87.41653442382812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1980000\n",
            "TimeSinceStart : 2161.053320646286\n",
            "Training Loss : -514.0430908203125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.45713996887207\n",
            "Eval_StdReturn : 14.886256217956543\n",
            "Eval_MaxReturn : 41.88285446166992\n",
            "Eval_MinReturn : 5.840429306030273\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.974580764770508\n",
            "Train_StdReturn : 28.287569046020508\n",
            "Train_MaxReturn : 84.79402160644531\n",
            "Train_MinReturn : -98.78959655761719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2010000\n",
            "TimeSinceStart : 2193.3161220550537\n",
            "Training Loss : -700.8839111328125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.570168495178223\n",
            "Eval_StdReturn : 6.022716045379639\n",
            "Eval_MaxReturn : 18.99827003479004\n",
            "Eval_MinReturn : 5.290760040283203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 6.260208606719971\n",
            "Train_StdReturn : 30.243518829345703\n",
            "Train_MaxReturn : 66.86309051513672\n",
            "Train_MinReturn : -105.00653076171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2040000\n",
            "TimeSinceStart : 2225.687366247177\n",
            "Training Loss : -1101.52392578125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 55.88875198364258\n",
            "Eval_StdReturn : 26.974884033203125\n",
            "Eval_MaxReturn : 86.81659698486328\n",
            "Eval_MinReturn : 21.083995819091797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 10.978755950927734\n",
            "Train_StdReturn : 37.3500862121582\n",
            "Train_MaxReturn : 91.72129821777344\n",
            "Train_MinReturn : -140.71173095703125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2070000\n",
            "TimeSinceStart : 2258.219869852066\n",
            "Training Loss : -680.159912109375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 35.21480941772461\n",
            "Eval_StdReturn : 43.904937744140625\n",
            "Eval_MaxReturn : 78.12448120117188\n",
            "Eval_MinReturn : -25.105636596679688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 14.115484237670898\n",
            "Train_StdReturn : 38.288082122802734\n",
            "Train_MaxReturn : 102.33152770996094\n",
            "Train_MinReturn : -104.00814819335938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2100000\n",
            "TimeSinceStart : 2290.5446469783783\n",
            "Training Loss : -755.7008666992188\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -81.1126708984375\n",
            "Eval_StdReturn : 49.071502685546875\n",
            "Eval_MaxReturn : -26.986530303955078\n",
            "Eval_MinReturn : -145.7894287109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 9.830804824829102\n",
            "Train_StdReturn : 34.27183532714844\n",
            "Train_MaxReturn : 90.87551879882812\n",
            "Train_MinReturn : -82.70673370361328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2130000\n",
            "TimeSinceStart : 2322.841592311859\n",
            "Training Loss : -351.0238037109375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 39.91471481323242\n",
            "Eval_StdReturn : 43.17485809326172\n",
            "Eval_MaxReturn : 95.39251708984375\n",
            "Eval_MinReturn : -9.909526824951172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 10.686858177185059\n",
            "Train_StdReturn : 38.522666931152344\n",
            "Train_MaxReturn : 104.82424926757812\n",
            "Train_MinReturn : -110.49922180175781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2160000\n",
            "TimeSinceStart : 2354.970683813095\n",
            "Training Loss : -1000.198974609375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 15.247997283935547\n",
            "Eval_StdReturn : 15.847476959228516\n",
            "Eval_MaxReturn : 36.955421447753906\n",
            "Eval_MinReturn : -0.4331984519958496\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.117187738418579\n",
            "Train_StdReturn : 37.198856353759766\n",
            "Train_MaxReturn : 134.7926025390625\n",
            "Train_MinReturn : -80.564453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2190000\n",
            "TimeSinceStart : 2387.232654571533\n",
            "Training Loss : -702.6779174804688\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.133135795593262\n",
            "Eval_StdReturn : 8.006489753723145\n",
            "Eval_MaxReturn : 19.28582763671875\n",
            "Eval_MinReturn : -0.2846336364746094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.6842589378356934\n",
            "Train_StdReturn : 35.12501525878906\n",
            "Train_MaxReturn : 96.195068359375\n",
            "Train_MinReturn : -126.22493743896484\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2220000\n",
            "TimeSinceStart : 2419.555276155472\n",
            "Training Loss : -595.6754150390625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.73692512512207\n",
            "Eval_StdReturn : 20.851835250854492\n",
            "Eval_MaxReturn : 7.630056381225586\n",
            "Eval_MinReturn : -43.44292449951172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.8989973664283752\n",
            "Train_StdReturn : 32.6328239440918\n",
            "Train_MaxReturn : 99.10213470458984\n",
            "Train_MinReturn : -89.99989318847656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2250000\n",
            "TimeSinceStart : 2451.927999973297\n",
            "Training Loss : -843.133056640625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.569869518280029\n",
            "Eval_StdReturn : 22.34151840209961\n",
            "Eval_MaxReturn : 22.272476196289062\n",
            "Eval_MinReturn : -32.424739837646484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.1528567522764206\n",
            "Train_StdReturn : 27.9403076171875\n",
            "Train_MaxReturn : 82.19804382324219\n",
            "Train_MinReturn : -90.99760437011719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2280000\n",
            "TimeSinceStart : 2484.4128398895264\n",
            "Training Loss : -354.58245849609375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.53661060333252\n",
            "Eval_StdReturn : 11.331615447998047\n",
            "Eval_MaxReturn : 2.584691047668457\n",
            "Eval_MinReturn : -24.692684173583984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 3.4127395153045654\n",
            "Train_StdReturn : 29.775978088378906\n",
            "Train_MaxReturn : 83.76190185546875\n",
            "Train_MinReturn : -90.05364990234375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2310000\n",
            "TimeSinceStart : 2516.822370529175\n",
            "Training Loss : -673.323974609375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 17.84446144104004\n",
            "Eval_StdReturn : 14.00915241241455\n",
            "Eval_MaxReturn : 37.31064987182617\n",
            "Eval_MinReturn : 4.919952392578125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 11.638274192810059\n",
            "Train_StdReturn : 28.817907333374023\n",
            "Train_MaxReturn : 78.39356994628906\n",
            "Train_MinReturn : -85.82698059082031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2340000\n",
            "TimeSinceStart : 2549.1067864894867\n",
            "Training Loss : -729.7727661132812\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.975695610046387\n",
            "Eval_StdReturn : 6.58283805847168\n",
            "Eval_MaxReturn : 19.276885986328125\n",
            "Eval_MinReturn : 4.983737945556641\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 14.348503112792969\n",
            "Train_StdReturn : 22.017589569091797\n",
            "Train_MaxReturn : 92.69097900390625\n",
            "Train_MinReturn : -35.81899642944336\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2370000\n",
            "TimeSinceStart : 2581.678424835205\n",
            "Training Loss : -677.6007080078125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 46.20332717895508\n",
            "Eval_StdReturn : 7.8307061195373535\n",
            "Eval_MaxReturn : 56.197654724121094\n",
            "Eval_MinReturn : 37.0751838684082\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 22.282609939575195\n",
            "Train_StdReturn : 23.047578811645508\n",
            "Train_MaxReturn : 94.53468322753906\n",
            "Train_MinReturn : -45.23420333862305\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2400000\n",
            "TimeSinceStart : 2614.4136872291565\n",
            "Training Loss : -1056.114990234375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.134495735168457\n",
            "Eval_StdReturn : 24.97364616394043\n",
            "Eval_MaxReturn : 49.0657958984375\n",
            "Eval_MinReturn : -7.845327377319336\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 22.501367568969727\n",
            "Train_StdReturn : 27.030025482177734\n",
            "Train_MaxReturn : 91.786865234375\n",
            "Train_MinReturn : -58.05079650878906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2430000\n",
            "TimeSinceStart : 2647.0034790039062\n",
            "Training Loss : -752.09765625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.519064426422119\n",
            "Eval_StdReturn : 31.529541015625\n",
            "Eval_MaxReturn : 49.66020965576172\n",
            "Eval_MinReturn : -24.813640594482422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 14.800512313842773\n",
            "Train_StdReturn : 29.55007553100586\n",
            "Train_MaxReturn : 91.24137878417969\n",
            "Train_MinReturn : -96.74603271484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2460000\n",
            "TimeSinceStart : 2679.86572432518\n",
            "Training Loss : -561.1677856445312\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.658290386199951\n",
            "Eval_StdReturn : 20.815229415893555\n",
            "Eval_MaxReturn : 23.46660041809082\n",
            "Eval_MinReturn : -26.247594833374023\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 9.306490898132324\n",
            "Train_StdReturn : 34.33188247680664\n",
            "Train_MaxReturn : 88.6221923828125\n",
            "Train_MinReturn : -144.95156860351562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2490000\n",
            "TimeSinceStart : 2712.8128447532654\n",
            "Training Loss : -378.4925537109375\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.260795593261719\n",
            "Eval_StdReturn : 12.735573768615723\n",
            "Eval_MaxReturn : 16.425073623657227\n",
            "Eval_MinReturn : -11.697983741760254\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 4.071938991546631\n",
            "Train_StdReturn : 34.48493576049805\n",
            "Train_MaxReturn : 121.93685913085938\n",
            "Train_MinReturn : -152.55577087402344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2520000\n",
            "TimeSinceStart : 2745.853977203369\n",
            "Training Loss : -770.5382080078125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.004426956176758\n",
            "Eval_StdReturn : 19.902555465698242\n",
            "Eval_MaxReturn : 42.36915588378906\n",
            "Eval_MinReturn : -6.269652366638184\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 12.382319450378418\n",
            "Train_StdReturn : 32.18696212768555\n",
            "Train_MaxReturn : 90.65771484375\n",
            "Train_MinReturn : -111.77841186523438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2550000\n",
            "TimeSinceStart : 2778.87295627594\n",
            "Training Loss : -147.5860595703125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.79225730895996\n",
            "Eval_StdReturn : 25.386445999145508\n",
            "Eval_MaxReturn : 38.50520706176758\n",
            "Eval_MinReturn : -18.8254451751709\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 16.816211700439453\n",
            "Train_StdReturn : 30.494915008544922\n",
            "Train_MaxReturn : 82.18496704101562\n",
            "Train_MinReturn : -92.14083862304688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2580000\n",
            "TimeSinceStart : 2812.079312801361\n",
            "Training Loss : -445.97088623046875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.54806137084961\n",
            "Eval_StdReturn : 35.34446334838867\n",
            "Eval_MaxReturn : 61.77934265136719\n",
            "Eval_MinReturn : -23.236248016357422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 20.732501983642578\n",
            "Train_StdReturn : 22.81316566467285\n",
            "Train_MaxReturn : 79.80115509033203\n",
            "Train_MinReturn : -103.8593521118164\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2610000\n",
            "TimeSinceStart : 2844.9460487365723\n",
            "Training Loss : -550.7232666015625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 30.177871704101562\n",
            "Eval_StdReturn : 16.631412506103516\n",
            "Eval_MaxReturn : 45.20964050292969\n",
            "Eval_MinReturn : 6.995456218719482\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 22.075979232788086\n",
            "Train_StdReturn : 22.920185089111328\n",
            "Train_MaxReturn : 83.60691833496094\n",
            "Train_MinReturn : -76.49696350097656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2640000\n",
            "TimeSinceStart : 2878.0802252292633\n",
            "Training Loss : -1072.02392578125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 47.775814056396484\n",
            "Eval_StdReturn : 10.183799743652344\n",
            "Eval_MaxReturn : 57.90156555175781\n",
            "Eval_MinReturn : 33.84352111816406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 24.063459396362305\n",
            "Train_StdReturn : 19.528488159179688\n",
            "Train_MaxReturn : 74.412353515625\n",
            "Train_MinReturn : -51.12956619262695\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2670000\n",
            "TimeSinceStart : 2910.9818184375763\n",
            "Training Loss : -967.5753173828125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 51.032711029052734\n",
            "Eval_StdReturn : 5.463066101074219\n",
            "Eval_MaxReturn : 56.499332427978516\n",
            "Eval_MinReturn : 43.571327209472656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 38.54277038574219\n",
            "Train_StdReturn : 21.480411529541016\n",
            "Train_MaxReturn : 82.93792724609375\n",
            "Train_MinReturn : -64.45487213134766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2700000\n",
            "TimeSinceStart : 2943.730948448181\n",
            "Training Loss : -995.3184814453125\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.5530879497528076\n",
            "Eval_StdReturn : 44.36345291137695\n",
            "Eval_MaxReturn : 64.0656967163086\n",
            "Eval_MinReturn : -41.0504150390625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 33.53455352783203\n",
            "Train_StdReturn : 28.4735050201416\n",
            "Train_MaxReturn : 105.01872253417969\n",
            "Train_MinReturn : -62.89965057373047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2730000\n",
            "TimeSinceStart : 2976.1621704101562\n",
            "Training Loss : -732.2098999023438\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 43.29489517211914\n",
            "Eval_StdReturn : 67.94454956054688\n",
            "Eval_MaxReturn : 100.37495422363281\n",
            "Eval_MinReturn : -52.186092376708984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 29.64291000366211\n",
            "Train_StdReturn : 33.03919219970703\n",
            "Train_MaxReturn : 131.2587127685547\n",
            "Train_MinReturn : -112.87228393554688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2760000\n",
            "TimeSinceStart : 3008.5822324752808\n",
            "Training Loss : -608.4498291015625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 45.114315032958984\n",
            "Eval_StdReturn : 26.313419342041016\n",
            "Eval_MaxReturn : 65.00133514404297\n",
            "Eval_MinReturn : 7.931610107421875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 28.706518173217773\n",
            "Train_StdReturn : 30.838260650634766\n",
            "Train_MaxReturn : 101.9124755859375\n",
            "Train_MinReturn : -73.29192352294922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2790000\n",
            "TimeSinceStart : 3041.138940811157\n",
            "Training Loss : -383.1695556640625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 46.691070556640625\n",
            "Eval_StdReturn : 6.411863803863525\n",
            "Eval_MaxReturn : 55.41505813598633\n",
            "Eval_MinReturn : 40.187339782714844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 39.29075622558594\n",
            "Train_StdReturn : 32.833282470703125\n",
            "Train_MaxReturn : 105.85211944580078\n",
            "Train_MinReturn : -117.36595153808594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2820000\n",
            "TimeSinceStart : 3073.496803045273\n",
            "Training Loss : -1014.6817016601562\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 23.342864990234375\n",
            "Eval_StdReturn : 14.185233116149902\n",
            "Eval_MaxReturn : 41.26167297363281\n",
            "Eval_MinReturn : 6.572025299072266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 43.057674407958984\n",
            "Train_StdReturn : 28.692848205566406\n",
            "Train_MaxReturn : 111.86500549316406\n",
            "Train_MinReturn : -74.38228607177734\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2850000\n",
            "TimeSinceStart : 3106.048403263092\n",
            "Training Loss : -942.0914916992188\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 46.45492935180664\n",
            "Eval_StdReturn : 16.649425506591797\n",
            "Eval_MaxReturn : 61.42317199707031\n",
            "Eval_MinReturn : 23.230134963989258\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 47.3753547668457\n",
            "Train_StdReturn : 27.75344467163086\n",
            "Train_MaxReturn : 129.05401611328125\n",
            "Train_MinReturn : -69.0012435913086\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2880000\n",
            "TimeSinceStart : 3138.5935821533203\n",
            "Training Loss : -307.6874084472656\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.108028411865234\n",
            "Eval_StdReturn : 6.12148380279541\n",
            "Eval_MaxReturn : 23.412212371826172\n",
            "Eval_MinReturn : 8.431571006774902\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 35.7681884765625\n",
            "Train_StdReturn : 27.093502044677734\n",
            "Train_MaxReturn : 183.2486572265625\n",
            "Train_MinReturn : -54.93608093261719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2910000\n",
            "TimeSinceStart : 3171.1914718151093\n",
            "Training Loss : -741.36572265625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 36.42197799682617\n",
            "Eval_StdReturn : 4.231130599975586\n",
            "Eval_MaxReturn : 41.23385238647461\n",
            "Eval_MinReturn : 30.93576431274414\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 39.007301330566406\n",
            "Train_StdReturn : 23.77665138244629\n",
            "Train_MaxReturn : 100.93302154541016\n",
            "Train_MinReturn : -73.47250366210938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2940000\n",
            "TimeSinceStart : 3203.772151708603\n",
            "Training Loss : -703.98388671875\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 53.313751220703125\n",
            "Eval_StdReturn : 19.18641471862793\n",
            "Eval_MaxReturn : 76.17698669433594\n",
            "Eval_MinReturn : 29.22780418395996\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 36.122032165527344\n",
            "Train_StdReturn : 24.429771423339844\n",
            "Train_MaxReturn : 97.7309341430664\n",
            "Train_MinReturn : -44.06062316894531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2970000\n",
            "TimeSinceStart : 3236.1929655075073\n",
            "Training Loss : -874.5601806640625\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 53.248966217041016\n",
            "Eval_StdReturn : 15.7883939743042\n",
            "Eval_MaxReturn : 74.21723937988281\n",
            "Eval_MinReturn : 36.119625091552734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 46.48646926879883\n",
            "Train_StdReturn : 24.472593307495117\n",
            "Train_MaxReturn : 90.10575103759766\n",
            "Train_MinReturn : -106.71661376953125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3000000\n",
            "TimeSinceStart : 3268.901206970215\n",
            "Training Loss : -875.3782348632812\n",
            "Initial_DataCollection_AverageReturn : -88.56880950927734\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "    --discount 0.95 -n 100 -l 2 -s 32 \\\n",
        "    -b 30000 -lr 0.02 -rtg --nn_baseline \\\n",
        "    --exp_name q4_search_b30000_lr0.02_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90rmvl6sPR5s",
        "outputId": "b2061a5f-ff95-405e-c7b0-5469d4063048"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q4_search_b50000_lr0.005_rtg_nnbaseline_HalfCheetah-v2_09-05-2022_08-58-53\n",
            "########################\n",
            "GPU not detected. Defaulting to CPU.\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -52.9120979309082\n",
            "Eval_StdReturn : 24.43634033203125\n",
            "Eval_MaxReturn : -19.707246780395508\n",
            "Eval_MinReturn : -77.80792236328125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -94.41527557373047\n",
            "Train_StdReturn : 38.59808349609375\n",
            "Train_MaxReturn : 1.7286391258239746\n",
            "Train_MinReturn : -216.81167602539062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50100\n",
            "TimeSinceStart : 40.09913444519043\n",
            "Training Loss : -3808.248779296875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -52.652069091796875\n",
            "Eval_StdReturn : 58.77749252319336\n",
            "Eval_MaxReturn : 19.986604690551758\n",
            "Eval_MinReturn : -123.9700927734375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -88.31709289550781\n",
            "Train_StdReturn : 33.91155242919922\n",
            "Train_MaxReturn : 1.1934089660644531\n",
            "Train_MinReturn : -201.56727600097656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100200\n",
            "TimeSinceStart : 79.2652382850647\n",
            "Training Loss : -4126.42138671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -72.82946014404297\n",
            "Eval_StdReturn : 3.900024652481079\n",
            "Eval_MaxReturn : -69.60298919677734\n",
            "Eval_MinReturn : -78.3166732788086\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -79.55107116699219\n",
            "Train_StdReturn : 35.823856353759766\n",
            "Train_MaxReturn : 44.015708923339844\n",
            "Train_MinReturn : -205.9536590576172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150300\n",
            "TimeSinceStart : 117.9823145866394\n",
            "Training Loss : -3319.597412109375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -72.43268585205078\n",
            "Eval_StdReturn : 16.9796199798584\n",
            "Eval_MaxReturn : -48.776145935058594\n",
            "Eval_MinReturn : -87.82989501953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -77.10327911376953\n",
            "Train_StdReturn : 33.3291130065918\n",
            "Train_MaxReturn : 35.92866134643555\n",
            "Train_MinReturn : -217.0353240966797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 200400\n",
            "TimeSinceStart : 156.7367126941681\n",
            "Training Loss : -3882.90087890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -79.5766830444336\n",
            "Eval_StdReturn : 55.07866287231445\n",
            "Eval_MaxReturn : -39.563323974609375\n",
            "Eval_MinReturn : -157.4598388671875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -76.9053726196289\n",
            "Train_StdReturn : 35.532962799072266\n",
            "Train_MaxReturn : 30.499134063720703\n",
            "Train_MinReturn : -204.53302001953125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 250500\n",
            "TimeSinceStart : 195.6405119895935\n",
            "Training Loss : -4448.14794921875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -81.31754302978516\n",
            "Eval_StdReturn : 31.038925170898438\n",
            "Eval_MaxReturn : -48.0093994140625\n",
            "Eval_MinReturn : -122.7314224243164\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -74.14556884765625\n",
            "Train_StdReturn : 32.33907699584961\n",
            "Train_MaxReturn : 39.19268798828125\n",
            "Train_MinReturn : -179.429931640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300600\n",
            "TimeSinceStart : 234.61565566062927\n",
            "Training Loss : -3545.762939453125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -81.93335723876953\n",
            "Eval_StdReturn : 8.658771514892578\n",
            "Eval_MaxReturn : -70.57980346679688\n",
            "Eval_MinReturn : -91.58305358886719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -67.83637237548828\n",
            "Train_StdReturn : 32.73727798461914\n",
            "Train_MaxReturn : 36.569725036621094\n",
            "Train_MinReturn : -187.85911560058594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 350700\n",
            "TimeSinceStart : 273.356703042984\n",
            "Training Loss : -4223.18603515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -102.48465728759766\n",
            "Eval_StdReturn : 23.29939079284668\n",
            "Eval_MaxReturn : -70.37418365478516\n",
            "Eval_MinReturn : -124.94149780273438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -72.12311553955078\n",
            "Train_StdReturn : 31.052885055541992\n",
            "Train_MaxReturn : 3.615398406982422\n",
            "Train_MinReturn : -190.0909423828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 400800\n",
            "TimeSinceStart : 312.71299862861633\n",
            "Training Loss : -4013.346435546875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -72.52899169921875\n",
            "Eval_StdReturn : 36.45890426635742\n",
            "Eval_MaxReturn : -28.65234375\n",
            "Eval_MinReturn : -117.9195556640625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -68.5211181640625\n",
            "Train_StdReturn : 31.29218101501465\n",
            "Train_MaxReturn : 19.329395294189453\n",
            "Train_MinReturn : -175.31431579589844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450900\n",
            "TimeSinceStart : 351.6236689090729\n",
            "Training Loss : -4040.912841796875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -81.55093383789062\n",
            "Eval_StdReturn : 23.870075225830078\n",
            "Eval_MaxReturn : -50.925514221191406\n",
            "Eval_MinReturn : -109.16134643554688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -69.74372100830078\n",
            "Train_StdReturn : 31.128000259399414\n",
            "Train_MaxReturn : 10.144510269165039\n",
            "Train_MinReturn : -218.96258544921875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 501000\n",
            "TimeSinceStart : 390.5117037296295\n",
            "Training Loss : -3525.7265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.06650924682617\n",
            "Eval_StdReturn : 23.314462661743164\n",
            "Eval_MaxReturn : -11.882441520690918\n",
            "Eval_MinReturn : -66.36222076416016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -67.45170593261719\n",
            "Train_StdReturn : 30.711759567260742\n",
            "Train_MaxReturn : 13.96535873413086\n",
            "Train_MinReturn : -195.39898681640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 551100\n",
            "TimeSinceStart : 429.11453580856323\n",
            "Training Loss : -2936.630615234375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -76.99747467041016\n",
            "Eval_StdReturn : 36.263648986816406\n",
            "Eval_MaxReturn : -33.991119384765625\n",
            "Eval_MinReturn : -122.69607543945312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -68.05754852294922\n",
            "Train_StdReturn : 30.809688568115234\n",
            "Train_MaxReturn : 15.761171340942383\n",
            "Train_MinReturn : -184.14376831054688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 601200\n",
            "TimeSinceStart : 467.8949189186096\n",
            "Training Loss : -3762.46630859375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -67.53327178955078\n",
            "Eval_StdReturn : 21.350109100341797\n",
            "Eval_MaxReturn : -44.720375061035156\n",
            "Eval_MinReturn : -96.0692138671875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -67.51760864257812\n",
            "Train_StdReturn : 30.412811279296875\n",
            "Train_MaxReturn : 10.929341316223145\n",
            "Train_MinReturn : -169.34579467773438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 651300\n",
            "TimeSinceStart : 506.57046914100647\n",
            "Training Loss : -4216.724609375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -95.43563079833984\n",
            "Eval_StdReturn : 25.9345760345459\n",
            "Eval_MaxReturn : -66.17947387695312\n",
            "Eval_MinReturn : -129.21994018554688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -62.184810638427734\n",
            "Train_StdReturn : 27.17772102355957\n",
            "Train_MaxReturn : 21.87770652770996\n",
            "Train_MinReturn : -163.33612060546875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 701400\n",
            "TimeSinceStart : 545.4099185466766\n",
            "Training Loss : -4111.0830078125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.67698287963867\n",
            "Eval_StdReturn : 25.065242767333984\n",
            "Eval_MaxReturn : -13.014688491821289\n",
            "Eval_MinReturn : -71.43415832519531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -61.54680633544922\n",
            "Train_StdReturn : 28.971275329589844\n",
            "Train_MaxReturn : 24.074481964111328\n",
            "Train_MinReturn : -158.34640502929688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 751500\n",
            "TimeSinceStart : 584.5769169330597\n",
            "Training Loss : -3329.62109375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -64.2468490600586\n",
            "Eval_StdReturn : 21.281269073486328\n",
            "Eval_MaxReturn : -37.69923782348633\n",
            "Eval_MinReturn : -89.79896545410156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -63.80617904663086\n",
            "Train_StdReturn : 29.335100173950195\n",
            "Train_MaxReturn : 20.972578048706055\n",
            "Train_MinReturn : -224.7916259765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 801600\n",
            "TimeSinceStart : 623.6306655406952\n",
            "Training Loss : -3517.27294921875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.99824523925781\n",
            "Eval_StdReturn : 3.8137364387512207\n",
            "Eval_MaxReturn : -45.18303680419922\n",
            "Eval_MinReturn : -54.50994110107422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -59.0704460144043\n",
            "Train_StdReturn : 29.208696365356445\n",
            "Train_MaxReturn : 12.227216720581055\n",
            "Train_MinReturn : -162.40322875976562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 851700\n",
            "TimeSinceStart : 662.5826396942139\n",
            "Training Loss : -4067.537109375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.292728424072266\n",
            "Eval_StdReturn : 26.464616775512695\n",
            "Eval_MaxReturn : -11.190011978149414\n",
            "Eval_MinReturn : -75.22392272949219\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -57.89344787597656\n",
            "Train_StdReturn : 26.742095947265625\n",
            "Train_MaxReturn : 24.087129592895508\n",
            "Train_MinReturn : -131.82919311523438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 901800\n",
            "TimeSinceStart : 701.6831166744232\n",
            "Training Loss : -3924.3603515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.395503997802734\n",
            "Eval_StdReturn : 25.6920223236084\n",
            "Eval_MaxReturn : -10.611392974853516\n",
            "Eval_MinReturn : -72.86751556396484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -58.69964599609375\n",
            "Train_StdReturn : 26.92157554626465\n",
            "Train_MaxReturn : 17.67109489440918\n",
            "Train_MinReturn : -191.57284545898438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 951900\n",
            "TimeSinceStart : 740.7263264656067\n",
            "Training Loss : -4270.25732421875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -65.58187103271484\n",
            "Eval_StdReturn : 54.157569885253906\n",
            "Eval_MaxReturn : -17.903274536132812\n",
            "Eval_MinReturn : -141.33096313476562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -58.51121520996094\n",
            "Train_StdReturn : 27.828020095825195\n",
            "Train_MaxReturn : 12.473587989807129\n",
            "Train_MinReturn : -157.03579711914062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1002000\n",
            "TimeSinceStart : 779.9538352489471\n",
            "Training Loss : -3778.087158203125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.92810821533203\n",
            "Eval_StdReturn : 16.265933990478516\n",
            "Eval_MaxReturn : -18.950918197631836\n",
            "Eval_MinReturn : -54.369354248046875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -56.56034851074219\n",
            "Train_StdReturn : 24.801027297973633\n",
            "Train_MaxReturn : -0.18859004974365234\n",
            "Train_MinReturn : -148.49679565429688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1052100\n",
            "TimeSinceStart : 818.6760067939758\n",
            "Training Loss : -3678.18359375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -63.5759391784668\n",
            "Eval_StdReturn : 20.66868019104004\n",
            "Eval_MaxReturn : -44.632225036621094\n",
            "Eval_MinReturn : -92.32584381103516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -55.22190856933594\n",
            "Train_StdReturn : 29.003150939941406\n",
            "Train_MaxReturn : 29.248014450073242\n",
            "Train_MinReturn : -169.81396484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1102200\n",
            "TimeSinceStart : 857.6090357303619\n",
            "Training Loss : -3679.01513671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -58.319427490234375\n",
            "Eval_StdReturn : 10.278704643249512\n",
            "Eval_MaxReturn : -44.06938934326172\n",
            "Eval_MinReturn : -67.93040466308594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -56.07796859741211\n",
            "Train_StdReturn : 30.46297264099121\n",
            "Train_MaxReturn : 22.455717086791992\n",
            "Train_MinReturn : -188.8422393798828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1152300\n",
            "TimeSinceStart : 896.8972091674805\n",
            "Training Loss : -3376.625732421875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -57.07989501953125\n",
            "Eval_StdReturn : 9.99288272857666\n",
            "Eval_MaxReturn : -42.94883346557617\n",
            "Eval_MinReturn : -64.29154205322266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -52.93537139892578\n",
            "Train_StdReturn : 28.698442459106445\n",
            "Train_MaxReturn : 33.1595344543457\n",
            "Train_MinReturn : -164.43603515625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1202400\n",
            "TimeSinceStart : 935.7424128055573\n",
            "Training Loss : -3261.7373046875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -78.74910736083984\n",
            "Eval_StdReturn : 48.77894973754883\n",
            "Eval_MaxReturn : -35.82661437988281\n",
            "Eval_MinReturn : -146.97918701171875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -52.76441955566406\n",
            "Train_StdReturn : 28.465408325195312\n",
            "Train_MaxReturn : 43.794044494628906\n",
            "Train_MinReturn : -139.43612670898438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1252500\n",
            "TimeSinceStart : 974.5471706390381\n",
            "Training Loss : -2497.085693359375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.53700828552246\n",
            "Eval_StdReturn : 29.486602783203125\n",
            "Eval_MaxReturn : -1.3246407508850098\n",
            "Eval_MinReturn : -69.50749206542969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.91728973388672\n",
            "Train_StdReturn : 29.911415100097656\n",
            "Train_MaxReturn : 33.952392578125\n",
            "Train_MinReturn : -175.52645874023438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1302600\n",
            "TimeSinceStart : 1013.3713600635529\n",
            "Training Loss : -3021.54150390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -58.26202392578125\n",
            "Eval_StdReturn : 17.25572395324707\n",
            "Eval_MaxReturn : -35.23557662963867\n",
            "Eval_MinReturn : -76.77361297607422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.92892837524414\n",
            "Train_StdReturn : 27.119400024414062\n",
            "Train_MaxReturn : 24.11281967163086\n",
            "Train_MinReturn : -152.38519287109375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1352700\n",
            "TimeSinceStart : 1052.2995789051056\n",
            "Training Loss : -3756.794921875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -71.29425811767578\n",
            "Eval_StdReturn : 30.70677375793457\n",
            "Eval_MaxReturn : -44.46405029296875\n",
            "Eval_MinReturn : -114.28069305419922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.904296875\n",
            "Train_StdReturn : 27.73744773864746\n",
            "Train_MaxReturn : 9.043802261352539\n",
            "Train_MinReturn : -153.54611206054688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1402800\n",
            "TimeSinceStart : 1091.361503124237\n",
            "Training Loss : -3660.8193359375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.822635650634766\n",
            "Eval_StdReturn : 3.5583624839782715\n",
            "Eval_MaxReturn : -30.591978073120117\n",
            "Eval_MinReturn : -39.2978515625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.209041595458984\n",
            "Train_StdReturn : 27.336368560791016\n",
            "Train_MaxReturn : 12.647491455078125\n",
            "Train_MinReturn : -157.9425506591797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1452900\n",
            "TimeSinceStart : 1130.1343667507172\n",
            "Training Loss : -2324.2392578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.84783935546875\n",
            "Eval_StdReturn : 16.094003677368164\n",
            "Eval_MaxReturn : -27.046876907348633\n",
            "Eval_MinReturn : -61.602943420410156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.90279006958008\n",
            "Train_StdReturn : 24.807947158813477\n",
            "Train_MaxReturn : 46.159000396728516\n",
            "Train_MinReturn : -152.26675415039062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1503000\n",
            "TimeSinceStart : 1169.1271181106567\n",
            "Training Loss : -2990.93603515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.370641708374023\n",
            "Eval_StdReturn : 12.63772201538086\n",
            "Eval_MaxReturn : -17.837078094482422\n",
            "Eval_MinReturn : -48.246826171875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.34849166870117\n",
            "Train_StdReturn : 27.283403396606445\n",
            "Train_MaxReturn : 20.174150466918945\n",
            "Train_MinReturn : -148.48643493652344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1553100\n",
            "TimeSinceStart : 1208.503181695938\n",
            "Training Loss : -2827.353271484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -59.6416015625\n",
            "Eval_StdReturn : 16.434558868408203\n",
            "Eval_MaxReturn : -36.43894958496094\n",
            "Eval_MinReturn : -72.41327667236328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.856876373291016\n",
            "Train_StdReturn : 26.327421188354492\n",
            "Train_MaxReturn : 39.71812438964844\n",
            "Train_MinReturn : -131.70388793945312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1603200\n",
            "TimeSinceStart : 1247.0697906017303\n",
            "Training Loss : -3417.48681640625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -57.59230422973633\n",
            "Eval_StdReturn : 10.413076400756836\n",
            "Eval_MaxReturn : -47.08750915527344\n",
            "Eval_MinReturn : -71.78255462646484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.51350021362305\n",
            "Train_StdReturn : 25.26155662536621\n",
            "Train_MaxReturn : 64.84381866455078\n",
            "Train_MinReturn : -144.53404235839844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1653300\n",
            "TimeSinceStart : 1285.9499180316925\n",
            "Training Loss : -3039.309814453125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -51.17482376098633\n",
            "Eval_StdReturn : 3.74981689453125\n",
            "Eval_MaxReturn : -46.630653381347656\n",
            "Eval_MinReturn : -55.814308166503906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -47.22564697265625\n",
            "Train_StdReturn : 24.739606857299805\n",
            "Train_MaxReturn : 16.566986083984375\n",
            "Train_MinReturn : -126.68789672851562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1703400\n",
            "TimeSinceStart : 1325.0481185913086\n",
            "Training Loss : -3018.4365234375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.18027877807617\n",
            "Eval_StdReturn : 20.529882431030273\n",
            "Eval_MaxReturn : -19.66590118408203\n",
            "Eval_MinReturn : -69.93649291992188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.09437561035156\n",
            "Train_StdReturn : 24.535633087158203\n",
            "Train_MaxReturn : 20.764848709106445\n",
            "Train_MinReturn : -160.6091766357422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1753500\n",
            "TimeSinceStart : 1363.896490573883\n",
            "Training Loss : -3202.146484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -63.70756912231445\n",
            "Eval_StdReturn : 12.924782752990723\n",
            "Eval_MaxReturn : -52.41162872314453\n",
            "Eval_MinReturn : -81.80047607421875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.87892532348633\n",
            "Train_StdReturn : 25.114770889282227\n",
            "Train_MaxReturn : 17.51734733581543\n",
            "Train_MinReturn : -145.16578674316406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1803600\n",
            "TimeSinceStart : 1403.0316333770752\n",
            "Training Loss : -2400.530517578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.08470153808594\n",
            "Eval_StdReturn : 5.947081089019775\n",
            "Eval_MaxReturn : -52.88727951049805\n",
            "Eval_MinReturn : -66.81233215332031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.63077926635742\n",
            "Train_StdReturn : 24.961750030517578\n",
            "Train_MaxReturn : 19.53616714477539\n",
            "Train_MinReturn : -152.852783203125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1853700\n",
            "TimeSinceStart : 1442.0418314933777\n",
            "Training Loss : -2623.54541015625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.240570068359375\n",
            "Eval_StdReturn : 16.7204532623291\n",
            "Eval_MaxReturn : -8.018954277038574\n",
            "Eval_MinReturn : -46.52259826660156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.574974060058594\n",
            "Train_StdReturn : 23.41075897216797\n",
            "Train_MaxReturn : 26.05626678466797\n",
            "Train_MinReturn : -141.39276123046875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1903800\n",
            "TimeSinceStart : 1481.0249691009521\n",
            "Training Loss : -3145.9443359375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.557199478149414\n",
            "Eval_StdReturn : 2.5717132091522217\n",
            "Eval_MaxReturn : -24.877471923828125\n",
            "Eval_MinReturn : -31.02658462524414\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.9640998840332\n",
            "Train_StdReturn : 25.14365577697754\n",
            "Train_MaxReturn : 30.710033416748047\n",
            "Train_MinReturn : -160.45474243164062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1953900\n",
            "TimeSinceStart : 1520.144057750702\n",
            "Training Loss : -2590.552001953125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.43037986755371\n",
            "Eval_StdReturn : 32.17146301269531\n",
            "Eval_MaxReturn : 15.774703979492188\n",
            "Eval_MinReturn : -62.92878723144531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.3044319152832\n",
            "Train_StdReturn : 24.1823787689209\n",
            "Train_MaxReturn : 66.10413360595703\n",
            "Train_MinReturn : -112.28591918945312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2004000\n",
            "TimeSinceStart : 1558.944326877594\n",
            "Training Loss : -2371.530517578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.45452880859375\n",
            "Eval_StdReturn : 5.308116436004639\n",
            "Eval_MaxReturn : -39.64390563964844\n",
            "Eval_MinReturn : -52.594017028808594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -42.66539001464844\n",
            "Train_StdReturn : 26.789501190185547\n",
            "Train_MaxReturn : 56.24699401855469\n",
            "Train_MinReturn : -166.13275146484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2054100\n",
            "TimeSinceStart : 1597.7929451465607\n",
            "Training Loss : -3200.545654296875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.09954833984375\n",
            "Eval_StdReturn : 11.55968189239502\n",
            "Eval_MaxReturn : -40.3736572265625\n",
            "Eval_MinReturn : -67.83052062988281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.472537994384766\n",
            "Train_StdReturn : 23.0386905670166\n",
            "Train_MaxReturn : 66.70228576660156\n",
            "Train_MinReturn : -125.80892944335938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2104200\n",
            "TimeSinceStart : 1636.698781967163\n",
            "Training Loss : -3389.4931640625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.899505615234375\n",
            "Eval_StdReturn : 10.680866241455078\n",
            "Eval_MaxReturn : -38.20280838012695\n",
            "Eval_MinReturn : -62.77790451049805\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.94590377807617\n",
            "Train_StdReturn : 26.3968563079834\n",
            "Train_MaxReturn : 59.51639175415039\n",
            "Train_MinReturn : -153.31187438964844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2154300\n",
            "TimeSinceStart : 1675.6683695316315\n",
            "Training Loss : -2196.39013671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.48689651489258\n",
            "Eval_StdReturn : 8.99409294128418\n",
            "Eval_MaxReturn : -21.20305633544922\n",
            "Eval_MinReturn : -43.21278762817383\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.954349517822266\n",
            "Train_StdReturn : 25.969709396362305\n",
            "Train_MaxReturn : 25.023006439208984\n",
            "Train_MinReturn : -146.81484985351562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2204400\n",
            "TimeSinceStart : 1714.7004902362823\n",
            "Training Loss : -2909.210205078125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.491823673248291\n",
            "Eval_StdReturn : 18.082962036132812\n",
            "Eval_MaxReturn : 12.747664451599121\n",
            "Eval_MinReturn : -31.149019241333008\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.013221740722656\n",
            "Train_StdReturn : 24.567655563354492\n",
            "Train_MaxReturn : 37.74085235595703\n",
            "Train_MinReturn : -145.81390380859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2254500\n",
            "TimeSinceStart : 1753.4129316806793\n",
            "Training Loss : -2669.5595703125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.24920082092285\n",
            "Eval_StdReturn : 18.58681869506836\n",
            "Eval_MaxReturn : -5.986017227172852\n",
            "Eval_MinReturn : -51.479042053222656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.49580001831055\n",
            "Train_StdReturn : 26.679244995117188\n",
            "Train_MaxReturn : 63.16952896118164\n",
            "Train_MinReturn : -148.35220336914062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2304600\n",
            "TimeSinceStart : 1792.4720754623413\n",
            "Training Loss : -3015.15576171875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.49702453613281\n",
            "Eval_StdReturn : 25.877473831176758\n",
            "Eval_MaxReturn : -22.664897918701172\n",
            "Eval_MinReturn : -82.46485900878906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.712284088134766\n",
            "Train_StdReturn : 24.7459659576416\n",
            "Train_MaxReturn : 40.99127197265625\n",
            "Train_MinReturn : -124.5197982788086\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2354700\n",
            "TimeSinceStart : 1831.390280008316\n",
            "Training Loss : -2931.297607421875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.711814880371094\n",
            "Eval_StdReturn : 11.750105857849121\n",
            "Eval_MaxReturn : -28.272613525390625\n",
            "Eval_MinReturn : -54.27513122558594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.579647064208984\n",
            "Train_StdReturn : 22.989036560058594\n",
            "Train_MaxReturn : 42.45683288574219\n",
            "Train_MinReturn : -164.56048583984375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2404800\n",
            "TimeSinceStart : 1870.175657749176\n",
            "Training Loss : -3145.83251953125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.304479598999023\n",
            "Eval_StdReturn : 19.741561889648438\n",
            "Eval_MaxReturn : 0.14613109827041626\n",
            "Eval_MinReturn : -46.37479019165039\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.764827728271484\n",
            "Train_StdReturn : 22.715662002563477\n",
            "Train_MaxReturn : 48.791908264160156\n",
            "Train_MinReturn : -112.02166748046875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2454900\n",
            "TimeSinceStart : 1908.8957815170288\n",
            "Training Loss : -2335.914306640625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.20777893066406\n",
            "Eval_StdReturn : 15.41024112701416\n",
            "Eval_MaxReturn : -24.080181121826172\n",
            "Eval_MinReturn : -60.35760498046875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.934818267822266\n",
            "Train_StdReturn : 24.512611389160156\n",
            "Train_MaxReturn : 25.135517120361328\n",
            "Train_MinReturn : -156.3231201171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2505000\n",
            "TimeSinceStart : 1948.169217824936\n",
            "Training Loss : -2377.5859375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.4495849609375\n",
            "Eval_StdReturn : 26.06696128845215\n",
            "Eval_MaxReturn : 6.5608320236206055\n",
            "Eval_MinReturn : -56.77138137817383\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.53740692138672\n",
            "Train_StdReturn : 26.061901092529297\n",
            "Train_MaxReturn : 49.764892578125\n",
            "Train_MinReturn : -145.44134521484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2555100\n",
            "TimeSinceStart : 1987.1442708969116\n",
            "Training Loss : -2589.505615234375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -57.2404670715332\n",
            "Eval_StdReturn : 4.9413886070251465\n",
            "Eval_MaxReturn : -50.277496337890625\n",
            "Eval_MinReturn : -61.23550796508789\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.06437683105469\n",
            "Train_StdReturn : 22.73406982421875\n",
            "Train_MaxReturn : 32.35001754760742\n",
            "Train_MinReturn : -129.11497497558594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2605200\n",
            "TimeSinceStart : 2026.1869032382965\n",
            "Training Loss : -2563.535400390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.628488540649414\n",
            "Eval_StdReturn : 13.708747863769531\n",
            "Eval_MaxReturn : -2.2500314712524414\n",
            "Eval_MinReturn : -31.81892967224121\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.005462646484375\n",
            "Train_StdReturn : 24.223848342895508\n",
            "Train_MaxReturn : 33.07923889160156\n",
            "Train_MinReturn : -137.54922485351562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2655300\n",
            "TimeSinceStart : 2065.23682308197\n",
            "Training Loss : -2125.479736328125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -66.46051788330078\n",
            "Eval_StdReturn : 13.68850326538086\n",
            "Eval_MaxReturn : -47.112220764160156\n",
            "Eval_MinReturn : -76.6779556274414\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.14302635192871\n",
            "Train_StdReturn : 23.89571189880371\n",
            "Train_MaxReturn : 40.631927490234375\n",
            "Train_MinReturn : -120.78092956542969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2705400\n",
            "TimeSinceStart : 2104.227417945862\n",
            "Training Loss : -2004.0736083984375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.662460327148438\n",
            "Eval_StdReturn : 5.4136271476745605\n",
            "Eval_MaxReturn : -21.460094451904297\n",
            "Eval_MinReturn : -34.1280632019043\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.52716827392578\n",
            "Train_StdReturn : 23.460264205932617\n",
            "Train_MaxReturn : 41.5218505859375\n",
            "Train_MinReturn : -138.18505859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2755500\n",
            "TimeSinceStart : 2143.044730424881\n",
            "Training Loss : -2095.218017578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.04494285583496\n",
            "Eval_StdReturn : 34.106170654296875\n",
            "Eval_MaxReturn : 14.983259201049805\n",
            "Eval_MinReturn : -68.36470031738281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.5301456451416\n",
            "Train_StdReturn : 21.93170928955078\n",
            "Train_MaxReturn : 40.630104064941406\n",
            "Train_MinReturn : -127.40782165527344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2805600\n",
            "TimeSinceStart : 2182.1598172187805\n",
            "Training Loss : -1774.7733154296875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.025131225585938\n",
            "Eval_StdReturn : 4.713944911956787\n",
            "Eval_MaxReturn : -16.376367568969727\n",
            "Eval_MinReturn : -26.77065086364746\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.900922775268555\n",
            "Train_StdReturn : 20.85110855102539\n",
            "Train_MaxReturn : 47.88966369628906\n",
            "Train_MinReturn : -141.51901245117188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2855700\n",
            "TimeSinceStart : 2221.120973587036\n",
            "Training Loss : -1233.850341796875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.38249588012695\n",
            "Eval_StdReturn : 8.178436279296875\n",
            "Eval_MaxReturn : -26.875797271728516\n",
            "Eval_MinReturn : -45.14933395385742\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.172542572021484\n",
            "Train_StdReturn : 21.042343139648438\n",
            "Train_MaxReturn : 29.689603805541992\n",
            "Train_MinReturn : -97.07466125488281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2905800\n",
            "TimeSinceStart : 2260.229864835739\n",
            "Training Loss : -2509.991455078125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.859601974487305\n",
            "Eval_StdReturn : 12.070651054382324\n",
            "Eval_MaxReturn : -7.342243671417236\n",
            "Eval_MinReturn : -36.1700325012207\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.647811889648438\n",
            "Train_StdReturn : 22.855527877807617\n",
            "Train_MaxReturn : 39.352142333984375\n",
            "Train_MinReturn : -115.355224609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2955900\n",
            "TimeSinceStart : 2299.680469751358\n",
            "Training Loss : -1464.512939453125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.82720375061035\n",
            "Eval_StdReturn : 22.016145706176758\n",
            "Eval_MaxReturn : -0.6264100074768066\n",
            "Eval_MinReturn : -52.175025939941406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.614042282104492\n",
            "Train_StdReturn : 21.81731605529785\n",
            "Train_MaxReturn : 25.694229125976562\n",
            "Train_MinReturn : -99.30073547363281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3006000\n",
            "TimeSinceStart : 2338.7541613578796\n",
            "Training Loss : -2157.310791015625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.816938400268555\n",
            "Eval_StdReturn : 17.427520751953125\n",
            "Eval_MaxReturn : 0.3168172836303711\n",
            "Eval_MinReturn : -41.339019775390625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.60148048400879\n",
            "Train_StdReturn : 23.044179916381836\n",
            "Train_MaxReturn : 39.36295700073242\n",
            "Train_MinReturn : -105.5772476196289\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3056100\n",
            "TimeSinceStart : 2377.740962743759\n",
            "Training Loss : -1946.757080078125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.447834968566895\n",
            "Eval_StdReturn : 11.303387641906738\n",
            "Eval_MaxReturn : -0.1799602508544922\n",
            "Eval_MinReturn : -27.824420928955078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.910974502563477\n",
            "Train_StdReturn : 22.131555557250977\n",
            "Train_MaxReturn : 41.41762924194336\n",
            "Train_MinReturn : -107.22753143310547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3106200\n",
            "TimeSinceStart : 2416.8011622428894\n",
            "Training Loss : -1962.9349365234375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.03580856323242\n",
            "Eval_StdReturn : 23.47295570373535\n",
            "Eval_MaxReturn : -2.426250457763672\n",
            "Eval_MinReturn : -56.71942901611328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.30709457397461\n",
            "Train_StdReturn : 21.595354080200195\n",
            "Train_MaxReturn : 70.6677474975586\n",
            "Train_MinReturn : -89.30317687988281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3156300\n",
            "TimeSinceStart : 2455.582397222519\n",
            "Training Loss : -2447.1728515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.449106216430664\n",
            "Eval_StdReturn : 8.101430892944336\n",
            "Eval_MaxReturn : -12.016449928283691\n",
            "Eval_MinReturn : -31.79735565185547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.661312103271484\n",
            "Train_StdReturn : 22.237934112548828\n",
            "Train_MaxReturn : 48.58095932006836\n",
            "Train_MinReturn : -143.4041290283203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3206400\n",
            "TimeSinceStart : 2494.4205877780914\n",
            "Training Loss : -1749.267333984375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.028440475463867\n",
            "Eval_StdReturn : 10.815872192382812\n",
            "Eval_MaxReturn : -15.687493324279785\n",
            "Eval_MinReturn : -41.806251525878906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.87640953063965\n",
            "Train_StdReturn : 21.123998641967773\n",
            "Train_MaxReturn : 36.70256042480469\n",
            "Train_MinReturn : -106.82551574707031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3256500\n",
            "TimeSinceStart : 2533.1621766090393\n",
            "Training Loss : -1847.55517578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.428593635559082\n",
            "Eval_StdReturn : 9.040495872497559\n",
            "Eval_MaxReturn : -5.180592060089111\n",
            "Eval_MinReturn : -25.173763275146484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.97628402709961\n",
            "Train_StdReturn : 20.447765350341797\n",
            "Train_MaxReturn : 38.920989990234375\n",
            "Train_MinReturn : -118.88948059082031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3306600\n",
            "TimeSinceStart : 2571.965035200119\n",
            "Training Loss : -1778.2996826171875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.547114372253418\n",
            "Eval_StdReturn : 11.624485969543457\n",
            "Eval_MaxReturn : -0.4888134002685547\n",
            "Eval_MinReturn : -28.253095626831055\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.03392219543457\n",
            "Train_StdReturn : 19.922122955322266\n",
            "Train_MaxReturn : 47.11823272705078\n",
            "Train_MinReturn : -115.60293579101562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3356700\n",
            "TimeSinceStart : 2610.865263223648\n",
            "Training Loss : -1903.6490478515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.804821014404297\n",
            "Eval_StdReturn : 18.04936981201172\n",
            "Eval_MaxReturn : -0.741541862487793\n",
            "Eval_MinReturn : -43.45561981201172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.995983123779297\n",
            "Train_StdReturn : 17.984907150268555\n",
            "Train_MaxReturn : 28.481115341186523\n",
            "Train_MinReturn : -80.10845184326172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3406800\n",
            "TimeSinceStart : 2649.6296203136444\n",
            "Training Loss : -2058.059814453125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.06413459777832\n",
            "Eval_StdReturn : 19.448291778564453\n",
            "Eval_MaxReturn : -0.627941906452179\n",
            "Eval_MinReturn : -48.21422576904297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.042097091674805\n",
            "Train_StdReturn : 18.76910400390625\n",
            "Train_MaxReturn : 35.32352828979492\n",
            "Train_MinReturn : -81.96610260009766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3456900\n",
            "TimeSinceStart : 2689.157162666321\n",
            "Training Loss : -2658.242919921875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.29876136779785\n",
            "Eval_StdReturn : 4.230231761932373\n",
            "Eval_MaxReturn : -17.43355369567871\n",
            "Eval_MinReturn : -27.252044677734375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.70062255859375\n",
            "Train_StdReturn : 21.051393508911133\n",
            "Train_MaxReturn : 49.81981658935547\n",
            "Train_MinReturn : -86.58642578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3507000\n",
            "TimeSinceStart : 2728.2422971725464\n",
            "Training Loss : -1671.72705078125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.60357093811035\n",
            "Eval_StdReturn : 13.268284797668457\n",
            "Eval_MaxReturn : -6.574061393737793\n",
            "Eval_MinReturn : -38.84748077392578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.807518005371094\n",
            "Train_StdReturn : 20.346647262573242\n",
            "Train_MaxReturn : 24.447097778320312\n",
            "Train_MinReturn : -144.09854125976562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3557100\n",
            "TimeSinceStart : 2767.296781539917\n",
            "Training Loss : -1893.2847900390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.18403434753418\n",
            "Eval_StdReturn : 11.18356704711914\n",
            "Eval_MaxReturn : -15.259765625\n",
            "Eval_MinReturn : -42.641883850097656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.483840942382812\n",
            "Train_StdReturn : 20.70842742919922\n",
            "Train_MaxReturn : 37.89944839477539\n",
            "Train_MinReturn : -137.2437744140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3607200\n",
            "TimeSinceStart : 2806.295016527176\n",
            "Training Loss : -1405.6339111328125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.389063835144043\n",
            "Eval_StdReturn : 10.730944633483887\n",
            "Eval_MaxReturn : 2.7799453735351562\n",
            "Eval_MinReturn : -20.368059158325195\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.791547775268555\n",
            "Train_StdReturn : 20.52190589904785\n",
            "Train_MaxReturn : 58.181060791015625\n",
            "Train_MinReturn : -87.60670471191406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3657300\n",
            "TimeSinceStart : 2845.83918261528\n",
            "Training Loss : -1408.276611328125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.61747932434082\n",
            "Eval_StdReturn : 9.814345359802246\n",
            "Eval_MaxReturn : -4.063999176025391\n",
            "Eval_MinReturn : -26.984481811523438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.271982192993164\n",
            "Train_StdReturn : 17.16750717163086\n",
            "Train_MaxReturn : 32.897216796875\n",
            "Train_MinReturn : -74.80786895751953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3707400\n",
            "TimeSinceStart : 2884.930559396744\n",
            "Training Loss : -1391.3065185546875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.239650249481201\n",
            "Eval_StdReturn : 17.433563232421875\n",
            "Eval_MaxReturn : 18.728181838989258\n",
            "Eval_MinReturn : -23.48582649230957\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.265663146972656\n",
            "Train_StdReturn : 17.671085357666016\n",
            "Train_MaxReturn : 30.97699546813965\n",
            "Train_MinReturn : -112.18345642089844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3757500\n",
            "TimeSinceStart : 2923.970860719681\n",
            "Training Loss : -2129.068603515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.685808181762695\n",
            "Eval_StdReturn : 8.101375579833984\n",
            "Eval_MaxReturn : -10.51052474975586\n",
            "Eval_MinReturn : -29.008752822875977\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.516498565673828\n",
            "Train_StdReturn : 18.999549865722656\n",
            "Train_MaxReturn : 44.254554748535156\n",
            "Train_MinReturn : -111.33160400390625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3807600\n",
            "TimeSinceStart : 2963.4775009155273\n",
            "Training Loss : -2213.458251953125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.83182716369629\n",
            "Eval_StdReturn : 4.103494644165039\n",
            "Eval_MaxReturn : -23.527484893798828\n",
            "Eval_MinReturn : -33.52261734008789\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.504600524902344\n",
            "Train_StdReturn : 16.801895141601562\n",
            "Train_MaxReturn : 26.883737564086914\n",
            "Train_MinReturn : -80.57025146484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3857700\n",
            "TimeSinceStart : 3002.5266013145447\n",
            "Training Loss : -1588.4510498046875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.529197692871094\n",
            "Eval_StdReturn : 9.769394874572754\n",
            "Eval_MaxReturn : -18.63384246826172\n",
            "Eval_MinReturn : -42.27151870727539\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.53273582458496\n",
            "Train_StdReturn : 16.27505874633789\n",
            "Train_MaxReturn : 25.25921630859375\n",
            "Train_MinReturn : -64.6329116821289\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3907800\n",
            "TimeSinceStart : 3041.3390991687775\n",
            "Training Loss : -1494.6654052734375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.475282669067383\n",
            "Eval_StdReturn : 17.774126052856445\n",
            "Eval_MaxReturn : 0.23948192596435547\n",
            "Eval_MinReturn : -43.16365432739258\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.667634963989258\n",
            "Train_StdReturn : 16.023778915405273\n",
            "Train_MaxReturn : 34.103633880615234\n",
            "Train_MinReturn : -69.74111938476562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3957900\n",
            "TimeSinceStart : 3080.138142347336\n",
            "Training Loss : -1905.6114501953125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.675146102905273\n",
            "Eval_StdReturn : 9.846219062805176\n",
            "Eval_MaxReturn : -21.46040916442871\n",
            "Eval_MinReturn : -42.59671401977539\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.190364837646484\n",
            "Train_StdReturn : 16.313766479492188\n",
            "Train_MaxReturn : 30.11992645263672\n",
            "Train_MinReturn : -72.37648010253906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4008000\n",
            "TimeSinceStart : 3119.5928795337677\n",
            "Training Loss : -1821.54150390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.030088424682617\n",
            "Eval_StdReturn : 5.587477207183838\n",
            "Eval_MaxReturn : -13.156760215759277\n",
            "Eval_MinReturn : -26.84282684326172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.83738136291504\n",
            "Train_StdReturn : 15.110204696655273\n",
            "Train_MaxReturn : 28.993896484375\n",
            "Train_MinReturn : -72.96076965332031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4058100\n",
            "TimeSinceStart : 3158.576804637909\n",
            "Training Loss : -1885.3973388671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.10484313964844\n",
            "Eval_StdReturn : 3.4701266288757324\n",
            "Eval_MaxReturn : -32.23046112060547\n",
            "Eval_MinReturn : -40.65058517456055\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.61478042602539\n",
            "Train_StdReturn : 14.692031860351562\n",
            "Train_MaxReturn : 26.13095474243164\n",
            "Train_MinReturn : -72.19633483886719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4108200\n",
            "TimeSinceStart : 3197.8398694992065\n",
            "Training Loss : -1374.859375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.587727546691895\n",
            "Eval_StdReturn : 24.72554588317871\n",
            "Eval_MaxReturn : 12.901473999023438\n",
            "Eval_MinReturn : -46.60024642944336\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.7718505859375\n",
            "Train_StdReturn : 14.426816940307617\n",
            "Train_MaxReturn : 20.592304229736328\n",
            "Train_MinReturn : -62.43999481201172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4158300\n",
            "TimeSinceStart : 3237.0286808013916\n",
            "Training Loss : -2251.095458984375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.726449012756348\n",
            "Eval_StdReturn : 3.907477617263794\n",
            "Eval_MaxReturn : -5.198200225830078\n",
            "Eval_MinReturn : -14.733527183532715\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.965511322021484\n",
            "Train_StdReturn : 14.709177017211914\n",
            "Train_MaxReturn : 26.594350814819336\n",
            "Train_MinReturn : -63.52361297607422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4208400\n",
            "TimeSinceStart : 3276.2442905902863\n",
            "Training Loss : -2496.957763671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.897790908813477\n",
            "Eval_StdReturn : 8.450702667236328\n",
            "Eval_MaxReturn : -12.054892539978027\n",
            "Eval_MinReturn : -31.208791732788086\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.633739471435547\n",
            "Train_StdReturn : 15.311416625976562\n",
            "Train_MaxReturn : 27.6385498046875\n",
            "Train_MinReturn : -80.40383911132812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4258500\n",
            "TimeSinceStart : 3315.3580179214478\n",
            "Training Loss : -1579.89892578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.889965057373047\n",
            "Eval_StdReturn : 7.965824604034424\n",
            "Eval_MaxReturn : -3.839298725128174\n",
            "Eval_MinReturn : -23.32206916809082\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.63545036315918\n",
            "Train_StdReturn : 15.846231460571289\n",
            "Train_MaxReturn : 23.306974411010742\n",
            "Train_MinReturn : -78.53607940673828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4308600\n",
            "TimeSinceStart : 3354.649531364441\n",
            "Training Loss : -2082.0908203125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.126449584960938\n",
            "Eval_StdReturn : 8.638751029968262\n",
            "Eval_MaxReturn : -5.74522590637207\n",
            "Eval_MinReturn : -26.895112991333008\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.180500030517578\n",
            "Train_StdReturn : 15.132420539855957\n",
            "Train_MaxReturn : 30.42975616455078\n",
            "Train_MinReturn : -60.519569396972656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4358700\n",
            "TimeSinceStart : 3394.063285589218\n",
            "Training Loss : -1447.7318115234375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.5826416015625\n",
            "Eval_StdReturn : 8.03209400177002\n",
            "Eval_MaxReturn : -13.36568832397461\n",
            "Eval_MinReturn : -30.924217224121094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.86809539794922\n",
            "Train_StdReturn : 16.256864547729492\n",
            "Train_MaxReturn : 38.73249816894531\n",
            "Train_MinReturn : -69.00102233886719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4408800\n",
            "TimeSinceStart : 3433.4710223674774\n",
            "Training Loss : -1656.290771484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.429115295410156\n",
            "Eval_StdReturn : 14.342351913452148\n",
            "Eval_MaxReturn : 9.166744232177734\n",
            "Eval_MinReturn : -25.741321563720703\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.051307678222656\n",
            "Train_StdReturn : 15.772436141967773\n",
            "Train_MaxReturn : 32.845420837402344\n",
            "Train_MinReturn : -62.87104034423828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4458900\n",
            "TimeSinceStart : 3472.8828597068787\n",
            "Training Loss : -2081.4462890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.26759910583496\n",
            "Eval_StdReturn : 11.14610481262207\n",
            "Eval_MaxReturn : -7.598819732666016\n",
            "Eval_MinReturn : -32.59212875366211\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.810834884643555\n",
            "Train_StdReturn : 16.024160385131836\n",
            "Train_MaxReturn : 23.634723663330078\n",
            "Train_MinReturn : -71.24073791503906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4509000\n",
            "TimeSinceStart : 3511.8470652103424\n",
            "Training Loss : -1276.5833740234375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.722786903381348\n",
            "Eval_StdReturn : 14.02033805847168\n",
            "Eval_MaxReturn : 5.926394939422607\n",
            "Eval_MinReturn : -27.87925910949707\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.91331672668457\n",
            "Train_StdReturn : 16.317373275756836\n",
            "Train_MaxReturn : 44.87899398803711\n",
            "Train_MinReturn : -55.59516143798828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4559100\n",
            "TimeSinceStart : 3550.8254640102386\n",
            "Training Loss : -828.1161499023438\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.532852172851562\n",
            "Eval_StdReturn : 17.107160568237305\n",
            "Eval_MaxReturn : 2.8420047760009766\n",
            "Eval_MinReturn : -36.39720153808594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.098962783813477\n",
            "Train_StdReturn : 15.116061210632324\n",
            "Train_MaxReturn : 21.360855102539062\n",
            "Train_MinReturn : -74.68545532226562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4609200\n",
            "TimeSinceStart : 3589.9349682331085\n",
            "Training Loss : -1635.3565673828125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 0.09495655447244644\n",
            "Eval_StdReturn : 2.1847543716430664\n",
            "Eval_MaxReturn : 3.065103530883789\n",
            "Eval_MinReturn : -2.1272716522216797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.227611541748047\n",
            "Train_StdReturn : 15.565616607666016\n",
            "Train_MaxReturn : 49.621070861816406\n",
            "Train_MinReturn : -56.59305953979492\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4659300\n",
            "TimeSinceStart : 3629.172894001007\n",
            "Training Loss : -1354.9228515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.47662353515625\n",
            "Eval_StdReturn : 11.544693946838379\n",
            "Eval_MaxReturn : -2.4803810119628906\n",
            "Eval_MinReturn : -30.56531524658203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.547292709350586\n",
            "Train_StdReturn : 14.352866172790527\n",
            "Train_MaxReturn : 33.982757568359375\n",
            "Train_MinReturn : -50.09619140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4709400\n",
            "TimeSinceStart : 3668.1153457164764\n",
            "Training Loss : -1314.14404296875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -5.4715895652771\n",
            "Eval_StdReturn : 9.99418830871582\n",
            "Eval_MaxReturn : 8.057308197021484\n",
            "Eval_MinReturn : -15.778973579406738\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.856361389160156\n",
            "Train_StdReturn : 14.351541519165039\n",
            "Train_MaxReturn : 24.893508911132812\n",
            "Train_MinReturn : -59.59529113769531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4759500\n",
            "TimeSinceStart : 3707.381011724472\n",
            "Training Loss : -2216.371826171875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.018755912780762\n",
            "Eval_StdReturn : 5.044136047363281\n",
            "Eval_MaxReturn : -4.051855087280273\n",
            "Eval_MinReturn : -15.829488754272461\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.607440948486328\n",
            "Train_StdReturn : 13.914511680603027\n",
            "Train_MaxReturn : 51.19563293457031\n",
            "Train_MinReturn : -60.57727813720703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4809600\n",
            "TimeSinceStart : 3746.4581632614136\n",
            "Training Loss : -1393.1170654296875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.345476150512695\n",
            "Eval_StdReturn : 8.733800888061523\n",
            "Eval_MaxReturn : -9.227643013000488\n",
            "Eval_MinReturn : -30.12019157409668\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.42033576965332\n",
            "Train_StdReturn : 15.25599193572998\n",
            "Train_MaxReturn : 65.80750274658203\n",
            "Train_MinReturn : -53.46970748901367\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4859700\n",
            "TimeSinceStart : 3785.7613842487335\n",
            "Training Loss : -1583.284912109375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.572211265563965\n",
            "Eval_StdReturn : 9.332027435302734\n",
            "Eval_MaxReturn : -0.9620227813720703\n",
            "Eval_MinReturn : -23.811710357666016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.513219833374023\n",
            "Train_StdReturn : 14.902325630187988\n",
            "Train_MaxReturn : 29.125486373901367\n",
            "Train_MinReturn : -57.158363342285156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4909800\n",
            "TimeSinceStart : 3825.193174600601\n",
            "Training Loss : -517.36181640625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.9904597997665405\n",
            "Eval_StdReturn : 2.0821824073791504\n",
            "Eval_MaxReturn : 3.9259166717529297\n",
            "Eval_MinReturn : -0.899176836013794\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.426142692565918\n",
            "Train_StdReturn : 13.256781578063965\n",
            "Train_MaxReturn : 25.268537521362305\n",
            "Train_MinReturn : -56.763099670410156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4959900\n",
            "TimeSinceStart : 3864.3382635116577\n",
            "Training Loss : -922.1871337890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.1188383102417\n",
            "Eval_StdReturn : 14.325860977172852\n",
            "Eval_MaxReturn : 3.373347282409668\n",
            "Eval_MinReturn : -31.532550811767578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.757814407348633\n",
            "Train_StdReturn : 13.512090682983398\n",
            "Train_MaxReturn : 21.37504768371582\n",
            "Train_MinReturn : -51.11769104003906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 5010000\n",
            "TimeSinceStart : 3903.946366071701\n",
            "Training Loss : -1236.01611328125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "    --discount 0.95 -n 100 -l 2 -s 32 \\\n",
        "    -b 50000 -lr 0.005 -rtg --nn_baseline \\\n",
        "    --exp_name q4_search_b50000_lr0.005_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if1ipbIsPSAm",
        "outputId": "88455ac7-977e-4f23-bfa8-1e741bf5d7a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q4_search_b50000_lr0.01_rtg_nnbaseline_HalfCheetah-v2_09-05-2022_10-05-18\n",
            "########################\n",
            "GPU not detected. Defaulting to CPU.\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -66.41124725341797\n",
            "Eval_StdReturn : 11.789060592651367\n",
            "Eval_MaxReturn : -55.715667724609375\n",
            "Eval_MinReturn : -82.83497619628906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -94.41527557373047\n",
            "Train_StdReturn : 38.59808349609375\n",
            "Train_MaxReturn : 1.7286391258239746\n",
            "Train_MinReturn : -216.81167602539062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50100\n",
            "TimeSinceStart : 38.63108158111572\n",
            "Training Loss : -3808.248779296875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.34890365600586\n",
            "Eval_StdReturn : 31.281234741210938\n",
            "Eval_MaxReturn : 10.649177551269531\n",
            "Eval_MinReturn : -59.33543395996094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -82.53659057617188\n",
            "Train_StdReturn : 37.07838439941406\n",
            "Train_MaxReturn : 28.852083206176758\n",
            "Train_MinReturn : -209.2916259765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100200\n",
            "TimeSinceStart : 77.5998854637146\n",
            "Training Loss : -4029.22412109375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -88.24618530273438\n",
            "Eval_StdReturn : 31.862991333007812\n",
            "Eval_MaxReturn : -43.46376037597656\n",
            "Eval_MinReturn : -114.97052764892578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -72.26811981201172\n",
            "Train_StdReturn : 37.420692443847656\n",
            "Train_MaxReturn : 67.6260986328125\n",
            "Train_MinReturn : -196.6527862548828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150300\n",
            "TimeSinceStart : 116.63448476791382\n",
            "Training Loss : -3139.872802734375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -81.69808959960938\n",
            "Eval_StdReturn : 24.008445739746094\n",
            "Eval_MaxReturn : -56.165794372558594\n",
            "Eval_MinReturn : -113.8468246459961\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -75.41958618164062\n",
            "Train_StdReturn : 34.274818420410156\n",
            "Train_MaxReturn : 43.808902740478516\n",
            "Train_MinReturn : -190.25003051757812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 200400\n",
            "TimeSinceStart : 155.44743847846985\n",
            "Training Loss : -3494.91357421875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -92.14392852783203\n",
            "Eval_StdReturn : 22.790382385253906\n",
            "Eval_MaxReturn : -62.3397331237793\n",
            "Eval_MinReturn : -117.67074584960938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -70.85337829589844\n",
            "Train_StdReturn : 32.63400650024414\n",
            "Train_MaxReturn : 103.09397888183594\n",
            "Train_MinReturn : -188.93533325195312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 250500\n",
            "TimeSinceStart : 194.26851725578308\n",
            "Training Loss : -3646.240478515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -73.5213394165039\n",
            "Eval_StdReturn : 12.574352264404297\n",
            "Eval_MaxReturn : -57.62250518798828\n",
            "Eval_MinReturn : -88.36943817138672\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -70.61878204345703\n",
            "Train_StdReturn : 30.42914581298828\n",
            "Train_MaxReturn : 22.514820098876953\n",
            "Train_MinReturn : -177.10443115234375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300600\n",
            "TimeSinceStart : 232.7796642780304\n",
            "Training Loss : -3296.988525390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.63844680786133\n",
            "Eval_StdReturn : 24.1828670501709\n",
            "Eval_MaxReturn : -28.53819465637207\n",
            "Eval_MinReturn : -85.63817596435547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -68.05770874023438\n",
            "Train_StdReturn : 29.421932220458984\n",
            "Train_MaxReturn : 54.06325149536133\n",
            "Train_MinReturn : -177.089111328125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 350700\n",
            "TimeSinceStart : 271.5294699668884\n",
            "Training Loss : -3115.988525390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.86738586425781\n",
            "Eval_StdReturn : 20.43506622314453\n",
            "Eval_MaxReturn : -33.35923767089844\n",
            "Eval_MinReturn : -80.22657775878906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -67.40409088134766\n",
            "Train_StdReturn : 29.84355354309082\n",
            "Train_MaxReturn : 45.54755401611328\n",
            "Train_MinReturn : -172.2442626953125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 400800\n",
            "TimeSinceStart : 310.2281527519226\n",
            "Training Loss : -3431.007568359375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -92.88253021240234\n",
            "Eval_StdReturn : 36.04473114013672\n",
            "Eval_MaxReturn : -43.385066986083984\n",
            "Eval_MinReturn : -128.1828155517578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -65.02605438232422\n",
            "Train_StdReturn : 30.40950584411621\n",
            "Train_MaxReturn : 26.05531120300293\n",
            "Train_MinReturn : -156.41806030273438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450900\n",
            "TimeSinceStart : 349.00158619880676\n",
            "Training Loss : -3729.899169921875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.67378807067871\n",
            "Eval_StdReturn : 27.354400634765625\n",
            "Eval_MaxReturn : 6.871482849121094\n",
            "Eval_MinReturn : -53.79094696044922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -59.013946533203125\n",
            "Train_StdReturn : 30.41060447692871\n",
            "Train_MaxReturn : 75.40251922607422\n",
            "Train_MinReturn : -160.06285095214844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 501000\n",
            "TimeSinceStart : 387.7857117652893\n",
            "Training Loss : -3580.861328125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -65.27213287353516\n",
            "Eval_StdReturn : 11.747635841369629\n",
            "Eval_MaxReturn : -52.30469512939453\n",
            "Eval_MinReturn : -80.74999237060547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -59.28620910644531\n",
            "Train_StdReturn : 29.3438663482666\n",
            "Train_MaxReturn : 11.246318817138672\n",
            "Train_MinReturn : -176.3170928955078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 551100\n",
            "TimeSinceStart : 426.6331226825714\n",
            "Training Loss : -3595.738525390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -50.63692092895508\n",
            "Eval_StdReturn : 18.899831771850586\n",
            "Eval_MaxReturn : -30.91421890258789\n",
            "Eval_MinReturn : -76.12091064453125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -54.744503021240234\n",
            "Train_StdReturn : 31.571136474609375\n",
            "Train_MaxReturn : 51.88151550292969\n",
            "Train_MinReturn : -187.7779998779297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 601200\n",
            "TimeSinceStart : 465.2862901687622\n",
            "Training Loss : -3174.630126953125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.73030090332031\n",
            "Eval_StdReturn : 8.123201370239258\n",
            "Eval_MaxReturn : -38.120487213134766\n",
            "Eval_MinReturn : -57.62178039550781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -53.32553482055664\n",
            "Train_StdReturn : 25.313215255737305\n",
            "Train_MaxReturn : 16.950286865234375\n",
            "Train_MinReturn : -149.40296936035156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 651300\n",
            "TimeSinceStart : 505.56367087364197\n",
            "Training Loss : -3192.211181640625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.749298095703125\n",
            "Eval_StdReturn : 7.998973846435547\n",
            "Eval_MaxReturn : -15.557130813598633\n",
            "Eval_MinReturn : -35.09569549560547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.50874328613281\n",
            "Train_StdReturn : 27.84770965576172\n",
            "Train_MaxReturn : 30.148021697998047\n",
            "Train_MinReturn : -214.8030242919922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 701400\n",
            "TimeSinceStart : 544.4456918239594\n",
            "Training Loss : -2922.5380859375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -58.648067474365234\n",
            "Eval_StdReturn : 24.39196014404297\n",
            "Eval_MaxReturn : -39.18354797363281\n",
            "Eval_MinReturn : -93.04408264160156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -47.47113037109375\n",
            "Train_StdReturn : 25.699289321899414\n",
            "Train_MaxReturn : 15.808332443237305\n",
            "Train_MinReturn : -128.66156005859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 751500\n",
            "TimeSinceStart : 583.284576177597\n",
            "Training Loss : -3641.58984375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.2418327331543\n",
            "Eval_StdReturn : 51.52458953857422\n",
            "Eval_MaxReturn : -14.226912498474121\n",
            "Eval_MinReturn : -132.96104431152344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.761070251464844\n",
            "Train_StdReturn : 28.437654495239258\n",
            "Train_MaxReturn : 28.21128273010254\n",
            "Train_MinReturn : -186.59751892089844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 801600\n",
            "TimeSinceStart : 622.4737544059753\n",
            "Training Loss : -3098.191650390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -43.85895919799805\n",
            "Eval_StdReturn : 12.938837051391602\n",
            "Eval_MaxReturn : -26.099140167236328\n",
            "Eval_MinReturn : -56.554874420166016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.65019226074219\n",
            "Train_StdReturn : 26.532163619995117\n",
            "Train_MaxReturn : 23.03817367553711\n",
            "Train_MinReturn : -175.60260009765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 851700\n",
            "TimeSinceStart : 661.515102148056\n",
            "Training Loss : -2533.033447265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.18351364135742\n",
            "Eval_StdReturn : 11.26175594329834\n",
            "Eval_MaxReturn : -33.507511138916016\n",
            "Eval_MinReturn : -60.40202331542969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.90411376953125\n",
            "Train_StdReturn : 27.636892318725586\n",
            "Train_MaxReturn : 15.975266456604004\n",
            "Train_MinReturn : -185.87689208984375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 901800\n",
            "TimeSinceStart : 700.5707142353058\n",
            "Training Loss : -3172.83642578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.591766357421875\n",
            "Eval_StdReturn : 18.144826889038086\n",
            "Eval_MaxReturn : -21.803329467773438\n",
            "Eval_MinReturn : -66.2020263671875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.88557434082031\n",
            "Train_StdReturn : 28.060134887695312\n",
            "Train_MaxReturn : 34.2891845703125\n",
            "Train_MinReturn : -212.3350830078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 951900\n",
            "TimeSinceStart : 739.6103167533875\n",
            "Training Loss : -3367.318115234375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.40012741088867\n",
            "Eval_StdReturn : 19.941543579101562\n",
            "Eval_MaxReturn : -12.867060661315918\n",
            "Eval_MinReturn : -61.53703308105469\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.120574951171875\n",
            "Train_StdReturn : 26.854280471801758\n",
            "Train_MaxReturn : 74.76017761230469\n",
            "Train_MinReturn : -125.03785705566406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1002000\n",
            "TimeSinceStart : 778.6523411273956\n",
            "Training Loss : -2719.966796875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.501129150390625\n",
            "Eval_StdReturn : 12.664495468139648\n",
            "Eval_MaxReturn : -20.34745979309082\n",
            "Eval_MinReturn : -51.345909118652344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.072784423828125\n",
            "Train_StdReturn : 26.168548583984375\n",
            "Train_MaxReturn : 47.289764404296875\n",
            "Train_MinReturn : -130.34657287597656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1052100\n",
            "TimeSinceStart : 818.1223809719086\n",
            "Training Loss : -3210.938232421875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.81756591796875\n",
            "Eval_StdReturn : 17.55766487121582\n",
            "Eval_MaxReturn : -12.987483978271484\n",
            "Eval_MinReturn : -50.32020568847656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -42.90946578979492\n",
            "Train_StdReturn : 25.439016342163086\n",
            "Train_MaxReturn : 22.584915161132812\n",
            "Train_MinReturn : -132.2574462890625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1102200\n",
            "TimeSinceStart : 857.2906451225281\n",
            "Training Loss : -3335.660400390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.232791900634766\n",
            "Eval_StdReturn : 33.74725341796875\n",
            "Eval_MaxReturn : -15.565750122070312\n",
            "Eval_MinReturn : -95.3615951538086\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -38.17253875732422\n",
            "Train_StdReturn : 24.85048484802246\n",
            "Train_MaxReturn : 42.195247650146484\n",
            "Train_MinReturn : -150.99591064453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1152300\n",
            "TimeSinceStart : 896.4466333389282\n",
            "Training Loss : -2517.050048828125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.35439109802246\n",
            "Eval_StdReturn : 26.51457977294922\n",
            "Eval_MaxReturn : 4.812418460845947\n",
            "Eval_MinReturn : -60.126319885253906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.31139373779297\n",
            "Train_StdReturn : 25.428770065307617\n",
            "Train_MaxReturn : 38.88362121582031\n",
            "Train_MinReturn : -165.95562744140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1202400\n",
            "TimeSinceStart : 935.23943567276\n",
            "Training Loss : -2444.231689453125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.3214054107666\n",
            "Eval_StdReturn : 28.02423095703125\n",
            "Eval_MaxReturn : 21.308334350585938\n",
            "Eval_MinReturn : -38.52234649658203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.228057861328125\n",
            "Train_StdReturn : 22.868122100830078\n",
            "Train_MaxReturn : 43.891170501708984\n",
            "Train_MinReturn : -106.69713592529297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1252500\n",
            "TimeSinceStart : 973.9652454853058\n",
            "Training Loss : -2343.10693359375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -50.04426574707031\n",
            "Eval_StdReturn : 17.919795989990234\n",
            "Eval_MaxReturn : -31.188987731933594\n",
            "Eval_MinReturn : -74.13606262207031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.37298583984375\n",
            "Train_StdReturn : 23.854969024658203\n",
            "Train_MaxReturn : 49.54747772216797\n",
            "Train_MinReturn : -191.30172729492188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1302600\n",
            "TimeSinceStart : 1012.8633389472961\n",
            "Training Loss : -2520.635986328125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.16753005981445\n",
            "Eval_StdReturn : 10.734390258789062\n",
            "Eval_MaxReturn : -24.851377487182617\n",
            "Eval_MinReturn : -50.698997497558594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.6953010559082\n",
            "Train_StdReturn : 22.353313446044922\n",
            "Train_MaxReturn : 30.851776123046875\n",
            "Train_MinReturn : -137.26124572753906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1352700\n",
            "TimeSinceStart : 1051.9324462413788\n",
            "Training Loss : -2952.0146484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.336435317993164\n",
            "Eval_StdReturn : 29.298053741455078\n",
            "Eval_MaxReturn : 9.356996536254883\n",
            "Eval_MinReturn : -58.43572998046875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.744619369506836\n",
            "Train_StdReturn : 23.7847843170166\n",
            "Train_MaxReturn : 52.26793670654297\n",
            "Train_MinReturn : -153.74429321289062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1402800\n",
            "TimeSinceStart : 1090.6717402935028\n",
            "Training Loss : -2217.210205078125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.63198471069336\n",
            "Eval_StdReturn : 15.283737182617188\n",
            "Eval_MaxReturn : -18.788360595703125\n",
            "Eval_MinReturn : -55.00823974609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.53628158569336\n",
            "Train_StdReturn : 25.330039978027344\n",
            "Train_MaxReturn : 29.819913864135742\n",
            "Train_MinReturn : -172.01968383789062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1452900\n",
            "TimeSinceStart : 1129.360451221466\n",
            "Training Loss : -2304.98779296875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.862300872802734\n",
            "Eval_StdReturn : 15.121460914611816\n",
            "Eval_MaxReturn : -25.55240249633789\n",
            "Eval_MinReturn : -59.16114807128906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.661115646362305\n",
            "Train_StdReturn : 26.32990264892578\n",
            "Train_MaxReturn : 30.413135528564453\n",
            "Train_MinReturn : -190.7879638671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1503000\n",
            "TimeSinceStart : 1168.1994454860687\n",
            "Training Loss : -2297.67919921875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -48.44432067871094\n",
            "Eval_StdReturn : 3.0252304077148438\n",
            "Eval_MaxReturn : -45.277305603027344\n",
            "Eval_MinReturn : -52.5189208984375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.47600746154785\n",
            "Train_StdReturn : 22.9219970703125\n",
            "Train_MaxReturn : 29.08194351196289\n",
            "Train_MinReturn : -122.7986831665039\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1553100\n",
            "TimeSinceStart : 1207.2076234817505\n",
            "Training Loss : -2700.5615234375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.0944766998291\n",
            "Eval_StdReturn : 18.35451316833496\n",
            "Eval_MaxReturn : 3.404723882675171\n",
            "Eval_MinReturn : -39.04827117919922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.79945945739746\n",
            "Train_StdReturn : 24.557077407836914\n",
            "Train_MaxReturn : 55.58320617675781\n",
            "Train_MinReturn : -151.0905303955078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1603200\n",
            "TimeSinceStart : 1246.03346824646\n",
            "Training Loss : -2088.10791015625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -1.7090402841567993\n",
            "Eval_StdReturn : 15.998356819152832\n",
            "Eval_MaxReturn : 16.084918975830078\n",
            "Eval_MinReturn : -22.70777130126953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.667205810546875\n",
            "Train_StdReturn : 21.095739364624023\n",
            "Train_MaxReturn : 30.469154357910156\n",
            "Train_MinReturn : -103.36991882324219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1653300\n",
            "TimeSinceStart : 1285.0839529037476\n",
            "Training Loss : -2092.328125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.729938507080078\n",
            "Eval_StdReturn : 9.936767578125\n",
            "Eval_MaxReturn : -9.679988861083984\n",
            "Eval_MinReturn : -33.26125717163086\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.525480270385742\n",
            "Train_StdReturn : 20.6900577545166\n",
            "Train_MaxReturn : 20.192344665527344\n",
            "Train_MinReturn : -96.6156997680664\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1703400\n",
            "TimeSinceStart : 1323.755039215088\n",
            "Training Loss : -2213.364990234375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.211002349853516\n",
            "Eval_StdReturn : 15.593245506286621\n",
            "Eval_MaxReturn : -13.50612735748291\n",
            "Eval_MinReturn : -51.13648986816406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.549238204956055\n",
            "Train_StdReturn : 19.56745719909668\n",
            "Train_MaxReturn : 35.675498962402344\n",
            "Train_MinReturn : -83.43058776855469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1753500\n",
            "TimeSinceStart : 1362.7451798915863\n",
            "Training Loss : -2378.40966796875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.8488655090332\n",
            "Eval_StdReturn : 7.329835891723633\n",
            "Eval_MaxReturn : -54.40972900390625\n",
            "Eval_MinReturn : -71.10355377197266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.249691009521484\n",
            "Train_StdReturn : 19.436716079711914\n",
            "Train_MaxReturn : 39.53356170654297\n",
            "Train_MinReturn : -145.34518432617188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1803600\n",
            "TimeSinceStart : 1402.141262769699\n",
            "Training Loss : -2395.013916015625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.110944747924805\n",
            "Eval_StdReturn : 26.080013275146484\n",
            "Eval_MaxReturn : -0.32099175453186035\n",
            "Eval_MinReturn : -62.459835052490234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.337045669555664\n",
            "Train_StdReturn : 20.324548721313477\n",
            "Train_MaxReturn : 29.08441925048828\n",
            "Train_MinReturn : -119.54658508300781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1853700\n",
            "TimeSinceStart : 1441.0378205776215\n",
            "Training Loss : -2279.187744140625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.595324516296387\n",
            "Eval_StdReturn : 3.3505496978759766\n",
            "Eval_MaxReturn : -8.556922912597656\n",
            "Eval_MinReturn : -16.76109504699707\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.08968734741211\n",
            "Train_StdReturn : 18.318822860717773\n",
            "Train_MaxReturn : 45.90378952026367\n",
            "Train_MinReturn : -69.8782958984375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1903800\n",
            "TimeSinceStart : 1479.819795370102\n",
            "Training Loss : -2254.475830078125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.922422409057617\n",
            "Eval_StdReturn : 15.075764656066895\n",
            "Eval_MaxReturn : -2.609825849533081\n",
            "Eval_MinReturn : -35.07667541503906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.702743530273438\n",
            "Train_StdReturn : 20.001176834106445\n",
            "Train_MaxReturn : 60.06292724609375\n",
            "Train_MinReturn : -93.23243713378906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1953900\n",
            "TimeSinceStart : 1518.6554579734802\n",
            "Training Loss : -1967.4757080078125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.924378395080566\n",
            "Eval_StdReturn : 8.787215232849121\n",
            "Eval_MaxReturn : -1.0447592735290527\n",
            "Eval_MinReturn : -22.564971923828125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.584808349609375\n",
            "Train_StdReturn : 19.151508331298828\n",
            "Train_MaxReturn : 40.56611633300781\n",
            "Train_MinReturn : -95.33262634277344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2004000\n",
            "TimeSinceStart : 1557.6068534851074\n",
            "Training Loss : -1973.90380859375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.502901077270508\n",
            "Eval_StdReturn : 1.8423566818237305\n",
            "Eval_MaxReturn : -14.550780296325684\n",
            "Eval_MinReturn : -18.97339630126953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.3448486328125\n",
            "Train_StdReturn : 15.725797653198242\n",
            "Train_MaxReturn : 16.930133819580078\n",
            "Train_MinReturn : -72.72257232666016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2054100\n",
            "TimeSinceStart : 1596.4659910202026\n",
            "Training Loss : -1912.87841796875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.82611083984375\n",
            "Eval_StdReturn : 4.528298377990723\n",
            "Eval_MaxReturn : -21.384075164794922\n",
            "Eval_MinReturn : -32.47055435180664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.100854873657227\n",
            "Train_StdReturn : 18.999109268188477\n",
            "Train_MaxReturn : 53.43728256225586\n",
            "Train_MinReturn : -117.49934387207031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2104200\n",
            "TimeSinceStart : 1635.5234270095825\n",
            "Training Loss : -1661.4683837890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.50848388671875\n",
            "Eval_StdReturn : 13.73116397857666\n",
            "Eval_MaxReturn : -3.8034090995788574\n",
            "Eval_MinReturn : -36.378482818603516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.932270050048828\n",
            "Train_StdReturn : 18.016048431396484\n",
            "Train_MaxReturn : 26.146230697631836\n",
            "Train_MinReturn : -73.3870849609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2154300\n",
            "TimeSinceStart : 1674.5765478610992\n",
            "Training Loss : -2699.00634765625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.149953842163086\n",
            "Eval_StdReturn : 8.492142677307129\n",
            "Eval_MaxReturn : -10.422445297241211\n",
            "Eval_MinReturn : -30.255115509033203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.100893020629883\n",
            "Train_StdReturn : 17.49216651916504\n",
            "Train_MaxReturn : 57.704830169677734\n",
            "Train_MinReturn : -95.98751831054688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2204400\n",
            "TimeSinceStart : 1713.653918504715\n",
            "Training Loss : -2852.978515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.597476959228516\n",
            "Eval_StdReturn : 38.20267105102539\n",
            "Eval_MaxReturn : -7.457535266876221\n",
            "Eval_MinReturn : -98.98445129394531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.06051254272461\n",
            "Train_StdReturn : 18.08712387084961\n",
            "Train_MaxReturn : 38.964813232421875\n",
            "Train_MinReturn : -125.90419006347656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2254500\n",
            "TimeSinceStart : 1752.3599436283112\n",
            "Training Loss : -1670.0958251953125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.413835525512695\n",
            "Eval_StdReturn : 10.182377815246582\n",
            "Eval_MaxReturn : -10.544082641601562\n",
            "Eval_MinReturn : -34.701873779296875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.091100692749023\n",
            "Train_StdReturn : 16.00994300842285\n",
            "Train_MaxReturn : 45.715309143066406\n",
            "Train_MinReturn : -59.30229949951172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2304600\n",
            "TimeSinceStart : 1791.4553184509277\n",
            "Training Loss : -2852.57666015625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.256328105926514\n",
            "Eval_StdReturn : 9.52989387512207\n",
            "Eval_MaxReturn : 14.858979225158691\n",
            "Eval_MinReturn : -7.02965784072876\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.76927661895752\n",
            "Train_StdReturn : 15.46304702758789\n",
            "Train_MaxReturn : 43.205604553222656\n",
            "Train_MinReturn : -57.10647201538086\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2354700\n",
            "TimeSinceStart : 1830.4391927719116\n",
            "Training Loss : -2378.2109375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 0.9421229362487793\n",
            "Eval_StdReturn : 3.921571731567383\n",
            "Eval_MaxReturn : 6.442025661468506\n",
            "Eval_MinReturn : -2.4253950119018555\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.012070655822754\n",
            "Train_StdReturn : 15.977818489074707\n",
            "Train_MaxReturn : 33.57868957519531\n",
            "Train_MinReturn : -74.39036560058594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2404800\n",
            "TimeSinceStart : 1869.5450503826141\n",
            "Training Loss : -1439.993896484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.218151092529297\n",
            "Eval_StdReturn : 4.117729663848877\n",
            "Eval_MaxReturn : -7.70333194732666\n",
            "Eval_MinReturn : -17.660816192626953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.277226448059082\n",
            "Train_StdReturn : 17.362754821777344\n",
            "Train_MaxReturn : 51.028175354003906\n",
            "Train_MinReturn : -69.76825714111328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2454900\n",
            "TimeSinceStart : 1908.4179062843323\n",
            "Training Loss : -947.633544921875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.8335771560668945\n",
            "Eval_StdReturn : 4.663191318511963\n",
            "Eval_MaxReturn : 1.2128067016601562\n",
            "Eval_MinReturn : -10.136892318725586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.299420356750488\n",
            "Train_StdReturn : 15.391512870788574\n",
            "Train_MaxReturn : 33.54603958129883\n",
            "Train_MinReturn : -55.103614807128906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2505000\n",
            "TimeSinceStart : 1947.5200412273407\n",
            "Training Loss : -2044.7896728515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 0.9358575344085693\n",
            "Eval_StdReturn : 3.483705520629883\n",
            "Eval_MaxReturn : 4.940732955932617\n",
            "Eval_MinReturn : -3.551542043685913\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.124306678771973\n",
            "Train_StdReturn : 17.207979202270508\n",
            "Train_MaxReturn : 47.68114471435547\n",
            "Train_MinReturn : -86.98017120361328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2555100\n",
            "TimeSinceStart : 1986.3261935710907\n",
            "Training Loss : -1842.0458984375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.7104561924934387\n",
            "Eval_StdReturn : 19.36618995666504\n",
            "Eval_MaxReturn : 18.260011672973633\n",
            "Eval_MinReturn : -27.303146362304688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.061152458190918\n",
            "Train_StdReturn : 15.89168930053711\n",
            "Train_MaxReturn : 53.700565338134766\n",
            "Train_MinReturn : -57.27904510498047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2605200\n",
            "TimeSinceStart : 2025.6297471523285\n",
            "Training Loss : -1128.263427734375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.487214088439941\n",
            "Eval_StdReturn : 11.503252029418945\n",
            "Eval_MaxReturn : 10.211729049682617\n",
            "Eval_MinReturn : -17.873489379882812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -7.207569122314453\n",
            "Train_StdReturn : 15.23268985748291\n",
            "Train_MaxReturn : 34.63075256347656\n",
            "Train_MinReturn : -81.55963134765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2655300\n",
            "TimeSinceStart : 2064.2671949863434\n",
            "Training Loss : -1158.756103515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.837132215499878\n",
            "Eval_StdReturn : 20.03535270690918\n",
            "Eval_MaxReturn : 28.57526397705078\n",
            "Eval_MinReturn : -20.496116638183594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -5.627140045166016\n",
            "Train_StdReturn : 16.7958927154541\n",
            "Train_MaxReturn : 33.660614013671875\n",
            "Train_MinReturn : -79.0169448852539\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2705400\n",
            "TimeSinceStart : 2103.0941474437714\n",
            "Training Loss : -1265.5584716796875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.831833839416504\n",
            "Eval_StdReturn : 8.864322662353516\n",
            "Eval_MaxReturn : 2.1790904998779297\n",
            "Eval_MinReturn : -18.946571350097656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -2.6158413887023926\n",
            "Train_StdReturn : 15.59097957611084\n",
            "Train_MaxReturn : 41.320594787597656\n",
            "Train_MinReturn : -47.94843292236328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2755500\n",
            "TimeSinceStart : 2142.068706512451\n",
            "Training Loss : -438.64227294921875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.7014166116714478\n",
            "Eval_StdReturn : 15.192824363708496\n",
            "Eval_MaxReturn : 19.625743865966797\n",
            "Eval_MinReturn : -17.52094841003418\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -0.9019398093223572\n",
            "Train_StdReturn : 17.10405158996582\n",
            "Train_MaxReturn : 56.17646026611328\n",
            "Train_MinReturn : -63.2503547668457\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2805600\n",
            "TimeSinceStart : 2180.7153222560883\n",
            "Training Loss : -226.01498413085938\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -5.2676100730896\n",
            "Eval_StdReturn : 24.68138313293457\n",
            "Eval_MaxReturn : 17.713464736938477\n",
            "Eval_MinReturn : -39.51026153564453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.406857430934906\n",
            "Train_StdReturn : 16.6462345123291\n",
            "Train_MaxReturn : 45.0513916015625\n",
            "Train_MinReturn : -96.11180877685547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2855700\n",
            "TimeSinceStart : 2219.5204372406006\n",
            "Training Loss : -229.87908935546875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -6.1634840965271\n",
            "Eval_StdReturn : 5.607909202575684\n",
            "Eval_MaxReturn : 1.4100627899169922\n",
            "Eval_MinReturn : -11.988395690917969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 3.3784239292144775\n",
            "Train_StdReturn : 16.294652938842773\n",
            "Train_MaxReturn : 47.601768493652344\n",
            "Train_MinReturn : -60.136688232421875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2905800\n",
            "TimeSinceStart : 2258.4592299461365\n",
            "Training Loss : -794.472900390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.7587242126464844\n",
            "Eval_StdReturn : 7.866302490234375\n",
            "Eval_MaxReturn : 11.918046951293945\n",
            "Eval_MinReturn : -7.246391296386719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 1.6936415433883667\n",
            "Train_StdReturn : 17.285764694213867\n",
            "Train_MaxReturn : 47.37517547607422\n",
            "Train_MinReturn : -56.33485412597656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2955900\n",
            "TimeSinceStart : 2297.383702993393\n",
            "Training Loss : 95.40019226074219\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.31526756286621\n",
            "Eval_StdReturn : 15.729644775390625\n",
            "Eval_MaxReturn : 43.58833312988281\n",
            "Eval_MinReturn : 5.192200660705566\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.7171571254730225\n",
            "Train_StdReturn : 17.025245666503906\n",
            "Train_MaxReturn : 44.877376556396484\n",
            "Train_MinReturn : -46.19812774658203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3006000\n",
            "TimeSinceStart : 2336.4137663841248\n",
            "Training Loss : -1185.749755859375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -6.088199615478516\n",
            "Eval_StdReturn : 15.998468399047852\n",
            "Eval_MaxReturn : 15.88237190246582\n",
            "Eval_MinReturn : -21.752904891967773\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.8974213004112244\n",
            "Train_StdReturn : 18.948965072631836\n",
            "Train_MaxReturn : 52.97541427612305\n",
            "Train_MinReturn : -57.302162170410156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3056100\n",
            "TimeSinceStart : 2375.3075094223022\n",
            "Training Loss : -1349.76611328125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.049031734466553\n",
            "Eval_StdReturn : 24.33779525756836\n",
            "Eval_MaxReturn : 34.60830307006836\n",
            "Eval_MinReturn : -24.945220947265625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.8523339629173279\n",
            "Train_StdReturn : 18.818843841552734\n",
            "Train_MaxReturn : 57.12986755371094\n",
            "Train_MinReturn : -45.30405044555664\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3106200\n",
            "TimeSinceStart : 2414.0035388469696\n",
            "Training Loss : -1089.2901611328125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.956744194030762\n",
            "Eval_StdReturn : 6.901528358459473\n",
            "Eval_MaxReturn : 17.81407356262207\n",
            "Eval_MinReturn : 1.5131464004516602\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 1.513147234916687\n",
            "Train_StdReturn : 19.37474250793457\n",
            "Train_MaxReturn : 60.51515579223633\n",
            "Train_MinReturn : -63.46894836425781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3156300\n",
            "TimeSinceStart : 2452.8020260334015\n",
            "Training Loss : -509.71124267578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.638636589050293\n",
            "Eval_StdReturn : 8.275809288024902\n",
            "Eval_MaxReturn : 17.953372955322266\n",
            "Eval_MinReturn : -2.155529499053955\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 1.085026502609253\n",
            "Train_StdReturn : 20.570873260498047\n",
            "Train_MaxReturn : 85.5412826538086\n",
            "Train_MinReturn : -51.16801452636719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3206400\n",
            "TimeSinceStart : 2491.7766015529633\n",
            "Training Loss : -1172.764404296875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.607991218566895\n",
            "Eval_StdReturn : 25.017881393432617\n",
            "Eval_MaxReturn : 6.095861434936523\n",
            "Eval_MinReturn : -50.65802764892578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.9681864380836487\n",
            "Train_StdReturn : 18.86072540283203\n",
            "Train_MaxReturn : 53.25841522216797\n",
            "Train_MinReturn : -50.83100891113281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3256500\n",
            "TimeSinceStart : 2530.6083137989044\n",
            "Training Loss : -1202.9659423828125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -2.9465243816375732\n",
            "Eval_StdReturn : 16.114177703857422\n",
            "Eval_MaxReturn : 15.317689895629883\n",
            "Eval_MinReturn : -23.881763458251953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 1.747711420059204\n",
            "Train_StdReturn : 18.595186233520508\n",
            "Train_MaxReturn : 55.24244689941406\n",
            "Train_MinReturn : -63.8190803527832\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3306600\n",
            "TimeSinceStart : 2569.4174859523773\n",
            "Training Loss : -917.4224243164062\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.5302772521972656\n",
            "Eval_StdReturn : 18.92031478881836\n",
            "Eval_MaxReturn : 14.112119674682617\n",
            "Eval_MinReturn : -27.246517181396484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.568915843963623\n",
            "Train_StdReturn : 18.434772491455078\n",
            "Train_MaxReturn : 68.6025161743164\n",
            "Train_MinReturn : -60.97461700439453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3356700\n",
            "TimeSinceStart : 2608.17001080513\n",
            "Training Loss : -1300.4029541015625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.5716047286987305\n",
            "Eval_StdReturn : 7.438581943511963\n",
            "Eval_MaxReturn : 13.539759635925293\n",
            "Eval_MinReturn : -4.323772430419922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 3.6203086376190186\n",
            "Train_StdReturn : 19.148462295532227\n",
            "Train_MaxReturn : 106.838134765625\n",
            "Train_MinReturn : -64.28201293945312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3406800\n",
            "TimeSinceStart : 2646.4983224868774\n",
            "Training Loss : -561.946044921875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.477321624755859\n",
            "Eval_StdReturn : 15.704523086547852\n",
            "Eval_MaxReturn : 25.539030075073242\n",
            "Eval_MinReturn : -12.746345520019531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 3.2850100994110107\n",
            "Train_StdReturn : 19.238441467285156\n",
            "Train_MaxReturn : 60.737831115722656\n",
            "Train_MinReturn : -65.12614440917969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3456900\n",
            "TimeSinceStart : 2685.545747756958\n",
            "Training Loss : -1111.3218994140625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.94017219543457\n",
            "Eval_StdReturn : 2.621350049972534\n",
            "Eval_MaxReturn : 7.753227710723877\n",
            "Eval_MinReturn : 1.4426507949829102\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 4.459972858428955\n",
            "Train_StdReturn : 19.653606414794922\n",
            "Train_MaxReturn : 66.76557922363281\n",
            "Train_MinReturn : -59.480613708496094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3507000\n",
            "TimeSinceStart : 2724.2064604759216\n",
            "Training Loss : -1073.027099609375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.663577675819397\n",
            "Eval_StdReturn : 25.017070770263672\n",
            "Eval_MaxReturn : 32.90153121948242\n",
            "Eval_MinReturn : -28.340232849121094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 3.890481472015381\n",
            "Train_StdReturn : 19.122055053710938\n",
            "Train_MaxReturn : 50.791297912597656\n",
            "Train_MinReturn : -62.76802062988281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3557100\n",
            "TimeSinceStart : 2762.715622663498\n",
            "Training Loss : -484.55035400390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.359054565429688\n",
            "Eval_StdReturn : 5.817782402038574\n",
            "Eval_MaxReturn : 13.775562286376953\n",
            "Eval_MinReturn : 0.28740882873535156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 5.70943021774292\n",
            "Train_StdReturn : 20.47060203552246\n",
            "Train_MaxReturn : 53.00132751464844\n",
            "Train_MinReturn : -110.99542236328125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3607200\n",
            "TimeSinceStart : 2801.4939591884613\n",
            "Training Loss : -687.2755126953125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 0.2088298797607422\n",
            "Eval_StdReturn : 20.438703536987305\n",
            "Eval_MaxReturn : 28.06406593322754\n",
            "Eval_MinReturn : -20.402740478515625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 8.06071662902832\n",
            "Train_StdReturn : 19.936473846435547\n",
            "Train_MaxReturn : 75.2629623413086\n",
            "Train_MinReturn : -85.68902587890625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3657300\n",
            "TimeSinceStart : 2840.3110156059265\n",
            "Training Loss : -1601.836181640625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.88936710357666\n",
            "Eval_StdReturn : 4.853646278381348\n",
            "Eval_MaxReturn : 10.809161186218262\n",
            "Eval_MinReturn : -1.0794916152954102\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 7.861754894256592\n",
            "Train_StdReturn : 18.233463287353516\n",
            "Train_MaxReturn : 52.400390625\n",
            "Train_MinReturn : -61.402069091796875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3707400\n",
            "TimeSinceStart : 2878.768580198288\n",
            "Training Loss : -1488.8306884765625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.716453552246094\n",
            "Eval_StdReturn : 19.71602439880371\n",
            "Eval_MaxReturn : 40.5630989074707\n",
            "Eval_MinReturn : -2.146176338195801\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 8.91477108001709\n",
            "Train_StdReturn : 20.068235397338867\n",
            "Train_MaxReturn : 68.23644256591797\n",
            "Train_MinReturn : -59.86449432373047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3757500\n",
            "TimeSinceStart : 2917.532810688019\n",
            "Training Loss : -2262.505859375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 30.980512619018555\n",
            "Eval_StdReturn : 9.822877883911133\n",
            "Eval_MaxReturn : 40.58665466308594\n",
            "Eval_MinReturn : 17.486934661865234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 8.904511451721191\n",
            "Train_StdReturn : 19.264802932739258\n",
            "Train_MaxReturn : 73.37265014648438\n",
            "Train_MinReturn : -113.82147979736328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3807600\n",
            "TimeSinceStart : 2956.132681131363\n",
            "Training Loss : -1261.3656005859375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 0.5535185933113098\n",
            "Eval_StdReturn : 11.749065399169922\n",
            "Eval_MaxReturn : 15.866081237792969\n",
            "Eval_MinReturn : -12.688894271850586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 10.946885108947754\n",
            "Train_StdReturn : 19.37071990966797\n",
            "Train_MaxReturn : 72.5740966796875\n",
            "Train_MinReturn : -59.412994384765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3857700\n",
            "TimeSinceStart : 2994.9638175964355\n",
            "Training Loss : -2191.2216796875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.452659606933594\n",
            "Eval_StdReturn : 10.23622989654541\n",
            "Eval_MaxReturn : 22.614749908447266\n",
            "Eval_MinReturn : 0.01759052276611328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 11.058232307434082\n",
            "Train_StdReturn : 21.482511520385742\n",
            "Train_MaxReturn : 70.6581039428711\n",
            "Train_MinReturn : -54.27018356323242\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3907800\n",
            "TimeSinceStart : 3033.5492267608643\n",
            "Training Loss : -1562.737060546875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.660895347595215\n",
            "Eval_StdReturn : 26.085800170898438\n",
            "Eval_MaxReturn : 45.506919860839844\n",
            "Eval_MinReturn : -11.337352752685547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 11.790331840515137\n",
            "Train_StdReturn : 21.182571411132812\n",
            "Train_MaxReturn : 61.31842803955078\n",
            "Train_MinReturn : -86.75277709960938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3957900\n",
            "TimeSinceStart : 3072.3950984477997\n",
            "Training Loss : -2205.69970703125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 21.14402961730957\n",
            "Eval_StdReturn : 11.936546325683594\n",
            "Eval_MaxReturn : 32.92461013793945\n",
            "Eval_MinReturn : 4.783059597015381\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 13.866506576538086\n",
            "Train_StdReturn : 19.333662033081055\n",
            "Train_MaxReturn : 61.91346740722656\n",
            "Train_MinReturn : -49.56431198120117\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4008000\n",
            "TimeSinceStart : 3111.1854798793793\n",
            "Training Loss : -1840.98828125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 46.396244049072266\n",
            "Eval_StdReturn : 24.72870445251465\n",
            "Eval_MaxReturn : 71.032958984375\n",
            "Eval_MinReturn : 12.582828521728516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 16.474838256835938\n",
            "Train_StdReturn : 21.976940155029297\n",
            "Train_MaxReturn : 101.38743591308594\n",
            "Train_MinReturn : -83.5677490234375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4058100\n",
            "TimeSinceStart : 3149.6937651634216\n",
            "Training Loss : -2262.4189453125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.270228862762451\n",
            "Eval_StdReturn : 18.96435546875\n",
            "Eval_MaxReturn : 32.02870178222656\n",
            "Eval_MinReturn : -9.6768798828125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 21.50092124938965\n",
            "Train_StdReturn : 20.69741439819336\n",
            "Train_MaxReturn : 85.44921875\n",
            "Train_MinReturn : -76.79933166503906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4108200\n",
            "TimeSinceStart : 3188.3983426094055\n",
            "Training Loss : -2132.311767578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 35.644962310791016\n",
            "Eval_StdReturn : 16.37578773498535\n",
            "Eval_MaxReturn : 58.73817443847656\n",
            "Eval_MinReturn : 22.58926010131836\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 25.156185150146484\n",
            "Train_StdReturn : 20.9185848236084\n",
            "Train_MaxReturn : 75.63277435302734\n",
            "Train_MinReturn : -107.17510223388672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4158300\n",
            "TimeSinceStart : 3227.2807133197784\n",
            "Training Loss : -2987.63037109375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 20.61574363708496\n",
            "Eval_StdReturn : 8.085006713867188\n",
            "Eval_MaxReturn : 27.35256576538086\n",
            "Eval_MinReturn : 9.246557235717773\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 25.947856903076172\n",
            "Train_StdReturn : 22.02983856201172\n",
            "Train_MaxReturn : 71.03179931640625\n",
            "Train_MinReturn : -65.23887634277344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4208400\n",
            "TimeSinceStart : 3265.987253665924\n",
            "Training Loss : -2782.857177734375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.38530349731445\n",
            "Eval_StdReturn : 15.35448932647705\n",
            "Eval_MaxReturn : 54.933536529541016\n",
            "Eval_MinReturn : 20.288301467895508\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 30.843509674072266\n",
            "Train_StdReturn : 20.41594123840332\n",
            "Train_MaxReturn : 78.73348999023438\n",
            "Train_MinReturn : -41.9418830871582\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4258500\n",
            "TimeSinceStart : 3305.001719236374\n",
            "Training Loss : -3276.25244140625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 47.17387771606445\n",
            "Eval_StdReturn : 11.596651077270508\n",
            "Eval_MaxReturn : 58.87541580200195\n",
            "Eval_MinReturn : 31.37177848815918\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 33.162315368652344\n",
            "Train_StdReturn : 20.731473922729492\n",
            "Train_MaxReturn : 89.57217407226562\n",
            "Train_MinReturn : -33.16395950317383\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4308600\n",
            "TimeSinceStart : 3343.6902062892914\n",
            "Training Loss : -2730.531494140625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 28.5538387298584\n",
            "Eval_StdReturn : 18.41498565673828\n",
            "Eval_MaxReturn : 54.49781799316406\n",
            "Eval_MinReturn : 13.619696617126465\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 37.568572998046875\n",
            "Train_StdReturn : 19.507375717163086\n",
            "Train_MaxReturn : 86.44935607910156\n",
            "Train_MinReturn : -36.654022216796875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4358700\n",
            "TimeSinceStart : 3382.502030611038\n",
            "Training Loss : -2961.28271484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 39.65949630737305\n",
            "Eval_StdReturn : 2.434122323989868\n",
            "Eval_MaxReturn : 42.92158889770508\n",
            "Eval_MinReturn : 37.07635498046875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 36.279327392578125\n",
            "Train_StdReturn : 18.95951271057129\n",
            "Train_MaxReturn : 90.34285736083984\n",
            "Train_MinReturn : -23.699438095092773\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4408800\n",
            "TimeSinceStart : 3421.2965445518494\n",
            "Training Loss : -4265.021484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 53.06034851074219\n",
            "Eval_StdReturn : 7.997070789337158\n",
            "Eval_MaxReturn : 63.926788330078125\n",
            "Eval_MinReturn : 44.91233825683594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 39.41959762573242\n",
            "Train_StdReturn : 18.48196029663086\n",
            "Train_MaxReturn : 91.26290130615234\n",
            "Train_MinReturn : -21.710542678833008\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4458900\n",
            "TimeSinceStart : 3459.963305711746\n",
            "Training Loss : -3466.93701171875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 54.45783615112305\n",
            "Eval_StdReturn : 7.892372131347656\n",
            "Eval_MaxReturn : 65.54551696777344\n",
            "Eval_MinReturn : 47.80412673950195\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 44.64768981933594\n",
            "Train_StdReturn : 18.731563568115234\n",
            "Train_MaxReturn : 94.82814025878906\n",
            "Train_MinReturn : -11.726633071899414\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4509000\n",
            "TimeSinceStart : 3498.781598329544\n",
            "Training Loss : -2792.99072265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 15.319132804870605\n",
            "Eval_StdReturn : 22.93950653076172\n",
            "Eval_MaxReturn : 40.80714416503906\n",
            "Eval_MinReturn : -14.805965423583984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 48.018985748291016\n",
            "Train_StdReturn : 19.827306747436523\n",
            "Train_MaxReturn : 103.35322570800781\n",
            "Train_MinReturn : -26.649154663085938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4559100\n",
            "TimeSinceStart : 3537.411665201187\n",
            "Training Loss : -3453.065673828125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 65.02452087402344\n",
            "Eval_StdReturn : 9.379481315612793\n",
            "Eval_MaxReturn : 77.64653015136719\n",
            "Eval_MinReturn : 55.181427001953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 50.89442443847656\n",
            "Train_StdReturn : 17.924739837646484\n",
            "Train_MaxReturn : 92.07930755615234\n",
            "Train_MinReturn : -4.561166763305664\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4609200\n",
            "TimeSinceStart : 3575.9822788238525\n",
            "Training Loss : -3704.933837890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.244693756103516\n",
            "Eval_StdReturn : 10.443059921264648\n",
            "Eval_MaxReturn : 41.42441940307617\n",
            "Eval_MinReturn : 18.505638122558594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 52.80599594116211\n",
            "Train_StdReturn : 19.428646087646484\n",
            "Train_MaxReturn : 108.77789306640625\n",
            "Train_MinReturn : -22.321422576904297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4659300\n",
            "TimeSinceStart : 3614.623780488968\n",
            "Training Loss : -3387.90771484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 61.64500045776367\n",
            "Eval_StdReturn : 12.330907821655273\n",
            "Eval_MaxReturn : 76.55492401123047\n",
            "Eval_MinReturn : 46.35757064819336\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 54.25229263305664\n",
            "Train_StdReturn : 18.59156036376953\n",
            "Train_MaxReturn : 100.53662109375\n",
            "Train_MinReturn : -0.39508914947509766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4709400\n",
            "TimeSinceStart : 3653.5435576438904\n",
            "Training Loss : -4135.2099609375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 75.27841186523438\n",
            "Eval_StdReturn : 16.409942626953125\n",
            "Eval_MaxReturn : 95.83753204345703\n",
            "Eval_MinReturn : 55.675697326660156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 56.73860168457031\n",
            "Train_StdReturn : 19.660301208496094\n",
            "Train_MaxReturn : 103.84767150878906\n",
            "Train_MinReturn : -7.111785411834717\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4759500\n",
            "TimeSinceStart : 3692.324110031128\n",
            "Training Loss : -3477.53857421875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 81.09088897705078\n",
            "Eval_StdReturn : 16.88796043395996\n",
            "Eval_MaxReturn : 104.54086303710938\n",
            "Eval_MinReturn : 65.44430541992188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 58.73353958129883\n",
            "Train_StdReturn : 18.052942276000977\n",
            "Train_MaxReturn : 106.93846130371094\n",
            "Train_MinReturn : 10.714012145996094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4809600\n",
            "TimeSinceStart : 3730.823489665985\n",
            "Training Loss : -3600.841064453125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 72.71477508544922\n",
            "Eval_StdReturn : 10.337102890014648\n",
            "Eval_MaxReturn : 87.30520629882812\n",
            "Eval_MinReturn : 64.63025665283203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 63.81211471557617\n",
            "Train_StdReturn : 18.436172485351562\n",
            "Train_MaxReturn : 120.151611328125\n",
            "Train_MinReturn : 10.795267105102539\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4859700\n",
            "TimeSinceStart : 3769.399046421051\n",
            "Training Loss : -3859.1318359375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 71.62162017822266\n",
            "Eval_StdReturn : 20.623517990112305\n",
            "Eval_MaxReturn : 100.01127624511719\n",
            "Eval_MinReturn : 51.637603759765625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 66.94800567626953\n",
            "Train_StdReturn : 18.702865600585938\n",
            "Train_MaxReturn : 112.82369995117188\n",
            "Train_MinReturn : 1.485417366027832\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4909800\n",
            "TimeSinceStart : 3808.211129426956\n",
            "Training Loss : -3141.631103515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.28591918945312\n",
            "Eval_StdReturn : 25.115863800048828\n",
            "Eval_MaxReturn : 127.79473876953125\n",
            "Eval_MinReturn : 73.7880859375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 70.11394500732422\n",
            "Train_StdReturn : 20.071678161621094\n",
            "Train_MaxReturn : 125.48744201660156\n",
            "Train_MinReturn : 2.9428882598876953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4959900\n",
            "TimeSinceStart : 3846.609987974167\n",
            "Training Loss : -2948.908203125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 91.00980377197266\n",
            "Eval_StdReturn : 11.785325050354004\n",
            "Eval_MaxReturn : 105.53459167480469\n",
            "Eval_MinReturn : 76.66830444335938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 72.07673645019531\n",
            "Train_StdReturn : 18.56315040588379\n",
            "Train_MaxReturn : 117.407958984375\n",
            "Train_MinReturn : 10.845995903015137\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 5010000\n",
            "TimeSinceStart : 3885.559426307678\n",
            "Training Loss : -3405.251708984375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "    --discount 0.95 -n 100 -l 2 -s 32 \\\n",
        "    -b 50000 -lr 0.01 -rtg --nn_baseline \\\n",
        "    --exp_name q4_search_b50000_lr0.01_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CckP03iPSHh",
        "outputId": "ebcb0751-e8ae-40d6-bbdc-463a6223680d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q4_search_b50000_lr0.02_rtg_nnbaseline_HalfCheetah-v2_09-05-2022_11-10-07\n",
            "########################\n",
            "GPU not detected. Defaulting to CPU.\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -59.231689453125\n",
            "Eval_StdReturn : 26.608047485351562\n",
            "Eval_MaxReturn : -31.151315689086914\n",
            "Eval_MinReturn : -94.9652328491211\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -94.41527557373047\n",
            "Train_StdReturn : 38.59808349609375\n",
            "Train_MaxReturn : 1.7286391258239746\n",
            "Train_MinReturn : -216.81167602539062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50100\n",
            "TimeSinceStart : 38.814775228500366\n",
            "Training Loss : -3808.248779296875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.611480712890625\n",
            "Eval_StdReturn : 9.577096939086914\n",
            "Eval_MaxReturn : -31.473430633544922\n",
            "Eval_MinReturn : -54.030921936035156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -76.45398712158203\n",
            "Train_StdReturn : 35.11733627319336\n",
            "Train_MaxReturn : 21.301454544067383\n",
            "Train_MinReturn : -222.55889892578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100200\n",
            "TimeSinceStart : 78.02407598495483\n",
            "Training Loss : -2998.368896484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -81.2682876586914\n",
            "Eval_StdReturn : 48.5988883972168\n",
            "Eval_MaxReturn : -12.561141014099121\n",
            "Eval_MinReturn : -117.12982940673828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -71.6938705444336\n",
            "Train_StdReturn : 33.9470329284668\n",
            "Train_MaxReturn : 11.81857681274414\n",
            "Train_MinReturn : -188.08160400390625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150300\n",
            "TimeSinceStart : 116.82006788253784\n",
            "Training Loss : -2479.476806640625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.831878662109375\n",
            "Eval_StdReturn : 13.65799617767334\n",
            "Eval_MaxReturn : -27.092544555664062\n",
            "Eval_MinReturn : -60.319576263427734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -69.0025405883789\n",
            "Train_StdReturn : 35.68440246582031\n",
            "Train_MaxReturn : 21.998485565185547\n",
            "Train_MinReturn : -223.10255432128906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 200400\n",
            "TimeSinceStart : 155.88809847831726\n",
            "Training Loss : -3225.3623046875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.4148063659668\n",
            "Eval_StdReturn : 14.918067932128906\n",
            "Eval_MaxReturn : -45.512001037597656\n",
            "Eval_MinReturn : -77.50813293457031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -59.58623123168945\n",
            "Train_StdReturn : 32.30575180053711\n",
            "Train_MaxReturn : 23.720413208007812\n",
            "Train_MinReturn : -200.30857849121094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 250500\n",
            "TimeSinceStart : 194.63212275505066\n",
            "Training Loss : -4096.171875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -80.36817169189453\n",
            "Eval_StdReturn : 26.239614486694336\n",
            "Eval_MaxReturn : -47.901126861572266\n",
            "Eval_MinReturn : -112.16429138183594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -57.99382400512695\n",
            "Train_StdReturn : 27.867097854614258\n",
            "Train_MaxReturn : 15.087448120117188\n",
            "Train_MinReturn : -176.66128540039062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300600\n",
            "TimeSinceStart : 234.17727327346802\n",
            "Training Loss : -3583.2978515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.00076675415039\n",
            "Eval_StdReturn : 19.786941528320312\n",
            "Eval_MaxReturn : -30.75887680053711\n",
            "Eval_MinReturn : -79.22677612304688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.722225189208984\n",
            "Train_StdReturn : 25.835763931274414\n",
            "Train_MaxReturn : 33.548343658447266\n",
            "Train_MinReturn : -142.86814880371094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 350700\n",
            "TimeSinceStart : 273.1729929447174\n",
            "Training Loss : -4166.80517578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.69929122924805\n",
            "Eval_StdReturn : 17.927654266357422\n",
            "Eval_MaxReturn : -20.34635353088379\n",
            "Eval_MinReturn : -58.52654266357422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -52.80870056152344\n",
            "Train_StdReturn : 26.695070266723633\n",
            "Train_MaxReturn : 22.266639709472656\n",
            "Train_MinReturn : -141.1156768798828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 400800\n",
            "TimeSinceStart : 312.22312211990356\n",
            "Training Loss : -4374.4501953125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.94745635986328\n",
            "Eval_StdReturn : 21.937530517578125\n",
            "Eval_MaxReturn : 1.5460598468780518\n",
            "Eval_MinReturn : -51.029808044433594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.59211730957031\n",
            "Train_StdReturn : 24.484609603881836\n",
            "Train_MaxReturn : 18.377981185913086\n",
            "Train_MinReturn : -122.29949951171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450900\n",
            "TimeSinceStart : 351.46703720092773\n",
            "Training Loss : -4076.19384765625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.15826416015625\n",
            "Eval_StdReturn : 27.55377769470215\n",
            "Eval_MaxReturn : -17.395883560180664\n",
            "Eval_MinReturn : -83.30697631835938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.284873962402344\n",
            "Train_StdReturn : 26.75030517578125\n",
            "Train_MaxReturn : 55.69646072387695\n",
            "Train_MinReturn : -136.2472686767578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 501000\n",
            "TimeSinceStart : 391.01370310783386\n",
            "Training Loss : -3773.795654296875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.77485275268555\n",
            "Eval_StdReturn : 25.299015045166016\n",
            "Eval_MaxReturn : -24.33812713623047\n",
            "Eval_MinReturn : -86.06816864013672\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.55742263793945\n",
            "Train_StdReturn : 27.993764877319336\n",
            "Train_MaxReturn : 30.670316696166992\n",
            "Train_MinReturn : -132.7242889404297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 551100\n",
            "TimeSinceStart : 430.3957829475403\n",
            "Training Loss : -3290.92236328125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.61477279663086\n",
            "Eval_StdReturn : 23.32110595703125\n",
            "Eval_MaxReturn : -3.5131020545959473\n",
            "Eval_MinReturn : -60.605491638183594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.09825134277344\n",
            "Train_StdReturn : 29.699087142944336\n",
            "Train_MaxReturn : 48.76630401611328\n",
            "Train_MinReturn : -136.5626220703125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 601200\n",
            "TimeSinceStart : 469.5118844509125\n",
            "Training Loss : -3072.486572265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.818434715270996\n",
            "Eval_StdReturn : 5.9101996421813965\n",
            "Eval_MaxReturn : -1.9815521240234375\n",
            "Eval_MinReturn : -16.253450393676758\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.708656311035156\n",
            "Train_StdReturn : 31.979732513427734\n",
            "Train_MaxReturn : 75.3721923828125\n",
            "Train_MinReturn : -167.54522705078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 651300\n",
            "TimeSinceStart : 508.7132987976074\n",
            "Training Loss : -3208.30615234375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.855300903320312\n",
            "Eval_StdReturn : 36.407047271728516\n",
            "Eval_MaxReturn : 61.26365661621094\n",
            "Eval_MinReturn : -18.31777572631836\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.955093383789062\n",
            "Train_StdReturn : 29.25002098083496\n",
            "Train_MaxReturn : 43.04836654663086\n",
            "Train_MinReturn : -115.53877258300781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 701400\n",
            "TimeSinceStart : 548.1284580230713\n",
            "Training Loss : -2565.962890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.07743835449219\n",
            "Eval_StdReturn : 9.631290435791016\n",
            "Eval_MaxReturn : -18.6662540435791\n",
            "Eval_MinReturn : -40.84403991699219\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.343008041381836\n",
            "Train_StdReturn : 28.27126693725586\n",
            "Train_MaxReturn : 81.40478515625\n",
            "Train_MinReturn : -150.3642578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 751500\n",
            "TimeSinceStart : 587.5938811302185\n",
            "Training Loss : -2055.943359375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.5907039642334\n",
            "Eval_StdReturn : 1.0024727582931519\n",
            "Eval_MaxReturn : -23.332223892211914\n",
            "Eval_MinReturn : -25.785274505615234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.760765075683594\n",
            "Train_StdReturn : 27.60980224609375\n",
            "Train_MaxReturn : 41.994407653808594\n",
            "Train_MinReturn : -129.02090454101562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 801600\n",
            "TimeSinceStart : 629.0086996555328\n",
            "Training Loss : -2046.5096435546875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.61732864379883\n",
            "Eval_StdReturn : 26.932706832885742\n",
            "Eval_MaxReturn : -3.9792375564575195\n",
            "Eval_MinReturn : -67.95267486572266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.5325927734375\n",
            "Train_StdReturn : 26.392799377441406\n",
            "Train_MaxReturn : 64.69868469238281\n",
            "Train_MinReturn : -142.06719970703125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 851700\n",
            "TimeSinceStart : 668.3487474918365\n",
            "Training Loss : -1282.962890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.104644775390625\n",
            "Eval_StdReturn : 36.3015251159668\n",
            "Eval_MaxReturn : -21.916513442993164\n",
            "Eval_MinReturn : -105.619384765625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.190752029418945\n",
            "Train_StdReturn : 27.93893051147461\n",
            "Train_MaxReturn : 48.51325225830078\n",
            "Train_MinReturn : -132.0376434326172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 901800\n",
            "TimeSinceStart : 708.2244794368744\n",
            "Training Loss : -1943.1087646484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.52983093261719\n",
            "Eval_StdReturn : 16.314220428466797\n",
            "Eval_MaxReturn : -16.63792610168457\n",
            "Eval_MinReturn : -53.46598815917969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.272306442260742\n",
            "Train_StdReturn : 27.93789291381836\n",
            "Train_MaxReturn : 53.06132507324219\n",
            "Train_MinReturn : -140.25196838378906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 951900\n",
            "TimeSinceStart : 747.6412777900696\n",
            "Training Loss : -1594.129638671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.185298919677734\n",
            "Eval_StdReturn : 10.852237701416016\n",
            "Eval_MaxReturn : -31.40035629272461\n",
            "Eval_MinReturn : -57.03400421142578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.97564125061035\n",
            "Train_StdReturn : 28.619892120361328\n",
            "Train_MaxReturn : 77.6187744140625\n",
            "Train_MinReturn : -121.28352355957031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1002000\n",
            "TimeSinceStart : 786.9918508529663\n",
            "Training Loss : -1377.164306640625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.57427978515625\n",
            "Eval_StdReturn : 14.862459182739258\n",
            "Eval_MaxReturn : -23.558080673217773\n",
            "Eval_MinReturn : -59.76768493652344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.74121856689453\n",
            "Train_StdReturn : 29.661008834838867\n",
            "Train_MaxReturn : 90.74897003173828\n",
            "Train_MinReturn : -132.75755310058594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1052100\n",
            "TimeSinceStart : 826.6105215549469\n",
            "Training Loss : -1984.90576171875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.5523858070373535\n",
            "Eval_StdReturn : 9.470925331115723\n",
            "Eval_MaxReturn : 5.05438232421875\n",
            "Eval_MinReturn : -17.773639678955078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -15.730375289916992\n",
            "Train_StdReturn : 26.56035614013672\n",
            "Train_MaxReturn : 73.5045166015625\n",
            "Train_MinReturn : -84.11933898925781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1102200\n",
            "TimeSinceStart : 865.8873243331909\n",
            "Training Loss : -1035.2139892578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.030429840087891\n",
            "Eval_StdReturn : 13.817217826843262\n",
            "Eval_MaxReturn : 14.177885055541992\n",
            "Eval_MinReturn : -15.505147933959961\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.41658878326416\n",
            "Train_StdReturn : 27.229320526123047\n",
            "Train_MaxReturn : 61.98117446899414\n",
            "Train_MinReturn : -105.13160705566406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1152300\n",
            "TimeSinceStart : 905.3334264755249\n",
            "Training Loss : -1509.32177734375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.9450042247772217\n",
            "Eval_StdReturn : 20.298006057739258\n",
            "Eval_MaxReturn : 20.438961029052734\n",
            "Eval_MinReturn : -25.511987686157227\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.389975547790527\n",
            "Train_StdReturn : 31.236997604370117\n",
            "Train_MaxReturn : 64.45250701904297\n",
            "Train_MinReturn : -120.51625061035156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1202400\n",
            "TimeSinceStart : 944.674111366272\n",
            "Training Loss : -1303.9208984375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.099092960357666\n",
            "Eval_StdReturn : 23.58642578125\n",
            "Eval_MaxReturn : 35.44257354736328\n",
            "Eval_MinReturn : -22.069902420043945\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -4.6656646728515625\n",
            "Train_StdReturn : 28.955766677856445\n",
            "Train_MaxReturn : 71.91246032714844\n",
            "Train_MinReturn : -96.85025787353516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1252500\n",
            "TimeSinceStart : 983.9128079414368\n",
            "Training Loss : -893.8739013671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.6579647064209\n",
            "Eval_StdReturn : 9.291010856628418\n",
            "Eval_MaxReturn : 40.568302154541016\n",
            "Eval_MinReturn : 18.83985710144043\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -2.272132635116577\n",
            "Train_StdReturn : 31.936368942260742\n",
            "Train_MaxReturn : 91.16259765625\n",
            "Train_MinReturn : -118.06306457519531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1302600\n",
            "TimeSinceStart : 1023.350572347641\n",
            "Training Loss : -401.62725830078125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.845890522003174\n",
            "Eval_StdReturn : 17.65096092224121\n",
            "Eval_MaxReturn : 30.042686462402344\n",
            "Eval_MinReturn : -11.564842224121094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.8832931518554688\n",
            "Train_StdReturn : 36.639705657958984\n",
            "Train_MaxReturn : 105.72615051269531\n",
            "Train_MinReturn : -174.9345245361328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1352700\n",
            "TimeSinceStart : 1062.6552374362946\n",
            "Training Loss : -844.6216430664062\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 18.020307540893555\n",
            "Eval_StdReturn : 34.53672409057617\n",
            "Eval_MaxReturn : 53.645172119140625\n",
            "Eval_MinReturn : -28.728775024414062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 10.0948486328125\n",
            "Train_StdReturn : 39.07035446166992\n",
            "Train_MaxReturn : 97.61548614501953\n",
            "Train_MinReturn : -165.37472534179688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1402800\n",
            "TimeSinceStart : 1101.7332966327667\n",
            "Training Loss : -954.1546630859375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 62.64412307739258\n",
            "Eval_StdReturn : 54.77564239501953\n",
            "Eval_MaxReturn : 139.5732421875\n",
            "Eval_MinReturn : 16.306209564208984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 11.82836627960205\n",
            "Train_StdReturn : 45.105987548828125\n",
            "Train_MaxReturn : 99.82707214355469\n",
            "Train_MinReturn : -148.77755737304688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1452900\n",
            "TimeSinceStart : 1141.2743563652039\n",
            "Training Loss : -523.8895263671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.020245552062988\n",
            "Eval_StdReturn : 28.864852905273438\n",
            "Eval_MaxReturn : 39.29292678833008\n",
            "Eval_MinReturn : -27.920469284057617\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 6.972291469573975\n",
            "Train_StdReturn : 45.00685119628906\n",
            "Train_MaxReturn : 122.7352066040039\n",
            "Train_MinReturn : -160.29815673828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1503000\n",
            "TimeSinceStart : 1180.3752994537354\n",
            "Training Loss : -1142.500244140625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.012224197387695\n",
            "Eval_StdReturn : 36.19933319091797\n",
            "Eval_MaxReturn : 51.99988555908203\n",
            "Eval_MinReturn : -33.513397216796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 10.532174110412598\n",
            "Train_StdReturn : 42.76934051513672\n",
            "Train_MaxReturn : 113.74528503417969\n",
            "Train_MinReturn : -133.52877807617188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1553100\n",
            "TimeSinceStart : 1219.6928324699402\n",
            "Training Loss : -577.5655517578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.74201202392578\n",
            "Eval_StdReturn : 28.57909393310547\n",
            "Eval_MaxReturn : 51.58148193359375\n",
            "Eval_MinReturn : -14.092187881469727\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 13.184062004089355\n",
            "Train_StdReturn : 42.504730224609375\n",
            "Train_MaxReturn : 125.14566802978516\n",
            "Train_MinReturn : -159.5342254638672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1603200\n",
            "TimeSinceStart : 1259.0787205696106\n",
            "Training Loss : -505.73126220703125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.623623847961426\n",
            "Eval_StdReturn : 25.372602462768555\n",
            "Eval_MaxReturn : 37.821083068847656\n",
            "Eval_MinReturn : -20.682947158813477\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 14.093694686889648\n",
            "Train_StdReturn : 37.483577728271484\n",
            "Train_MaxReturn : 134.66656494140625\n",
            "Train_MinReturn : -153.4318389892578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1653300\n",
            "TimeSinceStart : 1298.4673817157745\n",
            "Training Loss : -1349.118408203125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.726499080657959\n",
            "Eval_StdReturn : 19.476215362548828\n",
            "Eval_MaxReturn : 26.06841278076172\n",
            "Eval_MinReturn : -21.023466110229492\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 18.534982681274414\n",
            "Train_StdReturn : 29.700969696044922\n",
            "Train_MaxReturn : 104.66181945800781\n",
            "Train_MinReturn : -106.64070129394531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1703400\n",
            "TimeSinceStart : 1337.9820330142975\n",
            "Training Loss : -1998.41796875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 23.467758178710938\n",
            "Eval_StdReturn : 27.39882469177246\n",
            "Eval_MaxReturn : 56.14765930175781\n",
            "Eval_MinReturn : -10.901653289794922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 12.75095272064209\n",
            "Train_StdReturn : 26.813434600830078\n",
            "Train_MaxReturn : 85.99472045898438\n",
            "Train_MinReturn : -102.65876770019531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1753500\n",
            "TimeSinceStart : 1377.7560503482819\n",
            "Training Loss : -1652.145263671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.5861189961433411\n",
            "Eval_StdReturn : 4.975551128387451\n",
            "Eval_MaxReturn : 4.282011032104492\n",
            "Eval_MinReturn : -7.420200347900391\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 15.312129020690918\n",
            "Train_StdReturn : 24.91196632385254\n",
            "Train_MaxReturn : 83.6295166015625\n",
            "Train_MinReturn : -140.17515563964844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1803600\n",
            "TimeSinceStart : 1417.181781053543\n",
            "Training Loss : -1355.601806640625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 24.117464065551758\n",
            "Eval_StdReturn : 14.148940086364746\n",
            "Eval_MaxReturn : 41.49885940551758\n",
            "Eval_MinReturn : 6.841657638549805\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 18.046161651611328\n",
            "Train_StdReturn : 27.99387550354004\n",
            "Train_MaxReturn : 90.32991790771484\n",
            "Train_MinReturn : -112.68721008300781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1853700\n",
            "TimeSinceStart : 1456.8208684921265\n",
            "Training Loss : -1835.284912109375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 18.563100814819336\n",
            "Eval_StdReturn : 10.68502426147461\n",
            "Eval_MaxReturn : 33.661415100097656\n",
            "Eval_MinReturn : 10.47978687286377\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 18.592466354370117\n",
            "Train_StdReturn : 33.53447723388672\n",
            "Train_MaxReturn : 96.55946350097656\n",
            "Train_MinReturn : -117.600830078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1903800\n",
            "TimeSinceStart : 1496.1797835826874\n",
            "Training Loss : -2481.495849609375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 55.03065490722656\n",
            "Eval_StdReturn : 22.607629776000977\n",
            "Eval_MaxReturn : 80.91778564453125\n",
            "Eval_MinReturn : 25.83748435974121\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 23.38790512084961\n",
            "Train_StdReturn : 37.98493957519531\n",
            "Train_MaxReturn : 95.47067260742188\n",
            "Train_MinReturn : -140.57254028320312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1953900\n",
            "TimeSinceStart : 1535.4505319595337\n",
            "Training Loss : -2133.0390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 18.17633628845215\n",
            "Eval_StdReturn : 15.250816345214844\n",
            "Eval_MaxReturn : 32.59143829345703\n",
            "Eval_MinReturn : -2.924907684326172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 29.39967155456543\n",
            "Train_StdReturn : 39.44051742553711\n",
            "Train_MaxReturn : 137.10581970214844\n",
            "Train_MinReturn : -120.422607421875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2004000\n",
            "TimeSinceStart : 1574.6555976867676\n",
            "Training Loss : -1461.8729248046875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 75.6862564086914\n",
            "Eval_StdReturn : 49.54822540283203\n",
            "Eval_MaxReturn : 144.9217071533203\n",
            "Eval_MinReturn : 31.720844268798828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 37.76325607299805\n",
            "Train_StdReturn : 44.690879821777344\n",
            "Train_MaxReturn : 138.2750244140625\n",
            "Train_MinReturn : -122.82601928710938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2054100\n",
            "TimeSinceStart : 1614.2500030994415\n",
            "Training Loss : -1485.102783203125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 73.32831573486328\n",
            "Eval_StdReturn : 24.989181518554688\n",
            "Eval_MaxReturn : 103.1419677734375\n",
            "Eval_MinReturn : 41.988338470458984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 49.06055450439453\n",
            "Train_StdReturn : 50.792938232421875\n",
            "Train_MaxReturn : 176.1226348876953\n",
            "Train_MinReturn : -169.42361450195312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2104200\n",
            "TimeSinceStart : 1653.6439862251282\n",
            "Training Loss : -1378.724853515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 63.06639099121094\n",
            "Eval_StdReturn : 23.031635284423828\n",
            "Eval_MaxReturn : 95.49627685546875\n",
            "Eval_MinReturn : 44.22250747680664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 54.6767692565918\n",
            "Train_StdReturn : 45.000125885009766\n",
            "Train_MaxReturn : 160.2479248046875\n",
            "Train_MinReturn : -157.33056640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2154300\n",
            "TimeSinceStart : 1693.0456438064575\n",
            "Training Loss : -1846.049560546875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 81.43170928955078\n",
            "Eval_StdReturn : 10.492514610290527\n",
            "Eval_MaxReturn : 90.12498474121094\n",
            "Eval_MinReturn : 66.67068481445312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 59.39012145996094\n",
            "Train_StdReturn : 42.440757751464844\n",
            "Train_MaxReturn : 154.71920776367188\n",
            "Train_MinReturn : -143.2376708984375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2204400\n",
            "TimeSinceStart : 1732.357304096222\n",
            "Training Loss : -2215.4228515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 104.00345611572266\n",
            "Eval_StdReturn : 33.62076187133789\n",
            "Eval_MaxReturn : 149.73768615722656\n",
            "Eval_MinReturn : 69.8749771118164\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 73.91575622558594\n",
            "Train_StdReturn : 34.14316177368164\n",
            "Train_MaxReturn : 160.7733612060547\n",
            "Train_MinReturn : -106.47209930419922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2254500\n",
            "TimeSinceStart : 1771.621527671814\n",
            "Training Loss : -2056.670166015625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 101.08843994140625\n",
            "Eval_StdReturn : 13.675825119018555\n",
            "Eval_MaxReturn : 118.63893127441406\n",
            "Eval_MinReturn : 85.27561950683594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 80.21522521972656\n",
            "Train_StdReturn : 45.62104034423828\n",
            "Train_MaxReturn : 185.4398193359375\n",
            "Train_MinReturn : -149.214111328125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2304600\n",
            "TimeSinceStart : 1811.0156667232513\n",
            "Training Loss : -2307.44140625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 69.28907012939453\n",
            "Eval_StdReturn : 22.320072174072266\n",
            "Eval_MaxReturn : 91.35913848876953\n",
            "Eval_MinReturn : 38.71017837524414\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 92.07046508789062\n",
            "Train_StdReturn : 44.168914794921875\n",
            "Train_MaxReturn : 195.99169921875\n",
            "Train_MinReturn : -150.59576416015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2354700\n",
            "TimeSinceStart : 1850.3679780960083\n",
            "Training Loss : -2197.3779296875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 118.35906982421875\n",
            "Eval_StdReturn : 19.69780921936035\n",
            "Eval_MaxReturn : 142.43307495117188\n",
            "Eval_MinReturn : 94.1838150024414\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 98.67821502685547\n",
            "Train_StdReturn : 53.270668029785156\n",
            "Train_MaxReturn : 198.52313232421875\n",
            "Train_MinReturn : -163.98187255859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2404800\n",
            "TimeSinceStart : 1889.444147825241\n",
            "Training Loss : -992.2275390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 99.99786376953125\n",
            "Eval_StdReturn : 11.271444320678711\n",
            "Eval_MaxReturn : 113.67574310302734\n",
            "Eval_MinReturn : 86.06985473632812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 101.69271850585938\n",
            "Train_StdReturn : 59.45830535888672\n",
            "Train_MaxReturn : 216.66891479492188\n",
            "Train_MinReturn : -187.78123474121094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2454900\n",
            "TimeSinceStart : 1928.5608041286469\n",
            "Training Loss : -1543.003662109375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 103.1441421508789\n",
            "Eval_StdReturn : 4.092787742614746\n",
            "Eval_MaxReturn : 108.43276977539062\n",
            "Eval_MinReturn : 98.46287536621094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 106.50410461425781\n",
            "Train_StdReturn : 49.89110565185547\n",
            "Train_MaxReturn : 199.38238525390625\n",
            "Train_MinReturn : -193.8120880126953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2505000\n",
            "TimeSinceStart : 1967.8787546157837\n",
            "Training Loss : -1930.338134765625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 132.5269775390625\n",
            "Eval_StdReturn : 15.104161262512207\n",
            "Eval_MaxReturn : 153.64627075195312\n",
            "Eval_MinReturn : 119.19514465332031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 109.76368713378906\n",
            "Train_StdReturn : 32.136497497558594\n",
            "Train_MaxReturn : 195.64678955078125\n",
            "Train_MinReturn : -133.83396911621094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2555100\n",
            "TimeSinceStart : 2007.4169762134552\n",
            "Training Loss : -2541.35595703125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 123.21514129638672\n",
            "Eval_StdReturn : 22.62515640258789\n",
            "Eval_MaxReturn : 154.216796875\n",
            "Eval_MinReturn : 100.85723876953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 116.51736450195312\n",
            "Train_StdReturn : 29.301612854003906\n",
            "Train_MaxReturn : 211.48333740234375\n",
            "Train_MinReturn : -139.8239288330078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2605200\n",
            "TimeSinceStart : 2047.0346829891205\n",
            "Training Loss : -2690.87451171875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 122.41339111328125\n",
            "Eval_StdReturn : 19.555416107177734\n",
            "Eval_MaxReturn : 143.71018981933594\n",
            "Eval_MinReturn : 96.4857177734375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 123.92700958251953\n",
            "Train_StdReturn : 44.259429931640625\n",
            "Train_MaxReturn : 224.3177490234375\n",
            "Train_MinReturn : -188.15367126464844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2655300\n",
            "TimeSinceStart : 2086.603146791458\n",
            "Training Loss : -2468.05322265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 162.03236389160156\n",
            "Eval_StdReturn : 14.667354583740234\n",
            "Eval_MaxReturn : 175.96615600585938\n",
            "Eval_MinReturn : 141.7581787109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 124.91097259521484\n",
            "Train_StdReturn : 56.32500457763672\n",
            "Train_MaxReturn : 234.96974182128906\n",
            "Train_MinReturn : -187.54312133789062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2705400\n",
            "TimeSinceStart : 2125.7273297309875\n",
            "Training Loss : -1378.7325439453125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 207.7733917236328\n",
            "Eval_StdReturn : 31.69074058532715\n",
            "Eval_MaxReturn : 251.51724243164062\n",
            "Eval_MinReturn : 177.45687866210938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 133.7721405029297\n",
            "Train_StdReturn : 43.2649040222168\n",
            "Train_MaxReturn : 233.15866088867188\n",
            "Train_MinReturn : -147.52340698242188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2755500\n",
            "TimeSinceStart : 2165.151683330536\n",
            "Training Loss : -1706.4111328125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 135.0128631591797\n",
            "Eval_StdReturn : 15.229169845581055\n",
            "Eval_MaxReturn : 154.02938842773438\n",
            "Eval_MinReturn : 116.74844360351562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 140.83395385742188\n",
            "Train_StdReturn : 37.864627838134766\n",
            "Train_MaxReturn : 237.85372924804688\n",
            "Train_MinReturn : -153.9114990234375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2805600\n",
            "TimeSinceStart : 2204.55100941658\n",
            "Training Loss : -1810.6649169921875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 125.54073333740234\n",
            "Eval_StdReturn : 56.70438766479492\n",
            "Eval_MaxReturn : 184.3604736328125\n",
            "Eval_MinReturn : 48.926414489746094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 134.80751037597656\n",
            "Train_StdReturn : 43.52346420288086\n",
            "Train_MaxReturn : 225.02944946289062\n",
            "Train_MinReturn : -175.6920623779297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2855700\n",
            "TimeSinceStart : 2243.755382299423\n",
            "Training Loss : -1571.77197265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 133.96775817871094\n",
            "Eval_StdReturn : 40.70933532714844\n",
            "Eval_MaxReturn : 186.80026245117188\n",
            "Eval_MinReturn : 87.74191284179688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 128.4447479248047\n",
            "Train_StdReturn : 34.658077239990234\n",
            "Train_MaxReturn : 216.58798217773438\n",
            "Train_MinReturn : -57.78264617919922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2905800\n",
            "TimeSinceStart : 2283.010739803314\n",
            "Training Loss : -1387.8599853515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 142.13619995117188\n",
            "Eval_StdReturn : 17.05266761779785\n",
            "Eval_MaxReturn : 156.27188110351562\n",
            "Eval_MinReturn : 118.14715576171875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 132.55442810058594\n",
            "Train_StdReturn : 39.23650360107422\n",
            "Train_MaxReturn : 234.07022094726562\n",
            "Train_MinReturn : -136.99070739746094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2955900\n",
            "TimeSinceStart : 2322.490510702133\n",
            "Training Loss : -1453.540283203125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 158.90744018554688\n",
            "Eval_StdReturn : 13.64676284790039\n",
            "Eval_MaxReturn : 176.7511749267578\n",
            "Eval_MinReturn : 143.61752319335938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 145.62142944335938\n",
            "Train_StdReturn : 43.855140686035156\n",
            "Train_MaxReturn : 260.7142333984375\n",
            "Train_MinReturn : -128.77291870117188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3006000\n",
            "TimeSinceStart : 2361.759160757065\n",
            "Training Loss : -2053.14794921875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 180.82215881347656\n",
            "Eval_StdReturn : 37.230377197265625\n",
            "Eval_MaxReturn : 220.58078002929688\n",
            "Eval_MinReturn : 131.04986572265625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 141.58966064453125\n",
            "Train_StdReturn : 57.684383392333984\n",
            "Train_MaxReturn : 261.0968017578125\n",
            "Train_MinReturn : -150.57546997070312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3056100\n",
            "TimeSinceStart : 2400.9359259605408\n",
            "Training Loss : -1520.2252197265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 112.9372787475586\n",
            "Eval_StdReturn : 36.2547607421875\n",
            "Eval_MaxReturn : 163.35733032226562\n",
            "Eval_MinReturn : 79.66654968261719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 141.61883544921875\n",
            "Train_StdReturn : 68.1297836303711\n",
            "Train_MaxReturn : 297.8356018066406\n",
            "Train_MinReturn : -160.0142822265625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3106200\n",
            "TimeSinceStart : 2439.881100177765\n",
            "Training Loss : -1835.1387939453125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 155.51243591308594\n",
            "Eval_StdReturn : 33.85904312133789\n",
            "Eval_MaxReturn : 182.10299682617188\n",
            "Eval_MinReturn : 107.73008728027344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 141.36903381347656\n",
            "Train_StdReturn : 103.04177856445312\n",
            "Train_MaxReturn : 293.701904296875\n",
            "Train_MinReturn : -172.3541259765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3156300\n",
            "TimeSinceStart : 2478.8352031707764\n",
            "Training Loss : -1392.6083984375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 142.73284912109375\n",
            "Eval_StdReturn : 38.66360092163086\n",
            "Eval_MaxReturn : 183.82183837890625\n",
            "Eval_MinReturn : 90.946044921875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 157.10635375976562\n",
            "Train_StdReturn : 80.85948944091797\n",
            "Train_MaxReturn : 362.87005615234375\n",
            "Train_MinReturn : -156.63546752929688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3206400\n",
            "TimeSinceStart : 2518.0649869441986\n",
            "Training Loss : -1209.6644287109375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 129.18704223632812\n",
            "Eval_StdReturn : 14.896696090698242\n",
            "Eval_MaxReturn : 149.484619140625\n",
            "Eval_MinReturn : 114.15219116210938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 163.6449432373047\n",
            "Train_StdReturn : 40.69835662841797\n",
            "Train_MaxReturn : 286.3619689941406\n",
            "Train_MinReturn : -4.622596740722656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3256500\n",
            "TimeSinceStart : 2557.3044929504395\n",
            "Training Loss : -1165.3328857421875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 143.04884338378906\n",
            "Eval_StdReturn : 6.3225789070129395\n",
            "Eval_MaxReturn : 150.89828491210938\n",
            "Eval_MinReturn : 135.4157257080078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 132.41156005859375\n",
            "Train_StdReturn : 35.971824645996094\n",
            "Train_MaxReturn : 257.9166564941406\n",
            "Train_MinReturn : 52.40953826904297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3306600\n",
            "TimeSinceStart : 2596.6077575683594\n",
            "Training Loss : -1061.05712890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 180.42449951171875\n",
            "Eval_StdReturn : 52.63800811767578\n",
            "Eval_MaxReturn : 237.03048706054688\n",
            "Eval_MinReturn : 110.25312042236328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 164.4911651611328\n",
            "Train_StdReturn : 33.641380310058594\n",
            "Train_MaxReturn : 266.2153625488281\n",
            "Train_MinReturn : 50.64585494995117\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3356700\n",
            "TimeSinceStart : 2636.1169443130493\n",
            "Training Loss : -1455.2188720703125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 152.9734649658203\n",
            "Eval_StdReturn : 21.367361068725586\n",
            "Eval_MaxReturn : 182.6143798828125\n",
            "Eval_MinReturn : 133.06298828125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 173.82749938964844\n",
            "Train_StdReturn : 37.42767333984375\n",
            "Train_MaxReturn : 259.723876953125\n",
            "Train_MinReturn : -107.55400848388672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3406800\n",
            "TimeSinceStart : 2675.1456246376038\n",
            "Training Loss : -720.6109619140625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 169.8379669189453\n",
            "Eval_StdReturn : 17.769603729248047\n",
            "Eval_MaxReturn : 185.48892211914062\n",
            "Eval_MinReturn : 144.98533630371094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 172.09698486328125\n",
            "Train_StdReturn : 44.64430236816406\n",
            "Train_MaxReturn : 263.0771484375\n",
            "Train_MinReturn : -116.81612396240234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3456900\n",
            "TimeSinceStart : 2714.2572391033173\n",
            "Training Loss : -800.9539184570312\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 205.42222595214844\n",
            "Eval_StdReturn : 43.491233825683594\n",
            "Eval_MaxReturn : 253.61196899414062\n",
            "Eval_MinReturn : 148.22837829589844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 179.55856323242188\n",
            "Train_StdReturn : 47.36708450317383\n",
            "Train_MaxReturn : 299.35662841796875\n",
            "Train_MinReturn : -53.056270599365234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3507000\n",
            "TimeSinceStart : 2753.936851501465\n",
            "Training Loss : -1249.7877197265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 179.6112518310547\n",
            "Eval_StdReturn : 11.945040702819824\n",
            "Eval_MaxReturn : 194.32986450195312\n",
            "Eval_MinReturn : 165.072265625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 163.3375701904297\n",
            "Train_StdReturn : 61.74114990234375\n",
            "Train_MaxReturn : 265.1884460449219\n",
            "Train_MinReturn : -126.87229919433594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3557100\n",
            "TimeSinceStart : 2793.175229072571\n",
            "Training Loss : -1107.267578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 132.49278259277344\n",
            "Eval_StdReturn : 6.330327033996582\n",
            "Eval_MaxReturn : 139.2538604736328\n",
            "Eval_MinReturn : 124.0303726196289\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 157.40652465820312\n",
            "Train_StdReturn : 69.28445434570312\n",
            "Train_MaxReturn : 290.1819763183594\n",
            "Train_MinReturn : -151.24595642089844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3607200\n",
            "TimeSinceStart : 2832.498476743698\n",
            "Training Loss : -579.9053955078125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 145.5149383544922\n",
            "Eval_StdReturn : 26.484155654907227\n",
            "Eval_MaxReturn : 175.30181884765625\n",
            "Eval_MinReturn : 110.95751953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 150.83331298828125\n",
            "Train_StdReturn : 52.895416259765625\n",
            "Train_MaxReturn : 250.81744384765625\n",
            "Train_MinReturn : -127.17778015136719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3657300\n",
            "TimeSinceStart : 2872.0655624866486\n",
            "Training Loss : -1483.712890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 150.96751403808594\n",
            "Eval_StdReturn : 28.925437927246094\n",
            "Eval_MaxReturn : 186.22509765625\n",
            "Eval_MinReturn : 115.37490844726562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 125.8375244140625\n",
            "Train_StdReturn : 35.985260009765625\n",
            "Train_MaxReturn : 235.13636779785156\n",
            "Train_MinReturn : -145.94845581054688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3707400\n",
            "TimeSinceStart : 2911.834358215332\n",
            "Training Loss : -992.0685424804688\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 193.6422882080078\n",
            "Eval_StdReturn : 39.11333084106445\n",
            "Eval_MaxReturn : 248.29641723632812\n",
            "Eval_MinReturn : 158.93463134765625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 143.21563720703125\n",
            "Train_StdReturn : 26.911224365234375\n",
            "Train_MaxReturn : 223.17575073242188\n",
            "Train_MinReturn : 19.666168212890625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3757500\n",
            "TimeSinceStart : 2951.3731124401093\n",
            "Training Loss : -1973.6497802734375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 162.79083251953125\n",
            "Eval_StdReturn : 16.588237762451172\n",
            "Eval_MaxReturn : 175.52670288085938\n",
            "Eval_MinReturn : 139.3611602783203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 167.83035278320312\n",
            "Train_StdReturn : 38.40837097167969\n",
            "Train_MaxReturn : 270.7810363769531\n",
            "Train_MinReturn : -103.7896728515625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3807600\n",
            "TimeSinceStart : 2990.5591249465942\n",
            "Training Loss : -1172.41357421875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 166.8798370361328\n",
            "Eval_StdReturn : 15.684171676635742\n",
            "Eval_MaxReturn : 185.0562744140625\n",
            "Eval_MinReturn : 146.78240966796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 179.02088928222656\n",
            "Train_StdReturn : 34.395477294921875\n",
            "Train_MaxReturn : 278.4964599609375\n",
            "Train_MinReturn : 16.434696197509766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3857700\n",
            "TimeSinceStart : 3030.0831713676453\n",
            "Training Loss : -737.2460327148438\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 229.4122314453125\n",
            "Eval_StdReturn : 15.786286354064941\n",
            "Eval_MaxReturn : 251.0194091796875\n",
            "Eval_MinReturn : 213.74473571777344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 182.9827117919922\n",
            "Train_StdReturn : 31.116981506347656\n",
            "Train_MaxReturn : 269.0562744140625\n",
            "Train_MinReturn : 60.96675491333008\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3907800\n",
            "TimeSinceStart : 3069.3278431892395\n",
            "Training Loss : -1381.577880859375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 213.95970153808594\n",
            "Eval_StdReturn : 6.889412879943848\n",
            "Eval_MaxReturn : 223.2715301513672\n",
            "Eval_MinReturn : 206.8211669921875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 204.69964599609375\n",
            "Train_StdReturn : 33.354888916015625\n",
            "Train_MaxReturn : 286.0051574707031\n",
            "Train_MinReturn : 108.95186614990234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3957900\n",
            "TimeSinceStart : 3108.6562502384186\n",
            "Training Loss : -894.3767700195312\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.869873046875\n",
            "Eval_StdReturn : 47.458614349365234\n",
            "Eval_MaxReturn : 269.17974853515625\n",
            "Eval_MinReturn : 167.7589111328125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 214.06565856933594\n",
            "Train_StdReturn : 35.19864273071289\n",
            "Train_MaxReturn : 321.7467041015625\n",
            "Train_MinReturn : 120.89602661132812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4008000\n",
            "TimeSinceStart : 3147.842632293701\n",
            "Training Loss : -662.5028076171875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 248.2313232421875\n",
            "Eval_StdReturn : 37.08485794067383\n",
            "Eval_MaxReturn : 279.8714294433594\n",
            "Eval_MinReturn : 196.18824768066406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 231.32284545898438\n",
            "Train_StdReturn : 36.67741775512695\n",
            "Train_MaxReturn : 314.53546142578125\n",
            "Train_MinReturn : 123.33008575439453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4058100\n",
            "TimeSinceStart : 3186.90913105011\n",
            "Training Loss : -1225.202880859375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 245.04541015625\n",
            "Eval_StdReturn : 5.379369735717773\n",
            "Eval_MaxReturn : 250.94476318359375\n",
            "Eval_MinReturn : 237.93585205078125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 250.1923828125\n",
            "Train_StdReturn : 39.114356994628906\n",
            "Train_MaxReturn : 362.6331787109375\n",
            "Train_MinReturn : 134.27894592285156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4108200\n",
            "TimeSinceStart : 3226.4597446918488\n",
            "Training Loss : -1119.5435791015625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 243.310791015625\n",
            "Eval_StdReturn : 18.504859924316406\n",
            "Eval_MaxReturn : 269.15399169921875\n",
            "Eval_MinReturn : 226.81968688964844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 249.0021514892578\n",
            "Train_StdReturn : 43.48446273803711\n",
            "Train_MaxReturn : 377.0555725097656\n",
            "Train_MinReturn : 132.95989990234375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4158300\n",
            "TimeSinceStart : 3265.7218141555786\n",
            "Training Loss : -1002.916015625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 197.8094024658203\n",
            "Eval_StdReturn : 6.999521255493164\n",
            "Eval_MaxReturn : 207.02798461914062\n",
            "Eval_MinReturn : 190.07708740234375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 206.0817108154297\n",
            "Train_StdReturn : 47.092987060546875\n",
            "Train_MaxReturn : 363.5843505859375\n",
            "Train_MinReturn : -16.781593322753906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4208400\n",
            "TimeSinceStart : 3305.316917181015\n",
            "Training Loss : -883.7464599609375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 149.9308624267578\n",
            "Eval_StdReturn : 29.957204818725586\n",
            "Eval_MaxReturn : 178.04937744140625\n",
            "Eval_MinReturn : 108.42779541015625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 178.7821044921875\n",
            "Train_StdReturn : 50.6837272644043\n",
            "Train_MaxReturn : 330.84283447265625\n",
            "Train_MinReturn : -37.174041748046875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4258500\n",
            "TimeSinceStart : 3344.732000350952\n",
            "Training Loss : -1190.317138671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 244.40855407714844\n",
            "Eval_StdReturn : 32.606563568115234\n",
            "Eval_MaxReturn : 287.8134765625\n",
            "Eval_MinReturn : 209.2230987548828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 179.87890625\n",
            "Train_StdReturn : 63.22596740722656\n",
            "Train_MaxReturn : 337.78057861328125\n",
            "Train_MinReturn : -98.30252838134766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4308600\n",
            "TimeSinceStart : 3384.123284339905\n",
            "Training Loss : -791.9573974609375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 195.230712890625\n",
            "Eval_StdReturn : 30.508899688720703\n",
            "Eval_MaxReturn : 219.16891479492188\n",
            "Eval_MinReturn : 152.17445373535156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 194.51219177246094\n",
            "Train_StdReturn : 49.46407699584961\n",
            "Train_MaxReturn : 308.1886291503906\n",
            "Train_MinReturn : -44.53984069824219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4358700\n",
            "TimeSinceStart : 3423.581033229828\n",
            "Training Loss : -589.73974609375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 217.325439453125\n",
            "Eval_StdReturn : 45.497066497802734\n",
            "Eval_MaxReturn : 257.6990051269531\n",
            "Eval_MinReturn : 153.7513885498047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 192.3201446533203\n",
            "Train_StdReturn : 54.2928352355957\n",
            "Train_MaxReturn : 336.6761474609375\n",
            "Train_MinReturn : -161.94351196289062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4408800\n",
            "TimeSinceStart : 3463.29261803627\n",
            "Training Loss : -1050.15087890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 186.08917236328125\n",
            "Eval_StdReturn : 4.076606750488281\n",
            "Eval_MaxReturn : 191.46490478515625\n",
            "Eval_MinReturn : 181.5973663330078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 201.69082641601562\n",
            "Train_StdReturn : 48.761863708496094\n",
            "Train_MaxReturn : 369.5498046875\n",
            "Train_MinReturn : -53.651588439941406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4458900\n",
            "TimeSinceStart : 3503.0375254154205\n",
            "Training Loss : -1045.341552734375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 143.99168395996094\n",
            "Eval_StdReturn : 78.4079818725586\n",
            "Eval_MaxReturn : 243.286865234375\n",
            "Eval_MinReturn : 51.59989547729492\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 184.03233337402344\n",
            "Train_StdReturn : 66.2149429321289\n",
            "Train_MaxReturn : 305.16827392578125\n",
            "Train_MinReturn : -112.67292022705078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4509000\n",
            "TimeSinceStart : 3542.470049381256\n",
            "Training Loss : -587.6572265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 155.09864807128906\n",
            "Eval_StdReturn : 101.64045715332031\n",
            "Eval_MaxReturn : 255.83921813964844\n",
            "Eval_MinReturn : 15.932659149169922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 178.69322204589844\n",
            "Train_StdReturn : 69.3718490600586\n",
            "Train_MaxReturn : 335.5603332519531\n",
            "Train_MinReturn : -74.26101684570312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4559100\n",
            "TimeSinceStart : 3581.6297600269318\n",
            "Training Loss : -1351.510498046875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 216.9578399658203\n",
            "Eval_StdReturn : 22.151958465576172\n",
            "Eval_MaxReturn : 248.01925659179688\n",
            "Eval_MinReturn : 197.89788818359375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 163.34228515625\n",
            "Train_StdReturn : 74.35813903808594\n",
            "Train_MaxReturn : 310.7862548828125\n",
            "Train_MinReturn : -101.28569030761719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4609200\n",
            "TimeSinceStart : 3621.19654917717\n",
            "Training Loss : -1188.897216796875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.2119140625\n",
            "Eval_StdReturn : 36.30388641357422\n",
            "Eval_MaxReturn : 285.10894775390625\n",
            "Eval_MinReturn : 202.92584228515625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 215.0791473388672\n",
            "Train_StdReturn : 63.294342041015625\n",
            "Train_MaxReturn : 347.92291259765625\n",
            "Train_MinReturn : -73.10953521728516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4659300\n",
            "TimeSinceStart : 3660.4223272800446\n",
            "Training Loss : -720.903564453125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 258.5502014160156\n",
            "Eval_StdReturn : 16.535348892211914\n",
            "Eval_MaxReturn : 271.4360656738281\n",
            "Eval_MinReturn : 235.2078094482422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 211.4421844482422\n",
            "Train_StdReturn : 57.8080940246582\n",
            "Train_MaxReturn : 323.801513671875\n",
            "Train_MinReturn : -60.36458969116211\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4709400\n",
            "TimeSinceStart : 3699.711634159088\n",
            "Training Loss : -889.9540405273438\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 125.3857192993164\n",
            "Eval_StdReturn : 75.16620635986328\n",
            "Eval_MaxReturn : 215.8027801513672\n",
            "Eval_MinReturn : 31.76744270324707\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 202.77220153808594\n",
            "Train_StdReturn : 64.64273071289062\n",
            "Train_MaxReturn : 321.7237548828125\n",
            "Train_MinReturn : -45.9039306640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4759500\n",
            "TimeSinceStart : 3738.9438354969025\n",
            "Training Loss : -789.0189819335938\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 182.19432067871094\n",
            "Eval_StdReturn : 48.9994010925293\n",
            "Eval_MaxReturn : 217.7589874267578\n",
            "Eval_MinReturn : 112.90685272216797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 206.79946899414062\n",
            "Train_StdReturn : 58.89923858642578\n",
            "Train_MaxReturn : 324.9888916015625\n",
            "Train_MinReturn : -9.190580368041992\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4809600\n",
            "TimeSinceStart : 3777.773550271988\n",
            "Training Loss : -392.58978271484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 115.42449951171875\n",
            "Eval_StdReturn : 108.17485809326172\n",
            "Eval_MaxReturn : 216.8689422607422\n",
            "Eval_MinReturn : -34.46661376953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 165.0544891357422\n",
            "Train_StdReturn : 76.72132110595703\n",
            "Train_MaxReturn : 290.4222717285156\n",
            "Train_MinReturn : -55.99414825439453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4859700\n",
            "TimeSinceStart : 3816.8773884773254\n",
            "Training Loss : -662.8187866210938\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 133.81971740722656\n",
            "Eval_StdReturn : 58.435890197753906\n",
            "Eval_MaxReturn : 203.38768005371094\n",
            "Eval_MinReturn : 60.40473556518555\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 152.1251983642578\n",
            "Train_StdReturn : 72.06037902832031\n",
            "Train_MaxReturn : 284.87445068359375\n",
            "Train_MinReturn : -49.7205810546875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4909800\n",
            "TimeSinceStart : 3855.8074657917023\n",
            "Training Loss : -542.56396484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 161.31932067871094\n",
            "Eval_StdReturn : 56.93960189819336\n",
            "Eval_MaxReturn : 201.71441650390625\n",
            "Eval_MinReturn : 80.7947006225586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 156.41036987304688\n",
            "Train_StdReturn : 56.477108001708984\n",
            "Train_MaxReturn : 281.82696533203125\n",
            "Train_MinReturn : -40.70872497558594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4959900\n",
            "TimeSinceStart : 3894.922805786133\n",
            "Training Loss : -530.7332763671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 215.6600341796875\n",
            "Eval_StdReturn : 5.072572231292725\n",
            "Eval_MaxReturn : 222.49356079101562\n",
            "Eval_MinReturn : 210.35287475585938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 179.90707397460938\n",
            "Train_StdReturn : 47.79106521606445\n",
            "Train_MaxReturn : 307.05712890625\n",
            "Train_MinReturn : 18.607200622558594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 5010000\n",
            "TimeSinceStart : 3934.2845838069916\n",
            "Training Loss : -416.034423828125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "    --discount 0.95 -n 100 -l 2 -s 32 \\\n",
        "    -b 50000 -lr 0.02 -rtg --nn_baseline \\\n",
        "    --exp_name q4_search_b50000_lr0.02_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "    --discount 0.95 -n 100 -l 2 -s 32 \\\n",
        "    -b 50000 -lr 0.02 \\\n",
        "    --exp_name q4_b50000_r0.02"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp1_YSNiT0kz",
        "outputId": "ae5f4b3b-da8e-446a-ff3d-fb5083ffca30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q4_b50000_r0.02_HalfCheetah-v2_10-05-2022_00-06-06\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -97.7901840209961\n",
            "Eval_StdReturn : 14.889198303222656\n",
            "Eval_MaxReturn : -77.41633605957031\n",
            "Eval_MinReturn : -112.58277130126953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -89.54405975341797\n",
            "Train_StdReturn : 39.07257843017578\n",
            "Train_MaxReturn : 11.764884948730469\n",
            "Train_MinReturn : -232.5586395263672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50100\n",
            "TimeSinceStart : 44.37355160713196\n",
            "Training Loss : -571.5072021484375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -85.6600341796875\n",
            "Eval_StdReturn : 15.252279281616211\n",
            "Eval_MaxReturn : -65.40022277832031\n",
            "Eval_MinReturn : -102.20110321044922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -86.80549621582031\n",
            "Train_StdReturn : 35.777992248535156\n",
            "Train_MaxReturn : 19.638397216796875\n",
            "Train_MinReturn : -198.58642578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100200\n",
            "TimeSinceStart : 89.39626741409302\n",
            "Training Loss : -498.39385986328125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -76.72884368896484\n",
            "Eval_StdReturn : 21.31686782836914\n",
            "Eval_MaxReturn : -46.58995056152344\n",
            "Eval_MinReturn : -92.38856506347656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -91.28012084960938\n",
            "Train_StdReturn : 36.307315826416016\n",
            "Train_MaxReturn : 4.355167865753174\n",
            "Train_MinReturn : -222.08041381835938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150300\n",
            "TimeSinceStart : 133.9695496559143\n",
            "Training Loss : -588.2470703125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -143.71946716308594\n",
            "Eval_StdReturn : 19.960432052612305\n",
            "Eval_MaxReturn : -118.48981475830078\n",
            "Eval_MinReturn : -167.29908752441406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -84.8157958984375\n",
            "Train_StdReturn : 36.3929328918457\n",
            "Train_MaxReturn : 9.800872802734375\n",
            "Train_MinReturn : -190.80715942382812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 200400\n",
            "TimeSinceStart : 178.6699719429016\n",
            "Training Loss : -552.4892578125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -75.63213348388672\n",
            "Eval_StdReturn : 14.519330978393555\n",
            "Eval_MaxReturn : -55.220733642578125\n",
            "Eval_MinReturn : -87.77366638183594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -88.08639526367188\n",
            "Train_StdReturn : 37.51164627075195\n",
            "Train_MaxReturn : 17.62173080444336\n",
            "Train_MinReturn : -201.45803833007812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 250500\n",
            "TimeSinceStart : 223.09916806221008\n",
            "Training Loss : -518.2181396484375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -67.49697875976562\n",
            "Eval_StdReturn : 16.981399536132812\n",
            "Eval_MaxReturn : -48.146915435791016\n",
            "Eval_MinReturn : -89.4900131225586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -85.64810180664062\n",
            "Train_StdReturn : 38.59474182128906\n",
            "Train_MaxReturn : 16.753536224365234\n",
            "Train_MinReturn : -189.9632568359375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300600\n",
            "TimeSinceStart : 267.66409158706665\n",
            "Training Loss : -605.533203125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -82.62177276611328\n",
            "Eval_StdReturn : 16.94109535217285\n",
            "Eval_MaxReturn : -59.77880859375\n",
            "Eval_MinReturn : -100.3002700805664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -87.11199951171875\n",
            "Train_StdReturn : 37.38660430908203\n",
            "Train_MaxReturn : 9.595748901367188\n",
            "Train_MinReturn : -212.6265106201172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 350700\n",
            "TimeSinceStart : 311.7130796909332\n",
            "Training Loss : 107.7259521484375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -90.5597152709961\n",
            "Eval_StdReturn : 37.52309036254883\n",
            "Eval_MaxReturn : -58.956886291503906\n",
            "Eval_MinReturn : -143.27886962890625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -91.32117462158203\n",
            "Train_StdReturn : 36.728580474853516\n",
            "Train_MaxReturn : 4.110898017883301\n",
            "Train_MinReturn : -212.34512329101562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 400800\n",
            "TimeSinceStart : 356.16336846351624\n",
            "Training Loss : -505.34375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -123.28141021728516\n",
            "Eval_StdReturn : 15.090493202209473\n",
            "Eval_MaxReturn : -101.9455337524414\n",
            "Eval_MinReturn : -134.3610076904297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -87.08943176269531\n",
            "Train_StdReturn : 31.838977813720703\n",
            "Train_MaxReturn : -1.5866012573242188\n",
            "Train_MinReturn : -180.63722229003906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450900\n",
            "TimeSinceStart : 400.70052337646484\n",
            "Training Loss : -567.6815185546875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -92.4422836303711\n",
            "Eval_StdReturn : 29.231924057006836\n",
            "Eval_MaxReturn : -62.486263275146484\n",
            "Eval_MinReturn : -132.09286499023438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -92.72537994384766\n",
            "Train_StdReturn : 26.375568389892578\n",
            "Train_MaxReturn : -6.924866199493408\n",
            "Train_MinReturn : -175.94500732421875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 501000\n",
            "TimeSinceStart : 445.1059341430664\n",
            "Training Loss : -730.9886474609375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -96.64676666259766\n",
            "Eval_StdReturn : 6.4148850440979\n",
            "Eval_MaxReturn : -88.89202880859375\n",
            "Eval_MinReturn : -104.60140991210938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -102.79937744140625\n",
            "Train_StdReturn : 29.310184478759766\n",
            "Train_MaxReturn : -12.64020824432373\n",
            "Train_MinReturn : -210.74588012695312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 551100\n",
            "TimeSinceStart : 489.9611189365387\n",
            "Training Loss : -1059.44921875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -75.88860321044922\n",
            "Eval_StdReturn : 11.828502655029297\n",
            "Eval_MaxReturn : -59.1766471862793\n",
            "Eval_MinReturn : -84.87954711914062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -105.37860107421875\n",
            "Train_StdReturn : 25.618127822875977\n",
            "Train_MaxReturn : -30.484651565551758\n",
            "Train_MinReturn : -207.84292602539062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 601200\n",
            "TimeSinceStart : 534.4495806694031\n",
            "Training Loss : -826.953369140625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -86.1169662475586\n",
            "Eval_StdReturn : 2.447026014328003\n",
            "Eval_MaxReturn : -83.73977661132812\n",
            "Eval_MinReturn : -89.48355102539062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -102.95704650878906\n",
            "Train_StdReturn : 25.00807762145996\n",
            "Train_MaxReturn : -39.224327087402344\n",
            "Train_MinReturn : -225.3703155517578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 651300\n",
            "TimeSinceStart : 579.1909396648407\n",
            "Training Loss : -588.6129150390625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -75.7724838256836\n",
            "Eval_StdReturn : 7.400720119476318\n",
            "Eval_MaxReturn : -66.3800048828125\n",
            "Eval_MinReturn : -84.46772003173828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -91.81562042236328\n",
            "Train_StdReturn : 24.023361206054688\n",
            "Train_MaxReturn : -29.505552291870117\n",
            "Train_MinReturn : -182.6969757080078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 701400\n",
            "TimeSinceStart : 623.6087944507599\n",
            "Training Loss : 181.908447265625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -72.21757507324219\n",
            "Eval_StdReturn : 13.238014221191406\n",
            "Eval_MaxReturn : -53.745697021484375\n",
            "Eval_MinReturn : -84.09165954589844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -84.86042785644531\n",
            "Train_StdReturn : 22.094900131225586\n",
            "Train_MaxReturn : -30.760757446289062\n",
            "Train_MinReturn : -167.10574340820312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 751500\n",
            "TimeSinceStart : 668.4759619235992\n",
            "Training Loss : -531.599853515625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.370792388916016\n",
            "Eval_StdReturn : 16.44194793701172\n",
            "Eval_MaxReturn : -42.057430267333984\n",
            "Eval_MinReturn : -82.24139404296875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -76.36531829833984\n",
            "Train_StdReturn : 24.30324363708496\n",
            "Train_MaxReturn : -24.277204513549805\n",
            "Train_MinReturn : -151.3170166015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 801600\n",
            "TimeSinceStart : 713.1184890270233\n",
            "Training Loss : -784.5342407226562\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -62.1867561340332\n",
            "Eval_StdReturn : 18.258514404296875\n",
            "Eval_MaxReturn : -39.185081481933594\n",
            "Eval_MinReturn : -83.84890747070312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -70.4148178100586\n",
            "Train_StdReturn : 22.262039184570312\n",
            "Train_MaxReturn : -6.031940460205078\n",
            "Train_MinReturn : -158.60903930664062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 851700\n",
            "TimeSinceStart : 757.762476682663\n",
            "Training Loss : -561.9639282226562\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -59.602962493896484\n",
            "Eval_StdReturn : 18.752267837524414\n",
            "Eval_MaxReturn : -42.55732727050781\n",
            "Eval_MinReturn : -85.71998596191406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -65.29353332519531\n",
            "Train_StdReturn : 20.921653747558594\n",
            "Train_MaxReturn : -11.897811889648438\n",
            "Train_MinReturn : -126.95145416259766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 901800\n",
            "TimeSinceStart : 802.1619319915771\n",
            "Training Loss : -504.82232666015625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.0735969543457\n",
            "Eval_StdReturn : 7.422009468078613\n",
            "Eval_MaxReturn : -51.365562438964844\n",
            "Eval_MinReturn : -69.38375091552734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -62.49382400512695\n",
            "Train_StdReturn : 19.818946838378906\n",
            "Train_MaxReturn : -14.333314895629883\n",
            "Train_MinReturn : -122.386474609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 951900\n",
            "TimeSinceStart : 846.7982485294342\n",
            "Training Loss : -693.29052734375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -82.84896087646484\n",
            "Eval_StdReturn : 26.778451919555664\n",
            "Eval_MaxReturn : -61.87179946899414\n",
            "Eval_MinReturn : -120.64317321777344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -60.033851623535156\n",
            "Train_StdReturn : 19.967151641845703\n",
            "Train_MaxReturn : -5.642092704772949\n",
            "Train_MinReturn : -138.269287109375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1002000\n",
            "TimeSinceStart : 891.582578420639\n",
            "Training Loss : -81.016845703125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -65.08129119873047\n",
            "Eval_StdReturn : 12.656798362731934\n",
            "Eval_MaxReturn : -47.585105895996094\n",
            "Eval_MinReturn : -77.10115051269531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -63.29451370239258\n",
            "Train_StdReturn : 21.37261390686035\n",
            "Train_MaxReturn : -11.333483695983887\n",
            "Train_MinReturn : -148.18380737304688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1052100\n",
            "TimeSinceStart : 936.298184633255\n",
            "Training Loss : -850.0941772460938\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -59.30255126953125\n",
            "Eval_StdReturn : 7.365180015563965\n",
            "Eval_MaxReturn : -53.82951354980469\n",
            "Eval_MinReturn : -69.71391296386719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -64.65786743164062\n",
            "Train_StdReturn : 22.257675170898438\n",
            "Train_MaxReturn : 3.755133867263794\n",
            "Train_MinReturn : -163.42117309570312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1102200\n",
            "TimeSinceStart : 980.753119468689\n",
            "Training Loss : -1010.8289794921875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -68.76689910888672\n",
            "Eval_StdReturn : 10.231732368469238\n",
            "Eval_MaxReturn : -59.76374816894531\n",
            "Eval_MinReturn : -83.07867431640625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -64.49359130859375\n",
            "Train_StdReturn : 20.292125701904297\n",
            "Train_MaxReturn : -5.766844749450684\n",
            "Train_MinReturn : -128.64991760253906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1152300\n",
            "TimeSinceStart : 1025.39834523201\n",
            "Training Loss : -824.0940551757812\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -67.57144927978516\n",
            "Eval_StdReturn : 1.2492913007736206\n",
            "Eval_MaxReturn : -65.81588745117188\n",
            "Eval_MinReturn : -68.62123107910156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -63.76778793334961\n",
            "Train_StdReturn : 19.297401428222656\n",
            "Train_MaxReturn : -6.2854204177856445\n",
            "Train_MinReturn : -124.51007843017578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1202400\n",
            "TimeSinceStart : 1070.0373497009277\n",
            "Training Loss : -735.0531005859375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.04726028442383\n",
            "Eval_StdReturn : 6.37631368637085\n",
            "Eval_MaxReturn : -31.79219627380371\n",
            "Eval_MinReturn : -46.02099609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -60.88268280029297\n",
            "Train_StdReturn : 19.740310668945312\n",
            "Train_MaxReturn : 1.1657657623291016\n",
            "Train_MinReturn : -127.51448822021484\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1252500\n",
            "TimeSinceStart : 1115.1847445964813\n",
            "Training Loss : -340.8319091796875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.157867431640625\n",
            "Eval_StdReturn : 7.425906658172607\n",
            "Eval_MaxReturn : -34.52601623535156\n",
            "Eval_MinReturn : -50.650238037109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -56.853294372558594\n",
            "Train_StdReturn : 21.12213897705078\n",
            "Train_MaxReturn : -4.365782260894775\n",
            "Train_MinReturn : -133.33460998535156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1302600\n",
            "TimeSinceStart : 1159.6356370449066\n",
            "Training Loss : -335.54736328125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -50.84200668334961\n",
            "Eval_StdReturn : 14.894076347351074\n",
            "Eval_MaxReturn : -29.901458740234375\n",
            "Eval_MinReturn : -63.27959060668945\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -54.52011489868164\n",
            "Train_StdReturn : 20.81255340576172\n",
            "Train_MaxReturn : 17.41420555114746\n",
            "Train_MinReturn : -141.18324279785156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1352700\n",
            "TimeSinceStart : 1204.2636404037476\n",
            "Training Loss : -539.6031494140625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -76.08158111572266\n",
            "Eval_StdReturn : 17.542768478393555\n",
            "Eval_MaxReturn : -52.85052490234375\n",
            "Eval_MinReturn : -95.23777770996094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.60871887207031\n",
            "Train_StdReturn : 20.962127685546875\n",
            "Train_MaxReturn : 11.086435317993164\n",
            "Train_MinReturn : -168.95590209960938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1402800\n",
            "TimeSinceStart : 1248.768059015274\n",
            "Training Loss : -679.58349609375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.971866607666016\n",
            "Eval_StdReturn : 13.463438034057617\n",
            "Eval_MaxReturn : -27.61050033569336\n",
            "Eval_MinReturn : -57.88454818725586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.1180305480957\n",
            "Train_StdReturn : 20.01578712463379\n",
            "Train_MaxReturn : -3.664980888366699\n",
            "Train_MinReturn : -148.0897216796875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1452900\n",
            "TimeSinceStart : 1293.0963180065155\n",
            "Training Loss : -230.6326904296875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.702884674072266\n",
            "Eval_StdReturn : 18.585052490234375\n",
            "Eval_MaxReturn : -35.57151794433594\n",
            "Eval_MinReturn : -79.93318176269531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -48.26066589355469\n",
            "Train_StdReturn : 19.4499568939209\n",
            "Train_MaxReturn : 8.883383750915527\n",
            "Train_MinReturn : -102.43730163574219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1503000\n",
            "TimeSinceStart : 1337.2681477069855\n",
            "Training Loss : -339.06549072265625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.230010986328125\n",
            "Eval_StdReturn : 17.84499168395996\n",
            "Eval_MaxReturn : -29.39293670654297\n",
            "Eval_MinReturn : -69.32795715332031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.52733612060547\n",
            "Train_StdReturn : 21.211061477661133\n",
            "Train_MaxReturn : 46.0829963684082\n",
            "Train_MinReturn : -127.205322265625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1553100\n",
            "TimeSinceStart : 1381.7531723976135\n",
            "Training Loss : -711.2573852539062\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -72.42084503173828\n",
            "Eval_StdReturn : 16.80239486694336\n",
            "Eval_MaxReturn : -53.99421310424805\n",
            "Eval_MinReturn : -94.62743377685547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.54068374633789\n",
            "Train_StdReturn : 18.72688102722168\n",
            "Train_MaxReturn : 5.656618118286133\n",
            "Train_MinReturn : -128.19493103027344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1603200\n",
            "TimeSinceStart : 1426.2260193824768\n",
            "Training Loss : -157.451171875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.294124603271484\n",
            "Eval_StdReturn : 20.09845733642578\n",
            "Eval_MaxReturn : -35.70185089111328\n",
            "Eval_MinReturn : -82.92362976074219\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -42.520973205566406\n",
            "Train_StdReturn : 21.446338653564453\n",
            "Train_MaxReturn : 12.643020629882812\n",
            "Train_MinReturn : -161.6624755859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1653300\n",
            "TimeSinceStart : 1470.873556137085\n",
            "Training Loss : -561.5519409179688\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.315553665161133\n",
            "Eval_StdReturn : 11.910130500793457\n",
            "Eval_MaxReturn : 7.01124382019043\n",
            "Eval_MinReturn : -22.14928436279297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.50468826293945\n",
            "Train_StdReturn : 22.961071014404297\n",
            "Train_MaxReturn : 23.806625366210938\n",
            "Train_MinReturn : -134.27020263671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1703400\n",
            "TimeSinceStart : 1515.6078443527222\n",
            "Training Loss : -583.9359130859375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.93141555786133\n",
            "Eval_StdReturn : 4.621330261230469\n",
            "Eval_MaxReturn : -32.752967834472656\n",
            "Eval_MinReturn : -43.97357940673828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.076866149902344\n",
            "Train_StdReturn : 24.104413986206055\n",
            "Train_MaxReturn : 40.844635009765625\n",
            "Train_MinReturn : -134.41989135742188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1753500\n",
            "TimeSinceStart : 1560.0552110671997\n",
            "Training Loss : -775.1504516601562\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -58.05122756958008\n",
            "Eval_StdReturn : 6.806836128234863\n",
            "Eval_MaxReturn : -51.31561279296875\n",
            "Eval_MinReturn : -67.37496948242188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.39194107055664\n",
            "Train_StdReturn : 24.719497680664062\n",
            "Train_MaxReturn : 24.286022186279297\n",
            "Train_MinReturn : -133.50575256347656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1803600\n",
            "TimeSinceStart : 1603.94602560997\n",
            "Training Loss : -86.60797119140625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.80426597595215\n",
            "Eval_StdReturn : 31.749542236328125\n",
            "Eval_MaxReturn : 9.289159774780273\n",
            "Eval_MinReturn : -66.63156127929688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.904754638671875\n",
            "Train_StdReturn : 28.552038192749023\n",
            "Train_MaxReturn : 43.650142669677734\n",
            "Train_MinReturn : -170.02029418945312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1853700\n",
            "TimeSinceStart : 1648.2933559417725\n",
            "Training Loss : 43.005889892578125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.555015563964844\n",
            "Eval_StdReturn : 30.320768356323242\n",
            "Eval_MaxReturn : 0.02910900115966797\n",
            "Eval_MinReturn : -68.98445129394531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.521907806396484\n",
            "Train_StdReturn : 27.86009407043457\n",
            "Train_MaxReturn : 44.61802291870117\n",
            "Train_MinReturn : -140.1576690673828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1903800\n",
            "TimeSinceStart : 1692.7819457054138\n",
            "Training Loss : 44.05853271484375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.372901916503906\n",
            "Eval_StdReturn : 26.081130981445312\n",
            "Eval_MaxReturn : 27.87889862060547\n",
            "Eval_MinReturn : -34.396728515625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.511531829833984\n",
            "Train_StdReturn : 29.877777099609375\n",
            "Train_MaxReturn : 49.78776550292969\n",
            "Train_MinReturn : -182.77734375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1953900\n",
            "TimeSinceStart : 1736.794715642929\n",
            "Training Loss : -855.9117431640625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.794063568115234\n",
            "Eval_StdReturn : 5.813432216644287\n",
            "Eval_MaxReturn : -26.945093154907227\n",
            "Eval_MinReturn : -41.15716552734375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.126270294189453\n",
            "Train_StdReturn : 26.696565628051758\n",
            "Train_MaxReturn : 55.86260986328125\n",
            "Train_MinReturn : -147.4801788330078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2004000\n",
            "TimeSinceStart : 1780.961971282959\n",
            "Training Loss : -981.5206298828125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.28764724731445\n",
            "Eval_StdReturn : 6.72676420211792\n",
            "Eval_MaxReturn : -35.844390869140625\n",
            "Eval_MinReturn : -51.00563049316406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.54923439025879\n",
            "Train_StdReturn : 20.759010314941406\n",
            "Train_MaxReturn : 49.120880126953125\n",
            "Train_MinReturn : -98.6336669921875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2054100\n",
            "TimeSinceStart : 1825.292929649353\n",
            "Training Loss : -815.1087646484375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.606437683105469\n",
            "Eval_StdReturn : 14.318023681640625\n",
            "Eval_MaxReturn : 8.532598495483398\n",
            "Eval_MinReturn : -23.49889373779297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.2161808013916\n",
            "Train_StdReturn : 19.92654037475586\n",
            "Train_MaxReturn : 30.627666473388672\n",
            "Train_MinReturn : -98.14459991455078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2104200\n",
            "TimeSinceStart : 1869.599066734314\n",
            "Training Loss : -207.85333251953125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.206987380981445\n",
            "Eval_StdReturn : 12.745588302612305\n",
            "Eval_MaxReturn : -6.550683975219727\n",
            "Eval_MinReturn : -37.50177001953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.900025367736816\n",
            "Train_StdReturn : 20.6613712310791\n",
            "Train_MaxReturn : 46.06294250488281\n",
            "Train_MinReturn : -92.1504898071289\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2154300\n",
            "TimeSinceStart : 1913.6838443279266\n",
            "Training Loss : -448.87677001953125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 17.827186584472656\n",
            "Eval_StdReturn : 11.785794258117676\n",
            "Eval_MaxReturn : 34.4425163269043\n",
            "Eval_MinReturn : 8.376935958862305\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.849943161010742\n",
            "Train_StdReturn : 22.06610870361328\n",
            "Train_MaxReturn : 65.16020202636719\n",
            "Train_MinReturn : -120.7240982055664\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2204400\n",
            "TimeSinceStart : 1957.812471628189\n",
            "Training Loss : -617.059326171875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.343244552612305\n",
            "Eval_StdReturn : 33.204837799072266\n",
            "Eval_MaxReturn : 18.042707443237305\n",
            "Eval_MinReturn : -62.64434814453125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -8.519819259643555\n",
            "Train_StdReturn : 21.497821807861328\n",
            "Train_MaxReturn : 66.342529296875\n",
            "Train_MinReturn : -74.2021484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2254500\n",
            "TimeSinceStart : 2002.0379660129547\n",
            "Training Loss : -893.2760009765625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.837620735168457\n",
            "Eval_StdReturn : 31.21245765686035\n",
            "Eval_MaxReturn : 34.73114013671875\n",
            "Eval_MinReturn : -34.177490234375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -6.371742248535156\n",
            "Train_StdReturn : 25.8502197265625\n",
            "Train_MaxReturn : 70.96780395507812\n",
            "Train_MinReturn : -113.51074981689453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2304600\n",
            "TimeSinceStart : 2046.1877732276917\n",
            "Training Loss : -807.24755859375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.920544624328613\n",
            "Eval_StdReturn : 23.206125259399414\n",
            "Eval_MaxReturn : 18.66490364074707\n",
            "Eval_MinReturn : -38.175376892089844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 1.2849541902542114\n",
            "Train_StdReturn : 26.8615779876709\n",
            "Train_MaxReturn : 78.82459259033203\n",
            "Train_MinReturn : -76.38461303710938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2354700\n",
            "TimeSinceStart : 2090.012732744217\n",
            "Training Loss : -405.4576721191406\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 21.634450912475586\n",
            "Eval_StdReturn : 52.5553092956543\n",
            "Eval_MaxReturn : 90.2392349243164\n",
            "Eval_MinReturn : -37.42936706542969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 9.403762817382812\n",
            "Train_StdReturn : 35.98603820800781\n",
            "Train_MaxReturn : 100.6748046875\n",
            "Train_MinReturn : -143.528076171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2404800\n",
            "TimeSinceStart : 2134.160012245178\n",
            "Training Loss : -590.0947875976562\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.081229567527771\n",
            "Eval_StdReturn : 6.574220180511475\n",
            "Eval_MaxReturn : 8.836095809936523\n",
            "Eval_MinReturn : -7.237724304199219\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.14266300201416\n",
            "Train_StdReturn : 39.20612335205078\n",
            "Train_MaxReturn : 121.91104888916016\n",
            "Train_MinReturn : -96.37408447265625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2454900\n",
            "TimeSinceStart : 2177.84956073761\n",
            "Training Loss : -931.1679077148438\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.9458974003791809\n",
            "Eval_StdReturn : 41.152565002441406\n",
            "Eval_MaxReturn : 42.77663803100586\n",
            "Eval_MinReturn : -56.07209014892578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -0.8787378668785095\n",
            "Train_StdReturn : 41.065773010253906\n",
            "Train_MaxReturn : 158.6473388671875\n",
            "Train_MinReturn : -116.28144836425781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2505000\n",
            "TimeSinceStart : 2221.855778694153\n",
            "Training Loss : -508.17138671875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.713727951049805\n",
            "Eval_StdReturn : 9.973541259765625\n",
            "Eval_MaxReturn : -10.937124252319336\n",
            "Eval_MinReturn : -35.32445526123047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.964269638061523\n",
            "Train_StdReturn : 45.7685661315918\n",
            "Train_MaxReturn : 107.35893249511719\n",
            "Train_MinReturn : -180.139892578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2555100\n",
            "TimeSinceStart : 2265.4643003940582\n",
            "Training Loss : 90.69976806640625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -5.297299861907959\n",
            "Eval_StdReturn : 30.534238815307617\n",
            "Eval_MaxReturn : 35.217159271240234\n",
            "Eval_MinReturn : -38.49453353881836\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.190208435058594\n",
            "Train_StdReturn : 42.606475830078125\n",
            "Train_MaxReturn : 123.5278091430664\n",
            "Train_MinReturn : -154.5050506591797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2605200\n",
            "TimeSinceStart : 2309.414517879486\n",
            "Training Loss : -425.69927978515625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.803863525390625\n",
            "Eval_StdReturn : 5.433721542358398\n",
            "Eval_MaxReturn : -20.74142837524414\n",
            "Eval_MinReturn : -33.95796203613281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.50786781311035\n",
            "Train_StdReturn : 47.101585388183594\n",
            "Train_MaxReturn : 137.922607421875\n",
            "Train_MinReturn : -167.36434936523438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2655300\n",
            "TimeSinceStart : 2353.544660806656\n",
            "Training Loss : -657.63671875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.975786209106445\n",
            "Eval_StdReturn : 30.218902587890625\n",
            "Eval_MaxReturn : 11.465829849243164\n",
            "Eval_MinReturn : -60.17262649536133\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.391151428222656\n",
            "Train_StdReturn : 46.29547882080078\n",
            "Train_MaxReturn : 100.92201232910156\n",
            "Train_MinReturn : -168.62451171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2705400\n",
            "TimeSinceStart : 2397.0737674236298\n",
            "Training Loss : -524.25341796875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 15.573832511901855\n",
            "Eval_StdReturn : 4.7333984375\n",
            "Eval_MaxReturn : 22.17840576171875\n",
            "Eval_MinReturn : 11.326930046081543\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.94384765625\n",
            "Train_StdReturn : 39.39863204956055\n",
            "Train_MaxReturn : 96.33657836914062\n",
            "Train_MinReturn : -204.48866271972656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2755500\n",
            "TimeSinceStart : 2441.04438996315\n",
            "Training Loss : -57.62371826171875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -50.533084869384766\n",
            "Eval_StdReturn : 10.673203468322754\n",
            "Eval_MaxReturn : -35.51533889770508\n",
            "Eval_MinReturn : -59.35586166381836\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.448139190673828\n",
            "Train_StdReturn : 37.65871047973633\n",
            "Train_MaxReturn : 71.32665252685547\n",
            "Train_MinReturn : -159.1644287109375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2805600\n",
            "TimeSinceStart : 2484.9371864795685\n",
            "Training Loss : -419.3837890625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.474151611328125\n",
            "Eval_StdReturn : 24.333845138549805\n",
            "Eval_MaxReturn : -4.093111038208008\n",
            "Eval_MinReturn : -56.9538459777832\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.843612670898438\n",
            "Train_StdReturn : 31.12778091430664\n",
            "Train_MaxReturn : 61.949806213378906\n",
            "Train_MinReturn : -131.422119140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2855700\n",
            "TimeSinceStart : 2529.098046064377\n",
            "Training Loss : -861.0786743164062\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.33955192565918\n",
            "Eval_StdReturn : 16.535133361816406\n",
            "Eval_MaxReturn : -10.363183975219727\n",
            "Eval_MinReturn : -50.77815246582031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.41132926940918\n",
            "Train_StdReturn : 26.542831420898438\n",
            "Train_MaxReturn : 39.137725830078125\n",
            "Train_MinReturn : -142.35389709472656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2905800\n",
            "TimeSinceStart : 2573.1520261764526\n",
            "Training Loss : -311.51611328125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.79986572265625\n",
            "Eval_StdReturn : 7.440520286560059\n",
            "Eval_MaxReturn : -18.65797996520996\n",
            "Eval_MinReturn : -36.299522399902344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.126096725463867\n",
            "Train_StdReturn : 22.870180130004883\n",
            "Train_MaxReturn : 31.863489151000977\n",
            "Train_MinReturn : -135.60855102539062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2955900\n",
            "TimeSinceStart : 2616.9705893993378\n",
            "Training Loss : -436.6689758300781\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.352834701538086\n",
            "Eval_StdReturn : 11.038387298583984\n",
            "Eval_MaxReturn : -4.926792144775391\n",
            "Eval_MinReturn : -31.731700897216797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.16950607299805\n",
            "Train_StdReturn : 23.509944915771484\n",
            "Train_MaxReturn : 26.317249298095703\n",
            "Train_MinReturn : -132.6565704345703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3006000\n",
            "TimeSinceStart : 2660.8838863372803\n",
            "Training Loss : 179.136962890625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.85438919067383\n",
            "Eval_StdReturn : 30.57526969909668\n",
            "Eval_MaxReturn : -26.279319763183594\n",
            "Eval_MinReturn : -93.03353118896484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.793540954589844\n",
            "Train_StdReturn : 21.131980895996094\n",
            "Train_MaxReturn : 35.21812057495117\n",
            "Train_MinReturn : -143.24063110351562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3056100\n",
            "TimeSinceStart : 2704.7499973773956\n",
            "Training Loss : -677.51171875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.24601364135742\n",
            "Eval_StdReturn : 26.015522003173828\n",
            "Eval_MaxReturn : -17.673381805419922\n",
            "Eval_MinReturn : -80.12791442871094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.19288635253906\n",
            "Train_StdReturn : 22.590097427368164\n",
            "Train_MaxReturn : 13.626364707946777\n",
            "Train_MinReturn : -115.77496337890625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3106200\n",
            "TimeSinceStart : 2748.4935235977173\n",
            "Training Loss : -725.9674682617188\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.83437728881836\n",
            "Eval_StdReturn : 15.337230682373047\n",
            "Eval_MaxReturn : -23.145999908447266\n",
            "Eval_MinReturn : -55.91651153564453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.626976013183594\n",
            "Train_StdReturn : 21.05772590637207\n",
            "Train_MaxReturn : 10.22321891784668\n",
            "Train_MinReturn : -142.2052764892578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3156300\n",
            "TimeSinceStart : 2792.294018983841\n",
            "Training Loss : 197.3990478515625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.253358840942383\n",
            "Eval_StdReturn : 3.3820180892944336\n",
            "Eval_MaxReturn : -26.487163543701172\n",
            "Eval_MinReturn : -34.68967056274414\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.74052429199219\n",
            "Train_StdReturn : 16.08187484741211\n",
            "Train_MaxReturn : 9.593464851379395\n",
            "Train_MinReturn : -80.93985748291016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3206400\n",
            "TimeSinceStart : 2836.313065767288\n",
            "Training Loss : -144.67825317382812\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.525930404663086\n",
            "Eval_StdReturn : 9.977022171020508\n",
            "Eval_MaxReturn : -8.962644577026367\n",
            "Eval_MinReturn : -32.67497634887695\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.5786247253418\n",
            "Train_StdReturn : 14.843718528747559\n",
            "Train_MaxReturn : 14.716962814331055\n",
            "Train_MinReturn : -85.17987823486328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3256500\n",
            "TimeSinceStart : 2880.5396914482117\n",
            "Training Loss : -712.80029296875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.062885284423828\n",
            "Eval_StdReturn : 4.163143157958984\n",
            "Eval_MaxReturn : -10.581026077270508\n",
            "Eval_MinReturn : -20.663803100585938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.403535842895508\n",
            "Train_StdReturn : 13.236311912536621\n",
            "Train_MaxReturn : 9.740889549255371\n",
            "Train_MinReturn : -69.68649291992188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3306600\n",
            "TimeSinceStart : 2924.578235387802\n",
            "Training Loss : -595.75439453125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.263946533203125\n",
            "Eval_StdReturn : 10.20340633392334\n",
            "Eval_MaxReturn : -24.17855453491211\n",
            "Eval_MinReturn : -49.13465118408203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.792512893676758\n",
            "Train_StdReturn : 12.821534156799316\n",
            "Train_MaxReturn : 10.232254028320312\n",
            "Train_MinReturn : -63.41215515136719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3356700\n",
            "TimeSinceStart : 2968.5633459091187\n",
            "Training Loss : -723.0494384765625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.68444061279297\n",
            "Eval_StdReturn : 10.471567153930664\n",
            "Eval_MaxReturn : -4.076951026916504\n",
            "Eval_MinReturn : -28.096851348876953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.65108299255371\n",
            "Train_StdReturn : 12.088627815246582\n",
            "Train_MaxReturn : 16.707565307617188\n",
            "Train_MinReturn : -56.352935791015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3406800\n",
            "TimeSinceStart : 3012.6327838897705\n",
            "Training Loss : -338.0491943359375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.27857494354248\n",
            "Eval_StdReturn : 9.902154922485352\n",
            "Eval_MaxReturn : 2.5318241119384766\n",
            "Eval_MinReturn : -21.700281143188477\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.02401351928711\n",
            "Train_StdReturn : 12.772600173950195\n",
            "Train_MaxReturn : 30.917219161987305\n",
            "Train_MinReturn : -58.11658477783203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3456900\n",
            "TimeSinceStart : 3056.576247692108\n",
            "Training Loss : -475.3170166015625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.037272453308105\n",
            "Eval_StdReturn : 11.8740816116333\n",
            "Eval_MaxReturn : 27.682621002197266\n",
            "Eval_MinReturn : -1.4005999565124512\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -1.323826551437378\n",
            "Train_StdReturn : 15.156615257263184\n",
            "Train_MaxReturn : 52.60627746582031\n",
            "Train_MinReturn : -36.177085876464844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3507000\n",
            "TimeSinceStart : 3100.4355731010437\n",
            "Training Loss : -744.4027099609375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 32.481346130371094\n",
            "Eval_StdReturn : 2.0074071884155273\n",
            "Eval_MaxReturn : 35.312034606933594\n",
            "Eval_MinReturn : 30.879114151000977\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 16.461931228637695\n",
            "Train_StdReturn : 17.79344940185547\n",
            "Train_MaxReturn : 66.13145446777344\n",
            "Train_MinReturn : -110.61404418945312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3557100\n",
            "TimeSinceStart : 3143.7980766296387\n",
            "Training Loss : -401.76898193359375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 49.265506744384766\n",
            "Eval_StdReturn : 17.13535499572754\n",
            "Eval_MaxReturn : 73.49800109863281\n",
            "Eval_MinReturn : 37.006752014160156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 27.289735794067383\n",
            "Train_StdReturn : 21.07858657836914\n",
            "Train_MaxReturn : 94.69583892822266\n",
            "Train_MinReturn : -67.58663177490234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3607200\n",
            "TimeSinceStart : 3188.1078913211823\n",
            "Training Loss : -487.0198974609375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 38.14523696899414\n",
            "Eval_StdReturn : 21.442615509033203\n",
            "Eval_MaxReturn : 61.78826141357422\n",
            "Eval_MinReturn : 9.878840446472168\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 35.83714294433594\n",
            "Train_StdReturn : 24.72629737854004\n",
            "Train_MaxReturn : 89.17414093017578\n",
            "Train_MinReturn : -139.27862548828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3657300\n",
            "TimeSinceStart : 3231.9467236995697\n",
            "Training Loss : -817.1361083984375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 46.82381057739258\n",
            "Eval_StdReturn : 13.940836906433105\n",
            "Eval_MaxReturn : 65.32542419433594\n",
            "Eval_MinReturn : 31.67485809326172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 44.67471694946289\n",
            "Train_StdReturn : 34.107261657714844\n",
            "Train_MaxReturn : 128.3195037841797\n",
            "Train_MinReturn : -141.2382049560547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3707400\n",
            "TimeSinceStart : 3275.8045785427094\n",
            "Training Loss : 269.4320373535156\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 77.74425506591797\n",
            "Eval_StdReturn : 46.01215362548828\n",
            "Eval_MaxReturn : 138.31842041015625\n",
            "Eval_MinReturn : 26.87186050415039\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 44.9131965637207\n",
            "Train_StdReturn : 35.27506637573242\n",
            "Train_MaxReturn : 113.4682846069336\n",
            "Train_MinReturn : -156.1896514892578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3757500\n",
            "TimeSinceStart : 3319.880709171295\n",
            "Training Loss : -728.7503662109375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 66.92110443115234\n",
            "Eval_StdReturn : 40.4642219543457\n",
            "Eval_MaxReturn : 95.59825134277344\n",
            "Eval_MinReturn : 9.696098327636719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 46.75007629394531\n",
            "Train_StdReturn : 39.576847076416016\n",
            "Train_MaxReturn : 128.47811889648438\n",
            "Train_MinReturn : -166.4619140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3807600\n",
            "TimeSinceStart : 3363.6169517040253\n",
            "Training Loss : -130.50958251953125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.7343597412109375\n",
            "Eval_StdReturn : 54.360355377197266\n",
            "Eval_MaxReturn : 71.76998901367188\n",
            "Eval_MinReturn : -61.282447814941406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 40.38489532470703\n",
            "Train_StdReturn : 47.911075592041016\n",
            "Train_MaxReturn : 130.30731201171875\n",
            "Train_MinReturn : -172.68905639648438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3857700\n",
            "TimeSinceStart : 3407.6170647144318\n",
            "Training Loss : -791.8668823242188\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 45.60337829589844\n",
            "Eval_StdReturn : 16.967119216918945\n",
            "Eval_MaxReturn : 59.7242431640625\n",
            "Eval_MinReturn : 21.741886138916016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 42.66766357421875\n",
            "Train_StdReturn : 51.0035400390625\n",
            "Train_MaxReturn : 139.16073608398438\n",
            "Train_MinReturn : -188.22915649414062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3907800\n",
            "TimeSinceStart : 3451.2035682201385\n",
            "Training Loss : 24.91448974609375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.766231536865234\n",
            "Eval_StdReturn : 18.247671127319336\n",
            "Eval_MaxReturn : 47.591922760009766\n",
            "Eval_MinReturn : 7.982666015625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 39.04021453857422\n",
            "Train_StdReturn : 51.88595199584961\n",
            "Train_MaxReturn : 152.37460327148438\n",
            "Train_MinReturn : -188.98876953125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3957900\n",
            "TimeSinceStart : 3495.1979098320007\n",
            "Training Loss : 169.38153076171875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.9129638671875\n",
            "Eval_StdReturn : 18.884050369262695\n",
            "Eval_MaxReturn : 93.434814453125\n",
            "Eval_MinReturn : 48.34121322631836\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 26.393945693969727\n",
            "Train_StdReturn : 67.01360321044922\n",
            "Train_MaxReturn : 146.47918701171875\n",
            "Train_MinReturn : -195.43984985351562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4008000\n",
            "TimeSinceStart : 3538.9407510757446\n",
            "Training Loss : -390.180419921875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.96236801147461\n",
            "Eval_StdReturn : 59.25311279296875\n",
            "Eval_MaxReturn : 18.665447235107422\n",
            "Eval_MinReturn : -120.4609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 27.609960556030273\n",
            "Train_StdReturn : 62.69721603393555\n",
            "Train_MaxReturn : 160.1981658935547\n",
            "Train_MinReturn : -178.450439453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4058100\n",
            "TimeSinceStart : 3582.7112934589386\n",
            "Training Loss : -403.41473388671875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.663660049438477\n",
            "Eval_StdReturn : 50.12049865722656\n",
            "Eval_MaxReturn : 47.96242141723633\n",
            "Eval_MinReturn : -63.17898178100586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 1.949615716934204\n",
            "Train_StdReturn : 71.59959411621094\n",
            "Train_MaxReturn : 172.2303466796875\n",
            "Train_MinReturn : -181.44805908203125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4108200\n",
            "TimeSinceStart : 3626.6746032238007\n",
            "Training Loss : -841.3094482421875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 23.2737979888916\n",
            "Eval_StdReturn : 55.49579620361328\n",
            "Eval_MaxReturn : 100.46658325195312\n",
            "Eval_MinReturn : -27.595731735229492\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.0822207927703857\n",
            "Train_StdReturn : 59.44344711303711\n",
            "Train_MaxReturn : 133.92169189453125\n",
            "Train_MinReturn : -167.43003845214844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4158300\n",
            "TimeSinceStart : 3670.5871391296387\n",
            "Training Loss : 11.8848876953125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.664888381958008\n",
            "Eval_StdReturn : 47.43359375\n",
            "Eval_MaxReturn : 68.1793212890625\n",
            "Eval_MinReturn : -44.713157653808594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -3.581333637237549\n",
            "Train_StdReturn : 44.99927520751953\n",
            "Train_MaxReturn : 100.22197723388672\n",
            "Train_MinReturn : -141.41680908203125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4208400\n",
            "TimeSinceStart : 3714.8122980594635\n",
            "Training Loss : -387.3451843261719\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -48.662776947021484\n",
            "Eval_StdReturn : 23.30680274963379\n",
            "Eval_MaxReturn : -15.844466209411621\n",
            "Eval_MinReturn : -67.72325134277344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.172585487365723\n",
            "Train_StdReturn : 40.51108932495117\n",
            "Train_MaxReturn : 111.55747985839844\n",
            "Train_MinReturn : -119.36053466796875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4258500\n",
            "TimeSinceStart : 3758.6991124153137\n",
            "Training Loss : -80.66926574707031\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.1329402923584\n",
            "Eval_StdReturn : 47.450782775878906\n",
            "Eval_MaxReturn : 44.757652282714844\n",
            "Eval_MinReturn : -65.08677673339844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.523515701293945\n",
            "Train_StdReturn : 34.43854522705078\n",
            "Train_MaxReturn : 97.0234375\n",
            "Train_MinReturn : -148.66238403320312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4308600\n",
            "TimeSinceStart : 3803.050308227539\n",
            "Training Loss : -509.6658935546875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.498661041259766\n",
            "Eval_StdReturn : 25.819416046142578\n",
            "Eval_MaxReturn : 1.3844223022460938\n",
            "Eval_MinReturn : -60.285858154296875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.659805297851562\n",
            "Train_StdReturn : 26.559480667114258\n",
            "Train_MaxReturn : 53.30596160888672\n",
            "Train_MinReturn : -105.56051635742188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4358700\n",
            "TimeSinceStart : 3847.373343229294\n",
            "Training Loss : -523.6138916015625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.491925239562988\n",
            "Eval_StdReturn : 10.309818267822266\n",
            "Eval_MaxReturn : 5.053618431091309\n",
            "Eval_MinReturn : -17.63583755493164\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.505247116088867\n",
            "Train_StdReturn : 23.140033721923828\n",
            "Train_MaxReturn : 36.51961135864258\n",
            "Train_MinReturn : -146.06178283691406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4408800\n",
            "TimeSinceStart : 3891.578670501709\n",
            "Training Loss : -71.02587890625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.00312614440918\n",
            "Eval_StdReturn : 25.340526580810547\n",
            "Eval_MaxReturn : 2.699082374572754\n",
            "Eval_MinReturn : -59.36186218261719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.605541229248047\n",
            "Train_StdReturn : 30.700279235839844\n",
            "Train_MaxReturn : 66.46077728271484\n",
            "Train_MinReturn : -168.54058837890625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4458900\n",
            "TimeSinceStart : 3935.5856449604034\n",
            "Training Loss : -478.04931640625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.058250427246094\n",
            "Eval_StdReturn : 25.010290145874023\n",
            "Eval_MaxReturn : 16.764270782470703\n",
            "Eval_MinReturn : -40.837562561035156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.0042724609375\n",
            "Train_StdReturn : 30.0295352935791\n",
            "Train_MaxReturn : 68.51881408691406\n",
            "Train_MinReturn : -123.14521026611328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4509000\n",
            "TimeSinceStart : 3979.3910551071167\n",
            "Training Loss : -202.73110961914062\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.112545013427734\n",
            "Eval_StdReturn : 5.571353435516357\n",
            "Eval_MaxReturn : -43.8174934387207\n",
            "Eval_MinReturn : -56.81296920776367\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.246368408203125\n",
            "Train_StdReturn : 30.87622833251953\n",
            "Train_MaxReturn : 68.3141098022461\n",
            "Train_MinReturn : -132.0816192626953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4559100\n",
            "TimeSinceStart : 4023.5447635650635\n",
            "Training Loss : -186.95135498046875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -1.8018964529037476\n",
            "Eval_StdReturn : 25.224319458007812\n",
            "Eval_MaxReturn : 21.53284454345703\n",
            "Eval_MinReturn : -36.83626937866211\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.02681541442871\n",
            "Train_StdReturn : 29.751937866210938\n",
            "Train_MaxReturn : 62.68520736694336\n",
            "Train_MinReturn : -109.041015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4609200\n",
            "TimeSinceStart : 4067.551123380661\n",
            "Training Loss : 102.54144287109375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.9640069007873535\n",
            "Eval_StdReturn : 4.876334190368652\n",
            "Eval_MaxReturn : 1.9320788383483887\n",
            "Eval_MinReturn : -8.442885398864746\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -4.319375991821289\n",
            "Train_StdReturn : 25.233627319335938\n",
            "Train_MaxReturn : 46.08110809326172\n",
            "Train_MinReturn : -94.40313720703125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4659300\n",
            "TimeSinceStart : 4111.794146060944\n",
            "Training Loss : 58.736480712890625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.859829902648926\n",
            "Eval_StdReturn : 31.355287551879883\n",
            "Eval_MaxReturn : 46.35463333129883\n",
            "Eval_MinReturn : -30.20105743408203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 3.5830845832824707\n",
            "Train_StdReturn : 20.72429656982422\n",
            "Train_MaxReturn : 56.007240295410156\n",
            "Train_MinReturn : -82.25496673583984\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4709400\n",
            "TimeSinceStart : 4155.619924068451\n",
            "Training Loss : -82.5703125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.334869384765625\n",
            "Eval_StdReturn : 18.298357009887695\n",
            "Eval_MaxReturn : 32.889610290527344\n",
            "Eval_MinReturn : -8.972543716430664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 12.071525573730469\n",
            "Train_StdReturn : 19.659427642822266\n",
            "Train_MaxReturn : 63.20195770263672\n",
            "Train_MinReturn : -82.415771484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4759500\n",
            "TimeSinceStart : 4199.6613965034485\n",
            "Training Loss : -655.2299194335938\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 36.76849365234375\n",
            "Eval_StdReturn : 12.923256874084473\n",
            "Eval_MaxReturn : 49.918182373046875\n",
            "Eval_MinReturn : 19.201374053955078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 20.205493927001953\n",
            "Train_StdReturn : 20.718042373657227\n",
            "Train_MaxReturn : 69.33177185058594\n",
            "Train_MinReturn : -88.12767028808594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4809600\n",
            "TimeSinceStart : 4243.609984636307\n",
            "Training Loss : -691.5499877929688\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 34.96828842163086\n",
            "Eval_StdReturn : 14.769373893737793\n",
            "Eval_MaxReturn : 52.09844970703125\n",
            "Eval_MinReturn : 16.0533390045166\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 27.650379180908203\n",
            "Train_StdReturn : 20.8930606842041\n",
            "Train_MaxReturn : 76.45420837402344\n",
            "Train_MinReturn : -51.32210159301758\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4859700\n",
            "TimeSinceStart : 4287.566514492035\n",
            "Training Loss : -397.6849060058594\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.968303680419922\n",
            "Eval_StdReturn : 22.695798873901367\n",
            "Eval_MaxReturn : 36.77389144897461\n",
            "Eval_MinReturn : -16.99408721923828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 28.396203994750977\n",
            "Train_StdReturn : 27.531862258911133\n",
            "Train_MaxReturn : 94.57444763183594\n",
            "Train_MinReturn : -136.95431518554688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4909800\n",
            "TimeSinceStart : 4331.493099927902\n",
            "Training Loss : -1025.99609375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.318681716918945\n",
            "Eval_StdReturn : 18.94255828857422\n",
            "Eval_MaxReturn : 50.63489532470703\n",
            "Eval_MinReturn : 5.585947036743164\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 33.71205520629883\n",
            "Train_StdReturn : 24.28639793395996\n",
            "Train_MaxReturn : 93.81180572509766\n",
            "Train_MinReturn : -93.4974594116211\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4959900\n",
            "TimeSinceStart : 4375.664885044098\n",
            "Training Loss : -83.58160400390625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 52.35466384887695\n",
            "Eval_StdReturn : 21.141475677490234\n",
            "Eval_MaxReturn : 75.28169250488281\n",
            "Eval_MinReturn : 24.271686553955078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 36.54656982421875\n",
            "Train_StdReturn : 30.690338134765625\n",
            "Train_MaxReturn : 131.95953369140625\n",
            "Train_MinReturn : -160.44696044921875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 5010000\n",
            "TimeSinceStart : 4419.351996421814\n",
            "Training Loss : -520.60107421875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "    --discount 0.95 -n 100 -l 2 -s 32 \\\n",
        "    -b 50000 -lr 0.02 -rtg \\\n",
        "    --exp_name q4_b50000_r0.02_rtg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScbEjzsVUAOd",
        "outputId": "055fb6f0-17a1-4d45-843d-b44432c494c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q4_b50000_r0.02_rtg_HalfCheetah-v2_10-05-2022_01-19-59\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -83.60639190673828\n",
            "Eval_StdReturn : 21.169879913330078\n",
            "Eval_MaxReturn : -66.53305053710938\n",
            "Eval_MinReturn : -113.44145202636719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -89.54405975341797\n",
            "Train_StdReturn : 39.07257843017578\n",
            "Train_MaxReturn : 11.764884948730469\n",
            "Train_MinReturn : -232.5586395263672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50100\n",
            "TimeSinceStart : 51.97838473320007\n",
            "Training Loss : -3648.544921875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -57.11882400512695\n",
            "Eval_StdReturn : 15.569241523742676\n",
            "Eval_MaxReturn : -42.101646423339844\n",
            "Eval_MinReturn : -78.57249450683594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -78.9223403930664\n",
            "Train_StdReturn : 35.41376876831055\n",
            "Train_MaxReturn : 15.874031066894531\n",
            "Train_MinReturn : -196.88162231445312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100200\n",
            "TimeSinceStart : 104.31100726127625\n",
            "Training Loss : -3362.57177734375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -99.46209716796875\n",
            "Eval_StdReturn : 11.735048294067383\n",
            "Eval_MaxReturn : -83.98196411132812\n",
            "Eval_MinReturn : -112.38300323486328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -73.35453033447266\n",
            "Train_StdReturn : 33.12337875366211\n",
            "Train_MaxReturn : 27.512210845947266\n",
            "Train_MinReturn : -175.8793487548828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150300\n",
            "TimeSinceStart : 156.48400115966797\n",
            "Training Loss : -3832.87060546875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -95.39476776123047\n",
            "Eval_StdReturn : 18.426313400268555\n",
            "Eval_MaxReturn : -80.02070617675781\n",
            "Eval_MinReturn : -121.30327606201172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -70.44934844970703\n",
            "Train_StdReturn : 31.552356719970703\n",
            "Train_MaxReturn : 38.86346435546875\n",
            "Train_MinReturn : -185.4723663330078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 200400\n",
            "TimeSinceStart : 209.19951462745667\n",
            "Training Loss : -3720.76513671875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -69.11084747314453\n",
            "Eval_StdReturn : 14.561331748962402\n",
            "Eval_MaxReturn : -48.67491912841797\n",
            "Eval_MinReturn : -81.52613067626953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -62.33645248413086\n",
            "Train_StdReturn : 28.637815475463867\n",
            "Train_MaxReturn : 15.802846908569336\n",
            "Train_MinReturn : -141.7452392578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 250500\n",
            "TimeSinceStart : 262.00664234161377\n",
            "Training Loss : -3959.772216796875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.54539489746094\n",
            "Eval_StdReturn : 11.489675521850586\n",
            "Eval_MaxReturn : -37.05113983154297\n",
            "Eval_MinReturn : -62.71238708496094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -60.20756149291992\n",
            "Train_StdReturn : 27.084869384765625\n",
            "Train_MaxReturn : 43.52627182006836\n",
            "Train_MinReturn : -135.2074737548828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300600\n",
            "TimeSinceStart : 314.53747844696045\n",
            "Training Loss : -3733.646484375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.972835540771484\n",
            "Eval_StdReturn : 32.49018096923828\n",
            "Eval_MaxReturn : -36.734771728515625\n",
            "Eval_MinReturn : -107.84390258789062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -54.914920806884766\n",
            "Train_StdReturn : 28.662294387817383\n",
            "Train_MaxReturn : 28.443931579589844\n",
            "Train_MinReturn : -166.77197265625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 350700\n",
            "TimeSinceStart : 367.1495018005371\n",
            "Training Loss : -4565.02490234375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.88380432128906\n",
            "Eval_StdReturn : 13.001842498779297\n",
            "Eval_MaxReturn : -31.977188110351562\n",
            "Eval_MinReturn : -61.157257080078125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.97691345214844\n",
            "Train_StdReturn : 26.31173324584961\n",
            "Train_MaxReturn : 16.56027603149414\n",
            "Train_MinReturn : -142.05419921875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 400800\n",
            "TimeSinceStart : 419.49560809135437\n",
            "Training Loss : -3445.989013671875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.791961669921875\n",
            "Eval_StdReturn : 47.13885498046875\n",
            "Eval_MaxReturn : 2.4627742767333984\n",
            "Eval_MinReturn : -109.30126953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.0045166015625\n",
            "Train_StdReturn : 28.48849105834961\n",
            "Train_MaxReturn : 33.20648956298828\n",
            "Train_MinReturn : -159.80433654785156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450900\n",
            "TimeSinceStart : 472.03096103668213\n",
            "Training Loss : -3701.52099609375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.30332565307617\n",
            "Eval_StdReturn : 6.462862968444824\n",
            "Eval_MaxReturn : -25.912614822387695\n",
            "Eval_MinReturn : -41.65549850463867\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.923954010009766\n",
            "Train_StdReturn : 28.23863410949707\n",
            "Train_MaxReturn : 30.499834060668945\n",
            "Train_MinReturn : -145.79574584960938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 501000\n",
            "TimeSinceStart : 524.5695369243622\n",
            "Training Loss : -3262.6015625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.08353805541992\n",
            "Eval_StdReturn : 34.09205627441406\n",
            "Eval_MaxReturn : 8.606014251708984\n",
            "Eval_MinReturn : -71.8430404663086\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.522342681884766\n",
            "Train_StdReturn : 29.34629249572754\n",
            "Train_MaxReturn : 47.50432586669922\n",
            "Train_MinReturn : -189.4829559326172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 551100\n",
            "TimeSinceStart : 577.1636021137238\n",
            "Training Loss : -3387.052001953125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -2.411149263381958\n",
            "Eval_StdReturn : 34.42338180541992\n",
            "Eval_MaxReturn : 32.1297607421875\n",
            "Eval_MinReturn : -49.3909912109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -38.708866119384766\n",
            "Train_StdReturn : 28.42034149169922\n",
            "Train_MaxReturn : 41.57804870605469\n",
            "Train_MinReturn : -153.87872314453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 601200\n",
            "TimeSinceStart : 630.0621223449707\n",
            "Training Loss : -2794.68408203125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.849926948547363\n",
            "Eval_StdReturn : 15.92590618133545\n",
            "Eval_MaxReturn : 3.7957992553710938\n",
            "Eval_MinReturn : -33.70347595214844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.27555465698242\n",
            "Train_StdReturn : 27.95448112487793\n",
            "Train_MaxReturn : 65.36689758300781\n",
            "Train_MinReturn : -146.879638671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 651300\n",
            "TimeSinceStart : 682.9600162506104\n",
            "Training Loss : -3316.89453125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.843753814697266\n",
            "Eval_StdReturn : 23.99928855895996\n",
            "Eval_MaxReturn : -6.973326683044434\n",
            "Eval_MinReturn : -65.49417877197266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.11024284362793\n",
            "Train_StdReturn : 26.047712326049805\n",
            "Train_MaxReturn : 61.78952407836914\n",
            "Train_MinReturn : -132.60995483398438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 701400\n",
            "TimeSinceStart : 735.7718963623047\n",
            "Training Loss : -2940.76171875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.904244422912598\n",
            "Eval_StdReturn : 16.892993927001953\n",
            "Eval_MaxReturn : 8.843862533569336\n",
            "Eval_MinReturn : -32.10176086425781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.237918853759766\n",
            "Train_StdReturn : 28.281288146972656\n",
            "Train_MaxReturn : 69.29847717285156\n",
            "Train_MinReturn : -156.52279663085938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 751500\n",
            "TimeSinceStart : 788.4594032764435\n",
            "Training Loss : -2737.9677734375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.569400787353516\n",
            "Eval_StdReturn : 5.0619635581970215\n",
            "Eval_MaxReturn : -50.288578033447266\n",
            "Eval_MinReturn : -62.68448257446289\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.817447662353516\n",
            "Train_StdReturn : 26.984695434570312\n",
            "Train_MaxReturn : 44.9591178894043\n",
            "Train_MinReturn : -129.7662811279297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 801600\n",
            "TimeSinceStart : 841.1556916236877\n",
            "Training Loss : -2886.572265625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.419958114624023\n",
            "Eval_StdReturn : 35.00638198852539\n",
            "Eval_MaxReturn : 33.027034759521484\n",
            "Eval_MinReturn : -43.24506378173828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.57904815673828\n",
            "Train_StdReturn : 27.322023391723633\n",
            "Train_MaxReturn : 66.86211395263672\n",
            "Train_MinReturn : -103.7688217163086\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 851700\n",
            "TimeSinceStart : 893.7204024791718\n",
            "Training Loss : -3071.04541015625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.530675888061523\n",
            "Eval_StdReturn : 13.251969337463379\n",
            "Eval_MaxReturn : -11.601806640625\n",
            "Eval_MinReturn : -42.74480438232422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.510046005249023\n",
            "Train_StdReturn : 22.39923667907715\n",
            "Train_MaxReturn : 45.242774963378906\n",
            "Train_MinReturn : -76.07711791992188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 901800\n",
            "TimeSinceStart : 946.1192224025726\n",
            "Training Loss : -1983.0877685546875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.864439010620117\n",
            "Eval_StdReturn : 8.841462135314941\n",
            "Eval_MaxReturn : -10.030525207519531\n",
            "Eval_MinReturn : -30.94485855102539\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.850751876831055\n",
            "Train_StdReturn : 23.009613037109375\n",
            "Train_MaxReturn : 41.60267639160156\n",
            "Train_MinReturn : -123.195068359375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 951900\n",
            "TimeSinceStart : 998.4045443534851\n",
            "Training Loss : -2942.243896484375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.059219360351562\n",
            "Eval_StdReturn : 18.234712600708008\n",
            "Eval_MaxReturn : -8.966219902038574\n",
            "Eval_MinReturn : -51.32783508300781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.681886672973633\n",
            "Train_StdReturn : 23.105070114135742\n",
            "Train_MaxReturn : 32.284244537353516\n",
            "Train_MinReturn : -141.80657958984375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1002000\n",
            "TimeSinceStart : 1050.8302121162415\n",
            "Training Loss : -3709.81640625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.728638172149658\n",
            "Eval_StdReturn : 24.150287628173828\n",
            "Eval_MaxReturn : 14.425348281860352\n",
            "Eval_MinReturn : -41.316856384277344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.57672691345215\n",
            "Train_StdReturn : 20.33149528503418\n",
            "Train_MaxReturn : 54.174591064453125\n",
            "Train_MinReturn : -125.1175765991211\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1052100\n",
            "TimeSinceStart : 1103.2734973430634\n",
            "Training Loss : -2696.18603515625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.558204650878906\n",
            "Eval_StdReturn : 14.35948371887207\n",
            "Eval_MaxReturn : -1.6353797912597656\n",
            "Eval_MinReturn : -34.585845947265625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.935749053955078\n",
            "Train_StdReturn : 19.018930435180664\n",
            "Train_MaxReturn : 77.70099639892578\n",
            "Train_MinReturn : -89.19713592529297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1102200\n",
            "TimeSinceStart : 1155.5948867797852\n",
            "Training Loss : -3212.17236328125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.36182689666748\n",
            "Eval_StdReturn : 12.833795547485352\n",
            "Eval_MaxReturn : 9.357490539550781\n",
            "Eval_MinReturn : -20.62424659729004\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.245588302612305\n",
            "Train_StdReturn : 17.557693481445312\n",
            "Train_MaxReturn : 21.904945373535156\n",
            "Train_MinReturn : -109.63431549072266\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1152300\n",
            "TimeSinceStart : 1207.8105483055115\n",
            "Training Loss : -4015.37548828125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.897478103637695\n",
            "Eval_StdReturn : 15.429338455200195\n",
            "Eval_MaxReturn : -3.430739402770996\n",
            "Eval_MinReturn : -40.68303680419922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.014975547790527\n",
            "Train_StdReturn : 16.329524993896484\n",
            "Train_MaxReturn : 37.91933059692383\n",
            "Train_MinReturn : -59.46342468261719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1202400\n",
            "TimeSinceStart : 1260.1754446029663\n",
            "Training Loss : -3176.55029296875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.17101223766803741\n",
            "Eval_StdReturn : 18.20689582824707\n",
            "Eval_MaxReturn : 22.08456039428711\n",
            "Eval_MinReturn : -22.512794494628906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.53747272491455\n",
            "Train_StdReturn : 16.023244857788086\n",
            "Train_MaxReturn : 27.63739776611328\n",
            "Train_MinReturn : -66.82664489746094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1252500\n",
            "TimeSinceStart : 1312.805275440216\n",
            "Training Loss : -2964.78076171875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.887490272521973\n",
            "Eval_StdReturn : 1.2538321018218994\n",
            "Eval_MaxReturn : -12.624701499938965\n",
            "Eval_MinReturn : -15.596922874450684\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.483808517456055\n",
            "Train_StdReturn : 16.15127944946289\n",
            "Train_MaxReturn : 38.62288284301758\n",
            "Train_MinReturn : -55.577606201171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1302600\n",
            "TimeSinceStart : 1365.367872953415\n",
            "Training Loss : -3004.74755859375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.9907095432281494\n",
            "Eval_StdReturn : 11.971774101257324\n",
            "Eval_MaxReturn : 14.436518669128418\n",
            "Eval_MinReturn : -13.53636646270752\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -5.161797046661377\n",
            "Train_StdReturn : 16.491018295288086\n",
            "Train_MaxReturn : 35.56725311279297\n",
            "Train_MinReturn : -50.03443908691406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1352700\n",
            "TimeSinceStart : 1418.173005580902\n",
            "Training Loss : -3401.726806640625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.314231872558594\n",
            "Eval_StdReturn : 7.123768329620361\n",
            "Eval_MaxReturn : -15.239742279052734\n",
            "Eval_MinReturn : -30.37605857849121\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -1.9297139644622803\n",
            "Train_StdReturn : 15.883037567138672\n",
            "Train_MaxReturn : 36.82238006591797\n",
            "Train_MinReturn : -51.914894104003906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1402800\n",
            "TimeSinceStart : 1470.7225289344788\n",
            "Training Loss : -2871.9208984375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.556703567504883\n",
            "Eval_StdReturn : 7.335143089294434\n",
            "Eval_MaxReturn : -13.915060043334961\n",
            "Eval_MinReturn : -30.778461456298828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -0.3667072057723999\n",
            "Train_StdReturn : 16.7822208404541\n",
            "Train_MaxReturn : 49.192405700683594\n",
            "Train_MinReturn : -65.59494018554688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1452900\n",
            "TimeSinceStart : 1523.0757586956024\n",
            "Training Loss : -3665.68505859375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.911479949951172\n",
            "Eval_StdReturn : 20.381853103637695\n",
            "Eval_MaxReturn : 31.975242614746094\n",
            "Eval_MinReturn : -17.183486938476562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 3.097121238708496\n",
            "Train_StdReturn : 17.11979866027832\n",
            "Train_MaxReturn : 55.932464599609375\n",
            "Train_MinReturn : -51.530189514160156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1503000\n",
            "TimeSinceStart : 1575.986380815506\n",
            "Training Loss : -3288.0859375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.899796485900879\n",
            "Eval_StdReturn : 17.66798210144043\n",
            "Eval_MaxReturn : 17.706663131713867\n",
            "Eval_MinReturn : -22.762027740478516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 8.254627227783203\n",
            "Train_StdReturn : 17.107404708862305\n",
            "Train_MaxReturn : 63.23334503173828\n",
            "Train_MinReturn : -47.00750732421875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1553100\n",
            "TimeSinceStart : 1628.7248544692993\n",
            "Training Loss : -4418.09912109375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.857769012451172\n",
            "Eval_StdReturn : 26.31859016418457\n",
            "Eval_MaxReturn : 56.152015686035156\n",
            "Eval_MinReturn : -5.434140205383301\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 15.904338836669922\n",
            "Train_StdReturn : 16.653430938720703\n",
            "Train_MaxReturn : 65.30736541748047\n",
            "Train_MinReturn : -49.12932586669922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1603200\n",
            "TimeSinceStart : 1681.2374000549316\n",
            "Training Loss : -4627.81298828125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 26.764890670776367\n",
            "Eval_StdReturn : 8.453863143920898\n",
            "Eval_MaxReturn : 38.266448974609375\n",
            "Eval_MinReturn : 18.187929153442383\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 16.05679702758789\n",
            "Train_StdReturn : 18.12117576599121\n",
            "Train_MaxReturn : 66.52668762207031\n",
            "Train_MinReturn : -70.7650146484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1653300\n",
            "TimeSinceStart : 1733.9368081092834\n",
            "Training Loss : -3798.5546875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 27.31609535217285\n",
            "Eval_StdReturn : 2.5271942615509033\n",
            "Eval_MaxReturn : 29.65190887451172\n",
            "Eval_MinReturn : 23.805530548095703\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 21.346820831298828\n",
            "Train_StdReturn : 16.89009666442871\n",
            "Train_MaxReturn : 70.16427612304688\n",
            "Train_MinReturn : -24.81833267211914\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1703400\n",
            "TimeSinceStart : 1786.6903026103973\n",
            "Training Loss : -4672.77783203125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.613388061523438\n",
            "Eval_StdReturn : 19.448875427246094\n",
            "Eval_MaxReturn : 48.24663162231445\n",
            "Eval_MinReturn : 4.326009273529053\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 25.449146270751953\n",
            "Train_StdReturn : 19.24993896484375\n",
            "Train_MaxReturn : 92.07878112792969\n",
            "Train_MinReturn : -44.133033752441406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1753500\n",
            "TimeSinceStart : 1839.5829074382782\n",
            "Training Loss : -2959.21826171875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.517826080322266\n",
            "Eval_StdReturn : 7.116418361663818\n",
            "Eval_MaxReturn : 41.783843994140625\n",
            "Eval_MinReturn : 24.412914276123047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 30.805681228637695\n",
            "Train_StdReturn : 16.93911361694336\n",
            "Train_MaxReturn : 90.59458923339844\n",
            "Train_MinReturn : -25.956451416015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1803600\n",
            "TimeSinceStart : 1892.4649786949158\n",
            "Training Loss : -3205.4716796875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 42.98102951049805\n",
            "Eval_StdReturn : 5.895169734954834\n",
            "Eval_MaxReturn : 48.7851676940918\n",
            "Eval_MinReturn : 34.89595413208008\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 36.285701751708984\n",
            "Train_StdReturn : 19.501596450805664\n",
            "Train_MaxReturn : 93.02217864990234\n",
            "Train_MinReturn : -37.0146369934082\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1853700\n",
            "TimeSinceStart : 1944.9800112247467\n",
            "Training Loss : -3067.93798828125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 44.66170883178711\n",
            "Eval_StdReturn : 28.208288192749023\n",
            "Eval_MaxReturn : 83.15898132324219\n",
            "Eval_MinReturn : 16.355958938598633\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 43.89625930786133\n",
            "Train_StdReturn : 21.20038414001465\n",
            "Train_MaxReturn : 111.89844512939453\n",
            "Train_MinReturn : -24.381776809692383\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1903800\n",
            "TimeSinceStart : 1997.6565442085266\n",
            "Training Loss : -3461.382568359375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 47.341400146484375\n",
            "Eval_StdReturn : 12.0794038772583\n",
            "Eval_MaxReturn : 64.29314422607422\n",
            "Eval_MinReturn : 37.03612518310547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 42.09574508666992\n",
            "Train_StdReturn : 20.949142456054688\n",
            "Train_MaxReturn : 87.9208984375\n",
            "Train_MinReturn : -62.46553039550781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1953900\n",
            "TimeSinceStart : 2050.591764688492\n",
            "Training Loss : -2942.88330078125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 26.376296997070312\n",
            "Eval_StdReturn : 14.417290687561035\n",
            "Eval_MaxReturn : 41.081443786621094\n",
            "Eval_MinReturn : 6.792354583740234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 41.585792541503906\n",
            "Train_StdReturn : 23.46639633178711\n",
            "Train_MaxReturn : 91.30397033691406\n",
            "Train_MinReturn : -72.81632995605469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2004000\n",
            "TimeSinceStart : 2102.88307929039\n",
            "Training Loss : -3729.408935546875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 52.28965377807617\n",
            "Eval_StdReturn : 6.553576946258545\n",
            "Eval_MaxReturn : 57.314979553222656\n",
            "Eval_MinReturn : 43.032833099365234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 43.787052154541016\n",
            "Train_StdReturn : 20.67611312866211\n",
            "Train_MaxReturn : 95.20074462890625\n",
            "Train_MinReturn : -29.58139419555664\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2054100\n",
            "TimeSinceStart : 2155.3910830020905\n",
            "Training Loss : -3134.5693359375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 62.0655632019043\n",
            "Eval_StdReturn : 10.844809532165527\n",
            "Eval_MaxReturn : 74.42561340332031\n",
            "Eval_MinReturn : 48.02190399169922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 47.197113037109375\n",
            "Train_StdReturn : 19.856990814208984\n",
            "Train_MaxReturn : 98.05096435546875\n",
            "Train_MinReturn : -36.79149627685547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2104200\n",
            "TimeSinceStart : 2207.892545938492\n",
            "Training Loss : -3361.44140625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 44.99626541137695\n",
            "Eval_StdReturn : 10.672896385192871\n",
            "Eval_MaxReturn : 57.41291427612305\n",
            "Eval_MinReturn : 31.3558349609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 53.29798126220703\n",
            "Train_StdReturn : 20.876188278198242\n",
            "Train_MaxReturn : 102.72174072265625\n",
            "Train_MinReturn : -12.764714241027832\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2154300\n",
            "TimeSinceStart : 2260.415427207947\n",
            "Training Loss : -3097.029296875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 66.46614837646484\n",
            "Eval_StdReturn : 11.95211124420166\n",
            "Eval_MaxReturn : 82.39985656738281\n",
            "Eval_MinReturn : 53.613895416259766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 58.58013153076172\n",
            "Train_StdReturn : 20.9000244140625\n",
            "Train_MaxReturn : 111.12696075439453\n",
            "Train_MinReturn : -19.85116958618164\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2204400\n",
            "TimeSinceStart : 2312.7114980220795\n",
            "Training Loss : -2450.281982421875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 75.80069732666016\n",
            "Eval_StdReturn : 15.74617862701416\n",
            "Eval_MaxReturn : 89.20726013183594\n",
            "Eval_MinReturn : 53.698997497558594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 62.216609954833984\n",
            "Train_StdReturn : 21.082868576049805\n",
            "Train_MaxReturn : 110.92723083496094\n",
            "Train_MinReturn : -19.954635620117188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2254500\n",
            "TimeSinceStart : 2365.4019067287445\n",
            "Training Loss : -1992.5908203125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.6203727722168\n",
            "Eval_StdReturn : 9.761045455932617\n",
            "Eval_MaxReturn : 64.40687561035156\n",
            "Eval_MinReturn : 43.121978759765625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 62.164085388183594\n",
            "Train_StdReturn : 20.049339294433594\n",
            "Train_MaxReturn : 118.52264404296875\n",
            "Train_MinReturn : 4.557535171508789\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2304600\n",
            "TimeSinceStart : 2417.656597137451\n",
            "Training Loss : -3172.40234375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.04187774658203\n",
            "Eval_StdReturn : 2.7054877281188965\n",
            "Eval_MaxReturn : 67.02789306640625\n",
            "Eval_MinReturn : 60.477088928222656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 62.46217727661133\n",
            "Train_StdReturn : 20.32331085205078\n",
            "Train_MaxReturn : 114.89151000976562\n",
            "Train_MinReturn : -19.45832633972168\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2354700\n",
            "TimeSinceStart : 2470.214622735977\n",
            "Training Loss : -2672.418212890625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 71.62984466552734\n",
            "Eval_StdReturn : 16.085054397583008\n",
            "Eval_MaxReturn : 93.13429260253906\n",
            "Eval_MinReturn : 54.45403289794922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 72.78488159179688\n",
            "Train_StdReturn : 20.06605339050293\n",
            "Train_MaxReturn : 122.62676239013672\n",
            "Train_MinReturn : -6.262901306152344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2404800\n",
            "TimeSinceStart : 2522.962289571762\n",
            "Training Loss : -3295.25830078125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.89302825927734\n",
            "Eval_StdReturn : 24.811111450195312\n",
            "Eval_MaxReturn : 86.03115844726562\n",
            "Eval_MinReturn : 32.81160354614258\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 75.55322265625\n",
            "Train_StdReturn : 19.540252685546875\n",
            "Train_MaxReturn : 134.66796875\n",
            "Train_MinReturn : 7.0868730545043945\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2454900\n",
            "TimeSinceStart : 2575.6441917419434\n",
            "Training Loss : -2400.9228515625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 77.52317810058594\n",
            "Eval_StdReturn : 26.493518829345703\n",
            "Eval_MaxReturn : 109.52008056640625\n",
            "Eval_MinReturn : 44.64252853393555\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 75.28401184082031\n",
            "Train_StdReturn : 22.755891799926758\n",
            "Train_MaxReturn : 145.4371337890625\n",
            "Train_MinReturn : -33.66828918457031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2505000\n",
            "TimeSinceStart : 2628.197521209717\n",
            "Training Loss : -1495.7110595703125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 85.5458755493164\n",
            "Eval_StdReturn : 25.917009353637695\n",
            "Eval_MaxReturn : 114.40845489501953\n",
            "Eval_MinReturn : 51.550567626953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 71.03706359863281\n",
            "Train_StdReturn : 23.290283203125\n",
            "Train_MaxReturn : 118.22239685058594\n",
            "Train_MinReturn : -11.274765968322754\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2555100\n",
            "TimeSinceStart : 2680.7673754692078\n",
            "Training Loss : -1616.10986328125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.51123046875\n",
            "Eval_StdReturn : 15.789033889770508\n",
            "Eval_MaxReturn : 82.54595184326172\n",
            "Eval_MinReturn : 46.36439514160156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 78.92643737792969\n",
            "Train_StdReturn : 23.693880081176758\n",
            "Train_MaxReturn : 137.37985229492188\n",
            "Train_MinReturn : -45.47814178466797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2605200\n",
            "TimeSinceStart : 2733.35777926445\n",
            "Training Loss : -2049.411865234375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 94.0118637084961\n",
            "Eval_StdReturn : 19.517160415649414\n",
            "Eval_MaxReturn : 110.12899780273438\n",
            "Eval_MinReturn : 66.54820251464844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 82.8383560180664\n",
            "Train_StdReturn : 22.0845890045166\n",
            "Train_MaxReturn : 140.90396118164062\n",
            "Train_MinReturn : 12.054338455200195\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2655300\n",
            "TimeSinceStart : 2785.649295091629\n",
            "Training Loss : -2136.772216796875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 71.63753509521484\n",
            "Eval_StdReturn : 17.015914916992188\n",
            "Eval_MaxReturn : 91.61756896972656\n",
            "Eval_MinReturn : 50.03240966796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 76.0962142944336\n",
            "Train_StdReturn : 19.987030029296875\n",
            "Train_MaxReturn : 122.49791717529297\n",
            "Train_MinReturn : 8.107095718383789\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2705400\n",
            "TimeSinceStart : 2837.8372910022736\n",
            "Training Loss : -1743.1719970703125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.1998291015625\n",
            "Eval_StdReturn : 11.582467079162598\n",
            "Eval_MaxReturn : 108.28007507324219\n",
            "Eval_MinReturn : 81.4579086303711\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 84.18245697021484\n",
            "Train_StdReturn : 18.439327239990234\n",
            "Train_MaxReturn : 138.32247924804688\n",
            "Train_MinReturn : 21.60824966430664\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2755500\n",
            "TimeSinceStart : 2890.4634850025177\n",
            "Training Loss : -3218.116455078125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 86.90862274169922\n",
            "Eval_StdReturn : 7.710926532745361\n",
            "Eval_MaxReturn : 94.0921630859375\n",
            "Eval_MinReturn : 76.21156311035156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 84.83477020263672\n",
            "Train_StdReturn : 19.119754791259766\n",
            "Train_MaxReturn : 127.57884979248047\n",
            "Train_MinReturn : 14.778493881225586\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2805600\n",
            "TimeSinceStart : 2942.9844405651093\n",
            "Training Loss : -2464.77880859375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 72.60379028320312\n",
            "Eval_StdReturn : 29.53545379638672\n",
            "Eval_MaxReturn : 100.50916290283203\n",
            "Eval_MinReturn : 31.734895706176758\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 84.06419372558594\n",
            "Train_StdReturn : 19.15777015686035\n",
            "Train_MaxReturn : 123.23944091796875\n",
            "Train_MinReturn : 17.810054779052734\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2855700\n",
            "TimeSinceStart : 2995.399049282074\n",
            "Training Loss : -1770.522216796875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 103.91897583007812\n",
            "Eval_StdReturn : 11.26417350769043\n",
            "Eval_MaxReturn : 115.0089111328125\n",
            "Eval_MinReturn : 88.47035217285156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 90.1441650390625\n",
            "Train_StdReturn : 18.744653701782227\n",
            "Train_MaxReturn : 134.5166015625\n",
            "Train_MinReturn : -3.9411773681640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2905800\n",
            "TimeSinceStart : 3047.902306318283\n",
            "Training Loss : -1885.9051513671875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 123.17940521240234\n",
            "Eval_StdReturn : 19.63507080078125\n",
            "Eval_MaxReturn : 142.75852966308594\n",
            "Eval_MinReturn : 96.3370590209961\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 99.32501220703125\n",
            "Train_StdReturn : 18.138717651367188\n",
            "Train_MaxReturn : 141.94207763671875\n",
            "Train_MinReturn : 37.054054260253906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2955900\n",
            "TimeSinceStart : 3100.490757226944\n",
            "Training Loss : -1773.390380859375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 100.55462646484375\n",
            "Eval_StdReturn : 5.112912654876709\n",
            "Eval_MaxReturn : 107.47815704345703\n",
            "Eval_MinReturn : 95.28694152832031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 102.0119857788086\n",
            "Train_StdReturn : 20.126955032348633\n",
            "Train_MaxReturn : 155.8787384033203\n",
            "Train_MinReturn : 14.89290714263916\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3006000\n",
            "TimeSinceStart : 3153.088366985321\n",
            "Training Loss : -1940.364013671875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 94.35333251953125\n",
            "Eval_StdReturn : 23.124555587768555\n",
            "Eval_MaxReturn : 116.96582794189453\n",
            "Eval_MinReturn : 62.586788177490234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 90.63259887695312\n",
            "Train_StdReturn : 19.179079055786133\n",
            "Train_MaxReturn : 134.56597900390625\n",
            "Train_MinReturn : 22.151016235351562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3056100\n",
            "TimeSinceStart : 3205.4878792762756\n",
            "Training Loss : -2201.804443359375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 111.49349212646484\n",
            "Eval_StdReturn : 10.203634262084961\n",
            "Eval_MaxReturn : 123.87635040283203\n",
            "Eval_MinReturn : 98.88568878173828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 94.7000503540039\n",
            "Train_StdReturn : 17.82432746887207\n",
            "Train_MaxReturn : 136.2083740234375\n",
            "Train_MinReturn : 40.35322570800781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3106200\n",
            "TimeSinceStart : 3258.2396399974823\n",
            "Training Loss : -1393.212158203125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 114.66503143310547\n",
            "Eval_StdReturn : 13.03334903717041\n",
            "Eval_MaxReturn : 130.32089233398438\n",
            "Eval_MinReturn : 98.41256713867188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 110.4247055053711\n",
            "Train_StdReturn : 19.103092193603516\n",
            "Train_MaxReturn : 152.62237548828125\n",
            "Train_MinReturn : 43.10720443725586\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3156300\n",
            "TimeSinceStart : 3310.680332183838\n",
            "Training Loss : -1369.5162353515625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 113.80310821533203\n",
            "Eval_StdReturn : 16.56466293334961\n",
            "Eval_MaxReturn : 129.43121337890625\n",
            "Eval_MinReturn : 90.87602233886719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 107.19605255126953\n",
            "Train_StdReturn : 19.175582885742188\n",
            "Train_MaxReturn : 167.38735961914062\n",
            "Train_MinReturn : 42.48516845703125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3206400\n",
            "TimeSinceStart : 3363.2795622348785\n",
            "Training Loss : -1934.4759521484375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 122.36737060546875\n",
            "Eval_StdReturn : 10.663496971130371\n",
            "Eval_MaxReturn : 136.21371459960938\n",
            "Eval_MinReturn : 110.26980590820312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 106.56674194335938\n",
            "Train_StdReturn : 17.36370086669922\n",
            "Train_MaxReturn : 151.61767578125\n",
            "Train_MinReturn : 40.85322952270508\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3256500\n",
            "TimeSinceStart : 3416.2459268569946\n",
            "Training Loss : -1829.9073486328125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 127.48983001708984\n",
            "Eval_StdReturn : 11.643078804016113\n",
            "Eval_MaxReturn : 137.93936157226562\n",
            "Eval_MinReturn : 111.24474334716797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 104.86392211914062\n",
            "Train_StdReturn : 17.330101013183594\n",
            "Train_MaxReturn : 142.75799560546875\n",
            "Train_MinReturn : 44.28300476074219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3306600\n",
            "TimeSinceStart : 3468.847454071045\n",
            "Training Loss : -1688.168701171875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 106.71493530273438\n",
            "Eval_StdReturn : 4.857220649719238\n",
            "Eval_MaxReturn : 110.31476593017578\n",
            "Eval_MinReturn : 99.84848022460938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 101.54592895507812\n",
            "Train_StdReturn : 18.585826873779297\n",
            "Train_MaxReturn : 154.06007385253906\n",
            "Train_MinReturn : 40.90991973876953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3356700\n",
            "TimeSinceStart : 3521.2908811569214\n",
            "Training Loss : -2111.41552734375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 110.82218170166016\n",
            "Eval_StdReturn : 7.2342400550842285\n",
            "Eval_MaxReturn : 117.6739501953125\n",
            "Eval_MinReturn : 100.81668853759766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 99.0123291015625\n",
            "Train_StdReturn : 19.809587478637695\n",
            "Train_MaxReturn : 147.56954956054688\n",
            "Train_MinReturn : 33.43044662475586\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3406800\n",
            "TimeSinceStart : 3573.7798449993134\n",
            "Training Loss : -2012.709228515625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 117.17903900146484\n",
            "Eval_StdReturn : 13.673075675964355\n",
            "Eval_MaxReturn : 133.10482788085938\n",
            "Eval_MinReturn : 99.71843719482422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 107.64474487304688\n",
            "Train_StdReturn : 19.18538475036621\n",
            "Train_MaxReturn : 148.4807586669922\n",
            "Train_MinReturn : 27.637157440185547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3456900\n",
            "TimeSinceStart : 3626.3039181232452\n",
            "Training Loss : -1851.9010009765625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 115.96256256103516\n",
            "Eval_StdReturn : 10.81924057006836\n",
            "Eval_MaxReturn : 126.53604125976562\n",
            "Eval_MinReturn : 101.09797668457031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 112.97702026367188\n",
            "Train_StdReturn : 20.42462158203125\n",
            "Train_MaxReturn : 159.4113311767578\n",
            "Train_MinReturn : 33.67340850830078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3507000\n",
            "TimeSinceStart : 3678.632665872574\n",
            "Training Loss : -1840.7608642578125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 118.47295379638672\n",
            "Eval_StdReturn : 16.01744270324707\n",
            "Eval_MaxReturn : 139.22682189941406\n",
            "Eval_MinReturn : 100.23501586914062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 107.59394836425781\n",
            "Train_StdReturn : 25.00448989868164\n",
            "Train_MaxReturn : 151.87310791015625\n",
            "Train_MinReturn : 12.181968688964844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3557100\n",
            "TimeSinceStart : 3730.9828391075134\n",
            "Training Loss : -1253.7420654296875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 121.58858489990234\n",
            "Eval_StdReturn : 7.601830959320068\n",
            "Eval_MaxReturn : 128.20382690429688\n",
            "Eval_MinReturn : 110.94197845458984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 108.99824523925781\n",
            "Train_StdReturn : 23.5894832611084\n",
            "Train_MaxReturn : 175.9747772216797\n",
            "Train_MinReturn : 22.862045288085938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3607200\n",
            "TimeSinceStart : 3783.421242952347\n",
            "Training Loss : -1163.5181884765625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 130.0083770751953\n",
            "Eval_StdReturn : 20.39905548095703\n",
            "Eval_MaxReturn : 146.87350463867188\n",
            "Eval_MinReturn : 101.30619049072266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 107.72410583496094\n",
            "Train_StdReturn : 24.850088119506836\n",
            "Train_MaxReturn : 170.62339782714844\n",
            "Train_MinReturn : -8.941308975219727\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3657300\n",
            "TimeSinceStart : 3835.87056016922\n",
            "Training Loss : -1001.3258666992188\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 102.3810043334961\n",
            "Eval_StdReturn : 16.173542022705078\n",
            "Eval_MaxReturn : 123.60033416748047\n",
            "Eval_MinReturn : 84.3767318725586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 112.34980773925781\n",
            "Train_StdReturn : 22.84734344482422\n",
            "Train_MaxReturn : 160.8982696533203\n",
            "Train_MinReturn : 33.464256286621094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3707400\n",
            "TimeSinceStart : 3888.358795404434\n",
            "Training Loss : -1430.6190185546875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 118.92489624023438\n",
            "Eval_StdReturn : 11.115878105163574\n",
            "Eval_MaxReturn : 131.28036499023438\n",
            "Eval_MinReturn : 104.32986450195312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 114.22394561767578\n",
            "Train_StdReturn : 20.88551139831543\n",
            "Train_MaxReturn : 160.2327880859375\n",
            "Train_MinReturn : 60.381744384765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3757500\n",
            "TimeSinceStart : 3941.078417301178\n",
            "Training Loss : -1453.8128662109375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 116.83856201171875\n",
            "Eval_StdReturn : 17.319129943847656\n",
            "Eval_MaxReturn : 134.42813110351562\n",
            "Eval_MinReturn : 93.28289031982422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 112.51335906982422\n",
            "Train_StdReturn : 20.92493438720703\n",
            "Train_MaxReturn : 169.00282287597656\n",
            "Train_MinReturn : 27.325477600097656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3807600\n",
            "TimeSinceStart : 3993.755970478058\n",
            "Training Loss : -2637.66064453125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.2519302368164\n",
            "Eval_StdReturn : 36.99296569824219\n",
            "Eval_MaxReturn : 120.69317626953125\n",
            "Eval_MinReturn : 40.00446701049805\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 107.66000366210938\n",
            "Train_StdReturn : 19.467370986938477\n",
            "Train_MaxReturn : 150.26229858398438\n",
            "Train_MinReturn : 41.89747619628906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3857700\n",
            "TimeSinceStart : 4046.0591967105865\n",
            "Training Loss : -855.316650390625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 100.59745025634766\n",
            "Eval_StdReturn : 15.568761825561523\n",
            "Eval_MaxReturn : 113.65491485595703\n",
            "Eval_MinReturn : 78.71598815917969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 106.61073303222656\n",
            "Train_StdReturn : 23.004364013671875\n",
            "Train_MaxReturn : 157.44515991210938\n",
            "Train_MinReturn : 16.165019989013672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3907800\n",
            "TimeSinceStart : 4098.500772476196\n",
            "Training Loss : -2462.62939453125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 112.9410171508789\n",
            "Eval_StdReturn : 15.83384895324707\n",
            "Eval_MaxReturn : 134.62942504882812\n",
            "Eval_MinReturn : 97.27229309082031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 113.18789672851562\n",
            "Train_StdReturn : 20.109865188598633\n",
            "Train_MaxReturn : 161.020751953125\n",
            "Train_MinReturn : 34.72047424316406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3957900\n",
            "TimeSinceStart : 4151.332024097443\n",
            "Training Loss : -1642.9423828125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 134.97886657714844\n",
            "Eval_StdReturn : 10.280012130737305\n",
            "Eval_MaxReturn : 143.12738037109375\n",
            "Eval_MinReturn : 120.47774505615234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 121.81411743164062\n",
            "Train_StdReturn : 20.470006942749023\n",
            "Train_MaxReturn : 163.67596435546875\n",
            "Train_MinReturn : 57.21306610107422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4008000\n",
            "TimeSinceStart : 4203.695562362671\n",
            "Training Loss : -1332.0\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 137.68675231933594\n",
            "Eval_StdReturn : 6.971113681793213\n",
            "Eval_MaxReturn : 146.92950439453125\n",
            "Eval_MinReturn : 130.094970703125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 126.23196411132812\n",
            "Train_StdReturn : 16.6935977935791\n",
            "Train_MaxReturn : 163.6136474609375\n",
            "Train_MinReturn : 63.29278564453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4058100\n",
            "TimeSinceStart : 4256.409070014954\n",
            "Training Loss : -1212.411376953125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 143.3524932861328\n",
            "Eval_StdReturn : 6.222541332244873\n",
            "Eval_MaxReturn : 149.18917846679688\n",
            "Eval_MinReturn : 134.73065185546875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 125.75430297851562\n",
            "Train_StdReturn : 22.466543197631836\n",
            "Train_MaxReturn : 168.96380615234375\n",
            "Train_MinReturn : 17.737960815429688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4108200\n",
            "TimeSinceStart : 4308.823196411133\n",
            "Training Loss : -1549.6533203125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 122.30142974853516\n",
            "Eval_StdReturn : 25.569337844848633\n",
            "Eval_MaxReturn : 147.36207580566406\n",
            "Eval_MinReturn : 87.19547271728516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 120.84709167480469\n",
            "Train_StdReturn : 25.899751663208008\n",
            "Train_MaxReturn : 173.83665466308594\n",
            "Train_MinReturn : 6.331050872802734\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4158300\n",
            "TimeSinceStart : 4361.042595624924\n",
            "Training Loss : -1121.13818359375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 134.41590881347656\n",
            "Eval_StdReturn : 15.481866836547852\n",
            "Eval_MaxReturn : 154.44073486328125\n",
            "Eval_MinReturn : 116.73622131347656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 119.49600982666016\n",
            "Train_StdReturn : 29.01091957092285\n",
            "Train_MaxReturn : 160.71678161621094\n",
            "Train_MinReturn : -11.572368621826172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4208400\n",
            "TimeSinceStart : 4413.423604249954\n",
            "Training Loss : -1292.3341064453125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 124.98503875732422\n",
            "Eval_StdReturn : 8.277955055236816\n",
            "Eval_MaxReturn : 134.25567626953125\n",
            "Eval_MinReturn : 114.15873718261719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 119.08979797363281\n",
            "Train_StdReturn : 27.509357452392578\n",
            "Train_MaxReturn : 169.09364318847656\n",
            "Train_MinReturn : -3.3399600982666016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4258500\n",
            "TimeSinceStart : 4466.037438631058\n",
            "Training Loss : -915.8748779296875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 146.1993865966797\n",
            "Eval_StdReturn : 11.612956047058105\n",
            "Eval_MaxReturn : 157.4530792236328\n",
            "Eval_MinReturn : 130.21363830566406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 125.66880798339844\n",
            "Train_StdReturn : 24.991281509399414\n",
            "Train_MaxReturn : 170.17462158203125\n",
            "Train_MinReturn : 4.865749359130859\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4308600\n",
            "TimeSinceStart : 4518.535922050476\n",
            "Training Loss : -1528.83349609375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 121.36882781982422\n",
            "Eval_StdReturn : 11.073988914489746\n",
            "Eval_MaxReturn : 136.76918029785156\n",
            "Eval_MinReturn : 111.20457458496094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 132.45867919921875\n",
            "Train_StdReturn : 24.742849349975586\n",
            "Train_MaxReturn : 189.66163635253906\n",
            "Train_MinReturn : 13.246255874633789\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4358700\n",
            "TimeSinceStart : 4571.140747308731\n",
            "Training Loss : -2126.113525390625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 115.7525405883789\n",
            "Eval_StdReturn : 7.665185928344727\n",
            "Eval_MaxReturn : 126.58173370361328\n",
            "Eval_MinReturn : 109.9146728515625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 127.77572631835938\n",
            "Train_StdReturn : 26.562387466430664\n",
            "Train_MaxReturn : 173.74819946289062\n",
            "Train_MinReturn : -30.76266860961914\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4408800\n",
            "TimeSinceStart : 4623.7668652534485\n",
            "Training Loss : -887.48681640625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 154.0581817626953\n",
            "Eval_StdReturn : 6.236508369445801\n",
            "Eval_MaxReturn : 162.7493896484375\n",
            "Eval_MinReturn : 148.41323852539062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 126.35025024414062\n",
            "Train_StdReturn : 27.351032257080078\n",
            "Train_MaxReturn : 177.12203979492188\n",
            "Train_MinReturn : 5.809257507324219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4458900\n",
            "TimeSinceStart : 4676.142307758331\n",
            "Training Loss : -851.5517578125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 108.01708221435547\n",
            "Eval_StdReturn : 54.15922164916992\n",
            "Eval_MaxReturn : 159.5979766845703\n",
            "Eval_MinReturn : 33.192047119140625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 126.78369140625\n",
            "Train_StdReturn : 24.36749267578125\n",
            "Train_MaxReturn : 181.9404754638672\n",
            "Train_MinReturn : -6.149084091186523\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4509000\n",
            "TimeSinceStart : 4728.844641208649\n",
            "Training Loss : -894.416015625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 137.4227752685547\n",
            "Eval_StdReturn : 10.867755889892578\n",
            "Eval_MaxReturn : 150.14637756347656\n",
            "Eval_MinReturn : 123.59474182128906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 130.13720703125\n",
            "Train_StdReturn : 23.375171661376953\n",
            "Train_MaxReturn : 175.3926239013672\n",
            "Train_MinReturn : -11.396491050720215\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4559100\n",
            "TimeSinceStart : 4781.61247420311\n",
            "Training Loss : -600.0408325195312\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 140.44302368164062\n",
            "Eval_StdReturn : 3.344510078430176\n",
            "Eval_MaxReturn : 143.56317138671875\n",
            "Eval_MinReturn : 135.80445861816406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 128.7584991455078\n",
            "Train_StdReturn : 24.223548889160156\n",
            "Train_MaxReturn : 179.10598754882812\n",
            "Train_MinReturn : 31.61260414123535\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4609200\n",
            "TimeSinceStart : 4834.003568410873\n",
            "Training Loss : -845.085693359375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 111.85494232177734\n",
            "Eval_StdReturn : 28.000072479248047\n",
            "Eval_MaxReturn : 134.42507934570312\n",
            "Eval_MinReturn : 72.39279174804688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 127.3374252319336\n",
            "Train_StdReturn : 20.81360626220703\n",
            "Train_MaxReturn : 167.51031494140625\n",
            "Train_MinReturn : 47.871551513671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4659300\n",
            "TimeSinceStart : 4886.580177783966\n",
            "Training Loss : -1878.976806640625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 132.9702606201172\n",
            "Eval_StdReturn : 17.085098266601562\n",
            "Eval_MaxReturn : 147.78955078125\n",
            "Eval_MinReturn : 109.03359985351562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 128.4480743408203\n",
            "Train_StdReturn : 21.66675567626953\n",
            "Train_MaxReturn : 170.16436767578125\n",
            "Train_MinReturn : 38.410335540771484\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4709400\n",
            "TimeSinceStart : 4938.6926555633545\n",
            "Training Loss : -1490.45263671875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 93.01839447021484\n",
            "Eval_StdReturn : 30.098709106445312\n",
            "Eval_MaxReturn : 129.163330078125\n",
            "Eval_MinReturn : 55.4765625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 130.60023498535156\n",
            "Train_StdReturn : 25.542325973510742\n",
            "Train_MaxReturn : 186.5050506591797\n",
            "Train_MinReturn : 13.878166198730469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4759500\n",
            "TimeSinceStart : 4991.197489738464\n",
            "Training Loss : -1273.8175048828125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 91.02523803710938\n",
            "Eval_StdReturn : 21.7012882232666\n",
            "Eval_MaxReturn : 118.5923843383789\n",
            "Eval_MinReturn : 65.56013488769531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 132.32098388671875\n",
            "Train_StdReturn : 24.48154640197754\n",
            "Train_MaxReturn : 188.15354919433594\n",
            "Train_MinReturn : 11.660728454589844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4809600\n",
            "TimeSinceStart : 5043.8160400390625\n",
            "Training Loss : -588.65087890625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 135.7104949951172\n",
            "Eval_StdReturn : 31.83271598815918\n",
            "Eval_MaxReturn : 171.85780334472656\n",
            "Eval_MinReturn : 94.39868927001953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 130.65615844726562\n",
            "Train_StdReturn : 28.63482666015625\n",
            "Train_MaxReturn : 176.2762451171875\n",
            "Train_MinReturn : -62.00989532470703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4859700\n",
            "TimeSinceStart : 5096.604220151901\n",
            "Training Loss : -1237.604248046875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 137.1472930908203\n",
            "Eval_StdReturn : 9.109482765197754\n",
            "Eval_MaxReturn : 148.26254272460938\n",
            "Eval_MinReturn : 125.94941711425781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 130.323486328125\n",
            "Train_StdReturn : 24.794889450073242\n",
            "Train_MaxReturn : 179.02560424804688\n",
            "Train_MinReturn : 22.055675506591797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4909800\n",
            "TimeSinceStart : 5149.040729999542\n",
            "Training Loss : -719.10986328125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 125.5777587890625\n",
            "Eval_StdReturn : 17.82372283935547\n",
            "Eval_MaxReturn : 143.43899536132812\n",
            "Eval_MinReturn : 101.243896484375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 135.6717071533203\n",
            "Train_StdReturn : 21.354578018188477\n",
            "Train_MaxReturn : 177.6912384033203\n",
            "Train_MinReturn : 50.510581970214844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4959900\n",
            "TimeSinceStart : 5201.553505420685\n",
            "Training Loss : -748.0471801757812\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 138.25408935546875\n",
            "Eval_StdReturn : 12.02319049835205\n",
            "Eval_MaxReturn : 147.65628051757812\n",
            "Eval_MinReturn : 121.28373718261719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 135.13619995117188\n",
            "Train_StdReturn : 20.30750274658203\n",
            "Train_MaxReturn : 180.47964477539062\n",
            "Train_MinReturn : 13.027738571166992\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 5010000\n",
            "TimeSinceStart : 5254.0530462265015\n",
            "Training Loss : -1930.456787109375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "    --discount 0.95 -n 100 -l 2 -s 32 \\\n",
        "    -b 50000 -lr 0.02 --nn_baseline \\\n",
        "    --exp_name q4_b50000_r0.02_nnbaseline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOYJ_nJMUAbQ",
        "outputId": "8b8f432b-46bf-49cb-f1fb-7f87207d5f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q4_b50000_r0.02_nnbaseline_HalfCheetah-v2_10-05-2022_10-05-27\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -67.44086456298828\n",
            "Eval_StdReturn : 17.779043197631836\n",
            "Eval_MaxReturn : -45.44334030151367\n",
            "Eval_MinReturn : -88.98587036132812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -89.54405975341797\n",
            "Train_StdReturn : 39.07257843017578\n",
            "Train_MaxReturn : 11.764884948730469\n",
            "Train_MinReturn : -232.5586395263672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50100\n",
            "TimeSinceStart : 44.92436957359314\n",
            "Training Loss : -526.247314453125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -93.15642547607422\n",
            "Eval_StdReturn : 22.819103240966797\n",
            "Eval_MaxReturn : -70.07715606689453\n",
            "Eval_MinReturn : -124.23007202148438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -91.04741668701172\n",
            "Train_StdReturn : 34.65858840942383\n",
            "Train_MaxReturn : 16.4486141204834\n",
            "Train_MinReturn : -201.84579467773438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100200\n",
            "TimeSinceStart : 90.73408055305481\n",
            "Training Loss : -1035.129638671875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -93.91780853271484\n",
            "Eval_StdReturn : 29.040708541870117\n",
            "Eval_MaxReturn : -56.034423828125\n",
            "Eval_MinReturn : -126.59561920166016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -88.43740844726562\n",
            "Train_StdReturn : 35.656341552734375\n",
            "Train_MaxReturn : 19.810134887695312\n",
            "Train_MinReturn : -201.18496704101562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150300\n",
            "TimeSinceStart : 135.99652671813965\n",
            "Training Loss : -462.214599609375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -101.33270263671875\n",
            "Eval_StdReturn : 28.837282180786133\n",
            "Eval_MaxReturn : -65.03803253173828\n",
            "Eval_MinReturn : -135.58612060546875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -84.80596160888672\n",
            "Train_StdReturn : 35.945228576660156\n",
            "Train_MaxReturn : -5.099503993988037\n",
            "Train_MinReturn : -202.95108032226562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 200400\n",
            "TimeSinceStart : 181.2083330154419\n",
            "Training Loss : -442.8228759765625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.837799072265625\n",
            "Eval_StdReturn : 14.685297966003418\n",
            "Eval_MaxReturn : -43.36491012573242\n",
            "Eval_MinReturn : -79.2958984375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -89.55282592773438\n",
            "Train_StdReturn : 33.60282516479492\n",
            "Train_MaxReturn : -7.723012924194336\n",
            "Train_MinReturn : -208.20542907714844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 250500\n",
            "TimeSinceStart : 226.40051651000977\n",
            "Training Loss : -500.8758544921875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -93.51444244384766\n",
            "Eval_StdReturn : 28.4796142578125\n",
            "Eval_MaxReturn : -71.9498291015625\n",
            "Eval_MinReturn : -133.7561798095703\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -87.8003921508789\n",
            "Train_StdReturn : 36.44205093383789\n",
            "Train_MaxReturn : 2.5108327865600586\n",
            "Train_MinReturn : -214.18435668945312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300600\n",
            "TimeSinceStart : 271.5983316898346\n",
            "Training Loss : -872.9873046875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -119.6217269897461\n",
            "Eval_StdReturn : 21.088966369628906\n",
            "Eval_MaxReturn : -100.84136962890625\n",
            "Eval_MinReturn : -149.07655334472656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -92.36804962158203\n",
            "Train_StdReturn : 37.625953674316406\n",
            "Train_MaxReturn : 14.506998062133789\n",
            "Train_MinReturn : -212.89784240722656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 350700\n",
            "TimeSinceStart : 317.59132528305054\n",
            "Training Loss : 163.62060546875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -112.1186294555664\n",
            "Eval_StdReturn : 14.827193260192871\n",
            "Eval_MaxReturn : -94.47691345214844\n",
            "Eval_MinReturn : -130.7550811767578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -100.84962463378906\n",
            "Train_StdReturn : 37.97395324707031\n",
            "Train_MaxReturn : 5.101234436035156\n",
            "Train_MinReturn : -228.0588836669922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 400800\n",
            "TimeSinceStart : 362.7143974304199\n",
            "Training Loss : -311.6905517578125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -106.81949615478516\n",
            "Eval_StdReturn : 42.183624267578125\n",
            "Eval_MaxReturn : -53.22673797607422\n",
            "Eval_MinReturn : -156.31056213378906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -110.07128143310547\n",
            "Train_StdReturn : 35.68608856201172\n",
            "Train_MaxReturn : -14.075662612915039\n",
            "Train_MinReturn : -227.06100463867188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450900\n",
            "TimeSinceStart : 407.8196179866791\n",
            "Training Loss : -338.87896728515625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -101.08592987060547\n",
            "Eval_StdReturn : 14.24496078491211\n",
            "Eval_MaxReturn : -84.51323699951172\n",
            "Eval_MinReturn : -119.29133605957031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -111.36334991455078\n",
            "Train_StdReturn : 35.45207595825195\n",
            "Train_MaxReturn : -26.208168029785156\n",
            "Train_MinReturn : -239.65536499023438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 501000\n",
            "TimeSinceStart : 453.0992133617401\n",
            "Training Loss : -818.1602783203125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -130.80526733398438\n",
            "Eval_StdReturn : 24.199729919433594\n",
            "Eval_MaxReturn : -97.0284423828125\n",
            "Eval_MinReturn : -152.467041015625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -107.16217041015625\n",
            "Train_StdReturn : 30.62993621826172\n",
            "Train_MaxReturn : -7.06203556060791\n",
            "Train_MinReturn : -207.9290771484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 551100\n",
            "TimeSinceStart : 498.6838164329529\n",
            "Training Loss : -657.4180908203125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -90.72293853759766\n",
            "Eval_StdReturn : 28.0800724029541\n",
            "Eval_MaxReturn : -63.95762252807617\n",
            "Eval_MinReturn : -129.51129150390625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -104.646728515625\n",
            "Train_StdReturn : 30.409318923950195\n",
            "Train_MaxReturn : 0.47838783264160156\n",
            "Train_MinReturn : -191.67935180664062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 601200\n",
            "TimeSinceStart : 544.7997817993164\n",
            "Training Loss : -650.73876953125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.9443359375\n",
            "Eval_StdReturn : 12.071866035461426\n",
            "Eval_MaxReturn : -44.925594329833984\n",
            "Eval_MinReturn : -72.74686431884766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -95.20863342285156\n",
            "Train_StdReturn : 32.0003662109375\n",
            "Train_MaxReturn : -11.196467399597168\n",
            "Train_MinReturn : -196.49658203125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 651300\n",
            "TimeSinceStart : 591.0081219673157\n",
            "Training Loss : -871.3470458984375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -110.32315063476562\n",
            "Eval_StdReturn : 33.241676330566406\n",
            "Eval_MaxReturn : -72.24740600585938\n",
            "Eval_MinReturn : -153.23971557617188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -95.2158203125\n",
            "Train_StdReturn : 30.699325561523438\n",
            "Train_MaxReturn : 8.994047164916992\n",
            "Train_MinReturn : -183.20518493652344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 701400\n",
            "TimeSinceStart : 637.5778515338898\n",
            "Training Loss : -307.5743408203125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -72.94237518310547\n",
            "Eval_StdReturn : 27.445571899414062\n",
            "Eval_MaxReturn : -34.233612060546875\n",
            "Eval_MinReturn : -94.76919555664062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -97.0904541015625\n",
            "Train_StdReturn : 30.845867156982422\n",
            "Train_MaxReturn : -9.516805648803711\n",
            "Train_MinReturn : -200.558349609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 751500\n",
            "TimeSinceStart : 684.4443197250366\n",
            "Training Loss : -276.17938232421875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -93.4615707397461\n",
            "Eval_StdReturn : 21.74984359741211\n",
            "Eval_MaxReturn : -69.52568054199219\n",
            "Eval_MinReturn : -122.15937805175781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -88.94254302978516\n",
            "Train_StdReturn : 28.953872680664062\n",
            "Train_MaxReturn : -8.110946655273438\n",
            "Train_MinReturn : -213.3258819580078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 801600\n",
            "TimeSinceStart : 731.5587613582611\n",
            "Training Loss : -1165.864501953125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -69.28717041015625\n",
            "Eval_StdReturn : 10.700040817260742\n",
            "Eval_MaxReturn : -56.136173248291016\n",
            "Eval_MinReturn : -82.34532165527344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -86.92665100097656\n",
            "Train_StdReturn : 29.104467391967773\n",
            "Train_MaxReturn : -7.219562530517578\n",
            "Train_MinReturn : -203.40020751953125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 851700\n",
            "TimeSinceStart : 777.4624464511871\n",
            "Training Loss : -809.4537353515625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -81.71428680419922\n",
            "Eval_StdReturn : 18.1112117767334\n",
            "Eval_MaxReturn : -58.340538024902344\n",
            "Eval_MinReturn : -102.47171020507812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -82.52242279052734\n",
            "Train_StdReturn : 24.982128143310547\n",
            "Train_MaxReturn : -11.698799133300781\n",
            "Train_MinReturn : -171.91268920898438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 901800\n",
            "TimeSinceStart : 823.4094927310944\n",
            "Training Loss : -320.3294677734375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -63.4515380859375\n",
            "Eval_StdReturn : 20.146080017089844\n",
            "Eval_MaxReturn : -44.938438415527344\n",
            "Eval_MinReturn : -91.46296691894531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -78.21990203857422\n",
            "Train_StdReturn : 25.34956932067871\n",
            "Train_MaxReturn : 11.775147438049316\n",
            "Train_MinReturn : -192.34347534179688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 951900\n",
            "TimeSinceStart : 868.9755620956421\n",
            "Training Loss : -197.105712890625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.25115966796875\n",
            "Eval_StdReturn : 23.341066360473633\n",
            "Eval_MaxReturn : -24.21063995361328\n",
            "Eval_MinReturn : -81.36164855957031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -72.83973693847656\n",
            "Train_StdReturn : 21.505239486694336\n",
            "Train_MaxReturn : 6.340412139892578\n",
            "Train_MinReturn : -135.7249755859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1002000\n",
            "TimeSinceStart : 914.9952030181885\n",
            "Training Loss : -274.178955078125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.26424026489258\n",
            "Eval_StdReturn : 16.337139129638672\n",
            "Eval_MaxReturn : -42.361488342285156\n",
            "Eval_MinReturn : -78.31358337402344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -72.476318359375\n",
            "Train_StdReturn : 18.714927673339844\n",
            "Train_MaxReturn : -14.150347709655762\n",
            "Train_MinReturn : -144.49642944335938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1052100\n",
            "TimeSinceStart : 960.7301161289215\n",
            "Training Loss : -276.36456298828125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -64.19076538085938\n",
            "Eval_StdReturn : 12.361353874206543\n",
            "Eval_MaxReturn : -53.04513168334961\n",
            "Eval_MinReturn : -81.42701721191406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -71.78849029541016\n",
            "Train_StdReturn : 18.98982048034668\n",
            "Train_MaxReturn : -20.209890365600586\n",
            "Train_MinReturn : -154.90390014648438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1102200\n",
            "TimeSinceStart : 1006.4175577163696\n",
            "Training Loss : -1334.7532958984375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -62.90341567993164\n",
            "Eval_StdReturn : 20.746362686157227\n",
            "Eval_MaxReturn : -35.45372009277344\n",
            "Eval_MinReturn : -85.6006088256836\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -66.89474487304688\n",
            "Train_StdReturn : 15.45421028137207\n",
            "Train_MaxReturn : -21.143342971801758\n",
            "Train_MinReturn : -133.09573364257812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1152300\n",
            "TimeSinceStart : 1052.540493965149\n",
            "Training Loss : -63.1859130859375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.12845993041992\n",
            "Eval_StdReturn : 8.110282897949219\n",
            "Eval_MaxReturn : -52.81417465209961\n",
            "Eval_MinReturn : -72.12808227539062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -61.66850662231445\n",
            "Train_StdReturn : 18.46384048461914\n",
            "Train_MaxReturn : 7.622064590454102\n",
            "Train_MinReturn : -141.7781219482422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1202400\n",
            "TimeSinceStart : 1098.5295746326447\n",
            "Training Loss : -546.4165649414062\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.24810791015625\n",
            "Eval_StdReturn : 14.376422882080078\n",
            "Eval_MaxReturn : -26.94647216796875\n",
            "Eval_MinReturn : -58.35023498535156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -59.28091049194336\n",
            "Train_StdReturn : 18.374103546142578\n",
            "Train_MaxReturn : -12.985210418701172\n",
            "Train_MinReturn : -130.78036499023438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1252500\n",
            "TimeSinceStart : 1144.466017961502\n",
            "Training Loss : -552.7301025390625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.046356201171875\n",
            "Eval_StdReturn : 17.598634719848633\n",
            "Eval_MaxReturn : -6.262931823730469\n",
            "Eval_MinReturn : -45.41399383544922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -53.17259979248047\n",
            "Train_StdReturn : 20.52682113647461\n",
            "Train_MaxReturn : 2.6218366622924805\n",
            "Train_MinReturn : -155.6929473876953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1302600\n",
            "TimeSinceStart : 1190.2068972587585\n",
            "Training Loss : -645.4398193359375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.647953033447266\n",
            "Eval_StdReturn : 26.59038543701172\n",
            "Eval_MaxReturn : -2.484255790710449\n",
            "Eval_MinReturn : -67.17681884765625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.253662109375\n",
            "Train_StdReturn : 20.14015007019043\n",
            "Train_MaxReturn : 22.444507598876953\n",
            "Train_MinReturn : -124.51547241210938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1352700\n",
            "TimeSinceStart : 1236.119755744934\n",
            "Training Loss : -708.690673828125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.41957473754883\n",
            "Eval_StdReturn : 6.272597789764404\n",
            "Eval_MaxReturn : -30.022119522094727\n",
            "Eval_MinReturn : -45.094242095947266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -48.171634674072266\n",
            "Train_StdReturn : 19.50790023803711\n",
            "Train_MaxReturn : 13.931071281433105\n",
            "Train_MinReturn : -111.63166046142578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1402800\n",
            "TimeSinceStart : 1281.5456147193909\n",
            "Training Loss : -618.9056396484375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.75138282775879\n",
            "Eval_StdReturn : 7.705836772918701\n",
            "Eval_MaxReturn : -21.172395706176758\n",
            "Eval_MinReturn : -39.32240295410156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.49636459350586\n",
            "Train_StdReturn : 21.203615188598633\n",
            "Train_MaxReturn : 25.21743392944336\n",
            "Train_MinReturn : -133.64996337890625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1452900\n",
            "TimeSinceStart : 1327.3102464675903\n",
            "Training Loss : -818.844970703125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.8755989074707\n",
            "Eval_StdReturn : 7.787652969360352\n",
            "Eval_MaxReturn : -37.06468200683594\n",
            "Eval_MinReturn : -55.505157470703125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.13937759399414\n",
            "Train_StdReturn : 22.7906551361084\n",
            "Train_MaxReturn : 42.20606231689453\n",
            "Train_MinReturn : -125.67619323730469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1503000\n",
            "TimeSinceStart : 1372.8975162506104\n",
            "Training Loss : -125.75570678710938\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.679691314697266\n",
            "Eval_StdReturn : 8.806791305541992\n",
            "Eval_MaxReturn : -24.764766693115234\n",
            "Eval_MinReturn : -46.33211898803711\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.90502166748047\n",
            "Train_StdReturn : 22.645797729492188\n",
            "Train_MaxReturn : 27.501676559448242\n",
            "Train_MinReturn : -137.61123657226562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1553100\n",
            "TimeSinceStart : 1418.3898441791534\n",
            "Training Loss : -612.5059204101562\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -86.6605224609375\n",
            "Eval_StdReturn : 23.832317352294922\n",
            "Eval_MaxReturn : -64.1431884765625\n",
            "Eval_MinReturn : -119.63776397705078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.423770904541016\n",
            "Train_StdReturn : 22.701160430908203\n",
            "Train_MaxReturn : 32.155975341796875\n",
            "Train_MinReturn : -104.87684631347656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1603200\n",
            "TimeSinceStart : 1463.9069213867188\n",
            "Training Loss : -415.0489501953125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -62.67119216918945\n",
            "Eval_StdReturn : 7.457840919494629\n",
            "Eval_MaxReturn : -52.31084442138672\n",
            "Eval_MinReturn : -69.56206512451172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -48.94341278076172\n",
            "Train_StdReturn : 24.448532104492188\n",
            "Train_MaxReturn : 24.981082916259766\n",
            "Train_MinReturn : -133.83641052246094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1653300\n",
            "TimeSinceStart : 1509.5257999897003\n",
            "Training Loss : -1437.09765625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.8913688659668\n",
            "Eval_StdReturn : 9.82339859008789\n",
            "Eval_MaxReturn : -26.0921573638916\n",
            "Eval_MinReturn : -49.859432220458984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.31195068359375\n",
            "Train_StdReturn : 24.031295776367188\n",
            "Train_MaxReturn : 18.887407302856445\n",
            "Train_MinReturn : -145.8177490234375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1703400\n",
            "TimeSinceStart : 1554.7602212429047\n",
            "Training Loss : 343.72650146484375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.2293815612793\n",
            "Eval_StdReturn : 23.93175506591797\n",
            "Eval_MaxReturn : -16.538352966308594\n",
            "Eval_MinReturn : -73.162109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -56.2619514465332\n",
            "Train_StdReturn : 25.518503189086914\n",
            "Train_MaxReturn : 33.52000045776367\n",
            "Train_MinReturn : -124.52749633789062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1753500\n",
            "TimeSinceStart : 1600.082041978836\n",
            "Training Loss : -754.1266479492188\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -66.84957122802734\n",
            "Eval_StdReturn : 21.093265533447266\n",
            "Eval_MaxReturn : -40.67580032348633\n",
            "Eval_MinReturn : -92.32955932617188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.7852783203125\n",
            "Train_StdReturn : 22.68157958984375\n",
            "Train_MaxReturn : 0.7317862510681152\n",
            "Train_MinReturn : -150.83209228515625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1803600\n",
            "TimeSinceStart : 1645.7723865509033\n",
            "Training Loss : -658.3421630859375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -58.0307502746582\n",
            "Eval_StdReturn : 20.622665405273438\n",
            "Eval_MaxReturn : -35.93663787841797\n",
            "Eval_MinReturn : -85.56504821777344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.43616485595703\n",
            "Train_StdReturn : 25.536020278930664\n",
            "Train_MaxReturn : 17.084720611572266\n",
            "Train_MinReturn : -154.61434936523438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1853700\n",
            "TimeSinceStart : 1691.1484920978546\n",
            "Training Loss : -218.48263549804688\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.728729248046875\n",
            "Eval_StdReturn : 8.702179908752441\n",
            "Eval_MaxReturn : -24.782432556152344\n",
            "Eval_MinReturn : -45.26243209838867\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.81827163696289\n",
            "Train_StdReturn : 27.433420181274414\n",
            "Train_MaxReturn : 78.53178405761719\n",
            "Train_MinReturn : -135.31161499023438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1903800\n",
            "TimeSinceStart : 1736.5501296520233\n",
            "Training Loss : -465.53802490234375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.93030548095703\n",
            "Eval_StdReturn : 18.255870819091797\n",
            "Eval_MaxReturn : -10.529314041137695\n",
            "Eval_MinReturn : -54.43552017211914\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.88631057739258\n",
            "Train_StdReturn : 25.118650436401367\n",
            "Train_MaxReturn : 26.023252487182617\n",
            "Train_MinReturn : -186.0536651611328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1953900\n",
            "TimeSinceStart : 1782.226172208786\n",
            "Training Loss : -823.116455078125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.27960205078125\n",
            "Eval_StdReturn : 10.165837287902832\n",
            "Eval_MaxReturn : -36.56865310668945\n",
            "Eval_MinReturn : -60.94007873535156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -42.854034423828125\n",
            "Train_StdReturn : 23.903339385986328\n",
            "Train_MaxReturn : 24.137699127197266\n",
            "Train_MinReturn : -129.0328826904297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2004000\n",
            "TimeSinceStart : 1827.8414223194122\n",
            "Training Loss : -1394.869873046875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -48.6121940612793\n",
            "Eval_StdReturn : 24.13335418701172\n",
            "Eval_MaxReturn : -30.22903823852539\n",
            "Eval_MinReturn : -82.70703887939453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.09373092651367\n",
            "Train_StdReturn : 25.88275909423828\n",
            "Train_MaxReturn : 55.606754302978516\n",
            "Train_MinReturn : -131.3455047607422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2054100\n",
            "TimeSinceStart : 1873.0797457695007\n",
            "Training Loss : -100.7794189453125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -63.40671157836914\n",
            "Eval_StdReturn : 9.426008224487305\n",
            "Eval_MaxReturn : -54.782188415527344\n",
            "Eval_MinReturn : -76.52168273925781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.89881896972656\n",
            "Train_StdReturn : 23.275005340576172\n",
            "Train_MaxReturn : 12.223054885864258\n",
            "Train_MinReturn : -167.3851776123047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2104200\n",
            "TimeSinceStart : 1918.9223229885101\n",
            "Training Loss : 130.466796875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -52.45900344848633\n",
            "Eval_StdReturn : 11.703353881835938\n",
            "Eval_MaxReturn : -36.41979217529297\n",
            "Eval_MinReturn : -64.01563262939453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.99808120727539\n",
            "Train_StdReturn : 24.99335289001465\n",
            "Train_MaxReturn : 19.2943058013916\n",
            "Train_MinReturn : -172.77099609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2154300\n",
            "TimeSinceStart : 1964.8807966709137\n",
            "Training Loss : 155.34320068359375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.60001754760742\n",
            "Eval_StdReturn : 16.46088981628418\n",
            "Eval_MaxReturn : -10.416302680969238\n",
            "Eval_MinReturn : -47.01613235473633\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.689964294433594\n",
            "Train_StdReturn : 22.150310516357422\n",
            "Train_MaxReturn : 6.931692123413086\n",
            "Train_MinReturn : -135.897705078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2204400\n",
            "TimeSinceStart : 2010.5443620681763\n",
            "Training Loss : 79.75103759765625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.79056167602539\n",
            "Eval_StdReturn : 22.64006233215332\n",
            "Eval_MaxReturn : -15.213059425354004\n",
            "Eval_MinReturn : -68.06509399414062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.08576965332031\n",
            "Train_StdReturn : 22.53875732421875\n",
            "Train_MaxReturn : 32.055259704589844\n",
            "Train_MinReturn : -119.54780578613281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2254500\n",
            "TimeSinceStart : 2055.674351453781\n",
            "Training Loss : -420.5382080078125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -66.07172393798828\n",
            "Eval_StdReturn : 30.826040267944336\n",
            "Eval_MaxReturn : -22.971052169799805\n",
            "Eval_MinReturn : -93.28919982910156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.89411163330078\n",
            "Train_StdReturn : 25.129404067993164\n",
            "Train_MaxReturn : 43.7121467590332\n",
            "Train_MinReturn : -123.08924102783203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2304600\n",
            "TimeSinceStart : 2100.666182279587\n",
            "Training Loss : -404.2230224609375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.15287780761719\n",
            "Eval_StdReturn : 21.294736862182617\n",
            "Eval_MaxReturn : -31.86376953125\n",
            "Eval_MinReturn : -83.71586608886719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.82658004760742\n",
            "Train_StdReturn : 27.167076110839844\n",
            "Train_MaxReturn : 44.6533088684082\n",
            "Train_MinReturn : -171.08299255371094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2354700\n",
            "TimeSinceStart : 2145.345314025879\n",
            "Training Loss : -449.201416015625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.146724700927734\n",
            "Eval_StdReturn : 16.84241485595703\n",
            "Eval_MaxReturn : -14.657905578613281\n",
            "Eval_MinReturn : -53.312686920166016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.05543899536133\n",
            "Train_StdReturn : 28.750736236572266\n",
            "Train_MaxReturn : 60.128787994384766\n",
            "Train_MinReturn : -175.7311248779297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2404800\n",
            "TimeSinceStart : 2190.4348363876343\n",
            "Training Loss : -90.38311767578125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.304691314697266\n",
            "Eval_StdReturn : 18.534818649291992\n",
            "Eval_MaxReturn : -18.97745132446289\n",
            "Eval_MinReturn : -62.00164031982422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.801876068115234\n",
            "Train_StdReturn : 26.81569480895996\n",
            "Train_MaxReturn : 35.25860595703125\n",
            "Train_MinReturn : -141.52610778808594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2454900\n",
            "TimeSinceStart : 2235.845974445343\n",
            "Training Loss : -635.255859375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.36099624633789\n",
            "Eval_StdReturn : 35.88738250732422\n",
            "Eval_MaxReturn : 7.665122985839844\n",
            "Eval_MinReturn : -77.24005889892578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -38.6497802734375\n",
            "Train_StdReturn : 27.380531311035156\n",
            "Train_MaxReturn : 54.916595458984375\n",
            "Train_MinReturn : -163.93338012695312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2505000\n",
            "TimeSinceStart : 2281.0583028793335\n",
            "Training Loss : -650.599853515625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.66164207458496\n",
            "Eval_StdReturn : 21.980772018432617\n",
            "Eval_MaxReturn : 2.0889892578125\n",
            "Eval_MinReturn : -47.97783279418945\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -38.494083404541016\n",
            "Train_StdReturn : 27.941652297973633\n",
            "Train_MaxReturn : 45.49470520019531\n",
            "Train_MinReturn : -170.04588317871094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2555100\n",
            "TimeSinceStart : 2326.0038220882416\n",
            "Training Loss : -384.6705322265625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.798990249633789\n",
            "Eval_StdReturn : 7.1263298988342285\n",
            "Eval_MaxReturn : -1.483558177947998\n",
            "Eval_MinReturn : -18.887939453125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.4474983215332\n",
            "Train_StdReturn : 28.939960479736328\n",
            "Train_MaxReturn : 45.333221435546875\n",
            "Train_MinReturn : -148.8518524169922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2605200\n",
            "TimeSinceStart : 2371.009158372879\n",
            "Training Loss : -1057.7099609375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.114511489868164\n",
            "Eval_StdReturn : 21.629423141479492\n",
            "Eval_MaxReturn : -0.9260525703430176\n",
            "Eval_MinReturn : -50.4796257019043\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.0703239440918\n",
            "Train_StdReturn : 30.26621437072754\n",
            "Train_MaxReturn : 60.70490264892578\n",
            "Train_MinReturn : -132.5614013671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2655300\n",
            "TimeSinceStart : 2415.9483649730682\n",
            "Training Loss : -263.3656005859375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.238418579101562\n",
            "Eval_StdReturn : 4.3082661628723145\n",
            "Eval_MaxReturn : -21.896717071533203\n",
            "Eval_MinReturn : -32.447261810302734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.315990447998047\n",
            "Train_StdReturn : 27.782875061035156\n",
            "Train_MaxReturn : 42.00514602661133\n",
            "Train_MinReturn : -121.93093872070312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2705400\n",
            "TimeSinceStart : 2460.8747539520264\n",
            "Training Loss : -41.606658935546875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.46085262298584\n",
            "Eval_StdReturn : 37.52311706542969\n",
            "Eval_MaxReturn : 43.49970626831055\n",
            "Eval_MinReturn : -38.83270263671875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.27504539489746\n",
            "Train_StdReturn : 29.142127990722656\n",
            "Train_MaxReturn : 62.61371612548828\n",
            "Train_MinReturn : -135.84771728515625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2755500\n",
            "TimeSinceStart : 2505.9208555221558\n",
            "Training Loss : -665.1692504882812\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.36602783203125\n",
            "Eval_StdReturn : 39.08418273925781\n",
            "Eval_MaxReturn : 18.512405395507812\n",
            "Eval_MinReturn : -75.5463638305664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.503402709960938\n",
            "Train_StdReturn : 31.01887321472168\n",
            "Train_MaxReturn : 66.37759399414062\n",
            "Train_MinReturn : -151.34219360351562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2805600\n",
            "TimeSinceStart : 2551.1138405799866\n",
            "Training Loss : -418.55255126953125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -75.49671173095703\n",
            "Eval_StdReturn : 32.22639846801758\n",
            "Eval_MaxReturn : -30.23371124267578\n",
            "Eval_MinReturn : -102.73867797851562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.6024227142334\n",
            "Train_StdReturn : 31.99958038330078\n",
            "Train_MaxReturn : 97.95999908447266\n",
            "Train_MinReturn : -113.70713806152344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2855700\n",
            "TimeSinceStart : 2596.372711420059\n",
            "Training Loss : -355.01904296875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.59489440917969\n",
            "Eval_StdReturn : 14.577237129211426\n",
            "Eval_MaxReturn : -36.580509185791016\n",
            "Eval_MinReturn : -72.00017547607422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.730316162109375\n",
            "Train_StdReturn : 36.727848052978516\n",
            "Train_MaxReturn : 56.5547981262207\n",
            "Train_MinReturn : -127.02078247070312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2905800\n",
            "TimeSinceStart : 2641.2967903614044\n",
            "Training Loss : 367.10302734375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -74.78388977050781\n",
            "Eval_StdReturn : 28.863365173339844\n",
            "Eval_MaxReturn : -34.04804611206055\n",
            "Eval_MinReturn : -97.4065933227539\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.107650756835938\n",
            "Train_StdReturn : 40.6098747253418\n",
            "Train_MaxReturn : 67.070556640625\n",
            "Train_MinReturn : -162.44598388671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2955900\n",
            "TimeSinceStart : 2686.367327451706\n",
            "Training Loss : -936.55517578125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.006937980651855469\n",
            "Eval_StdReturn : 51.323448181152344\n",
            "Eval_MaxReturn : 56.073524475097656\n",
            "Eval_MinReturn : -67.95181274414062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.262435913085938\n",
            "Train_StdReturn : 40.59891128540039\n",
            "Train_MaxReturn : 75.96879577636719\n",
            "Train_MinReturn : -142.2496337890625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3006000\n",
            "TimeSinceStart : 2731.2268381118774\n",
            "Training Loss : -257.63189697265625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.204983711242676\n",
            "Eval_StdReturn : 49.45659637451172\n",
            "Eval_MaxReturn : 56.65631866455078\n",
            "Eval_MinReturn : -59.80073928833008\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.656513214111328\n",
            "Train_StdReturn : 45.61400604248047\n",
            "Train_MaxReturn : 105.66644287109375\n",
            "Train_MinReturn : -189.99179077148438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3056100\n",
            "TimeSinceStart : 2775.9444115161896\n",
            "Training Loss : -518.3353881835938\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.5120906829834\n",
            "Eval_StdReturn : 25.818557739257812\n",
            "Eval_MaxReturn : -9.225797653198242\n",
            "Eval_MinReturn : -67.70294952392578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -8.338384628295898\n",
            "Train_StdReturn : 42.66038513183594\n",
            "Train_MaxReturn : 101.49842834472656\n",
            "Train_MinReturn : -171.82444763183594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3106200\n",
            "TimeSinceStart : 2820.7375547885895\n",
            "Training Loss : 23.8797607421875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.0218119621276855\n",
            "Eval_StdReturn : 18.725297927856445\n",
            "Eval_MaxReturn : 29.995519638061523\n",
            "Eval_MinReturn : -13.434955596923828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.473847389221191\n",
            "Train_StdReturn : 41.189552307128906\n",
            "Train_MaxReturn : 108.20201110839844\n",
            "Train_MinReturn : -133.22177124023438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3156300\n",
            "TimeSinceStart : 2865.9596016407013\n",
            "Training Loss : -375.5653076171875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 0.8772150874137878\n",
            "Eval_StdReturn : 18.749820709228516\n",
            "Eval_MaxReturn : 25.82872200012207\n",
            "Eval_MinReturn : -19.37030601501465\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.239005088806152\n",
            "Train_StdReturn : 43.84608459472656\n",
            "Train_MaxReturn : 90.886962890625\n",
            "Train_MinReturn : -184.9025421142578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3206400\n",
            "TimeSinceStart : 2911.387231826782\n",
            "Training Loss : -159.00457763671875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.554388523101807\n",
            "Eval_StdReturn : 18.829471588134766\n",
            "Eval_MaxReturn : 11.7156982421875\n",
            "Eval_MinReturn : -30.945573806762695\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -7.308367729187012\n",
            "Train_StdReturn : 38.3316535949707\n",
            "Train_MaxReturn : 106.23704528808594\n",
            "Train_MinReturn : -135.8988800048828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3256500\n",
            "TimeSinceStart : 2956.792946577072\n",
            "Training Loss : -353.5103454589844\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.522433280944824\n",
            "Eval_StdReturn : 17.638219833374023\n",
            "Eval_MaxReturn : 6.067776203155518\n",
            "Eval_MinReturn : -37.1368408203125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -3.230567455291748\n",
            "Train_StdReturn : 30.46019744873047\n",
            "Train_MaxReturn : 102.28044128417969\n",
            "Train_MinReturn : -100.41139221191406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3306600\n",
            "TimeSinceStart : 3001.7574334144592\n",
            "Training Loss : -222.2261962890625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.691184043884277\n",
            "Eval_StdReturn : 17.739179611206055\n",
            "Eval_MaxReturn : 8.629042625427246\n",
            "Eval_MinReturn : -29.761795043945312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -4.144667625427246\n",
            "Train_StdReturn : 28.095022201538086\n",
            "Train_MaxReturn : 71.28851318359375\n",
            "Train_MinReturn : -102.89627075195312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3356700\n",
            "TimeSinceStart : 3047.2594039440155\n",
            "Training Loss : -771.2388916015625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.60482406616211\n",
            "Eval_StdReturn : 24.209848403930664\n",
            "Eval_MaxReturn : -7.468894958496094\n",
            "Eval_MinReturn : -66.50528717041016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -7.323964595794678\n",
            "Train_StdReturn : 24.582555770874023\n",
            "Train_MaxReturn : 51.25358581542969\n",
            "Train_MinReturn : -102.73326110839844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3406800\n",
            "TimeSinceStart : 3092.5546641349792\n",
            "Training Loss : -719.84326171875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.28163719177246\n",
            "Eval_StdReturn : 13.987751007080078\n",
            "Eval_MaxReturn : -6.315207481384277\n",
            "Eval_MinReturn : -38.702762603759766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.026663780212402\n",
            "Train_StdReturn : 20.176902770996094\n",
            "Train_MaxReturn : 44.01797103881836\n",
            "Train_MinReturn : -77.32386779785156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3456900\n",
            "TimeSinceStart : 3138.4114713668823\n",
            "Training Loss : -350.31640625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -43.4692268371582\n",
            "Eval_StdReturn : 13.407254219055176\n",
            "Eval_MaxReturn : -30.48063087463379\n",
            "Eval_MinReturn : -61.92613220214844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.371295928955078\n",
            "Train_StdReturn : 23.028900146484375\n",
            "Train_MaxReturn : 58.144798278808594\n",
            "Train_MinReturn : -104.07791900634766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3507000\n",
            "TimeSinceStart : 3183.781000852585\n",
            "Training Loss : -296.1898193359375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.659759521484375\n",
            "Eval_StdReturn : 9.050440788269043\n",
            "Eval_MaxReturn : 6.3105573654174805\n",
            "Eval_MinReturn : -15.854982376098633\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.525232315063477\n",
            "Train_StdReturn : 25.74458122253418\n",
            "Train_MaxReturn : 63.279991149902344\n",
            "Train_MinReturn : -115.49234771728516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3557100\n",
            "TimeSinceStart : 3229.1817865371704\n",
            "Training Loss : -991.308837890625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.317020416259766\n",
            "Eval_StdReturn : 11.805828094482422\n",
            "Eval_MaxReturn : 9.374924659729004\n",
            "Eval_MinReturn : -15.980184555053711\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.625701904296875\n",
            "Train_StdReturn : 30.117399215698242\n",
            "Train_MaxReturn : 59.465721130371094\n",
            "Train_MinReturn : -112.55538177490234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3607200\n",
            "TimeSinceStart : 3274.3529546260834\n",
            "Training Loss : -179.79913330078125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.383644104003906\n",
            "Eval_StdReturn : 22.750225067138672\n",
            "Eval_MaxReturn : 28.00191879272461\n",
            "Eval_MinReturn : -25.741378784179688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -7.938337802886963\n",
            "Train_StdReturn : 32.09225845336914\n",
            "Train_MaxReturn : 67.64781188964844\n",
            "Train_MinReturn : -135.4603271484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3657300\n",
            "TimeSinceStart : 3319.9315659999847\n",
            "Training Loss : -171.6846923828125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.739191055297852\n",
            "Eval_StdReturn : 14.299689292907715\n",
            "Eval_MaxReturn : 21.289203643798828\n",
            "Eval_MinReturn : -12.699060440063477\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -5.0718512535095215\n",
            "Train_StdReturn : 37.0794563293457\n",
            "Train_MaxReturn : 97.5645980834961\n",
            "Train_MinReturn : -143.8267822265625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3707400\n",
            "TimeSinceStart : 3365.175112247467\n",
            "Training Loss : -376.60723876953125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.111964225769043\n",
            "Eval_StdReturn : 48.02632522583008\n",
            "Eval_MaxReturn : 20.87889862060547\n",
            "Eval_MinReturn : -81.03143310546875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.2039942443370819\n",
            "Train_StdReturn : 37.019203186035156\n",
            "Train_MaxReturn : 84.33349609375\n",
            "Train_MinReturn : -195.1252899169922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3757500\n",
            "TimeSinceStart : 3410.2915003299713\n",
            "Training Loss : -368.165283203125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.68492889404297\n",
            "Eval_StdReturn : 32.68824005126953\n",
            "Eval_MaxReturn : 21.234039306640625\n",
            "Eval_MinReturn : -52.266944885253906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -0.15502728521823883\n",
            "Train_StdReturn : 44.368255615234375\n",
            "Train_MaxReturn : 79.42326354980469\n",
            "Train_MinReturn : -145.54713439941406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3807600\n",
            "TimeSinceStart : 3455.7757561206818\n",
            "Training Loss : -770.104736328125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.945884704589844\n",
            "Eval_StdReturn : 30.889209747314453\n",
            "Eval_MaxReturn : 42.70241165161133\n",
            "Eval_MinReturn : -26.48832893371582\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.2266039848327637\n",
            "Train_StdReturn : 45.30812072753906\n",
            "Train_MaxReturn : 95.34542846679688\n",
            "Train_MinReturn : -173.15328979492188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3857700\n",
            "TimeSinceStart : 3501.1005144119263\n",
            "Training Loss : -621.358642578125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.01000213623047\n",
            "Eval_StdReturn : 39.55569839477539\n",
            "Eval_MaxReturn : 50.67350769042969\n",
            "Eval_MinReturn : -36.759788513183594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 8.403733253479004\n",
            "Train_StdReturn : 41.096065521240234\n",
            "Train_MaxReturn : 101.73002624511719\n",
            "Train_MinReturn : -132.75559997558594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3907800\n",
            "TimeSinceStart : 3546.60293841362\n",
            "Training Loss : -716.976806640625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 35.71162796020508\n",
            "Eval_StdReturn : 4.055352210998535\n",
            "Eval_MaxReturn : 41.033302307128906\n",
            "Eval_MinReturn : 31.199127197265625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 9.489554405212402\n",
            "Train_StdReturn : 42.780494689941406\n",
            "Train_MaxReturn : 114.462158203125\n",
            "Train_MinReturn : -137.2230682373047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3957900\n",
            "TimeSinceStart : 3591.6325986385345\n",
            "Training Loss : -685.1090087890625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 15.414746284484863\n",
            "Eval_StdReturn : 17.015676498413086\n",
            "Eval_MaxReturn : 38.504615783691406\n",
            "Eval_MinReturn : -1.9990310668945312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 14.400138854980469\n",
            "Train_StdReturn : 39.31503677368164\n",
            "Train_MaxReturn : 97.98045349121094\n",
            "Train_MinReturn : -135.1768798828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4008000\n",
            "TimeSinceStart : 3637.302346229553\n",
            "Training Loss : -522.9034423828125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.27659034729004\n",
            "Eval_StdReturn : 40.98088073730469\n",
            "Eval_MaxReturn : 89.19783020019531\n",
            "Eval_MinReturn : 0.5848827362060547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 21.83854103088379\n",
            "Train_StdReturn : 38.97347640991211\n",
            "Train_MaxReturn : 130.20162963867188\n",
            "Train_MinReturn : -164.6421661376953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4058100\n",
            "TimeSinceStart : 3682.5644793510437\n",
            "Training Loss : -568.5377197265625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 24.54466438293457\n",
            "Eval_StdReturn : 6.8882246017456055\n",
            "Eval_MaxReturn : 31.2513484954834\n",
            "Eval_MinReturn : 15.072765350341797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 20.84952163696289\n",
            "Train_StdReturn : 34.06615447998047\n",
            "Train_MaxReturn : 188.219970703125\n",
            "Train_MinReturn : -115.11189270019531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4108200\n",
            "TimeSinceStart : 3728.1549270153046\n",
            "Training Loss : -706.46484375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 38.46786880493164\n",
            "Eval_StdReturn : 23.488933563232422\n",
            "Eval_MaxReturn : 67.41468811035156\n",
            "Eval_MinReturn : 9.882187843322754\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 20.816482543945312\n",
            "Train_StdReturn : 28.26273536682129\n",
            "Train_MaxReturn : 95.28984832763672\n",
            "Train_MinReturn : -86.12457275390625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4158300\n",
            "TimeSinceStart : 3773.4027032852173\n",
            "Training Loss : -133.1927490234375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.695112228393555\n",
            "Eval_StdReturn : 10.883942604064941\n",
            "Eval_MaxReturn : 30.027292251586914\n",
            "Eval_MinReturn : 4.648492336273193\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 23.73517608642578\n",
            "Train_StdReturn : 25.541257858276367\n",
            "Train_MaxReturn : 87.29444885253906\n",
            "Train_MinReturn : -54.538978576660156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4208400\n",
            "TimeSinceStart : 3818.963012933731\n",
            "Training Loss : -50.101226806640625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 22.27418327331543\n",
            "Eval_StdReturn : 38.67906951904297\n",
            "Eval_MaxReturn : 74.86279296875\n",
            "Eval_MinReturn : -17.05600357055664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 17.24052619934082\n",
            "Train_StdReturn : 21.3387393951416\n",
            "Train_MaxReturn : 83.71546173095703\n",
            "Train_MinReturn : -67.50752258300781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4258500\n",
            "TimeSinceStart : 3864.670674085617\n",
            "Training Loss : -350.31866455078125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.602272033691406\n",
            "Eval_StdReturn : 26.15255355834961\n",
            "Eval_MaxReturn : 61.9515380859375\n",
            "Eval_MinReturn : 1.5130670070648193\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 19.451011657714844\n",
            "Train_StdReturn : 22.78606414794922\n",
            "Train_MaxReturn : 113.54826354980469\n",
            "Train_MinReturn : -58.659629821777344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4308600\n",
            "TimeSinceStart : 3910.2051503658295\n",
            "Training Loss : -620.9264526367188\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 23.75384521484375\n",
            "Eval_StdReturn : 8.173284530639648\n",
            "Eval_MaxReturn : 32.19652557373047\n",
            "Eval_MinReturn : 12.695493698120117\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 25.32124137878418\n",
            "Train_StdReturn : 27.01342010498047\n",
            "Train_MaxReturn : 95.49678802490234\n",
            "Train_MinReturn : -76.69393157958984\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4358700\n",
            "TimeSinceStart : 3955.4420952796936\n",
            "Training Loss : 18.05010986328125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.216875076293945\n",
            "Eval_StdReturn : 41.16755294799805\n",
            "Eval_MaxReturn : 67.1297607421875\n",
            "Eval_MinReturn : -30.734331130981445\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 23.73198127746582\n",
            "Train_StdReturn : 29.89186668395996\n",
            "Train_MaxReturn : 119.3076171875\n",
            "Train_MinReturn : -61.780296325683594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4408800\n",
            "TimeSinceStart : 4000.4646983146667\n",
            "Training Loss : -23.036651611328125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 44.34576416015625\n",
            "Eval_StdReturn : 15.105530738830566\n",
            "Eval_MaxReturn : 59.04337692260742\n",
            "Eval_MinReturn : 23.571208953857422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 21.772066116333008\n",
            "Train_StdReturn : 35.839378356933594\n",
            "Train_MaxReturn : 117.09071350097656\n",
            "Train_MinReturn : -75.39812469482422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4458900\n",
            "TimeSinceStart : 4046.0038714408875\n",
            "Training Loss : -194.57586669921875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.76910924911499\n",
            "Eval_StdReturn : 43.49821853637695\n",
            "Eval_MaxReturn : 59.35730743408203\n",
            "Eval_MinReturn : -47.04457092285156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 19.58184051513672\n",
            "Train_StdReturn : 35.43289566040039\n",
            "Train_MaxReturn : 137.573974609375\n",
            "Train_MinReturn : -90.1009521484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4509000\n",
            "TimeSinceStart : 4090.9901740550995\n",
            "Training Loss : 17.4798583984375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.8841438293457\n",
            "Eval_StdReturn : 21.30879020690918\n",
            "Eval_MaxReturn : -11.363570213317871\n",
            "Eval_MinReturn : -62.485557556152344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 5.76951789855957\n",
            "Train_StdReturn : 33.55229568481445\n",
            "Train_MaxReturn : 100.18637084960938\n",
            "Train_MinReturn : -87.45316314697266\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4559100\n",
            "TimeSinceStart : 4136.292881727219\n",
            "Training Loss : -665.073974609375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.253222465515137\n",
            "Eval_StdReturn : 23.69740104675293\n",
            "Eval_MaxReturn : 24.07120704650879\n",
            "Eval_MinReturn : -28.99148941040039\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.7545883655548096\n",
            "Train_StdReturn : 36.963661193847656\n",
            "Train_MaxReturn : 113.19674682617188\n",
            "Train_MinReturn : -128.2233123779297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4609200\n",
            "TimeSinceStart : 4181.714431285858\n",
            "Training Loss : -643.106689453125\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 18.325849533081055\n",
            "Eval_StdReturn : 29.80088233947754\n",
            "Eval_MaxReturn : 57.69276809692383\n",
            "Eval_MinReturn : -14.389233589172363\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 1.423189640045166\n",
            "Train_StdReturn : 33.528526306152344\n",
            "Train_MaxReturn : 90.8947525024414\n",
            "Train_MinReturn : -94.26617431640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4659300\n",
            "TimeSinceStart : 4226.877164363861\n",
            "Training Loss : -18.8074951171875\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.826733589172363\n",
            "Eval_StdReturn : 31.586637496948242\n",
            "Eval_MaxReturn : 14.459314346313477\n",
            "Eval_MinReturn : -58.68138122558594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.153111457824707\n",
            "Train_StdReturn : 31.33809471130371\n",
            "Train_MaxReturn : 89.337890625\n",
            "Train_MinReturn : -88.74222564697266\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4709400\n",
            "TimeSinceStart : 4272.446155786514\n",
            "Training Loss : -788.9993896484375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.79364585876465\n",
            "Eval_StdReturn : 12.891080856323242\n",
            "Eval_MaxReturn : -0.5961289405822754\n",
            "Eval_MinReturn : -28.845149993896484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.875843048095703\n",
            "Train_StdReturn : 28.345388412475586\n",
            "Train_MaxReturn : 76.08541870117188\n",
            "Train_MinReturn : -92.11550903320312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4759500\n",
            "TimeSinceStart : 4317.930152177811\n",
            "Training Loss : -1011.9908447265625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -48.12260818481445\n",
            "Eval_StdReturn : 21.795381546020508\n",
            "Eval_MaxReturn : -23.216087341308594\n",
            "Eval_MinReturn : -76.30186462402344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.97231674194336\n",
            "Train_StdReturn : 26.082313537597656\n",
            "Train_MaxReturn : 59.88807678222656\n",
            "Train_MinReturn : -96.29985046386719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4809600\n",
            "TimeSinceStart : 4363.884133338928\n",
            "Training Loss : -804.5631103515625\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.430144309997559\n",
            "Eval_StdReturn : 15.525415420532227\n",
            "Eval_MaxReturn : 5.42979621887207\n",
            "Eval_MinReturn : -32.595863342285156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.65550422668457\n",
            "Train_StdReturn : 24.13958168029785\n",
            "Train_MaxReturn : 54.6154670715332\n",
            "Train_MinReturn : -91.50120544433594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4859700\n",
            "TimeSinceStart : 4409.35816693306\n",
            "Training Loss : -37.791839599609375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -2.743793487548828\n",
            "Eval_StdReturn : 32.195411682128906\n",
            "Eval_MaxReturn : 39.405521392822266\n",
            "Eval_MinReturn : -38.73130798339844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.811023712158203\n",
            "Train_StdReturn : 21.442306518554688\n",
            "Train_MaxReturn : 38.57429885864258\n",
            "Train_MinReturn : -81.71798706054688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4909800\n",
            "TimeSinceStart : 4455.109264135361\n",
            "Training Loss : -951.7825927734375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.736263275146484\n",
            "Eval_StdReturn : 20.76906967163086\n",
            "Eval_MaxReturn : -10.749248504638672\n",
            "Eval_MinReturn : -58.33416748046875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.3902645111084\n",
            "Train_StdReturn : 25.180910110473633\n",
            "Train_MaxReturn : 50.759117126464844\n",
            "Train_MinReturn : -129.13543701171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4959900\n",
            "TimeSinceStart : 4500.6212639808655\n",
            "Training Loss : -691.4631958007812\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.421720504760742\n",
            "Eval_StdReturn : 6.99403715133667\n",
            "Eval_MaxReturn : -16.38485336303711\n",
            "Eval_MinReturn : -33.42240905761719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.692148208618164\n",
            "Train_StdReturn : 26.90634536743164\n",
            "Train_MaxReturn : 34.32908630371094\n",
            "Train_MinReturn : -133.07015991210938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 5010000\n",
            "TimeSinceStart : 4547.189543008804\n",
            "Training Loss : -687.3441162109375\n",
            "Initial_DataCollection_AverageReturn : -89.54405975341797\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "    --discount 0.95 -n 100 -l 2 -s 32 \\\n",
        "    -b 50000 -lr 0.02 -rtg --nn_baseline \\\n",
        "    --exp_name q4_b50000_r0.02_rtg_nnbaseline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYx3JsCCUAnl",
        "outputId": "7871e2e3-04aa-4d10-bb9a-ee7a7feb16d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cds_rl_2022/rl_hw/hw2/hw2/scripts/../../data/q2_pg_q4_b50000_r0.02_rtg_nnbaseline_HalfCheetah-v2_10-05-2022_12-38-27\n",
            "########################\n",
            "GPU not detected. Defaulting to CPU.\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -59.231689453125\n",
            "Eval_StdReturn : 26.608047485351562\n",
            "Eval_MaxReturn : -31.151315689086914\n",
            "Eval_MinReturn : -94.9652328491211\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -94.41527557373047\n",
            "Train_StdReturn : 38.59808349609375\n",
            "Train_MaxReturn : 1.7286391258239746\n",
            "Train_MinReturn : -216.81167602539062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50100\n",
            "TimeSinceStart : 42.39908766746521\n",
            "Training Loss : -3808.248779296875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.611480712890625\n",
            "Eval_StdReturn : 9.577096939086914\n",
            "Eval_MaxReturn : -31.473430633544922\n",
            "Eval_MinReturn : -54.030921936035156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -76.45398712158203\n",
            "Train_StdReturn : 35.11733627319336\n",
            "Train_MaxReturn : 21.301454544067383\n",
            "Train_MinReturn : -222.55889892578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100200\n",
            "TimeSinceStart : 80.50767183303833\n",
            "Training Loss : -2998.368896484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -81.2682876586914\n",
            "Eval_StdReturn : 48.5988883972168\n",
            "Eval_MaxReturn : -12.561141014099121\n",
            "Eval_MinReturn : -117.12982940673828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -71.6938705444336\n",
            "Train_StdReturn : 33.9470329284668\n",
            "Train_MaxReturn : 11.81857681274414\n",
            "Train_MinReturn : -188.08160400390625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150300\n",
            "TimeSinceStart : 119.6517641544342\n",
            "Training Loss : -2479.476806640625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.831878662109375\n",
            "Eval_StdReturn : 13.65799617767334\n",
            "Eval_MaxReturn : -27.092544555664062\n",
            "Eval_MinReturn : -60.319576263427734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -69.0025405883789\n",
            "Train_StdReturn : 35.68440246582031\n",
            "Train_MaxReturn : 21.998485565185547\n",
            "Train_MinReturn : -223.10255432128906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 200400\n",
            "TimeSinceStart : 158.4155833721161\n",
            "Training Loss : -3225.3623046875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.4148063659668\n",
            "Eval_StdReturn : 14.918067932128906\n",
            "Eval_MaxReturn : -45.512001037597656\n",
            "Eval_MinReturn : -77.50813293457031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -59.58623123168945\n",
            "Train_StdReturn : 32.30575180053711\n",
            "Train_MaxReturn : 23.720413208007812\n",
            "Train_MinReturn : -200.30857849121094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 250500\n",
            "TimeSinceStart : 197.55265879631042\n",
            "Training Loss : -4096.171875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -80.36817169189453\n",
            "Eval_StdReturn : 26.239614486694336\n",
            "Eval_MaxReturn : -47.901126861572266\n",
            "Eval_MinReturn : -112.16429138183594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -57.99382400512695\n",
            "Train_StdReturn : 27.867097854614258\n",
            "Train_MaxReturn : 15.087448120117188\n",
            "Train_MinReturn : -176.66128540039062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300600\n",
            "TimeSinceStart : 235.95898747444153\n",
            "Training Loss : -3583.2978515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.00076675415039\n",
            "Eval_StdReturn : 19.786941528320312\n",
            "Eval_MaxReturn : -30.75887680053711\n",
            "Eval_MinReturn : -79.22677612304688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.722225189208984\n",
            "Train_StdReturn : 25.835763931274414\n",
            "Train_MaxReturn : 33.548343658447266\n",
            "Train_MinReturn : -142.86814880371094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 350700\n",
            "TimeSinceStart : 274.28402638435364\n",
            "Training Loss : -4166.80517578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.69929122924805\n",
            "Eval_StdReturn : 17.927654266357422\n",
            "Eval_MaxReturn : -20.34635353088379\n",
            "Eval_MinReturn : -58.52654266357422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -52.80870056152344\n",
            "Train_StdReturn : 26.695070266723633\n",
            "Train_MaxReturn : 22.266639709472656\n",
            "Train_MinReturn : -141.1156768798828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 400800\n",
            "TimeSinceStart : 312.7864351272583\n",
            "Training Loss : -4374.4501953125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.94745635986328\n",
            "Eval_StdReturn : 21.937530517578125\n",
            "Eval_MaxReturn : 1.5460598468780518\n",
            "Eval_MinReturn : -51.029808044433594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.59211730957031\n",
            "Train_StdReturn : 24.484609603881836\n",
            "Train_MaxReturn : 18.377981185913086\n",
            "Train_MinReturn : -122.29949951171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450900\n",
            "TimeSinceStart : 351.0529613494873\n",
            "Training Loss : -4076.19384765625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.15826416015625\n",
            "Eval_StdReturn : 27.55377769470215\n",
            "Eval_MaxReturn : -17.395883560180664\n",
            "Eval_MinReturn : -83.30697631835938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.284873962402344\n",
            "Train_StdReturn : 26.75030517578125\n",
            "Train_MaxReturn : 55.69646072387695\n",
            "Train_MinReturn : -136.2472686767578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 501000\n",
            "TimeSinceStart : 389.2721960544586\n",
            "Training Loss : -3773.795654296875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.77485275268555\n",
            "Eval_StdReturn : 25.299015045166016\n",
            "Eval_MaxReturn : -24.33812713623047\n",
            "Eval_MinReturn : -86.06816864013672\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.55742263793945\n",
            "Train_StdReturn : 27.993764877319336\n",
            "Train_MaxReturn : 30.670316696166992\n",
            "Train_MinReturn : -132.7242889404297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 551100\n",
            "TimeSinceStart : 427.514440536499\n",
            "Training Loss : -3290.92236328125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.61477279663086\n",
            "Eval_StdReturn : 23.32110595703125\n",
            "Eval_MaxReturn : -3.5131020545959473\n",
            "Eval_MinReturn : -60.605491638183594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.09825134277344\n",
            "Train_StdReturn : 29.699087142944336\n",
            "Train_MaxReturn : 48.76630401611328\n",
            "Train_MinReturn : -136.5626220703125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 601200\n",
            "TimeSinceStart : 465.99334931373596\n",
            "Training Loss : -3072.486572265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.818434715270996\n",
            "Eval_StdReturn : 5.9101996421813965\n",
            "Eval_MaxReturn : -1.9815521240234375\n",
            "Eval_MinReturn : -16.253450393676758\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.708656311035156\n",
            "Train_StdReturn : 31.979732513427734\n",
            "Train_MaxReturn : 75.3721923828125\n",
            "Train_MinReturn : -167.54522705078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 651300\n",
            "TimeSinceStart : 504.60599398612976\n",
            "Training Loss : -3208.30615234375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.855300903320312\n",
            "Eval_StdReturn : 36.407047271728516\n",
            "Eval_MaxReturn : 61.26365661621094\n",
            "Eval_MinReturn : -18.31777572631836\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.955093383789062\n",
            "Train_StdReturn : 29.25002098083496\n",
            "Train_MaxReturn : 43.04836654663086\n",
            "Train_MinReturn : -115.53877258300781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 701400\n",
            "TimeSinceStart : 543.2419202327728\n",
            "Training Loss : -2565.962890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.07743835449219\n",
            "Eval_StdReturn : 9.631290435791016\n",
            "Eval_MaxReturn : -18.6662540435791\n",
            "Eval_MinReturn : -40.84403991699219\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.343008041381836\n",
            "Train_StdReturn : 28.27126693725586\n",
            "Train_MaxReturn : 81.40478515625\n",
            "Train_MinReturn : -150.3642578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 751500\n",
            "TimeSinceStart : 581.4968421459198\n",
            "Training Loss : -2055.943359375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.5907039642334\n",
            "Eval_StdReturn : 1.0024727582931519\n",
            "Eval_MaxReturn : -23.332223892211914\n",
            "Eval_MinReturn : -25.785274505615234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.760765075683594\n",
            "Train_StdReturn : 27.60980224609375\n",
            "Train_MaxReturn : 41.994407653808594\n",
            "Train_MinReturn : -129.02090454101562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 801600\n",
            "TimeSinceStart : 620.3622643947601\n",
            "Training Loss : -2046.5096435546875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.61732864379883\n",
            "Eval_StdReturn : 26.932706832885742\n",
            "Eval_MaxReturn : -3.9792375564575195\n",
            "Eval_MinReturn : -67.95267486572266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.5325927734375\n",
            "Train_StdReturn : 26.392799377441406\n",
            "Train_MaxReturn : 64.69868469238281\n",
            "Train_MinReturn : -142.06719970703125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 851700\n",
            "TimeSinceStart : 658.8755023479462\n",
            "Training Loss : -1282.962890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.104644775390625\n",
            "Eval_StdReturn : 36.3015251159668\n",
            "Eval_MaxReturn : -21.916513442993164\n",
            "Eval_MinReturn : -105.619384765625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.190752029418945\n",
            "Train_StdReturn : 27.93893051147461\n",
            "Train_MaxReturn : 48.51325225830078\n",
            "Train_MinReturn : -132.0376434326172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 901800\n",
            "TimeSinceStart : 697.3448481559753\n",
            "Training Loss : -1943.1087646484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.52983093261719\n",
            "Eval_StdReturn : 16.314220428466797\n",
            "Eval_MaxReturn : -16.63792610168457\n",
            "Eval_MinReturn : -53.46598815917969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.272306442260742\n",
            "Train_StdReturn : 27.93789291381836\n",
            "Train_MaxReturn : 53.06132507324219\n",
            "Train_MinReturn : -140.25196838378906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 951900\n",
            "TimeSinceStart : 736.0016829967499\n",
            "Training Loss : -1594.129638671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.185298919677734\n",
            "Eval_StdReturn : 10.852237701416016\n",
            "Eval_MaxReturn : -31.40035629272461\n",
            "Eval_MinReturn : -57.03400421142578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.97564125061035\n",
            "Train_StdReturn : 28.619892120361328\n",
            "Train_MaxReturn : 77.6187744140625\n",
            "Train_MinReturn : -121.28352355957031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1002000\n",
            "TimeSinceStart : 774.3721191883087\n",
            "Training Loss : -1377.164306640625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.57427978515625\n",
            "Eval_StdReturn : 14.862459182739258\n",
            "Eval_MaxReturn : -23.558080673217773\n",
            "Eval_MinReturn : -59.76768493652344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.74121856689453\n",
            "Train_StdReturn : 29.661008834838867\n",
            "Train_MaxReturn : 90.74897003173828\n",
            "Train_MinReturn : -132.75755310058594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1052100\n",
            "TimeSinceStart : 812.720370054245\n",
            "Training Loss : -1984.90576171875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.5523858070373535\n",
            "Eval_StdReturn : 9.470925331115723\n",
            "Eval_MaxReturn : 5.05438232421875\n",
            "Eval_MinReturn : -17.773639678955078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -15.730375289916992\n",
            "Train_StdReturn : 26.56035614013672\n",
            "Train_MaxReturn : 73.5045166015625\n",
            "Train_MinReturn : -84.11933898925781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1102200\n",
            "TimeSinceStart : 851.4023480415344\n",
            "Training Loss : -1035.2139892578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.030429840087891\n",
            "Eval_StdReturn : 13.817217826843262\n",
            "Eval_MaxReturn : 14.177885055541992\n",
            "Eval_MinReturn : -15.505147933959961\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.41658878326416\n",
            "Train_StdReturn : 27.229320526123047\n",
            "Train_MaxReturn : 61.98117446899414\n",
            "Train_MinReturn : -105.13160705566406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1152300\n",
            "TimeSinceStart : 890.1121499538422\n",
            "Training Loss : -1509.32177734375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.9450042247772217\n",
            "Eval_StdReturn : 20.298006057739258\n",
            "Eval_MaxReturn : 20.438961029052734\n",
            "Eval_MinReturn : -25.511987686157227\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.389975547790527\n",
            "Train_StdReturn : 31.236997604370117\n",
            "Train_MaxReturn : 64.45250701904297\n",
            "Train_MinReturn : -120.51625061035156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1202400\n",
            "TimeSinceStart : 928.8448133468628\n",
            "Training Loss : -1303.9208984375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.099092960357666\n",
            "Eval_StdReturn : 23.58642578125\n",
            "Eval_MaxReturn : 35.44257354736328\n",
            "Eval_MinReturn : -22.069902420043945\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -4.6656646728515625\n",
            "Train_StdReturn : 28.955766677856445\n",
            "Train_MaxReturn : 71.91246032714844\n",
            "Train_MinReturn : -96.85025787353516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1252500\n",
            "TimeSinceStart : 967.7607617378235\n",
            "Training Loss : -893.8739013671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.6579647064209\n",
            "Eval_StdReturn : 9.291010856628418\n",
            "Eval_MaxReturn : 40.568302154541016\n",
            "Eval_MinReturn : 18.83985710144043\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -2.272132635116577\n",
            "Train_StdReturn : 31.936368942260742\n",
            "Train_MaxReturn : 91.16259765625\n",
            "Train_MinReturn : -118.06306457519531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1302600\n",
            "TimeSinceStart : 1006.5794038772583\n",
            "Training Loss : -401.62725830078125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.845890522003174\n",
            "Eval_StdReturn : 17.65096092224121\n",
            "Eval_MaxReturn : 30.042686462402344\n",
            "Eval_MinReturn : -11.564842224121094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.8832931518554688\n",
            "Train_StdReturn : 36.639705657958984\n",
            "Train_MaxReturn : 105.72615051269531\n",
            "Train_MinReturn : -174.9345245361328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1352700\n",
            "TimeSinceStart : 1045.3424937725067\n",
            "Training Loss : -844.6216430664062\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 18.020307540893555\n",
            "Eval_StdReturn : 34.53672409057617\n",
            "Eval_MaxReturn : 53.645172119140625\n",
            "Eval_MinReturn : -28.728775024414062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 10.0948486328125\n",
            "Train_StdReturn : 39.07035446166992\n",
            "Train_MaxReturn : 97.61548614501953\n",
            "Train_MinReturn : -165.37472534179688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1402800\n",
            "TimeSinceStart : 1083.806310415268\n",
            "Training Loss : -954.1546630859375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 62.64412307739258\n",
            "Eval_StdReturn : 54.77564239501953\n",
            "Eval_MaxReturn : 139.5732421875\n",
            "Eval_MinReturn : 16.306209564208984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 11.82836627960205\n",
            "Train_StdReturn : 45.105987548828125\n",
            "Train_MaxReturn : 99.82707214355469\n",
            "Train_MinReturn : -148.77755737304688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1452900\n",
            "TimeSinceStart : 1122.4695904254913\n",
            "Training Loss : -523.8895263671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.020245552062988\n",
            "Eval_StdReturn : 28.864852905273438\n",
            "Eval_MaxReturn : 39.29292678833008\n",
            "Eval_MinReturn : -27.920469284057617\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 6.972291469573975\n",
            "Train_StdReturn : 45.00685119628906\n",
            "Train_MaxReturn : 122.7352066040039\n",
            "Train_MinReturn : -160.29815673828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1503000\n",
            "TimeSinceStart : 1161.1998121738434\n",
            "Training Loss : -1142.500244140625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.012224197387695\n",
            "Eval_StdReturn : 36.19933319091797\n",
            "Eval_MaxReturn : 51.99988555908203\n",
            "Eval_MinReturn : -33.513397216796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 10.532174110412598\n",
            "Train_StdReturn : 42.76934051513672\n",
            "Train_MaxReturn : 113.74528503417969\n",
            "Train_MinReturn : -133.52877807617188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1553100\n",
            "TimeSinceStart : 1199.6040184497833\n",
            "Training Loss : -577.5655517578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.74201202392578\n",
            "Eval_StdReturn : 28.57909393310547\n",
            "Eval_MaxReturn : 51.58148193359375\n",
            "Eval_MinReturn : -14.092187881469727\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 13.184062004089355\n",
            "Train_StdReturn : 42.504730224609375\n",
            "Train_MaxReturn : 125.14566802978516\n",
            "Train_MinReturn : -159.5342254638672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1603200\n",
            "TimeSinceStart : 1238.270052433014\n",
            "Training Loss : -505.73126220703125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.623623847961426\n",
            "Eval_StdReturn : 25.372602462768555\n",
            "Eval_MaxReturn : 37.821083068847656\n",
            "Eval_MinReturn : -20.682947158813477\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 14.093694686889648\n",
            "Train_StdReturn : 37.483577728271484\n",
            "Train_MaxReturn : 134.66656494140625\n",
            "Train_MinReturn : -153.4318389892578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1653300\n",
            "TimeSinceStart : 1276.7521810531616\n",
            "Training Loss : -1349.118408203125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.726499080657959\n",
            "Eval_StdReturn : 19.476215362548828\n",
            "Eval_MaxReturn : 26.06841278076172\n",
            "Eval_MinReturn : -21.023466110229492\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 18.534982681274414\n",
            "Train_StdReturn : 29.700969696044922\n",
            "Train_MaxReturn : 104.66181945800781\n",
            "Train_MinReturn : -106.64070129394531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1703400\n",
            "TimeSinceStart : 1315.0618867874146\n",
            "Training Loss : -1998.41796875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 23.467758178710938\n",
            "Eval_StdReturn : 27.39882469177246\n",
            "Eval_MaxReturn : 56.14765930175781\n",
            "Eval_MinReturn : -10.901653289794922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 12.75095272064209\n",
            "Train_StdReturn : 26.813434600830078\n",
            "Train_MaxReturn : 85.99472045898438\n",
            "Train_MinReturn : -102.65876770019531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1753500\n",
            "TimeSinceStart : 1353.9927451610565\n",
            "Training Loss : -1652.145263671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.5861189961433411\n",
            "Eval_StdReturn : 4.975551128387451\n",
            "Eval_MaxReturn : 4.282011032104492\n",
            "Eval_MinReturn : -7.420200347900391\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 15.312129020690918\n",
            "Train_StdReturn : 24.91196632385254\n",
            "Train_MaxReturn : 83.6295166015625\n",
            "Train_MinReturn : -140.17515563964844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1803600\n",
            "TimeSinceStart : 1392.6407670974731\n",
            "Training Loss : -1355.601806640625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 24.117464065551758\n",
            "Eval_StdReturn : 14.148940086364746\n",
            "Eval_MaxReturn : 41.49885940551758\n",
            "Eval_MinReturn : 6.841657638549805\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 18.046161651611328\n",
            "Train_StdReturn : 27.99387550354004\n",
            "Train_MaxReturn : 90.32991790771484\n",
            "Train_MinReturn : -112.68721008300781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1853700\n",
            "TimeSinceStart : 1431.3486099243164\n",
            "Training Loss : -1835.284912109375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 18.563100814819336\n",
            "Eval_StdReturn : 10.68502426147461\n",
            "Eval_MaxReturn : 33.661415100097656\n",
            "Eval_MinReturn : 10.47978687286377\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 18.592466354370117\n",
            "Train_StdReturn : 33.53447723388672\n",
            "Train_MaxReturn : 96.55946350097656\n",
            "Train_MinReturn : -117.600830078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1903800\n",
            "TimeSinceStart : 1470.0804543495178\n",
            "Training Loss : -2481.495849609375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 55.03065490722656\n",
            "Eval_StdReturn : 22.607629776000977\n",
            "Eval_MaxReturn : 80.91778564453125\n",
            "Eval_MinReturn : 25.83748435974121\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 23.38790512084961\n",
            "Train_StdReturn : 37.98493957519531\n",
            "Train_MaxReturn : 95.47067260742188\n",
            "Train_MinReturn : -140.57254028320312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1953900\n",
            "TimeSinceStart : 1508.2909243106842\n",
            "Training Loss : -2133.0390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 18.17633628845215\n",
            "Eval_StdReturn : 15.250816345214844\n",
            "Eval_MaxReturn : 32.59143829345703\n",
            "Eval_MinReturn : -2.924907684326172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 29.39967155456543\n",
            "Train_StdReturn : 39.44051742553711\n",
            "Train_MaxReturn : 137.10581970214844\n",
            "Train_MinReturn : -120.422607421875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2004000\n",
            "TimeSinceStart : 1546.5764422416687\n",
            "Training Loss : -1461.8729248046875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 75.6862564086914\n",
            "Eval_StdReturn : 49.54822540283203\n",
            "Eval_MaxReturn : 144.9217071533203\n",
            "Eval_MinReturn : 31.720844268798828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 37.76325607299805\n",
            "Train_StdReturn : 44.690879821777344\n",
            "Train_MaxReturn : 138.2750244140625\n",
            "Train_MinReturn : -122.82601928710938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2054100\n",
            "TimeSinceStart : 1584.9884915351868\n",
            "Training Loss : -1485.102783203125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 73.32831573486328\n",
            "Eval_StdReturn : 24.989181518554688\n",
            "Eval_MaxReturn : 103.1419677734375\n",
            "Eval_MinReturn : 41.988338470458984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 49.06055450439453\n",
            "Train_StdReturn : 50.792938232421875\n",
            "Train_MaxReturn : 176.1226348876953\n",
            "Train_MinReturn : -169.42361450195312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2104200\n",
            "TimeSinceStart : 1623.4446420669556\n",
            "Training Loss : -1378.724853515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 63.06639099121094\n",
            "Eval_StdReturn : 23.031635284423828\n",
            "Eval_MaxReturn : 95.49627685546875\n",
            "Eval_MinReturn : 44.22250747680664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 54.6767692565918\n",
            "Train_StdReturn : 45.000125885009766\n",
            "Train_MaxReturn : 160.2479248046875\n",
            "Train_MinReturn : -157.33056640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2154300\n",
            "TimeSinceStart : 1661.9860785007477\n",
            "Training Loss : -1846.049560546875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 81.43170928955078\n",
            "Eval_StdReturn : 10.492514610290527\n",
            "Eval_MaxReturn : 90.12498474121094\n",
            "Eval_MinReturn : 66.67068481445312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 59.39012145996094\n",
            "Train_StdReturn : 42.440757751464844\n",
            "Train_MaxReturn : 154.71920776367188\n",
            "Train_MinReturn : -143.2376708984375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2204400\n",
            "TimeSinceStart : 1700.5308895111084\n",
            "Training Loss : -2215.4228515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 104.00345611572266\n",
            "Eval_StdReturn : 33.62076187133789\n",
            "Eval_MaxReturn : 149.73768615722656\n",
            "Eval_MinReturn : 69.8749771118164\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 73.91575622558594\n",
            "Train_StdReturn : 34.14316177368164\n",
            "Train_MaxReturn : 160.7733612060547\n",
            "Train_MinReturn : -106.47209930419922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2254500\n",
            "TimeSinceStart : 1739.2131071090698\n",
            "Training Loss : -2056.670166015625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 101.08843994140625\n",
            "Eval_StdReturn : 13.675825119018555\n",
            "Eval_MaxReturn : 118.63893127441406\n",
            "Eval_MinReturn : 85.27561950683594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 80.21522521972656\n",
            "Train_StdReturn : 45.62104034423828\n",
            "Train_MaxReturn : 185.4398193359375\n",
            "Train_MinReturn : -149.214111328125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2304600\n",
            "TimeSinceStart : 1778.031784772873\n",
            "Training Loss : -2307.44140625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 69.28907012939453\n",
            "Eval_StdReturn : 22.320072174072266\n",
            "Eval_MaxReturn : 91.35913848876953\n",
            "Eval_MinReturn : 38.71017837524414\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 92.07046508789062\n",
            "Train_StdReturn : 44.168914794921875\n",
            "Train_MaxReturn : 195.99169921875\n",
            "Train_MinReturn : -150.59576416015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2354700\n",
            "TimeSinceStart : 1816.7658717632294\n",
            "Training Loss : -2197.3779296875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 118.35906982421875\n",
            "Eval_StdReturn : 19.69780921936035\n",
            "Eval_MaxReturn : 142.43307495117188\n",
            "Eval_MinReturn : 94.1838150024414\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 98.67821502685547\n",
            "Train_StdReturn : 53.270668029785156\n",
            "Train_MaxReturn : 198.52313232421875\n",
            "Train_MinReturn : -163.98187255859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2404800\n",
            "TimeSinceStart : 1855.1234135627747\n",
            "Training Loss : -992.2275390625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 99.99786376953125\n",
            "Eval_StdReturn : 11.271444320678711\n",
            "Eval_MaxReturn : 113.67574310302734\n",
            "Eval_MinReturn : 86.06985473632812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 101.69271850585938\n",
            "Train_StdReturn : 59.45830535888672\n",
            "Train_MaxReturn : 216.66891479492188\n",
            "Train_MinReturn : -187.78123474121094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2454900\n",
            "TimeSinceStart : 1893.7048573493958\n",
            "Training Loss : -1543.003662109375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 103.1441421508789\n",
            "Eval_StdReturn : 4.092787742614746\n",
            "Eval_MaxReturn : 108.43276977539062\n",
            "Eval_MinReturn : 98.46287536621094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 106.50410461425781\n",
            "Train_StdReturn : 49.89110565185547\n",
            "Train_MaxReturn : 199.38238525390625\n",
            "Train_MinReturn : -193.8120880126953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2505000\n",
            "TimeSinceStart : 1932.2405104637146\n",
            "Training Loss : -1930.338134765625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 132.5269775390625\n",
            "Eval_StdReturn : 15.104161262512207\n",
            "Eval_MaxReturn : 153.64627075195312\n",
            "Eval_MinReturn : 119.19514465332031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 109.76368713378906\n",
            "Train_StdReturn : 32.136497497558594\n",
            "Train_MaxReturn : 195.64678955078125\n",
            "Train_MinReturn : -133.83396911621094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2555100\n",
            "TimeSinceStart : 1971.248399734497\n",
            "Training Loss : -2541.35595703125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 123.21514129638672\n",
            "Eval_StdReturn : 22.62515640258789\n",
            "Eval_MaxReturn : 154.216796875\n",
            "Eval_MinReturn : 100.85723876953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 116.51736450195312\n",
            "Train_StdReturn : 29.301612854003906\n",
            "Train_MaxReturn : 211.48333740234375\n",
            "Train_MinReturn : -139.8239288330078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2605200\n",
            "TimeSinceStart : 2009.8008136749268\n",
            "Training Loss : -2690.87451171875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 122.41339111328125\n",
            "Eval_StdReturn : 19.555416107177734\n",
            "Eval_MaxReturn : 143.71018981933594\n",
            "Eval_MinReturn : 96.4857177734375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 123.92700958251953\n",
            "Train_StdReturn : 44.259429931640625\n",
            "Train_MaxReturn : 224.3177490234375\n",
            "Train_MinReturn : -188.15367126464844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2655300\n",
            "TimeSinceStart : 2048.1025853157043\n",
            "Training Loss : -2468.05322265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 162.03236389160156\n",
            "Eval_StdReturn : 14.667354583740234\n",
            "Eval_MaxReturn : 175.96615600585938\n",
            "Eval_MinReturn : 141.7581787109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 124.91097259521484\n",
            "Train_StdReturn : 56.32500457763672\n",
            "Train_MaxReturn : 234.96974182128906\n",
            "Train_MinReturn : -187.54312133789062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2705400\n",
            "TimeSinceStart : 2086.666088581085\n",
            "Training Loss : -1378.7325439453125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 207.7733917236328\n",
            "Eval_StdReturn : 31.69074058532715\n",
            "Eval_MaxReturn : 251.51724243164062\n",
            "Eval_MinReturn : 177.45687866210938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 133.7721405029297\n",
            "Train_StdReturn : 43.2649040222168\n",
            "Train_MaxReturn : 233.15866088867188\n",
            "Train_MinReturn : -147.52340698242188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2755500\n",
            "TimeSinceStart : 2125.0347185134888\n",
            "Training Loss : -1706.4111328125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 135.0128631591797\n",
            "Eval_StdReturn : 15.229169845581055\n",
            "Eval_MaxReturn : 154.02938842773438\n",
            "Eval_MinReturn : 116.74844360351562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 140.83395385742188\n",
            "Train_StdReturn : 37.864627838134766\n",
            "Train_MaxReturn : 237.85372924804688\n",
            "Train_MinReturn : -153.9114990234375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2805600\n",
            "TimeSinceStart : 2163.7431106567383\n",
            "Training Loss : -1810.6649169921875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 125.54073333740234\n",
            "Eval_StdReturn : 56.70438766479492\n",
            "Eval_MaxReturn : 184.3604736328125\n",
            "Eval_MinReturn : 48.926414489746094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 134.80751037597656\n",
            "Train_StdReturn : 43.52346420288086\n",
            "Train_MaxReturn : 225.02944946289062\n",
            "Train_MinReturn : -175.6920623779297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2855700\n",
            "TimeSinceStart : 2202.2588653564453\n",
            "Training Loss : -1571.77197265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 133.96775817871094\n",
            "Eval_StdReturn : 40.70933532714844\n",
            "Eval_MaxReturn : 186.80026245117188\n",
            "Eval_MinReturn : 87.74191284179688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 128.4447479248047\n",
            "Train_StdReturn : 34.658077239990234\n",
            "Train_MaxReturn : 216.58798217773438\n",
            "Train_MinReturn : -57.78264617919922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2905800\n",
            "TimeSinceStart : 2240.453936815262\n",
            "Training Loss : -1387.8599853515625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 142.13619995117188\n",
            "Eval_StdReturn : 17.05266761779785\n",
            "Eval_MaxReturn : 156.27188110351562\n",
            "Eval_MinReturn : 118.14715576171875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 132.55442810058594\n",
            "Train_StdReturn : 39.23650360107422\n",
            "Train_MaxReturn : 234.07022094726562\n",
            "Train_MinReturn : -136.99070739746094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2955900\n",
            "TimeSinceStart : 2279.1683230400085\n",
            "Training Loss : -1453.540283203125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 158.90744018554688\n",
            "Eval_StdReturn : 13.64676284790039\n",
            "Eval_MaxReturn : 176.7511749267578\n",
            "Eval_MinReturn : 143.61752319335938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 145.62142944335938\n",
            "Train_StdReturn : 43.855140686035156\n",
            "Train_MaxReturn : 260.7142333984375\n",
            "Train_MinReturn : -128.77291870117188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3006000\n",
            "TimeSinceStart : 2317.7167341709137\n",
            "Training Loss : -2053.14794921875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 180.82215881347656\n",
            "Eval_StdReturn : 37.230377197265625\n",
            "Eval_MaxReturn : 220.58078002929688\n",
            "Eval_MinReturn : 131.04986572265625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 141.58966064453125\n",
            "Train_StdReturn : 57.684383392333984\n",
            "Train_MaxReturn : 261.0968017578125\n",
            "Train_MinReturn : -150.57546997070312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3056100\n",
            "TimeSinceStart : 2356.2446534633636\n",
            "Training Loss : -1520.2252197265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 112.9372787475586\n",
            "Eval_StdReturn : 36.2547607421875\n",
            "Eval_MaxReturn : 163.35733032226562\n",
            "Eval_MinReturn : 79.66654968261719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 141.61883544921875\n",
            "Train_StdReturn : 68.1297836303711\n",
            "Train_MaxReturn : 297.8356018066406\n",
            "Train_MinReturn : -160.0142822265625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3106200\n",
            "TimeSinceStart : 2394.754350423813\n",
            "Training Loss : -1835.1387939453125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 155.51243591308594\n",
            "Eval_StdReturn : 33.85904312133789\n",
            "Eval_MaxReturn : 182.10299682617188\n",
            "Eval_MinReturn : 107.73008728027344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 141.36903381347656\n",
            "Train_StdReturn : 103.04177856445312\n",
            "Train_MaxReturn : 293.701904296875\n",
            "Train_MinReturn : -172.3541259765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3156300\n",
            "TimeSinceStart : 2433.134375810623\n",
            "Training Loss : -1392.6083984375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 142.73284912109375\n",
            "Eval_StdReturn : 38.66360092163086\n",
            "Eval_MaxReturn : 183.82183837890625\n",
            "Eval_MinReturn : 90.946044921875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 157.10635375976562\n",
            "Train_StdReturn : 80.85948944091797\n",
            "Train_MaxReturn : 362.87005615234375\n",
            "Train_MinReturn : -156.63546752929688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3206400\n",
            "TimeSinceStart : 2471.39763879776\n",
            "Training Loss : -1209.6644287109375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 129.18704223632812\n",
            "Eval_StdReturn : 14.896696090698242\n",
            "Eval_MaxReturn : 149.484619140625\n",
            "Eval_MinReturn : 114.15219116210938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 163.6449432373047\n",
            "Train_StdReturn : 40.69835662841797\n",
            "Train_MaxReturn : 286.3619689941406\n",
            "Train_MinReturn : -4.622596740722656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3256500\n",
            "TimeSinceStart : 2509.9504041671753\n",
            "Training Loss : -1165.3328857421875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 143.04884338378906\n",
            "Eval_StdReturn : 6.3225789070129395\n",
            "Eval_MaxReturn : 150.89828491210938\n",
            "Eval_MinReturn : 135.4157257080078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 132.41156005859375\n",
            "Train_StdReturn : 35.971824645996094\n",
            "Train_MaxReturn : 257.9166564941406\n",
            "Train_MinReturn : 52.40953826904297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3306600\n",
            "TimeSinceStart : 2548.5386736392975\n",
            "Training Loss : -1061.05712890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 180.42449951171875\n",
            "Eval_StdReturn : 52.63800811767578\n",
            "Eval_MaxReturn : 237.03048706054688\n",
            "Eval_MinReturn : 110.25312042236328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 164.4911651611328\n",
            "Train_StdReturn : 33.641380310058594\n",
            "Train_MaxReturn : 266.2153625488281\n",
            "Train_MinReturn : 50.64585494995117\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3356700\n",
            "TimeSinceStart : 2587.1314899921417\n",
            "Training Loss : -1455.2188720703125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 152.9734649658203\n",
            "Eval_StdReturn : 21.367361068725586\n",
            "Eval_MaxReturn : 182.6143798828125\n",
            "Eval_MinReturn : 133.06298828125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 173.82749938964844\n",
            "Train_StdReturn : 37.42767333984375\n",
            "Train_MaxReturn : 259.723876953125\n",
            "Train_MinReturn : -107.55400848388672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3406800\n",
            "TimeSinceStart : 2625.5139544010162\n",
            "Training Loss : -720.6109619140625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 169.8379669189453\n",
            "Eval_StdReturn : 17.769603729248047\n",
            "Eval_MaxReturn : 185.48892211914062\n",
            "Eval_MinReturn : 144.98533630371094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 172.09698486328125\n",
            "Train_StdReturn : 44.64430236816406\n",
            "Train_MaxReturn : 263.0771484375\n",
            "Train_MinReturn : -116.81612396240234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3456900\n",
            "TimeSinceStart : 2664.074158668518\n",
            "Training Loss : -800.9539184570312\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 205.42222595214844\n",
            "Eval_StdReturn : 43.491233825683594\n",
            "Eval_MaxReturn : 253.61196899414062\n",
            "Eval_MinReturn : 148.22837829589844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 179.55856323242188\n",
            "Train_StdReturn : 47.36708450317383\n",
            "Train_MaxReturn : 299.35662841796875\n",
            "Train_MinReturn : -53.056270599365234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3507000\n",
            "TimeSinceStart : 2702.5372869968414\n",
            "Training Loss : -1249.7877197265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 179.6112518310547\n",
            "Eval_StdReturn : 11.945040702819824\n",
            "Eval_MaxReturn : 194.32986450195312\n",
            "Eval_MinReturn : 165.072265625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 163.3375701904297\n",
            "Train_StdReturn : 61.74114990234375\n",
            "Train_MaxReturn : 265.1884460449219\n",
            "Train_MinReturn : -126.87229919433594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3557100\n",
            "TimeSinceStart : 2740.854908466339\n",
            "Training Loss : -1107.267578125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 132.49278259277344\n",
            "Eval_StdReturn : 6.330327033996582\n",
            "Eval_MaxReturn : 139.2538604736328\n",
            "Eval_MinReturn : 124.0303726196289\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 157.40652465820312\n",
            "Train_StdReturn : 69.28445434570312\n",
            "Train_MaxReturn : 290.1819763183594\n",
            "Train_MinReturn : -151.24595642089844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3607200\n",
            "TimeSinceStart : 2779.0340955257416\n",
            "Training Loss : -579.9053955078125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 145.5149383544922\n",
            "Eval_StdReturn : 26.484155654907227\n",
            "Eval_MaxReturn : 175.30181884765625\n",
            "Eval_MinReturn : 110.95751953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 150.83331298828125\n",
            "Train_StdReturn : 52.895416259765625\n",
            "Train_MaxReturn : 250.81744384765625\n",
            "Train_MinReturn : -127.17778015136719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3657300\n",
            "TimeSinceStart : 2817.7008516788483\n",
            "Training Loss : -1483.712890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 150.96751403808594\n",
            "Eval_StdReturn : 28.925437927246094\n",
            "Eval_MaxReturn : 186.22509765625\n",
            "Eval_MinReturn : 115.37490844726562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 125.8375244140625\n",
            "Train_StdReturn : 35.985260009765625\n",
            "Train_MaxReturn : 235.13636779785156\n",
            "Train_MinReturn : -145.94845581054688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3707400\n",
            "TimeSinceStart : 2856.6200873851776\n",
            "Training Loss : -992.0685424804688\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 193.6422882080078\n",
            "Eval_StdReturn : 39.11333084106445\n",
            "Eval_MaxReturn : 248.29641723632812\n",
            "Eval_MinReturn : 158.93463134765625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 143.21563720703125\n",
            "Train_StdReturn : 26.911224365234375\n",
            "Train_MaxReturn : 223.17575073242188\n",
            "Train_MinReturn : 19.666168212890625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3757500\n",
            "TimeSinceStart : 2895.162379026413\n",
            "Training Loss : -1973.6497802734375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 162.79083251953125\n",
            "Eval_StdReturn : 16.588237762451172\n",
            "Eval_MaxReturn : 175.52670288085938\n",
            "Eval_MinReturn : 139.3611602783203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 167.83035278320312\n",
            "Train_StdReturn : 38.40837097167969\n",
            "Train_MaxReturn : 270.7810363769531\n",
            "Train_MinReturn : -103.7896728515625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3807600\n",
            "TimeSinceStart : 2933.627899646759\n",
            "Training Loss : -1172.41357421875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 166.8798370361328\n",
            "Eval_StdReturn : 15.684171676635742\n",
            "Eval_MaxReturn : 185.0562744140625\n",
            "Eval_MinReturn : 146.78240966796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 179.02088928222656\n",
            "Train_StdReturn : 34.395477294921875\n",
            "Train_MaxReturn : 278.4964599609375\n",
            "Train_MinReturn : 16.434696197509766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3857700\n",
            "TimeSinceStart : 2971.821152448654\n",
            "Training Loss : -737.2460327148438\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 229.4122314453125\n",
            "Eval_StdReturn : 15.786286354064941\n",
            "Eval_MaxReturn : 251.0194091796875\n",
            "Eval_MinReturn : 213.74473571777344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 182.9827117919922\n",
            "Train_StdReturn : 31.116981506347656\n",
            "Train_MaxReturn : 269.0562744140625\n",
            "Train_MinReturn : 60.96675491333008\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3907800\n",
            "TimeSinceStart : 3010.3640832901\n",
            "Training Loss : -1381.577880859375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 213.95970153808594\n",
            "Eval_StdReturn : 6.889412879943848\n",
            "Eval_MaxReturn : 223.2715301513672\n",
            "Eval_MinReturn : 206.8211669921875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 204.69964599609375\n",
            "Train_StdReturn : 33.354888916015625\n",
            "Train_MaxReturn : 286.0051574707031\n",
            "Train_MinReturn : 108.95186614990234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3957900\n",
            "TimeSinceStart : 3048.5319600105286\n",
            "Training Loss : -894.3767700195312\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.869873046875\n",
            "Eval_StdReturn : 47.458614349365234\n",
            "Eval_MaxReturn : 269.17974853515625\n",
            "Eval_MinReturn : 167.7589111328125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 214.06565856933594\n",
            "Train_StdReturn : 35.19864273071289\n",
            "Train_MaxReturn : 321.7467041015625\n",
            "Train_MinReturn : 120.89602661132812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4008000\n",
            "TimeSinceStart : 3086.727868795395\n",
            "Training Loss : -662.5028076171875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 248.2313232421875\n",
            "Eval_StdReturn : 37.08485794067383\n",
            "Eval_MaxReturn : 279.8714294433594\n",
            "Eval_MinReturn : 196.18824768066406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 231.32284545898438\n",
            "Train_StdReturn : 36.67741775512695\n",
            "Train_MaxReturn : 314.53546142578125\n",
            "Train_MinReturn : 123.33008575439453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4058100\n",
            "TimeSinceStart : 3125.0229535102844\n",
            "Training Loss : -1225.202880859375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 245.04541015625\n",
            "Eval_StdReturn : 5.379369735717773\n",
            "Eval_MaxReturn : 250.94476318359375\n",
            "Eval_MinReturn : 237.93585205078125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 250.1923828125\n",
            "Train_StdReturn : 39.114356994628906\n",
            "Train_MaxReturn : 362.6331787109375\n",
            "Train_MinReturn : 134.27894592285156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4108200\n",
            "TimeSinceStart : 3163.245641231537\n",
            "Training Loss : -1119.5435791015625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 243.310791015625\n",
            "Eval_StdReturn : 18.504859924316406\n",
            "Eval_MaxReturn : 269.15399169921875\n",
            "Eval_MinReturn : 226.81968688964844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 249.0021514892578\n",
            "Train_StdReturn : 43.48446273803711\n",
            "Train_MaxReturn : 377.0555725097656\n",
            "Train_MinReturn : 132.95989990234375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4158300\n",
            "TimeSinceStart : 3201.6890811920166\n",
            "Training Loss : -1002.916015625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 197.8094024658203\n",
            "Eval_StdReturn : 6.999521255493164\n",
            "Eval_MaxReturn : 207.02798461914062\n",
            "Eval_MinReturn : 190.07708740234375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 206.0817108154297\n",
            "Train_StdReturn : 47.092987060546875\n",
            "Train_MaxReturn : 363.5843505859375\n",
            "Train_MinReturn : -16.781593322753906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4208400\n",
            "TimeSinceStart : 3240.33282828331\n",
            "Training Loss : -883.7464599609375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 149.9308624267578\n",
            "Eval_StdReturn : 29.957204818725586\n",
            "Eval_MaxReturn : 178.04937744140625\n",
            "Eval_MinReturn : 108.42779541015625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 178.7821044921875\n",
            "Train_StdReturn : 50.6837272644043\n",
            "Train_MaxReturn : 330.84283447265625\n",
            "Train_MinReturn : -37.174041748046875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4258500\n",
            "TimeSinceStart : 3278.5944871902466\n",
            "Training Loss : -1190.317138671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 244.40855407714844\n",
            "Eval_StdReturn : 32.606563568115234\n",
            "Eval_MaxReturn : 287.8134765625\n",
            "Eval_MinReturn : 209.2230987548828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 179.87890625\n",
            "Train_StdReturn : 63.22596740722656\n",
            "Train_MaxReturn : 337.78057861328125\n",
            "Train_MinReturn : -98.30252838134766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4308600\n",
            "TimeSinceStart : 3317.153852701187\n",
            "Training Loss : -791.9573974609375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 195.230712890625\n",
            "Eval_StdReturn : 30.508899688720703\n",
            "Eval_MaxReturn : 219.16891479492188\n",
            "Eval_MinReturn : 152.17445373535156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 194.51219177246094\n",
            "Train_StdReturn : 49.46407699584961\n",
            "Train_MaxReturn : 308.1886291503906\n",
            "Train_MinReturn : -44.53984069824219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4358700\n",
            "TimeSinceStart : 3355.721743822098\n",
            "Training Loss : -589.73974609375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 217.325439453125\n",
            "Eval_StdReturn : 45.497066497802734\n",
            "Eval_MaxReturn : 257.6990051269531\n",
            "Eval_MinReturn : 153.7513885498047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 192.3201446533203\n",
            "Train_StdReturn : 54.2928352355957\n",
            "Train_MaxReturn : 336.6761474609375\n",
            "Train_MinReturn : -161.94351196289062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4408800\n",
            "TimeSinceStart : 3394.5595910549164\n",
            "Training Loss : -1050.15087890625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 186.08917236328125\n",
            "Eval_StdReturn : 4.076606750488281\n",
            "Eval_MaxReturn : 191.46490478515625\n",
            "Eval_MinReturn : 181.5973663330078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 201.69082641601562\n",
            "Train_StdReturn : 48.761863708496094\n",
            "Train_MaxReturn : 369.5498046875\n",
            "Train_MinReturn : -53.651588439941406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4458900\n",
            "TimeSinceStart : 3433.1932077407837\n",
            "Training Loss : -1045.341552734375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 143.99168395996094\n",
            "Eval_StdReturn : 78.4079818725586\n",
            "Eval_MaxReturn : 243.286865234375\n",
            "Eval_MinReturn : 51.59989547729492\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 184.03233337402344\n",
            "Train_StdReturn : 66.2149429321289\n",
            "Train_MaxReturn : 305.16827392578125\n",
            "Train_MinReturn : -112.67292022705078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4509000\n",
            "TimeSinceStart : 3471.6575903892517\n",
            "Training Loss : -587.6572265625\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 155.09864807128906\n",
            "Eval_StdReturn : 101.64045715332031\n",
            "Eval_MaxReturn : 255.83921813964844\n",
            "Eval_MinReturn : 15.932659149169922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 178.69322204589844\n",
            "Train_StdReturn : 69.3718490600586\n",
            "Train_MaxReturn : 335.5603332519531\n",
            "Train_MinReturn : -74.26101684570312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4559100\n",
            "TimeSinceStart : 3510.009688615799\n",
            "Training Loss : -1351.510498046875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 216.9578399658203\n",
            "Eval_StdReturn : 22.151958465576172\n",
            "Eval_MaxReturn : 248.01925659179688\n",
            "Eval_MinReturn : 197.89788818359375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 163.34228515625\n",
            "Train_StdReturn : 74.35813903808594\n",
            "Train_MaxReturn : 310.7862548828125\n",
            "Train_MinReturn : -101.28569030761719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4609200\n",
            "TimeSinceStart : 3548.519846200943\n",
            "Training Loss : -1188.897216796875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.2119140625\n",
            "Eval_StdReturn : 36.30388641357422\n",
            "Eval_MaxReturn : 285.10894775390625\n",
            "Eval_MinReturn : 202.92584228515625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 215.0791473388672\n",
            "Train_StdReturn : 63.294342041015625\n",
            "Train_MaxReturn : 347.92291259765625\n",
            "Train_MinReturn : -73.10953521728516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4659300\n",
            "TimeSinceStart : 3586.8142473697662\n",
            "Training Loss : -720.903564453125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 258.5502014160156\n",
            "Eval_StdReturn : 16.535348892211914\n",
            "Eval_MaxReturn : 271.4360656738281\n",
            "Eval_MinReturn : 235.2078094482422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 211.4421844482422\n",
            "Train_StdReturn : 57.8080940246582\n",
            "Train_MaxReturn : 323.801513671875\n",
            "Train_MinReturn : -60.36458969116211\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4709400\n",
            "TimeSinceStart : 3625.1414637565613\n",
            "Training Loss : -889.9540405273438\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 125.3857192993164\n",
            "Eval_StdReturn : 75.16620635986328\n",
            "Eval_MaxReturn : 215.8027801513672\n",
            "Eval_MinReturn : 31.76744270324707\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 202.77220153808594\n",
            "Train_StdReturn : 64.64273071289062\n",
            "Train_MaxReturn : 321.7237548828125\n",
            "Train_MinReturn : -45.9039306640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4759500\n",
            "TimeSinceStart : 3663.656860589981\n",
            "Training Loss : -789.0189819335938\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 182.19432067871094\n",
            "Eval_StdReturn : 48.9994010925293\n",
            "Eval_MaxReturn : 217.7589874267578\n",
            "Eval_MinReturn : 112.90685272216797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 206.79946899414062\n",
            "Train_StdReturn : 58.89923858642578\n",
            "Train_MaxReturn : 324.9888916015625\n",
            "Train_MinReturn : -9.190580368041992\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4809600\n",
            "TimeSinceStart : 3702.124613761902\n",
            "Training Loss : -392.58978271484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 115.42449951171875\n",
            "Eval_StdReturn : 108.17485809326172\n",
            "Eval_MaxReturn : 216.8689422607422\n",
            "Eval_MinReturn : -34.46661376953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 165.0544891357422\n",
            "Train_StdReturn : 76.72132110595703\n",
            "Train_MaxReturn : 290.4222717285156\n",
            "Train_MinReturn : -55.99414825439453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4859700\n",
            "TimeSinceStart : 3740.4104051589966\n",
            "Training Loss : -662.8187866210938\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 133.81971740722656\n",
            "Eval_StdReturn : 58.435890197753906\n",
            "Eval_MaxReturn : 203.38768005371094\n",
            "Eval_MinReturn : 60.40473556518555\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 152.1251983642578\n",
            "Train_StdReturn : 72.06037902832031\n",
            "Train_MaxReturn : 284.87445068359375\n",
            "Train_MinReturn : -49.7205810546875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4909800\n",
            "TimeSinceStart : 3778.7567896842957\n",
            "Training Loss : -542.56396484375\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 161.31932067871094\n",
            "Eval_StdReturn : 56.93960189819336\n",
            "Eval_MaxReturn : 201.71441650390625\n",
            "Eval_MinReturn : 80.7947006225586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 156.41036987304688\n",
            "Train_StdReturn : 56.477108001708984\n",
            "Train_MaxReturn : 281.82696533203125\n",
            "Train_MinReturn : -40.70872497558594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4959900\n",
            "TimeSinceStart : 3817.1264872550964\n",
            "Training Loss : -530.7332763671875\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 215.6600341796875\n",
            "Eval_StdReturn : 5.072572231292725\n",
            "Eval_MaxReturn : 222.49356079101562\n",
            "Eval_MinReturn : 210.35287475585938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 179.90707397460938\n",
            "Train_StdReturn : 47.79106521606445\n",
            "Train_MaxReturn : 307.05712890625\n",
            "Train_MinReturn : 18.607200622558594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 5010000\n",
            "TimeSinceStart : 3855.6308455467224\n",
            "Training Loss : -416.034423828125\n",
            "Initial_DataCollection_AverageReturn : -94.41527557373047\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "files = ['/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q4_b50000_r0.02_HalfCheetah-v2_10-05-2022_00-06-06/events.out.tfevents.1652141166.1a33eba480a9',\n",
        "         '/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q4_b50000_r0.02_rtg_HalfCheetah-v2_10-05-2022_01-19-59/events.out.tfevents.1652145599.1a33eba480a9',\n",
        "         '/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q4_b50000_r0.02_nnbaseline_HalfCheetah-v2_10-05-2022_10-05-27/events.out.tfevents.1652177127.bd1a90a43fe6',\n",
        "         '/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q4_b50000_r0.02_rtg_nnbaseline_HalfCheetah-v2_10-05-2022_12-38-27/events.out.tfevents.1652186307.916d7fe8be07']\n",
        "labels = ['simple', 'rtg', 'nnbaseline', 'rtg_nnbaseline']\n",
        "for logfile in files:\n",
        "    Eval_AverageReturns = []\n",
        "    for summary in summary_iterator(logfile):\n",
        "        for v in summary.summary.value:\n",
        "            if v.tag == \"Eval_AverageReturn\":\n",
        "                Eval_AverageReturns.append(v.simple_value)\n",
        "\n",
        "    plt.plot(Eval_AverageReturns, label = labels[i])\n",
        "    i+=1\n",
        "plt.legend()\n",
        "plt.savefig('q4')\n",
        "plt.delaxes()"
      ],
      "metadata": {
        "id": "4D-ujeb0gEGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZaKjaffGgXC"
      },
      "source": [
        "#Hopper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOy2tRn8HgXN",
        "outputId": "5499ac98-068f-4c3e-afb4-ee79567dcd43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Eval_StdReturn : 49.72883605957031\n",
            "Eval_MaxReturn : 180.5194549560547\n",
            "Eval_MinReturn : 21.16425132751465\n",
            "Eval_AverageEpLen : 36.36363636363637\n",
            "Train_AverageReturn : 57.51398468017578\n",
            "Train_StdReturn : 41.891658782958984\n",
            "Train_MaxReturn : 176.84664916992188\n",
            "Train_MinReturn : 13.647541999816895\n",
            "Train_AverageEpLen : 34.49152542372882\n",
            "Train_EnvstepsSoFar : 246604\n",
            "TimeSinceStart : 254.23944783210754\n",
            "Training Loss : -117.98336791992188\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 122 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 83.71263885498047\n",
            "Eval_StdReturn : 52.74229049682617\n",
            "Eval_MaxReturn : 170.0969696044922\n",
            "Eval_MinReturn : 22.535554885864258\n",
            "Eval_AverageEpLen : 46.888888888888886\n",
            "Train_AverageReturn : 70.4600601196289\n",
            "Train_StdReturn : 51.12076950073242\n",
            "Train_MaxReturn : 187.5303497314453\n",
            "Train_MinReturn : 19.07515525817871\n",
            "Train_AverageEpLen : 40.22\n",
            "Train_EnvstepsSoFar : 248615\n",
            "TimeSinceStart : 256.27553725242615\n",
            "Training Loss : 84.10859680175781\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 123 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 116.51301574707031\n",
            "Eval_StdReturn : 37.929527282714844\n",
            "Eval_MaxReturn : 187.1563720703125\n",
            "Eval_MinReturn : 79.36793518066406\n",
            "Eval_AverageEpLen : 62.857142857142854\n",
            "Train_AverageReturn : 93.777587890625\n",
            "Train_StdReturn : 63.091739654541016\n",
            "Train_MaxReturn : 195.44915771484375\n",
            "Train_MinReturn : 14.656156539916992\n",
            "Train_AverageEpLen : 50.34146341463415\n",
            "Train_EnvstepsSoFar : 250679\n",
            "TimeSinceStart : 258.4143364429474\n",
            "Training Loss : 31.32770538330078\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 124 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 174.1730194091797\n",
            "Eval_StdReturn : 17.97624397277832\n",
            "Eval_MaxReturn : 193.45480346679688\n",
            "Eval_MinReturn : 140.272705078125\n",
            "Eval_AverageEpLen : 83.4\n",
            "Train_AverageReturn : 108.75143432617188\n",
            "Train_StdReturn : 64.55569458007812\n",
            "Train_MaxReturn : 195.20236206054688\n",
            "Train_MinReturn : 21.905454635620117\n",
            "Train_AverageEpLen : 55.94444444444444\n",
            "Train_EnvstepsSoFar : 252693\n",
            "TimeSinceStart : 260.47489976882935\n",
            "Training Loss : 1.6949386596679688\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 125 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 185.37869262695312\n",
            "Eval_StdReturn : 12.607653617858887\n",
            "Eval_MaxReturn : 207.3312225341797\n",
            "Eval_MinReturn : 171.89398193359375\n",
            "Eval_AverageEpLen : 85.4\n",
            "Train_AverageReturn : 101.60414123535156\n",
            "Train_StdReturn : 64.25543212890625\n",
            "Train_MaxReturn : 200.3043212890625\n",
            "Train_MinReturn : 17.9586124420166\n",
            "Train_AverageEpLen : 53.578947368421055\n",
            "Train_EnvstepsSoFar : 254729\n",
            "TimeSinceStart : 262.5826880931854\n",
            "Training Loss : -88.12362670898438\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 126 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 168.17593383789062\n",
            "Eval_StdReturn : 36.25578308105469\n",
            "Eval_MaxReturn : 201.1597137451172\n",
            "Eval_MinReturn : 98.1533432006836\n",
            "Eval_AverageEpLen : 81.0\n",
            "Train_AverageReturn : 139.25511169433594\n",
            "Train_StdReturn : 63.40580749511719\n",
            "Train_MaxReturn : 205.0368194580078\n",
            "Train_MinReturn : 16.661996841430664\n",
            "Train_AverageEpLen : 68.93333333333334\n",
            "Train_EnvstepsSoFar : 256797\n",
            "TimeSinceStart : 264.7040889263153\n",
            "Training Loss : -71.86859130859375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 127 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 147.32395935058594\n",
            "Eval_StdReturn : 60.508853912353516\n",
            "Eval_MaxReturn : 200.87416076660156\n",
            "Eval_MinReturn : 33.69695281982422\n",
            "Eval_AverageEpLen : 74.33333333333333\n",
            "Train_AverageReturn : 154.75799560546875\n",
            "Train_StdReturn : 52.192840576171875\n",
            "Train_MaxReturn : 211.67025756835938\n",
            "Train_MinReturn : 28.035459518432617\n",
            "Train_AverageEpLen : 75.07407407407408\n",
            "Train_EnvstepsSoFar : 258824\n",
            "TimeSinceStart : 266.8272306919098\n",
            "Training Loss : 25.26561737060547\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 128 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 167.6006622314453\n",
            "Eval_StdReturn : 24.3996524810791\n",
            "Eval_MaxReturn : 187.1657257080078\n",
            "Eval_MinReturn : 119.63874053955078\n",
            "Eval_AverageEpLen : 80.0\n",
            "Train_AverageReturn : 158.46688842773438\n",
            "Train_StdReturn : 48.551483154296875\n",
            "Train_MaxReturn : 202.6500244140625\n",
            "Train_MinReturn : 38.50719451904297\n",
            "Train_AverageEpLen : 77.29629629629629\n",
            "Train_EnvstepsSoFar : 260911\n",
            "TimeSinceStart : 268.97390389442444\n",
            "Training Loss : -92.27102661132812\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 129 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 194.54116821289062\n",
            "Eval_StdReturn : 8.901535987854004\n",
            "Eval_MaxReturn : 208.2869415283203\n",
            "Eval_MinReturn : 186.11314392089844\n",
            "Eval_AverageEpLen : 89.8\n",
            "Train_AverageReturn : 169.53927612304688\n",
            "Train_StdReturn : 47.31232452392578\n",
            "Train_MaxReturn : 203.33758544921875\n",
            "Train_MinReturn : 32.347774505615234\n",
            "Train_AverageEpLen : 80.16\n",
            "Train_EnvstepsSoFar : 262915\n",
            "TimeSinceStart : 271.09376978874207\n",
            "Training Loss : -33.79170227050781\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 130 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 155.2882537841797\n",
            "Eval_StdReturn : 57.19326400756836\n",
            "Eval_MaxReturn : 201.02232360839844\n",
            "Eval_MinReturn : 34.3624382019043\n",
            "Eval_AverageEpLen : 74.83333333333333\n",
            "Train_AverageReturn : 187.82965087890625\n",
            "Train_StdReturn : 22.98465347290039\n",
            "Train_MaxReturn : 230.7383575439453\n",
            "Train_MinReturn : 96.09528350830078\n",
            "Train_AverageEpLen : 88.73913043478261\n",
            "Train_EnvstepsSoFar : 264956\n",
            "TimeSinceStart : 273.22403502464294\n",
            "Training Loss : -40.893524169921875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 131 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 187.78323364257812\n",
            "Eval_StdReturn : 27.618499755859375\n",
            "Eval_MaxReturn : 210.654541015625\n",
            "Eval_MinReturn : 135.35191345214844\n",
            "Eval_AverageEpLen : 88.6\n",
            "Train_AverageReturn : 186.63177490234375\n",
            "Train_StdReturn : 20.853641510009766\n",
            "Train_MaxReturn : 216.7183380126953\n",
            "Train_MinReturn : 102.13475036621094\n",
            "Train_AverageEpLen : 88.30434782608695\n",
            "Train_EnvstepsSoFar : 266987\n",
            "TimeSinceStart : 275.3475046157837\n",
            "Training Loss : -137.2390899658203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 132 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 189.345458984375\n",
            "Eval_StdReturn : 8.361595153808594\n",
            "Eval_MaxReturn : 199.09854125976562\n",
            "Eval_MinReturn : 176.79180908203125\n",
            "Eval_AverageEpLen : 86.8\n",
            "Train_AverageReturn : 187.19573974609375\n",
            "Train_StdReturn : 25.3532772064209\n",
            "Train_MaxReturn : 215.67518615722656\n",
            "Train_MinReturn : 86.6044921875\n",
            "Train_AverageEpLen : 88.08695652173913\n",
            "Train_EnvstepsSoFar : 269013\n",
            "TimeSinceStart : 277.48767161369324\n",
            "Training Loss : -68.55847930908203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 133 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 184.35064697265625\n",
            "Eval_StdReturn : 4.021073341369629\n",
            "Eval_MaxReturn : 191.80470275878906\n",
            "Eval_MinReturn : 181.20611572265625\n",
            "Eval_AverageEpLen : 85.4\n",
            "Train_AverageReturn : 184.83291625976562\n",
            "Train_StdReturn : 19.411283493041992\n",
            "Train_MaxReturn : 211.84754943847656\n",
            "Train_MinReturn : 146.1870574951172\n",
            "Train_AverageEpLen : 87.78260869565217\n",
            "Train_EnvstepsSoFar : 271032\n",
            "TimeSinceStart : 279.709125995636\n",
            "Training Loss : 22.524307250976562\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 134 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 169.57786560058594\n",
            "Eval_StdReturn : 33.44173049926758\n",
            "Eval_MaxReturn : 199.1713409423828\n",
            "Eval_MinReturn : 101.4847183227539\n",
            "Eval_AverageEpLen : 79.0\n",
            "Train_AverageReturn : 190.14198303222656\n",
            "Train_StdReturn : 15.291403770446777\n",
            "Train_MaxReturn : 209.1116943359375\n",
            "Train_MinReturn : 130.0557861328125\n",
            "Train_AverageEpLen : 89.21739130434783\n",
            "Train_EnvstepsSoFar : 273084\n",
            "TimeSinceStart : 281.8823390007019\n",
            "Training Loss : 8.342048645019531\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 135 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 164.8357696533203\n",
            "Eval_StdReturn : 38.660640716552734\n",
            "Eval_MaxReturn : 207.94473266601562\n",
            "Eval_MinReturn : 94.56304931640625\n",
            "Eval_AverageEpLen : 81.8\n",
            "Train_AverageReturn : 179.42626953125\n",
            "Train_StdReturn : 23.916770935058594\n",
            "Train_MaxReturn : 218.8780975341797\n",
            "Train_MinReturn : 132.48158264160156\n",
            "Train_AverageEpLen : 85.41666666666667\n",
            "Train_EnvstepsSoFar : 275134\n",
            "TimeSinceStart : 283.9814898967743\n",
            "Training Loss : -93.85499572753906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 136 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 164.6168212890625\n",
            "Eval_StdReturn : 19.597368240356445\n",
            "Eval_MaxReturn : 201.02186584472656\n",
            "Eval_MinReturn : 144.53797912597656\n",
            "Eval_AverageEpLen : 80.6\n",
            "Train_AverageReturn : 177.1424102783203\n",
            "Train_StdReturn : 27.730358123779297\n",
            "Train_MaxReturn : 212.5659942626953\n",
            "Train_MinReturn : 111.12351989746094\n",
            "Train_AverageEpLen : 85.0\n",
            "Train_EnvstepsSoFar : 277174\n",
            "TimeSinceStart : 286.14945578575134\n",
            "Training Loss : -126.65168762207031\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 137 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 169.6312255859375\n",
            "Eval_StdReturn : 37.390716552734375\n",
            "Eval_MaxReturn : 215.1812744140625\n",
            "Eval_MinReturn : 114.69903564453125\n",
            "Eval_AverageEpLen : 81.0\n",
            "Train_AverageReturn : 174.44813537597656\n",
            "Train_StdReturn : 31.509735107421875\n",
            "Train_MaxReturn : 221.20558166503906\n",
            "Train_MinReturn : 112.96695709228516\n",
            "Train_AverageEpLen : 84.25\n",
            "Train_EnvstepsSoFar : 279196\n",
            "TimeSinceStart : 288.2449698448181\n",
            "Training Loss : -116.67239379882812\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 138 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 153.11329650878906\n",
            "Eval_StdReturn : 40.60873031616211\n",
            "Eval_MaxReturn : 202.9772186279297\n",
            "Eval_MinReturn : 90.6078109741211\n",
            "Eval_AverageEpLen : 77.16666666666667\n",
            "Train_AverageReturn : 156.62506103515625\n",
            "Train_StdReturn : 35.519901275634766\n",
            "Train_MaxReturn : 209.59376525878906\n",
            "Train_MinReturn : 73.21592712402344\n",
            "Train_AverageEpLen : 77.22222222222223\n",
            "Train_EnvstepsSoFar : 281281\n",
            "TimeSinceStart : 290.4080286026001\n",
            "Training Loss : 5.302989959716797\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 139 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 137.02908325195312\n",
            "Eval_StdReturn : 33.4132080078125\n",
            "Eval_MaxReturn : 200.7354278564453\n",
            "Eval_MinReturn : 106.33648681640625\n",
            "Eval_AverageEpLen : 69.83333333333333\n",
            "Train_AverageReturn : 163.26953125\n",
            "Train_StdReturn : 38.12116241455078\n",
            "Train_MaxReturn : 210.43917846679688\n",
            "Train_MinReturn : 89.22935485839844\n",
            "Train_AverageEpLen : 78.76923076923077\n",
            "Train_EnvstepsSoFar : 283329\n",
            "TimeSinceStart : 292.60748529434204\n",
            "Training Loss : -95.85587310791016\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 140 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 159.671630859375\n",
            "Eval_StdReturn : 19.663068771362305\n",
            "Eval_MaxReturn : 188.0433807373047\n",
            "Eval_MinReturn : 129.9680938720703\n",
            "Eval_AverageEpLen : 80.0\n",
            "Train_AverageReturn : 146.55105590820312\n",
            "Train_StdReturn : 42.07571792602539\n",
            "Train_MaxReturn : 218.5872344970703\n",
            "Train_MinReturn : 61.35301208496094\n",
            "Train_AverageEpLen : 73.39285714285714\n",
            "Train_EnvstepsSoFar : 285384\n",
            "TimeSinceStart : 294.69553804397583\n",
            "Training Loss : -118.4544448852539\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 141 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 135.03738403320312\n",
            "Eval_StdReturn : 33.48149108886719\n",
            "Eval_MaxReturn : 198.25721740722656\n",
            "Eval_MinReturn : 87.449951171875\n",
            "Eval_AverageEpLen : 69.66666666666667\n",
            "Train_AverageReturn : 137.98780822753906\n",
            "Train_StdReturn : 36.5002555847168\n",
            "Train_MaxReturn : 218.29164123535156\n",
            "Train_MinReturn : 57.13625717163086\n",
            "Train_AverageEpLen : 70.37931034482759\n",
            "Train_EnvstepsSoFar : 287425\n",
            "TimeSinceStart : 296.8353624343872\n",
            "Training Loss : -96.3880615234375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 142 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 118.67255401611328\n",
            "Eval_StdReturn : 25.760969161987305\n",
            "Eval_MaxReturn : 154.52383422851562\n",
            "Eval_MinReturn : 85.76434326171875\n",
            "Eval_AverageEpLen : 64.42857142857143\n",
            "Train_AverageReturn : 144.08416748046875\n",
            "Train_StdReturn : 33.51012420654297\n",
            "Train_MaxReturn : 213.4298095703125\n",
            "Train_MinReturn : 87.52490997314453\n",
            "Train_AverageEpLen : 72.96428571428571\n",
            "Train_EnvstepsSoFar : 289468\n",
            "TimeSinceStart : 298.96515011787415\n",
            "Training Loss : -176.06173706054688\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 143 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 121.51591491699219\n",
            "Eval_StdReturn : 36.46702575683594\n",
            "Eval_MaxReturn : 184.3419647216797\n",
            "Eval_MinReturn : 54.98784255981445\n",
            "Eval_AverageEpLen : 63.714285714285715\n",
            "Train_AverageReturn : 129.4986114501953\n",
            "Train_StdReturn : 38.65254211425781\n",
            "Train_MaxReturn : 212.98574829101562\n",
            "Train_MinReturn : 55.66254425048828\n",
            "Train_AverageEpLen : 67.4\n",
            "Train_EnvstepsSoFar : 291490\n",
            "TimeSinceStart : 301.0866696834564\n",
            "Training Loss : -98.63458251953125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 144 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 119.33855438232422\n",
            "Eval_StdReturn : 33.18696212768555\n",
            "Eval_MaxReturn : 185.1067657470703\n",
            "Eval_MinReturn : 76.00443267822266\n",
            "Eval_AverageEpLen : 63.714285714285715\n",
            "Train_AverageReturn : 123.70881652832031\n",
            "Train_StdReturn : 29.473159790039062\n",
            "Train_MaxReturn : 196.40887451171875\n",
            "Train_MinReturn : 77.348876953125\n",
            "Train_AverageEpLen : 65.3225806451613\n",
            "Train_EnvstepsSoFar : 293515\n",
            "TimeSinceStart : 303.1593656539917\n",
            "Training Loss : -94.63578033447266\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 145 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 128.20843505859375\n",
            "Eval_StdReturn : 13.698729515075684\n",
            "Eval_MaxReturn : 144.0338897705078\n",
            "Eval_MinReturn : 102.69084930419922\n",
            "Eval_AverageEpLen : 66.66666666666667\n",
            "Train_AverageReturn : 119.37593078613281\n",
            "Train_StdReturn : 25.71637725830078\n",
            "Train_MaxReturn : 190.7695770263672\n",
            "Train_MinReturn : 69.96005249023438\n",
            "Train_AverageEpLen : 63.53125\n",
            "Train_EnvstepsSoFar : 295548\n",
            "TimeSinceStart : 305.223708152771\n",
            "Training Loss : -164.30337524414062\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 146 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 135.3038330078125\n",
            "Eval_StdReturn : 22.84876251220703\n",
            "Eval_MaxReturn : 175.5599822998047\n",
            "Eval_MinReturn : 105.32413482666016\n",
            "Eval_AverageEpLen : 74.0\n",
            "Train_AverageReturn : 106.64347076416016\n",
            "Train_StdReturn : 24.303300857543945\n",
            "Train_MaxReturn : 171.46571350097656\n",
            "Train_MinReturn : 63.22038650512695\n",
            "Train_AverageEpLen : 58.970588235294116\n",
            "Train_EnvstepsSoFar : 297553\n",
            "TimeSinceStart : 307.2956962585449\n",
            "Training Loss : -59.33036804199219\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 147 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 88.6981430053711\n",
            "Eval_StdReturn : 11.219170570373535\n",
            "Eval_MaxReturn : 113.68186950683594\n",
            "Eval_MinReturn : 71.92879486083984\n",
            "Eval_AverageEpLen : 51.125\n",
            "Train_AverageReturn : 104.44342041015625\n",
            "Train_StdReturn : 23.78118133544922\n",
            "Train_MaxReturn : 184.62060546875\n",
            "Train_MinReturn : 63.85408020019531\n",
            "Train_AverageEpLen : 58.42857142857143\n",
            "Train_EnvstepsSoFar : 299598\n",
            "TimeSinceStart : 309.337206363678\n",
            "Training Loss : -135.7316436767578\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 148 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 147.7307586669922\n",
            "Eval_StdReturn : 24.97360610961914\n",
            "Eval_MaxReturn : 196.14256286621094\n",
            "Eval_MinReturn : 128.5280303955078\n",
            "Eval_AverageEpLen : 82.8\n",
            "Train_AverageReturn : 109.99604034423828\n",
            "Train_StdReturn : 30.648000717163086\n",
            "Train_MaxReturn : 177.65975952148438\n",
            "Train_MinReturn : 66.3577651977539\n",
            "Train_AverageEpLen : 60.72727272727273\n",
            "Train_EnvstepsSoFar : 301602\n",
            "TimeSinceStart : 311.3829002380371\n",
            "Training Loss : -68.42362976074219\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 149 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.55540466308594\n",
            "Eval_StdReturn : 19.371389389038086\n",
            "Eval_MaxReturn : 146.06085205078125\n",
            "Eval_MinReturn : 76.15748596191406\n",
            "Eval_AverageEpLen : 60.142857142857146\n",
            "Train_AverageReturn : 101.68557739257812\n",
            "Train_StdReturn : 19.96078872680664\n",
            "Train_MaxReturn : 159.4396514892578\n",
            "Train_MinReturn : 70.84402465820312\n",
            "Train_AverageEpLen : 57.111111111111114\n",
            "Train_EnvstepsSoFar : 303658\n",
            "TimeSinceStart : 313.4539556503296\n",
            "Training Loss : -42.154441833496094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 150 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 86.77359008789062\n",
            "Eval_StdReturn : 18.559890747070312\n",
            "Eval_MaxReturn : 117.89265441894531\n",
            "Eval_MinReturn : 64.42927551269531\n",
            "Eval_AverageEpLen : 49.55555555555556\n",
            "Train_AverageReturn : 99.01423645019531\n",
            "Train_StdReturn : 23.212358474731445\n",
            "Train_MaxReturn : 160.97665405273438\n",
            "Train_MinReturn : 58.38490295410156\n",
            "Train_AverageEpLen : 55.270270270270274\n",
            "Train_EnvstepsSoFar : 305703\n",
            "TimeSinceStart : 315.54185914993286\n",
            "Training Loss : -118.33810424804688\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 151 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 95.22105407714844\n",
            "Eval_StdReturn : 19.244281768798828\n",
            "Eval_MaxReturn : 117.09337615966797\n",
            "Eval_MinReturn : 61.00477600097656\n",
            "Eval_AverageEpLen : 55.0\n",
            "Train_AverageReturn : 96.13391876220703\n",
            "Train_StdReturn : 19.654462814331055\n",
            "Train_MaxReturn : 141.91783142089844\n",
            "Train_MinReturn : 57.73555374145508\n",
            "Train_AverageEpLen : 54.08108108108108\n",
            "Train_EnvstepsSoFar : 307704\n",
            "TimeSinceStart : 317.5837094783783\n",
            "Training Loss : -56.602474212646484\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 152 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 91.59080505371094\n",
            "Eval_StdReturn : 25.024446487426758\n",
            "Eval_MaxReturn : 135.7639923095703\n",
            "Eval_MinReturn : 53.95155334472656\n",
            "Eval_AverageEpLen : 52.5\n",
            "Train_AverageReturn : 95.06936645507812\n",
            "Train_StdReturn : 24.81898307800293\n",
            "Train_MaxReturn : 161.81182861328125\n",
            "Train_MinReturn : 60.976802825927734\n",
            "Train_AverageEpLen : 53.86842105263158\n",
            "Train_EnvstepsSoFar : 309751\n",
            "TimeSinceStart : 319.64794397354126\n",
            "Training Loss : -172.20770263671875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 153 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 77.52156829833984\n",
            "Eval_StdReturn : 17.336597442626953\n",
            "Eval_MaxReturn : 107.82064819335938\n",
            "Eval_MinReturn : 51.68938064575195\n",
            "Eval_AverageEpLen : 45.0\n",
            "Train_AverageReturn : 94.94397735595703\n",
            "Train_StdReturn : 28.64481544494629\n",
            "Train_MaxReturn : 169.01438903808594\n",
            "Train_MinReturn : 55.77505111694336\n",
            "Train_AverageEpLen : 53.256410256410255\n",
            "Train_EnvstepsSoFar : 311828\n",
            "TimeSinceStart : 321.8184382915497\n",
            "Training Loss : -90.69134521484375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 154 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 88.12348937988281\n",
            "Eval_StdReturn : 14.656270027160645\n",
            "Eval_MaxReturn : 108.84525299072266\n",
            "Eval_MinReturn : 59.168643951416016\n",
            "Eval_AverageEpLen : 51.375\n",
            "Train_AverageReturn : 93.15415954589844\n",
            "Train_StdReturn : 25.43313217163086\n",
            "Train_MaxReturn : 167.75173950195312\n",
            "Train_MinReturn : 60.12348556518555\n",
            "Train_AverageEpLen : 52.86842105263158\n",
            "Train_EnvstepsSoFar : 313837\n",
            "TimeSinceStart : 323.84396624565125\n",
            "Training Loss : -63.90699768066406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 155 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.52149963378906\n",
            "Eval_StdReturn : 36.683013916015625\n",
            "Eval_MaxReturn : 178.1321563720703\n",
            "Eval_MinReturn : 61.60800552368164\n",
            "Eval_AverageEpLen : 51.5\n",
            "Train_AverageReturn : 89.53833770751953\n",
            "Train_StdReturn : 23.50924301147461\n",
            "Train_MaxReturn : 146.40438842773438\n",
            "Train_MinReturn : 52.24224090576172\n",
            "Train_AverageEpLen : 51.56410256410256\n",
            "Train_EnvstepsSoFar : 315848\n",
            "TimeSinceStart : 325.89038348197937\n",
            "Training Loss : -149.40142822265625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 156 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 74.06706237792969\n",
            "Eval_StdReturn : 11.16201114654541\n",
            "Eval_MaxReturn : 91.4086685180664\n",
            "Eval_MinReturn : 53.00457763671875\n",
            "Eval_AverageEpLen : 43.1\n",
            "Train_AverageReturn : 87.71273040771484\n",
            "Train_StdReturn : 18.642765045166016\n",
            "Train_MaxReturn : 124.8613052368164\n",
            "Train_MinReturn : 57.42036056518555\n",
            "Train_AverageEpLen : 50.2\n",
            "Train_EnvstepsSoFar : 317856\n",
            "TimeSinceStart : 327.9404993057251\n",
            "Training Loss : -63.716304779052734\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 157 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 79.71934509277344\n",
            "Eval_StdReturn : 19.6092529296875\n",
            "Eval_MaxReturn : 135.41244506835938\n",
            "Eval_MinReturn : 63.69353103637695\n",
            "Eval_AverageEpLen : 46.0\n",
            "Train_AverageReturn : 80.0413589477539\n",
            "Train_StdReturn : 20.595130920410156\n",
            "Train_MaxReturn : 150.05142211914062\n",
            "Train_MinReturn : 53.39314651489258\n",
            "Train_AverageEpLen : 46.04545454545455\n",
            "Train_EnvstepsSoFar : 319882\n",
            "TimeSinceStart : 329.97524094581604\n",
            "Training Loss : -137.92156982421875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 158 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 79.24903106689453\n",
            "Eval_StdReturn : 23.82273292541504\n",
            "Eval_MaxReturn : 139.71484375\n",
            "Eval_MinReturn : 58.22418212890625\n",
            "Eval_AverageEpLen : 45.55555555555556\n",
            "Train_AverageReturn : 76.40315246582031\n",
            "Train_StdReturn : 18.94717788696289\n",
            "Train_MaxReturn : 163.37608337402344\n",
            "Train_MinReturn : 47.26285171508789\n",
            "Train_AverageEpLen : 44.21739130434783\n",
            "Train_EnvstepsSoFar : 321916\n",
            "TimeSinceStart : 331.99865651130676\n",
            "Training Loss : -111.6766357421875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 159 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 62.26958084106445\n",
            "Eval_StdReturn : 11.140909194946289\n",
            "Eval_MaxReturn : 77.15538024902344\n",
            "Eval_MinReturn : 43.27083206176758\n",
            "Eval_AverageEpLen : 35.833333333333336\n",
            "Train_AverageReturn : 76.06156921386719\n",
            "Train_StdReturn : 19.104450225830078\n",
            "Train_MaxReturn : 142.4821014404297\n",
            "Train_MinReturn : 46.55488967895508\n",
            "Train_AverageEpLen : 44.08695652173913\n",
            "Train_EnvstepsSoFar : 323944\n",
            "TimeSinceStart : 334.004976272583\n",
            "Training Loss : -130.4285430908203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 160 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 69.51361083984375\n",
            "Eval_StdReturn : 15.030840873718262\n",
            "Eval_MaxReturn : 107.19315338134766\n",
            "Eval_MinReturn : 45.656211853027344\n",
            "Eval_AverageEpLen : 40.2\n",
            "Train_AverageReturn : 76.385986328125\n",
            "Train_StdReturn : 19.62880516052246\n",
            "Train_MaxReturn : 136.12057495117188\n",
            "Train_MinReturn : 43.01972961425781\n",
            "Train_AverageEpLen : 44.08695652173913\n",
            "Train_EnvstepsSoFar : 325972\n",
            "TimeSinceStart : 336.05787110328674\n",
            "Training Loss : -124.02497863769531\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 161 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 70.59822082519531\n",
            "Eval_StdReturn : 13.618477821350098\n",
            "Eval_MaxReturn : 99.2350082397461\n",
            "Eval_MinReturn : 55.06704330444336\n",
            "Eval_AverageEpLen : 41.4\n",
            "Train_AverageReturn : 66.1234130859375\n",
            "Train_StdReturn : 13.003571510314941\n",
            "Train_MaxReturn : 117.82129669189453\n",
            "Train_MinReturn : 43.469139099121094\n",
            "Train_AverageEpLen : 38.43396226415094\n",
            "Train_EnvstepsSoFar : 328009\n",
            "TimeSinceStart : 338.0906970500946\n",
            "Training Loss : -87.55819702148438\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 162 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 74.96194458007812\n",
            "Eval_StdReturn : 24.912424087524414\n",
            "Eval_MaxReturn : 139.82302856445312\n",
            "Eval_MinReturn : 53.20842742919922\n",
            "Eval_AverageEpLen : 42.6\n",
            "Train_AverageReturn : 70.85028076171875\n",
            "Train_StdReturn : 17.064388275146484\n",
            "Train_MaxReturn : 117.84795379638672\n",
            "Train_MinReturn : 43.25396728515625\n",
            "Train_AverageEpLen : 41.04081632653061\n",
            "Train_EnvstepsSoFar : 330020\n",
            "TimeSinceStart : 340.133403301239\n",
            "Training Loss : -62.594093322753906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 163 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 70.75227355957031\n",
            "Eval_StdReturn : 15.195732116699219\n",
            "Eval_MaxReturn : 96.4865493774414\n",
            "Eval_MinReturn : 50.01218795776367\n",
            "Eval_AverageEpLen : 41.0\n",
            "Train_AverageReturn : 68.0888671875\n",
            "Train_StdReturn : 15.836073875427246\n",
            "Train_MaxReturn : 116.90388488769531\n",
            "Train_MinReturn : 41.004425048828125\n",
            "Train_AverageEpLen : 39.31372549019608\n",
            "Train_EnvstepsSoFar : 332025\n",
            "TimeSinceStart : 342.14713430404663\n",
            "Training Loss : -125.94325256347656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 164 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 65.62602996826172\n",
            "Eval_StdReturn : 15.030732154846191\n",
            "Eval_MaxReturn : 104.85505676269531\n",
            "Eval_MinReturn : 51.9637336730957\n",
            "Eval_AverageEpLen : 37.90909090909091\n",
            "Train_AverageReturn : 68.57276153564453\n",
            "Train_StdReturn : 18.980632781982422\n",
            "Train_MaxReturn : 138.5640106201172\n",
            "Train_MinReturn : 45.21861267089844\n",
            "Train_AverageEpLen : 39.568627450980394\n",
            "Train_EnvstepsSoFar : 334043\n",
            "TimeSinceStart : 344.1901104450226\n",
            "Training Loss : -44.92691421508789\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 165 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 70.53668212890625\n",
            "Eval_StdReturn : 21.28215789794922\n",
            "Eval_MaxReturn : 109.45287322998047\n",
            "Eval_MinReturn : 45.91421890258789\n",
            "Eval_AverageEpLen : 40.9\n",
            "Train_AverageReturn : 67.91309356689453\n",
            "Train_StdReturn : 17.777938842773438\n",
            "Train_MaxReturn : 119.80369567871094\n",
            "Train_MinReturn : 43.262245178222656\n",
            "Train_AverageEpLen : 39.450980392156865\n",
            "Train_EnvstepsSoFar : 336055\n",
            "TimeSinceStart : 346.22848534584045\n",
            "Training Loss : -82.26618957519531\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 166 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 70.07620239257812\n",
            "Eval_StdReturn : 20.778987884521484\n",
            "Eval_MaxReturn : 117.97819519042969\n",
            "Eval_MinReturn : 46.74882507324219\n",
            "Eval_AverageEpLen : 40.63636363636363\n",
            "Train_AverageReturn : 65.77340698242188\n",
            "Train_StdReturn : 15.532197952270508\n",
            "Train_MaxReturn : 124.02692413330078\n",
            "Train_MinReturn : 40.72600173950195\n",
            "Train_AverageEpLen : 38.132075471698116\n",
            "Train_EnvstepsSoFar : 338076\n",
            "TimeSinceStart : 348.27736353874207\n",
            "Training Loss : -32.38509750366211\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 167 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 62.801658630371094\n",
            "Eval_StdReturn : 16.21139144897461\n",
            "Eval_MaxReturn : 96.811767578125\n",
            "Eval_MinReturn : 43.315101623535156\n",
            "Eval_AverageEpLen : 36.54545454545455\n",
            "Train_AverageReturn : 63.70679473876953\n",
            "Train_StdReturn : 12.745168685913086\n",
            "Train_MaxReturn : 106.06097412109375\n",
            "Train_MinReturn : 46.17719650268555\n",
            "Train_AverageEpLen : 36.89090909090909\n",
            "Train_EnvstepsSoFar : 340105\n",
            "TimeSinceStart : 350.33749198913574\n",
            "Training Loss : 29.948467254638672\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 168 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.641639709472656\n",
            "Eval_StdReturn : 11.882487297058105\n",
            "Eval_MaxReturn : 80.8844223022461\n",
            "Eval_MinReturn : 43.19765853881836\n",
            "Eval_AverageEpLen : 33.30769230769231\n",
            "Train_AverageReturn : 60.692813873291016\n",
            "Train_StdReturn : 11.863497734069824\n",
            "Train_MaxReturn : 106.84280395507812\n",
            "Train_MinReturn : 41.695579528808594\n",
            "Train_AverageEpLen : 35.13793103448276\n",
            "Train_EnvstepsSoFar : 342143\n",
            "TimeSinceStart : 352.38520669937134\n",
            "Training Loss : -82.93183898925781\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 169 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.09859848022461\n",
            "Eval_StdReturn : 14.68986701965332\n",
            "Eval_MaxReturn : 94.56116485595703\n",
            "Eval_MinReturn : 48.53538513183594\n",
            "Eval_AverageEpLen : 35.0\n",
            "Train_AverageReturn : 61.00299072265625\n",
            "Train_StdReturn : 13.338943481445312\n",
            "Train_MaxReturn : 116.01156616210938\n",
            "Train_MinReturn : 42.97117233276367\n",
            "Train_AverageEpLen : 35.35087719298246\n",
            "Train_EnvstepsSoFar : 344158\n",
            "TimeSinceStart : 354.40320014953613\n",
            "Training Loss : -142.83056640625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 170 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.57454299926758\n",
            "Eval_StdReturn : 7.988875389099121\n",
            "Eval_MaxReturn : 71.7618179321289\n",
            "Eval_MinReturn : 45.96010971069336\n",
            "Eval_AverageEpLen : 33.333333333333336\n",
            "Train_AverageReturn : 61.958396911621094\n",
            "Train_StdReturn : 13.025492668151855\n",
            "Train_MaxReturn : 98.5484848022461\n",
            "Train_MinReturn : 45.91969299316406\n",
            "Train_AverageEpLen : 35.857142857142854\n",
            "Train_EnvstepsSoFar : 346166\n",
            "TimeSinceStart : 356.41692757606506\n",
            "Training Loss : -39.7568359375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 171 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.052635192871094\n",
            "Eval_StdReturn : 9.241554260253906\n",
            "Eval_MaxReturn : 81.88296508789062\n",
            "Eval_MinReturn : 41.241943359375\n",
            "Eval_AverageEpLen : 33.0\n",
            "Train_AverageReturn : 58.73947525024414\n",
            "Train_StdReturn : 13.431113243103027\n",
            "Train_MaxReturn : 127.72010040283203\n",
            "Train_MinReturn : 44.25481033325195\n",
            "Train_AverageEpLen : 34.08474576271186\n",
            "Train_EnvstepsSoFar : 348177\n",
            "TimeSinceStart : 358.48134899139404\n",
            "Training Loss : -46.3646240234375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 172 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 61.12083053588867\n",
            "Eval_StdReturn : 11.028459548950195\n",
            "Eval_MaxReturn : 78.16007995605469\n",
            "Eval_MinReturn : 44.026615142822266\n",
            "Eval_AverageEpLen : 35.416666666666664\n",
            "Train_AverageReturn : 58.06698989868164\n",
            "Train_StdReturn : 10.432758331298828\n",
            "Train_MaxReturn : 93.00006103515625\n",
            "Train_MinReturn : 42.99664306640625\n",
            "Train_AverageEpLen : 33.56666666666667\n",
            "Train_EnvstepsSoFar : 350191\n",
            "TimeSinceStart : 360.52946853637695\n",
            "Training Loss : -43.67142105102539\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 173 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 69.33198547363281\n",
            "Eval_StdReturn : 9.913552284240723\n",
            "Eval_MaxReturn : 84.3782730102539\n",
            "Eval_MinReturn : 51.733543395996094\n",
            "Eval_AverageEpLen : 40.1\n",
            "Train_AverageReturn : 60.35230255126953\n",
            "Train_StdReturn : 13.262763023376465\n",
            "Train_MaxReturn : 110.0121841430664\n",
            "Train_MinReturn : 43.110843658447266\n",
            "Train_AverageEpLen : 34.827586206896555\n",
            "Train_EnvstepsSoFar : 352211\n",
            "TimeSinceStart : 362.5232651233673\n",
            "Training Loss : 59.07569122314453\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 174 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.45943832397461\n",
            "Eval_StdReturn : 11.566316604614258\n",
            "Eval_MaxReturn : 86.3938980102539\n",
            "Eval_MinReturn : 47.432247161865234\n",
            "Eval_AverageEpLen : 34.416666666666664\n",
            "Train_AverageReturn : 57.07692337036133\n",
            "Train_StdReturn : 12.96216869354248\n",
            "Train_MaxReturn : 112.13288116455078\n",
            "Train_MinReturn : 40.463356018066406\n",
            "Train_AverageEpLen : 33.01639344262295\n",
            "Train_EnvstepsSoFar : 354225\n",
            "TimeSinceStart : 364.5283408164978\n",
            "Training Loss : 71.83546447753906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 175 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.07829666137695\n",
            "Eval_StdReturn : 13.774015426635742\n",
            "Eval_MaxReturn : 98.3496322631836\n",
            "Eval_MinReturn : 47.966670989990234\n",
            "Eval_AverageEpLen : 34.833333333333336\n",
            "Train_AverageReturn : 58.77281188964844\n",
            "Train_StdReturn : 15.766274452209473\n",
            "Train_MaxReturn : 137.3668975830078\n",
            "Train_MinReturn : 41.37738037109375\n",
            "Train_AverageEpLen : 33.96666666666667\n",
            "Train_EnvstepsSoFar : 356263\n",
            "TimeSinceStart : 366.5966637134552\n",
            "Training Loss : -149.46218872070312\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 176 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 58.397552490234375\n",
            "Eval_StdReturn : 9.876008987426758\n",
            "Eval_MaxReturn : 83.15335083007812\n",
            "Eval_MinReturn : 48.630699157714844\n",
            "Eval_AverageEpLen : 33.666666666666664\n",
            "Train_AverageReturn : 61.76301574707031\n",
            "Train_StdReturn : 14.853264808654785\n",
            "Train_MaxReturn : 112.66120910644531\n",
            "Train_MinReturn : 43.19879150390625\n",
            "Train_AverageEpLen : 35.59649122807018\n",
            "Train_EnvstepsSoFar : 358292\n",
            "TimeSinceStart : 368.6025800704956\n",
            "Training Loss : 30.394577026367188\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 177 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 58.01919174194336\n",
            "Eval_StdReturn : 10.930702209472656\n",
            "Eval_MaxReturn : 88.63985443115234\n",
            "Eval_MinReturn : 48.40027618408203\n",
            "Eval_AverageEpLen : 33.666666666666664\n",
            "Train_AverageReturn : 59.83018493652344\n",
            "Train_StdReturn : 11.968518257141113\n",
            "Train_MaxReturn : 93.1596450805664\n",
            "Train_MinReturn : 42.47825622558594\n",
            "Train_AverageEpLen : 34.48275862068966\n",
            "Train_EnvstepsSoFar : 360292\n",
            "TimeSinceStart : 370.5725586414337\n",
            "Training Loss : -52.899166107177734\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 178 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 56.55653762817383\n",
            "Eval_StdReturn : 8.2523832321167\n",
            "Eval_MaxReturn : 73.94672393798828\n",
            "Eval_MinReturn : 46.50353240966797\n",
            "Eval_AverageEpLen : 32.69230769230769\n",
            "Train_AverageReturn : 59.46784973144531\n",
            "Train_StdReturn : 13.045310974121094\n",
            "Train_MaxReturn : 110.81182861328125\n",
            "Train_MinReturn : 42.06066131591797\n",
            "Train_AverageEpLen : 34.3728813559322\n",
            "Train_EnvstepsSoFar : 362320\n",
            "TimeSinceStart : 372.59798526763916\n",
            "Training Loss : 27.383769989013672\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 179 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.660987854003906\n",
            "Eval_StdReturn : 8.830056190490723\n",
            "Eval_MaxReturn : 76.91526794433594\n",
            "Eval_MinReturn : 44.244285583496094\n",
            "Eval_AverageEpLen : 33.30769230769231\n",
            "Train_AverageReturn : 58.62257766723633\n",
            "Train_StdReturn : 10.576744079589844\n",
            "Train_MaxReturn : 99.78898620605469\n",
            "Train_MinReturn : 42.76875686645508\n",
            "Train_AverageEpLen : 33.86666666666667\n",
            "Train_EnvstepsSoFar : 364352\n",
            "TimeSinceStart : 374.6139442920685\n",
            "Training Loss : 23.319442749023438\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 180 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 61.571502685546875\n",
            "Eval_StdReturn : 12.524148941040039\n",
            "Eval_MaxReturn : 89.19700622558594\n",
            "Eval_MinReturn : 45.554805755615234\n",
            "Eval_AverageEpLen : 35.416666666666664\n",
            "Train_AverageReturn : 62.020755767822266\n",
            "Train_StdReturn : 14.96965503692627\n",
            "Train_MaxReturn : 111.72460174560547\n",
            "Train_MinReturn : 42.82867431640625\n",
            "Train_AverageEpLen : 35.82142857142857\n",
            "Train_EnvstepsSoFar : 366358\n",
            "TimeSinceStart : 376.7481083869934\n",
            "Training Loss : -33.92950439453125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 181 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 63.941341400146484\n",
            "Eval_StdReturn : 15.334651947021484\n",
            "Eval_MaxReturn : 104.75190734863281\n",
            "Eval_MinReturn : 48.882659912109375\n",
            "Eval_AverageEpLen : 37.0\n",
            "Train_AverageReturn : 60.89141845703125\n",
            "Train_StdReturn : 12.673877716064453\n",
            "Train_MaxReturn : 112.07164001464844\n",
            "Train_MinReturn : 44.97001647949219\n",
            "Train_AverageEpLen : 35.175438596491226\n",
            "Train_EnvstepsSoFar : 368363\n",
            "TimeSinceStart : 378.73081254959106\n",
            "Training Loss : -63.43516540527344\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 182 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 68.23857879638672\n",
            "Eval_StdReturn : 15.82265567779541\n",
            "Eval_MaxReturn : 93.12846374511719\n",
            "Eval_MinReturn : 44.462745666503906\n",
            "Eval_AverageEpLen : 39.45454545454545\n",
            "Train_AverageReturn : 60.581756591796875\n",
            "Train_StdReturn : 12.421236038208008\n",
            "Train_MaxReturn : 107.27041625976562\n",
            "Train_MinReturn : 44.647987365722656\n",
            "Train_AverageEpLen : 34.758620689655174\n",
            "Train_EnvstepsSoFar : 370379\n",
            "TimeSinceStart : 380.78327989578247\n",
            "Training Loss : -22.850685119628906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 183 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 68.95675659179688\n",
            "Eval_StdReturn : 9.94958782196045\n",
            "Eval_MaxReturn : 85.50318908691406\n",
            "Eval_MinReturn : 51.853275299072266\n",
            "Eval_AverageEpLen : 39.63636363636363\n",
            "Train_AverageReturn : 62.279239654541016\n",
            "Train_StdReturn : 15.499382019042969\n",
            "Train_MaxReturn : 117.0488052368164\n",
            "Train_MinReturn : 41.67713165283203\n",
            "Train_AverageEpLen : 35.767857142857146\n",
            "Train_EnvstepsSoFar : 372382\n",
            "TimeSinceStart : 382.82679867744446\n",
            "Training Loss : 46.17432403564453\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 184 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 63.131858825683594\n",
            "Eval_StdReturn : 14.100791931152344\n",
            "Eval_MaxReturn : 91.46660614013672\n",
            "Eval_MinReturn : 50.187103271484375\n",
            "Eval_AverageEpLen : 36.36363636363637\n",
            "Train_AverageReturn : 64.74654388427734\n",
            "Train_StdReturn : 15.120292663574219\n",
            "Train_MaxReturn : 97.3128890991211\n",
            "Train_MinReturn : 41.892677307128906\n",
            "Train_AverageEpLen : 37.388888888888886\n",
            "Train_EnvstepsSoFar : 374401\n",
            "TimeSinceStart : 384.8408203125\n",
            "Training Loss : 9.442626953125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 185 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.31993865966797\n",
            "Eval_StdReturn : 13.597716331481934\n",
            "Eval_MaxReturn : 97.13262939453125\n",
            "Eval_MinReturn : 48.98490905761719\n",
            "Eval_AverageEpLen : 36.81818181818182\n",
            "Train_AverageReturn : 74.7856674194336\n",
            "Train_StdReturn : 22.28729820251465\n",
            "Train_MaxReturn : 155.93670654296875\n",
            "Train_MinReturn : 41.07737731933594\n",
            "Train_AverageEpLen : 43.276595744680854\n",
            "Train_EnvstepsSoFar : 376435\n",
            "TimeSinceStart : 386.8844985961914\n",
            "Training Loss : -9.599014282226562\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 186 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 84.57255554199219\n",
            "Eval_StdReturn : 27.396411895751953\n",
            "Eval_MaxReturn : 133.10353088378906\n",
            "Eval_MinReturn : 57.36205291748047\n",
            "Eval_AverageEpLen : 48.888888888888886\n",
            "Train_AverageReturn : 78.79234313964844\n",
            "Train_StdReturn : 25.564878463745117\n",
            "Train_MaxReturn : 154.89627075195312\n",
            "Train_MinReturn : 48.67448425292969\n",
            "Train_AverageEpLen : 45.31111111111111\n",
            "Train_EnvstepsSoFar : 378474\n",
            "TimeSinceStart : 388.97416400909424\n",
            "Training Loss : 0.3857288360595703\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 187 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 74.96317291259766\n",
            "Eval_StdReturn : 21.51700782775879\n",
            "Eval_MaxReturn : 119.03446960449219\n",
            "Eval_MinReturn : 52.58723449707031\n",
            "Eval_AverageEpLen : 43.4\n",
            "Train_AverageReturn : 74.13288879394531\n",
            "Train_StdReturn : 21.952964782714844\n",
            "Train_MaxReturn : 145.46249389648438\n",
            "Train_MinReturn : 43.49252700805664\n",
            "Train_AverageEpLen : 42.744680851063826\n",
            "Train_EnvstepsSoFar : 380483\n",
            "TimeSinceStart : 391.01955485343933\n",
            "Training Loss : -55.99028778076172\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 188 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 72.61099243164062\n",
            "Eval_StdReturn : 34.04353332519531\n",
            "Eval_MaxReturn : 155.86328125\n",
            "Eval_MinReturn : 43.08322525024414\n",
            "Eval_AverageEpLen : 41.9\n",
            "Train_AverageReturn : 78.68807983398438\n",
            "Train_StdReturn : 26.797489166259766\n",
            "Train_MaxReturn : 143.6756591796875\n",
            "Train_MinReturn : 44.93936538696289\n",
            "Train_AverageEpLen : 45.46666666666667\n",
            "Train_EnvstepsSoFar : 382529\n",
            "TimeSinceStart : 393.1599974632263\n",
            "Training Loss : 24.179582595825195\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 189 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 97.27134704589844\n",
            "Eval_StdReturn : 28.281442642211914\n",
            "Eval_MaxReturn : 150.12973022460938\n",
            "Eval_MinReturn : 58.056060791015625\n",
            "Eval_AverageEpLen : 56.75\n",
            "Train_AverageReturn : 80.63355255126953\n",
            "Train_StdReturn : 29.38572120666504\n",
            "Train_MaxReturn : 160.52268981933594\n",
            "Train_MinReturn : 47.25943374633789\n",
            "Train_AverageEpLen : 46.38636363636363\n",
            "Train_EnvstepsSoFar : 384570\n",
            "TimeSinceStart : 395.3029637336731\n",
            "Training Loss : 57.67641067504883\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 190 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 127.0821304321289\n",
            "Eval_StdReturn : 27.61949920654297\n",
            "Eval_MaxReturn : 164.39791870117188\n",
            "Eval_MinReturn : 85.89833068847656\n",
            "Eval_AverageEpLen : 74.33333333333333\n",
            "Train_AverageReturn : 83.96208190917969\n",
            "Train_StdReturn : 30.762493133544922\n",
            "Train_MaxReturn : 163.7188720703125\n",
            "Train_MinReturn : 47.46380615234375\n",
            "Train_AverageEpLen : 48.5\n",
            "Train_EnvstepsSoFar : 386607\n",
            "TimeSinceStart : 397.3900680541992\n",
            "Training Loss : -36.32151794433594\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 191 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 101.32003021240234\n",
            "Eval_StdReturn : 28.24209976196289\n",
            "Eval_MaxReturn : 138.4978485107422\n",
            "Eval_MinReturn : 65.79753112792969\n",
            "Eval_AverageEpLen : 60.285714285714285\n",
            "Train_AverageReturn : 99.78279876708984\n",
            "Train_StdReturn : 35.27857208251953\n",
            "Train_MaxReturn : 167.56895446777344\n",
            "Train_MinReturn : 45.748138427734375\n",
            "Train_AverageEpLen : 57.82857142857143\n",
            "Train_EnvstepsSoFar : 388631\n",
            "TimeSinceStart : 399.4796929359436\n",
            "Training Loss : 94.36590576171875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 192 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 116.08885192871094\n",
            "Eval_StdReturn : 35.080997467041016\n",
            "Eval_MaxReturn : 154.0689697265625\n",
            "Eval_MinReturn : 53.54745864868164\n",
            "Eval_AverageEpLen : 67.85714285714286\n",
            "Train_AverageReturn : 107.54619598388672\n",
            "Train_StdReturn : 34.569122314453125\n",
            "Train_MaxReturn : 155.95655822753906\n",
            "Train_MinReturn : 47.06475830078125\n",
            "Train_AverageEpLen : 62.6875\n",
            "Train_EnvstepsSoFar : 390637\n",
            "TimeSinceStart : 401.599404335022\n",
            "Training Loss : 41.95609664916992\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 193 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 98.43280792236328\n",
            "Eval_StdReturn : 24.27298355102539\n",
            "Eval_MaxReturn : 140.84759521484375\n",
            "Eval_MinReturn : 64.41433715820312\n",
            "Eval_AverageEpLen : 62.714285714285715\n",
            "Train_AverageReturn : 122.83113861083984\n",
            "Train_StdReturn : 29.999069213867188\n",
            "Train_MaxReturn : 180.05416870117188\n",
            "Train_MinReturn : 53.04473876953125\n",
            "Train_AverageEpLen : 73.75\n",
            "Train_EnvstepsSoFar : 392702\n",
            "TimeSinceStart : 403.7388253211975\n",
            "Training Loss : 100.86959075927734\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 194 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 105.20458221435547\n",
            "Eval_StdReturn : 30.612140655517578\n",
            "Eval_MaxReturn : 140.07278442382812\n",
            "Eval_MinReturn : 59.49620056152344\n",
            "Eval_AverageEpLen : 65.85714285714286\n",
            "Train_AverageReturn : 117.35752868652344\n",
            "Train_StdReturn : 27.767534255981445\n",
            "Train_MaxReturn : 156.7285614013672\n",
            "Train_MinReturn : 38.889366149902344\n",
            "Train_AverageEpLen : 72.60714285714286\n",
            "Train_EnvstepsSoFar : 394735\n",
            "TimeSinceStart : 405.91379141807556\n",
            "Training Loss : -71.87161254882812\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 195 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.1937255859375\n",
            "Eval_StdReturn : 11.847965240478516\n",
            "Eval_MaxReturn : 118.17961883544922\n",
            "Eval_MinReturn : 86.9577407836914\n",
            "Eval_AverageEpLen : 68.66666666666667\n",
            "Train_AverageReturn : 117.43017578125\n",
            "Train_StdReturn : 24.049894332885742\n",
            "Train_MaxReturn : 170.71621704101562\n",
            "Train_MinReturn : 54.819541931152344\n",
            "Train_AverageEpLen : 74.28571428571429\n",
            "Train_EnvstepsSoFar : 396815\n",
            "TimeSinceStart : 408.0566940307617\n",
            "Training Loss : -19.264022827148438\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 196 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 82.50755310058594\n",
            "Eval_StdReturn : 23.135480880737305\n",
            "Eval_MaxReturn : 109.96184539794922\n",
            "Eval_MinReturn : 44.11638259887695\n",
            "Eval_AverageEpLen : 57.125\n",
            "Train_AverageReturn : 107.12094116210938\n",
            "Train_StdReturn : 24.4507999420166\n",
            "Train_MaxReturn : 163.23248291015625\n",
            "Train_MinReturn : 38.61591720581055\n",
            "Train_AverageEpLen : 71.3103448275862\n",
            "Train_EnvstepsSoFar : 398883\n",
            "TimeSinceStart : 410.1889293193817\n",
            "Training Loss : 54.883766174316406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 197 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 89.59186553955078\n",
            "Eval_StdReturn : 20.066238403320312\n",
            "Eval_MaxReturn : 122.47167205810547\n",
            "Eval_MinReturn : 56.65848159790039\n",
            "Eval_AverageEpLen : 63.0\n",
            "Train_AverageReturn : 95.55763244628906\n",
            "Train_StdReturn : 16.92208480834961\n",
            "Train_MaxReturn : 131.5335693359375\n",
            "Train_MinReturn : 54.76924133300781\n",
            "Train_AverageEpLen : 66.2258064516129\n",
            "Train_EnvstepsSoFar : 400936\n",
            "TimeSinceStart : 412.2902843952179\n",
            "Training Loss : -30.24016571044922\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 198 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 74.6248550415039\n",
            "Eval_StdReturn : 20.325321197509766\n",
            "Eval_MaxReturn : 102.91291809082031\n",
            "Eval_MinReturn : 38.946876525878906\n",
            "Eval_AverageEpLen : 54.375\n",
            "Train_AverageReturn : 83.64595031738281\n",
            "Train_StdReturn : 17.96614646911621\n",
            "Train_MaxReturn : 114.70510864257812\n",
            "Train_MinReturn : 36.31560516357422\n",
            "Train_AverageEpLen : 59.44117647058823\n",
            "Train_EnvstepsSoFar : 402957\n",
            "TimeSinceStart : 414.3501946926117\n",
            "Training Loss : -126.65995788574219\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 199 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.9257583618164\n",
            "Eval_StdReturn : 16.5847110748291\n",
            "Eval_MaxReturn : 95.13050842285156\n",
            "Eval_MinReturn : 34.91029357910156\n",
            "Eval_AverageEpLen : 46.2\n",
            "Train_AverageReturn : 68.33174896240234\n",
            "Train_StdReturn : 18.305988311767578\n",
            "Train_MaxReturn : 99.36309814453125\n",
            "Train_MinReturn : 26.06963348388672\n",
            "Train_AverageEpLen : 48.90243902439025\n",
            "Train_EnvstepsSoFar : 404962\n",
            "TimeSinceStart : 416.41070103645325\n",
            "Training Loss : -25.50932502746582\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 200 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 56.53885269165039\n",
            "Eval_StdReturn : 14.457879066467285\n",
            "Eval_MaxReturn : 94.8963623046875\n",
            "Eval_MinReturn : 32.71142578125\n",
            "Eval_AverageEpLen : 40.0\n",
            "Train_AverageReturn : 64.46375274658203\n",
            "Train_StdReturn : 15.59253978729248\n",
            "Train_MaxReturn : 93.22196960449219\n",
            "Train_MinReturn : 27.32170867919922\n",
            "Train_AverageEpLen : 46.47727272727273\n",
            "Train_EnvstepsSoFar : 407007\n",
            "TimeSinceStart : 418.49226331710815\n",
            "Training Loss : -29.552879333496094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 201 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 48.41567611694336\n",
            "Eval_StdReturn : 10.704874038696289\n",
            "Eval_MaxReturn : 74.07618713378906\n",
            "Eval_MinReturn : 31.90275764465332\n",
            "Eval_AverageEpLen : 35.0\n",
            "Train_AverageReturn : 58.665252685546875\n",
            "Train_StdReturn : 15.41666316986084\n",
            "Train_MaxReturn : 88.66217803955078\n",
            "Train_MinReturn : 26.141407012939453\n",
            "Train_AverageEpLen : 42.270833333333336\n",
            "Train_EnvstepsSoFar : 409036\n",
            "TimeSinceStart : 420.65096139907837\n",
            "Training Loss : 103.92669677734375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 202 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.169471740722656\n",
            "Eval_StdReturn : 16.991785049438477\n",
            "Eval_MaxReturn : 88.62948608398438\n",
            "Eval_MinReturn : 28.24181365966797\n",
            "Eval_AverageEpLen : 41.4\n",
            "Train_AverageReturn : 49.96041488647461\n",
            "Train_StdReturn : 11.113990783691406\n",
            "Train_MaxReturn : 78.70801544189453\n",
            "Train_MinReturn : 29.29867935180664\n",
            "Train_AverageEpLen : 36.07142857142857\n",
            "Train_EnvstepsSoFar : 411056\n",
            "TimeSinceStart : 422.6576840877533\n",
            "Training Loss : 28.572975158691406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 203 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 48.780338287353516\n",
            "Eval_StdReturn : 8.446263313293457\n",
            "Eval_MaxReturn : 60.80389404296875\n",
            "Eval_MinReturn : 31.485090255737305\n",
            "Eval_AverageEpLen : 35.166666666666664\n",
            "Train_AverageReturn : 47.28994369506836\n",
            "Train_StdReturn : 8.09288215637207\n",
            "Train_MaxReturn : 62.44596862792969\n",
            "Train_MinReturn : 27.174041748046875\n",
            "Train_AverageEpLen : 34.25423728813559\n",
            "Train_EnvstepsSoFar : 413077\n",
            "TimeSinceStart : 424.65376925468445\n",
            "Training Loss : 13.243106842041016\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 204 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 39.20517349243164\n",
            "Eval_StdReturn : 11.294487953186035\n",
            "Eval_MaxReturn : 60.634666442871094\n",
            "Eval_MinReturn : 12.322771072387695\n",
            "Eval_AverageEpLen : 29.571428571428573\n",
            "Train_AverageReturn : 41.24086380004883\n",
            "Train_StdReturn : 10.261052131652832\n",
            "Train_MaxReturn : 72.90235900878906\n",
            "Train_MinReturn : 21.460542678833008\n",
            "Train_AverageEpLen : 30.666666666666668\n",
            "Train_EnvstepsSoFar : 415101\n",
            "TimeSinceStart : 426.7162880897522\n",
            "Training Loss : -5.362037658691406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 205 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.368595123291016\n",
            "Eval_StdReturn : 7.7833075523376465\n",
            "Eval_MaxReturn : 47.424285888671875\n",
            "Eval_MinReturn : 18.05124282836914\n",
            "Eval_AverageEpLen : 25.875\n",
            "Train_AverageReturn : 40.876800537109375\n",
            "Train_StdReturn : 10.483866691589355\n",
            "Train_MaxReturn : 72.7944107055664\n",
            "Train_MinReturn : 14.8247652053833\n",
            "Train_AverageEpLen : 30.484848484848484\n",
            "Train_EnvstepsSoFar : 417113\n",
            "TimeSinceStart : 428.71689534187317\n",
            "Training Loss : 90.24026489257812\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 206 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 37.9957160949707\n",
            "Eval_StdReturn : 10.340254783630371\n",
            "Eval_MaxReturn : 52.49258804321289\n",
            "Eval_MinReturn : 16.22828483581543\n",
            "Eval_AverageEpLen : 28.642857142857142\n",
            "Train_AverageReturn : 37.546714782714844\n",
            "Train_StdReturn : 11.433605194091797\n",
            "Train_MaxReturn : 64.25200653076172\n",
            "Train_MinReturn : 8.251669883728027\n",
            "Train_AverageEpLen : 28.43661971830986\n",
            "Train_EnvstepsSoFar : 419132\n",
            "TimeSinceStart : 430.71655678749084\n",
            "Training Loss : -21.94635772705078\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 207 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 38.01910400390625\n",
            "Eval_StdReturn : 9.860363006591797\n",
            "Eval_MaxReturn : 52.05731201171875\n",
            "Eval_MinReturn : 21.7934627532959\n",
            "Eval_AverageEpLen : 28.571428571428573\n",
            "Train_AverageReturn : 34.8396110534668\n",
            "Train_StdReturn : 10.514504432678223\n",
            "Train_MaxReturn : 58.88749313354492\n",
            "Train_MinReturn : 14.119041442871094\n",
            "Train_AverageEpLen : 26.786666666666665\n",
            "Train_EnvstepsSoFar : 421141\n",
            "TimeSinceStart : 432.6908931732178\n",
            "Training Loss : 51.448333740234375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 208 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 32.07978057861328\n",
            "Eval_StdReturn : 10.715669631958008\n",
            "Eval_MaxReturn : 52.74701690673828\n",
            "Eval_MinReturn : 14.991250038146973\n",
            "Eval_AverageEpLen : 25.25\n",
            "Train_AverageReturn : 32.284393310546875\n",
            "Train_StdReturn : 9.227559089660645\n",
            "Train_MaxReturn : 56.17264938354492\n",
            "Train_MinReturn : 10.636760711669922\n",
            "Train_AverageEpLen : 25.3125\n",
            "Train_EnvstepsSoFar : 423166\n",
            "TimeSinceStart : 434.6726861000061\n",
            "Training Loss : 14.553916931152344\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 209 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.25120544433594\n",
            "Eval_StdReturn : 10.334217071533203\n",
            "Eval_MaxReturn : 47.64353942871094\n",
            "Eval_MinReturn : 14.416036605834961\n",
            "Eval_AverageEpLen : 25.875\n",
            "Train_AverageReturn : 33.74101257324219\n",
            "Train_StdReturn : 9.993435859680176\n",
            "Train_MaxReturn : 58.71174621582031\n",
            "Train_MinReturn : 10.892740249633789\n",
            "Train_AverageEpLen : 26.142857142857142\n",
            "Train_EnvstepsSoFar : 425179\n",
            "TimeSinceStart : 436.65894889831543\n",
            "Training Loss : 19.509674072265625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 210 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 29.49755096435547\n",
            "Eval_StdReturn : 11.444561958312988\n",
            "Eval_MaxReturn : 50.06182861328125\n",
            "Eval_MinReturn : 8.967700004577637\n",
            "Eval_AverageEpLen : 23.705882352941178\n",
            "Train_AverageReturn : 32.755393981933594\n",
            "Train_StdReturn : 10.41193962097168\n",
            "Train_MaxReturn : 58.688323974609375\n",
            "Train_MinReturn : 7.779051303863525\n",
            "Train_AverageEpLen : 25.544303797468356\n",
            "Train_EnvstepsSoFar : 427197\n",
            "TimeSinceStart : 438.6615934371948\n",
            "Training Loss : -15.0650634765625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 211 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 36.12356948852539\n",
            "Eval_StdReturn : 9.970614433288574\n",
            "Eval_MaxReturn : 55.47032928466797\n",
            "Eval_MinReturn : 16.076271057128906\n",
            "Eval_AverageEpLen : 27.466666666666665\n",
            "Train_AverageReturn : 33.40628433227539\n",
            "Train_StdReturn : 11.718465805053711\n",
            "Train_MaxReturn : 56.05263900756836\n",
            "Train_MinReturn : 8.992436408996582\n",
            "Train_AverageEpLen : 26.0\n",
            "Train_EnvstepsSoFar : 429199\n",
            "TimeSinceStart : 440.72036957740784\n",
            "Training Loss : 18.32019805908203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 212 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 41.96809768676758\n",
            "Eval_StdReturn : 6.509718894958496\n",
            "Eval_MaxReturn : 52.14829635620117\n",
            "Eval_MinReturn : 30.515697479248047\n",
            "Eval_AverageEpLen : 30.76923076923077\n",
            "Train_AverageReturn : 37.64895248413086\n",
            "Train_StdReturn : 11.374512672424316\n",
            "Train_MaxReturn : 63.673828125\n",
            "Train_MinReturn : 10.80477237701416\n",
            "Train_AverageEpLen : 28.408450704225352\n",
            "Train_EnvstepsSoFar : 431216\n",
            "TimeSinceStart : 442.73252296447754\n",
            "Training Loss : 88.43246459960938\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 213 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 38.262813568115234\n",
            "Eval_StdReturn : 10.947699546813965\n",
            "Eval_MaxReturn : 59.69738006591797\n",
            "Eval_MinReturn : 20.4947566986084\n",
            "Eval_AverageEpLen : 28.714285714285715\n",
            "Train_AverageReturn : 36.98815155029297\n",
            "Train_StdReturn : 9.83562183380127\n",
            "Train_MaxReturn : 64.01232147216797\n",
            "Train_MinReturn : 15.934901237487793\n",
            "Train_AverageEpLen : 27.944444444444443\n",
            "Train_EnvstepsSoFar : 433228\n",
            "TimeSinceStart : 444.72365856170654\n",
            "Training Loss : 54.36041259765625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 214 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 43.2498779296875\n",
            "Eval_StdReturn : 10.13595199584961\n",
            "Eval_MaxReturn : 59.010684967041016\n",
            "Eval_MinReturn : 14.645648956298828\n",
            "Eval_AverageEpLen : 31.384615384615383\n",
            "Train_AverageReturn : 39.055728912353516\n",
            "Train_StdReturn : 8.564240455627441\n",
            "Train_MaxReturn : 57.572566986083984\n",
            "Train_MinReturn : 20.561063766479492\n",
            "Train_AverageEpLen : 29.043478260869566\n",
            "Train_EnvstepsSoFar : 435232\n",
            "TimeSinceStart : 446.73948192596436\n",
            "Training Loss : 92.25941467285156\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 215 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 47.65037155151367\n",
            "Eval_StdReturn : 11.362354278564453\n",
            "Eval_MaxReturn : 77.21011352539062\n",
            "Eval_MinReturn : 36.47480392456055\n",
            "Eval_AverageEpLen : 34.0\n",
            "Train_AverageReturn : 43.27513885498047\n",
            "Train_StdReturn : 9.955426216125488\n",
            "Train_MaxReturn : 65.99761962890625\n",
            "Train_MinReturn : 17.798070907592773\n",
            "Train_AverageEpLen : 31.578125\n",
            "Train_EnvstepsSoFar : 437253\n",
            "TimeSinceStart : 448.75343108177185\n",
            "Training Loss : 128.25454711914062\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 216 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 52.97434997558594\n",
            "Eval_StdReturn : 8.795607566833496\n",
            "Eval_MaxReturn : 69.35240173339844\n",
            "Eval_MinReturn : 37.537025451660156\n",
            "Eval_AverageEpLen : 37.09090909090909\n",
            "Train_AverageReturn : 47.23910140991211\n",
            "Train_StdReturn : 8.974325180053711\n",
            "Train_MaxReturn : 71.32910919189453\n",
            "Train_MinReturn : 21.166736602783203\n",
            "Train_AverageEpLen : 33.94915254237288\n",
            "Train_EnvstepsSoFar : 439256\n",
            "TimeSinceStart : 450.7539577484131\n",
            "Training Loss : 44.409873962402344\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 217 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 52.34556579589844\n",
            "Eval_StdReturn : 9.352640151977539\n",
            "Eval_MaxReturn : 69.4560546875\n",
            "Eval_MinReturn : 39.3597297668457\n",
            "Eval_AverageEpLen : 37.0\n",
            "Train_AverageReturn : 50.16299057006836\n",
            "Train_StdReturn : 8.452234268188477\n",
            "Train_MaxReturn : 66.65433502197266\n",
            "Train_MinReturn : 25.909557342529297\n",
            "Train_AverageEpLen : 35.732142857142854\n",
            "Train_EnvstepsSoFar : 441257\n",
            "TimeSinceStart : 452.7274479866028\n",
            "Training Loss : 86.1613998413086\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 218 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 55.493263244628906\n",
            "Eval_StdReturn : 6.546112060546875\n",
            "Eval_MaxReturn : 65.71776580810547\n",
            "Eval_MinReturn : 45.08280563354492\n",
            "Eval_AverageEpLen : 39.45454545454545\n",
            "Train_AverageReturn : 51.90174102783203\n",
            "Train_StdReturn : 8.197660446166992\n",
            "Train_MaxReturn : 70.07341003417969\n",
            "Train_MinReturn : 31.10529899597168\n",
            "Train_AverageEpLen : 36.74545454545454\n",
            "Train_EnvstepsSoFar : 443278\n",
            "TimeSinceStart : 454.7668445110321\n",
            "Training Loss : 65.45075988769531\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 219 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.994476318359375\n",
            "Eval_StdReturn : 8.896895408630371\n",
            "Eval_MaxReturn : 79.62937927246094\n",
            "Eval_MinReturn : 50.48883819580078\n",
            "Eval_AverageEpLen : 43.4\n",
            "Train_AverageReturn : 59.534210205078125\n",
            "Train_StdReturn : 8.781723022460938\n",
            "Train_MaxReturn : 78.67881774902344\n",
            "Train_MinReturn : 40.41501235961914\n",
            "Train_AverageEpLen : 41.833333333333336\n",
            "Train_EnvstepsSoFar : 445286\n",
            "TimeSinceStart : 456.80341625213623\n",
            "Training Loss : -9.86104965209961\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 220 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.4748764038086\n",
            "Eval_StdReturn : 9.424787521362305\n",
            "Eval_MaxReturn : 85.09757995605469\n",
            "Eval_MinReturn : 51.4967155456543\n",
            "Eval_AverageEpLen : 45.333333333333336\n",
            "Train_AverageReturn : 63.257568359375\n",
            "Train_StdReturn : 13.117826461791992\n",
            "Train_MaxReturn : 97.14546203613281\n",
            "Train_MinReturn : 44.59576416015625\n",
            "Train_AverageEpLen : 44.46666666666667\n",
            "Train_EnvstepsSoFar : 447287\n",
            "TimeSinceStart : 458.7961230278015\n",
            "Training Loss : 119.15666961669922\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 221 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 73.00819396972656\n",
            "Eval_StdReturn : 20.048362731933594\n",
            "Eval_MaxReturn : 113.44561004638672\n",
            "Eval_MinReturn : 49.982322692871094\n",
            "Eval_AverageEpLen : 51.25\n",
            "Train_AverageReturn : 71.26432800292969\n",
            "Train_StdReturn : 10.160857200622559\n",
            "Train_MaxReturn : 92.5555419921875\n",
            "Train_MinReturn : 51.84367752075195\n",
            "Train_AverageEpLen : 50.05\n",
            "Train_EnvstepsSoFar : 449289\n",
            "TimeSinceStart : 460.8035190105438\n",
            "Training Loss : 55.09965515136719\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 222 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 73.85515594482422\n",
            "Eval_StdReturn : 15.281166076660156\n",
            "Eval_MaxReturn : 108.61963653564453\n",
            "Eval_MinReturn : 54.83926010131836\n",
            "Eval_AverageEpLen : 51.875\n",
            "Train_AverageReturn : 74.62054443359375\n",
            "Train_StdReturn : 14.886683464050293\n",
            "Train_MaxReturn : 120.76254272460938\n",
            "Train_MinReturn : 49.486412048339844\n",
            "Train_AverageEpLen : 53.1578947368421\n",
            "Train_EnvstepsSoFar : 451309\n",
            "TimeSinceStart : 462.854026556015\n",
            "Training Loss : 92.94701385498047\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 223 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 102.65052032470703\n",
            "Eval_StdReturn : 10.919912338256836\n",
            "Eval_MaxReturn : 113.34833526611328\n",
            "Eval_MinReturn : 87.56346130371094\n",
            "Eval_AverageEpLen : 71.5\n",
            "Train_AverageReturn : 82.97174072265625\n",
            "Train_StdReturn : 15.733160972595215\n",
            "Train_MaxReturn : 130.74085998535156\n",
            "Train_MinReturn : 55.3533935546875\n",
            "Train_AverageEpLen : 59.14705882352941\n",
            "Train_EnvstepsSoFar : 453320\n",
            "TimeSinceStart : 464.94866585731506\n",
            "Training Loss : -47.509708404541016\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 224 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 112.95791625976562\n",
            "Eval_StdReturn : 10.436846733093262\n",
            "Eval_MaxReturn : 127.4465560913086\n",
            "Eval_MinReturn : 97.7758560180664\n",
            "Eval_AverageEpLen : 74.33333333333333\n",
            "Train_AverageReturn : 93.4858169555664\n",
            "Train_StdReturn : 13.50697135925293\n",
            "Train_MaxReturn : 115.91536712646484\n",
            "Train_MinReturn : 69.32035827636719\n",
            "Train_AverageEpLen : 66.06451612903226\n",
            "Train_EnvstepsSoFar : 455368\n",
            "TimeSinceStart : 467.0442645549774\n",
            "Training Loss : 12.131305694580078\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 225 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.30902099609375\n",
            "Eval_StdReturn : 9.087081909179688\n",
            "Eval_MaxReturn : 118.76335906982422\n",
            "Eval_MinReturn : 91.2236557006836\n",
            "Eval_AverageEpLen : 72.0\n",
            "Train_AverageReturn : 105.57994079589844\n",
            "Train_StdReturn : 14.15310287475586\n",
            "Train_MaxReturn : 135.04180908203125\n",
            "Train_MinReturn : 77.23707580566406\n",
            "Train_AverageEpLen : 71.55172413793103\n",
            "Train_EnvstepsSoFar : 457443\n",
            "TimeSinceStart : 469.19848132133484\n",
            "Training Loss : 32.066471099853516\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 226 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 131.40072631835938\n",
            "Eval_StdReturn : 21.37380027770996\n",
            "Eval_MaxReturn : 171.68466186523438\n",
            "Eval_MinReturn : 110.71705627441406\n",
            "Eval_AverageEpLen : 81.0\n",
            "Train_AverageReturn : 112.74633026123047\n",
            "Train_StdReturn : 14.384941101074219\n",
            "Train_MaxReturn : 147.27894592285156\n",
            "Train_MinReturn : 88.04882049560547\n",
            "Train_AverageEpLen : 74.44444444444444\n",
            "Train_EnvstepsSoFar : 459453\n",
            "TimeSinceStart : 471.24921345710754\n",
            "Training Loss : -51.29292297363281\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 227 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 151.8955078125\n",
            "Eval_StdReturn : 16.880281448364258\n",
            "Eval_MaxReturn : 182.56320190429688\n",
            "Eval_MinReturn : 130.66453552246094\n",
            "Eval_AverageEpLen : 88.2\n",
            "Train_AverageReturn : 135.55604553222656\n",
            "Train_StdReturn : 20.24244499206543\n",
            "Train_MaxReturn : 172.4730987548828\n",
            "Train_MinReturn : 102.32666778564453\n",
            "Train_AverageEpLen : 83.79166666666667\n",
            "Train_EnvstepsSoFar : 461464\n",
            "TimeSinceStart : 473.34741592407227\n",
            "Training Loss : -27.049758911132812\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 228 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 143.26101684570312\n",
            "Eval_StdReturn : 23.838016510009766\n",
            "Eval_MaxReturn : 181.115478515625\n",
            "Eval_MinReturn : 106.60458374023438\n",
            "Eval_AverageEpLen : 83.4\n",
            "Train_AverageReturn : 139.53135681152344\n",
            "Train_StdReturn : 21.39131736755371\n",
            "Train_MaxReturn : 200.48724365234375\n",
            "Train_MinReturn : 111.4426498413086\n",
            "Train_AverageEpLen : 84.5\n",
            "Train_EnvstepsSoFar : 463492\n",
            "TimeSinceStart : 475.4800281524658\n",
            "Training Loss : -4.080305099487305\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 229 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 141.90794372558594\n",
            "Eval_StdReturn : 27.695592880249023\n",
            "Eval_MaxReturn : 180.23387145996094\n",
            "Eval_MinReturn : 101.4076156616211\n",
            "Eval_AverageEpLen : 82.0\n",
            "Train_AverageReturn : 143.4106903076172\n",
            "Train_StdReturn : 25.847881317138672\n",
            "Train_MaxReturn : 189.86578369140625\n",
            "Train_MinReturn : 95.22733306884766\n",
            "Train_AverageEpLen : 83.95833333333333\n",
            "Train_EnvstepsSoFar : 465507\n",
            "TimeSinceStart : 477.57795214653015\n",
            "Training Loss : -12.440238952636719\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 230 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 140.66355895996094\n",
            "Eval_StdReturn : 30.323535919189453\n",
            "Eval_MaxReturn : 185.7589111328125\n",
            "Eval_MinReturn : 90.97734832763672\n",
            "Eval_AverageEpLen : 81.66666666666667\n",
            "Train_AverageReturn : 153.3235626220703\n",
            "Train_StdReturn : 20.48383331298828\n",
            "Train_MaxReturn : 184.10507202148438\n",
            "Train_MinReturn : 103.09378814697266\n",
            "Train_AverageEpLen : 86.95652173913044\n",
            "Train_EnvstepsSoFar : 467507\n",
            "TimeSinceStart : 479.7383303642273\n",
            "Training Loss : 61.40900421142578\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 231 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 177.30531311035156\n",
            "Eval_StdReturn : 13.538935661315918\n",
            "Eval_MaxReturn : 193.08926391601562\n",
            "Eval_MinReturn : 160.3459930419922\n",
            "Eval_AverageEpLen : 97.8\n",
            "Train_AverageReturn : 158.97015380859375\n",
            "Train_StdReturn : 19.844881057739258\n",
            "Train_MaxReturn : 196.1501007080078\n",
            "Train_MinReturn : 115.82064819335938\n",
            "Train_AverageEpLen : 88.6086956521739\n",
            "Train_EnvstepsSoFar : 469545\n",
            "TimeSinceStart : 481.93891954421997\n",
            "Training Loss : -17.845170974731445\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 232 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 169.50613403320312\n",
            "Eval_StdReturn : 29.652359008789062\n",
            "Eval_MaxReturn : 200.40042114257812\n",
            "Eval_MinReturn : 113.05842590332031\n",
            "Eval_AverageEpLen : 93.0\n",
            "Train_AverageReturn : 163.185302734375\n",
            "Train_StdReturn : 24.619186401367188\n",
            "Train_MaxReturn : 198.81649780273438\n",
            "Train_MinReturn : 101.58222198486328\n",
            "Train_AverageEpLen : 89.1304347826087\n",
            "Train_EnvstepsSoFar : 471595\n",
            "TimeSinceStart : 484.136990070343\n",
            "Training Loss : -8.255542755126953\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 233 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 177.52439880371094\n",
            "Eval_StdReturn : 21.005861282348633\n",
            "Eval_MaxReturn : 199.78433227539062\n",
            "Eval_MinReturn : 150.18231201171875\n",
            "Eval_AverageEpLen : 94.6\n",
            "Train_AverageReturn : 176.04051208496094\n",
            "Train_StdReturn : 17.541349411010742\n",
            "Train_MaxReturn : 198.50149536132812\n",
            "Train_MinReturn : 140.7210235595703\n",
            "Train_AverageEpLen : 94.54545454545455\n",
            "Train_EnvstepsSoFar : 473675\n",
            "TimeSinceStart : 486.3899643421173\n",
            "Training Loss : -14.649932861328125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 234 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 187.2710723876953\n",
            "Eval_StdReturn : 7.175115585327148\n",
            "Eval_MaxReturn : 198.14703369140625\n",
            "Eval_MinReturn : 179.2507781982422\n",
            "Eval_AverageEpLen : 94.6\n",
            "Train_AverageReturn : 163.93609619140625\n",
            "Train_StdReturn : 27.712636947631836\n",
            "Train_MaxReturn : 204.13250732421875\n",
            "Train_MinReturn : 100.13296508789062\n",
            "Train_AverageEpLen : 87.34782608695652\n",
            "Train_EnvstepsSoFar : 475684\n",
            "TimeSinceStart : 488.585729598999\n",
            "Training Loss : -45.899375915527344\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 235 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 151.52859497070312\n",
            "Eval_StdReturn : 33.35432052612305\n",
            "Eval_MaxReturn : 184.83297729492188\n",
            "Eval_MinReturn : 97.88227844238281\n",
            "Eval_AverageEpLen : 80.4\n",
            "Train_AverageReturn : 165.8315887451172\n",
            "Train_StdReturn : 33.48423767089844\n",
            "Train_MaxReturn : 202.89222717285156\n",
            "Train_MinReturn : 65.49141693115234\n",
            "Train_AverageEpLen : 87.16666666666667\n",
            "Train_EnvstepsSoFar : 477776\n",
            "TimeSinceStart : 490.7623119354248\n",
            "Training Loss : 21.466537475585938\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 236 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 185.7563018798828\n",
            "Eval_StdReturn : 8.792877197265625\n",
            "Eval_MaxReturn : 195.1505126953125\n",
            "Eval_MinReturn : 170.40554809570312\n",
            "Eval_AverageEpLen : 96.0\n",
            "Train_AverageReturn : 176.34750366210938\n",
            "Train_StdReturn : 29.09974479675293\n",
            "Train_MaxReturn : 203.12857055664062\n",
            "Train_MinReturn : 85.10659790039062\n",
            "Train_AverageEpLen : 89.91304347826087\n",
            "Train_EnvstepsSoFar : 479844\n",
            "TimeSinceStart : 492.9716112613678\n",
            "Training Loss : -13.50390625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 237 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 174.50338745117188\n",
            "Eval_StdReturn : 21.49327278137207\n",
            "Eval_MaxReturn : 190.3073272705078\n",
            "Eval_MinReturn : 132.26820373535156\n",
            "Eval_AverageEpLen : 89.0\n",
            "Train_AverageReturn : 187.67938232421875\n",
            "Train_StdReturn : 9.845282554626465\n",
            "Train_MaxReturn : 206.21853637695312\n",
            "Train_MinReturn : 169.75828552246094\n",
            "Train_AverageEpLen : 96.04761904761905\n",
            "Train_EnvstepsSoFar : 481861\n",
            "TimeSinceStart : 495.12319254875183\n",
            "Training Loss : 78.91046142578125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 238 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 188.1870880126953\n",
            "Eval_StdReturn : 8.727344512939453\n",
            "Eval_MaxReturn : 200.20846557617188\n",
            "Eval_MinReturn : 175.02792358398438\n",
            "Eval_AverageEpLen : 96.6\n",
            "Train_AverageReturn : 185.40911865234375\n",
            "Train_StdReturn : 13.879019737243652\n",
            "Train_MaxReturn : 205.0859832763672\n",
            "Train_MinReturn : 135.8760986328125\n",
            "Train_AverageEpLen : 94.54545454545455\n",
            "Train_EnvstepsSoFar : 483941\n",
            "TimeSinceStart : 497.35463643074036\n",
            "Training Loss : -38.66114044189453\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 239 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 185.76388549804688\n",
            "Eval_StdReturn : 8.126930236816406\n",
            "Eval_MaxReturn : 196.6848907470703\n",
            "Eval_MinReturn : 173.02325439453125\n",
            "Eval_AverageEpLen : 93.4\n",
            "Train_AverageReturn : 187.2216796875\n",
            "Train_StdReturn : 8.31639575958252\n",
            "Train_MaxReturn : 199.85813903808594\n",
            "Train_MinReturn : 167.7391815185547\n",
            "Train_AverageEpLen : 95.13636363636364\n",
            "Train_EnvstepsSoFar : 486034\n",
            "TimeSinceStart : 499.60620522499084\n",
            "Training Loss : -141.339111328125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 240 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 188.54661560058594\n",
            "Eval_StdReturn : 3.1608028411865234\n",
            "Eval_MaxReturn : 192.2570343017578\n",
            "Eval_MinReturn : 183.9967803955078\n",
            "Eval_AverageEpLen : 92.2\n",
            "Train_AverageReturn : 187.07176208496094\n",
            "Train_StdReturn : 12.757299423217773\n",
            "Train_MaxReturn : 200.85910034179688\n",
            "Train_MinReturn : 137.01710510253906\n",
            "Train_AverageEpLen : 93.77272727272727\n",
            "Train_EnvstepsSoFar : 488097\n",
            "TimeSinceStart : 501.84410572052\n",
            "Training Loss : -65.78650665283203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 241 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 182.27481079101562\n",
            "Eval_StdReturn : 4.761731147766113\n",
            "Eval_MaxReturn : 186.5825958251953\n",
            "Eval_MinReturn : 175.63552856445312\n",
            "Eval_AverageEpLen : 92.0\n",
            "Train_AverageReturn : 186.78199768066406\n",
            "Train_StdReturn : 9.545891761779785\n",
            "Train_MaxReturn : 202.44088745117188\n",
            "Train_MinReturn : 166.9862823486328\n",
            "Train_AverageEpLen : 93.5\n",
            "Train_EnvstepsSoFar : 490154\n",
            "TimeSinceStart : 504.0218913555145\n",
            "Training Loss : 34.78611373901367\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 242 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 179.38584899902344\n",
            "Eval_StdReturn : 7.427400588989258\n",
            "Eval_MaxReturn : 189.978271484375\n",
            "Eval_MinReturn : 167.98756408691406\n",
            "Eval_AverageEpLen : 89.6\n",
            "Train_AverageReturn : 185.09596252441406\n",
            "Train_StdReturn : 6.938209056854248\n",
            "Train_MaxReturn : 201.54226684570312\n",
            "Train_MinReturn : 168.8358154296875\n",
            "Train_AverageEpLen : 93.0\n",
            "Train_EnvstepsSoFar : 492200\n",
            "TimeSinceStart : 506.19693875312805\n",
            "Training Loss : -43.87079620361328\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 243 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 179.83499145507812\n",
            "Eval_StdReturn : 9.908172607421875\n",
            "Eval_MaxReturn : 194.76800537109375\n",
            "Eval_MinReturn : 167.92596435546875\n",
            "Eval_AverageEpLen : 92.2\n",
            "Train_AverageReturn : 185.23023986816406\n",
            "Train_StdReturn : 7.365163326263428\n",
            "Train_MaxReturn : 200.1103515625\n",
            "Train_MinReturn : 168.04335021972656\n",
            "Train_AverageEpLen : 93.04545454545455\n",
            "Train_EnvstepsSoFar : 494247\n",
            "TimeSinceStart : 508.38012957572937\n",
            "Training Loss : 36.432716369628906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 244 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 183.56976318359375\n",
            "Eval_StdReturn : 3.6817643642425537\n",
            "Eval_MaxReturn : 188.0963897705078\n",
            "Eval_MinReturn : 178.93960571289062\n",
            "Eval_AverageEpLen : 92.8\n",
            "Train_AverageReturn : 185.01412963867188\n",
            "Train_StdReturn : 5.161309719085693\n",
            "Train_MaxReturn : 195.4963836669922\n",
            "Train_MinReturn : 173.66188049316406\n",
            "Train_AverageEpLen : 92.68181818181819\n",
            "Train_EnvstepsSoFar : 496286\n",
            "TimeSinceStart : 510.6448645591736\n",
            "Training Loss : -86.00819396972656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 245 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 176.63662719726562\n",
            "Eval_StdReturn : 7.287463665008545\n",
            "Eval_MaxReturn : 187.7809600830078\n",
            "Eval_MinReturn : 166.86050415039062\n",
            "Eval_AverageEpLen : 89.2\n",
            "Train_AverageReturn : 179.28280639648438\n",
            "Train_StdReturn : 10.265275001525879\n",
            "Train_MaxReturn : 191.4067840576172\n",
            "Train_MinReturn : 141.76304626464844\n",
            "Train_AverageEpLen : 89.43478260869566\n",
            "Train_EnvstepsSoFar : 498343\n",
            "TimeSinceStart : 512.8174588680267\n",
            "Training Loss : -71.68782806396484\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 246 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 167.65023803710938\n",
            "Eval_StdReturn : 14.361016273498535\n",
            "Eval_MaxReturn : 185.712890625\n",
            "Eval_MinReturn : 145.27218627929688\n",
            "Eval_AverageEpLen : 84.4\n",
            "Train_AverageReturn : 171.09439086914062\n",
            "Train_StdReturn : 17.502365112304688\n",
            "Train_MaxReturn : 190.89959716796875\n",
            "Train_MinReturn : 114.28514862060547\n",
            "Train_AverageEpLen : 88.69565217391305\n",
            "Train_EnvstepsSoFar : 500383\n",
            "TimeSinceStart : 514.9708721637726\n",
            "Training Loss : -108.67880249023438\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 247 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 147.2158660888672\n",
            "Eval_StdReturn : 17.621475219726562\n",
            "Eval_MaxReturn : 172.64334106445312\n",
            "Eval_MinReturn : 122.11438751220703\n",
            "Eval_AverageEpLen : 76.83333333333333\n",
            "Train_AverageReturn : 170.56785583496094\n",
            "Train_StdReturn : 15.62072467803955\n",
            "Train_MaxReturn : 190.07241821289062\n",
            "Train_MinReturn : 115.69038391113281\n",
            "Train_AverageEpLen : 86.91666666666667\n",
            "Train_EnvstepsSoFar : 502469\n",
            "TimeSinceStart : 517.2289180755615\n",
            "Training Loss : -16.439075469970703\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 248 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 166.27377319335938\n",
            "Eval_StdReturn : 13.350878715515137\n",
            "Eval_MaxReturn : 182.52792358398438\n",
            "Eval_MinReturn : 144.169921875\n",
            "Eval_AverageEpLen : 86.2\n",
            "Train_AverageReturn : 155.2267608642578\n",
            "Train_StdReturn : 26.17771339416504\n",
            "Train_MaxReturn : 191.11280822753906\n",
            "Train_MinReturn : 88.91156005859375\n",
            "Train_AverageEpLen : 80.72\n",
            "Train_EnvstepsSoFar : 504487\n",
            "TimeSinceStart : 519.3486816883087\n",
            "Training Loss : -68.67125701904297\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 249 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 154.35476684570312\n",
            "Eval_StdReturn : 21.912416458129883\n",
            "Eval_MaxReturn : 181.2853240966797\n",
            "Eval_MinReturn : 114.17672729492188\n",
            "Eval_AverageEpLen : 80.2\n",
            "Train_AverageReturn : 148.34217834472656\n",
            "Train_StdReturn : 32.03752136230469\n",
            "Train_MaxReturn : 187.3800048828125\n",
            "Train_MinReturn : 86.599853515625\n",
            "Train_AverageEpLen : 78.3076923076923\n",
            "Train_EnvstepsSoFar : 506523\n",
            "TimeSinceStart : 521.4874284267426\n",
            "Training Loss : -7.688720703125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 250 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 147.16697692871094\n",
            "Eval_StdReturn : 22.34833335876465\n",
            "Eval_MaxReturn : 178.22715759277344\n",
            "Eval_MinReturn : 105.69649505615234\n",
            "Eval_AverageEpLen : 77.5\n",
            "Train_AverageReturn : 141.75926208496094\n",
            "Train_StdReturn : 26.09479522705078\n",
            "Train_MaxReturn : 180.25189208984375\n",
            "Train_MinReturn : 93.6796646118164\n",
            "Train_AverageEpLen : 76.25925925925925\n",
            "Train_EnvstepsSoFar : 508582\n",
            "TimeSinceStart : 523.6615536212921\n",
            "Training Loss : 10.638750076293945\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 251 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 141.29275512695312\n",
            "Eval_StdReturn : 21.33705711364746\n",
            "Eval_MaxReturn : 167.71803283691406\n",
            "Eval_MinReturn : 103.82734680175781\n",
            "Eval_AverageEpLen : 75.83333333333333\n",
            "Train_AverageReturn : 126.83250427246094\n",
            "Train_StdReturn : 23.77207374572754\n",
            "Train_MaxReturn : 178.90284729003906\n",
            "Train_MinReturn : 89.19419860839844\n",
            "Train_AverageEpLen : 69.93103448275862\n",
            "Train_EnvstepsSoFar : 510610\n",
            "TimeSinceStart : 525.8430073261261\n",
            "Training Loss : -3.0863571166992188\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 252 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 121.41118621826172\n",
            "Eval_StdReturn : 28.850488662719727\n",
            "Eval_MaxReturn : 171.73617553710938\n",
            "Eval_MinReturn : 76.23905944824219\n",
            "Eval_AverageEpLen : 67.42857142857143\n",
            "Train_AverageReturn : 126.8197250366211\n",
            "Train_StdReturn : 25.01915168762207\n",
            "Train_MaxReturn : 185.27279663085938\n",
            "Train_MinReturn : 81.275390625\n",
            "Train_AverageEpLen : 69.93103448275862\n",
            "Train_EnvstepsSoFar : 512638\n",
            "TimeSinceStart : 527.9779179096222\n",
            "Training Loss : -44.120887756347656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 253 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 117.85147857666016\n",
            "Eval_StdReturn : 15.42650318145752\n",
            "Eval_MaxReturn : 136.1862030029297\n",
            "Eval_MinReturn : 93.67554473876953\n",
            "Eval_AverageEpLen : 67.16666666666667\n",
            "Train_AverageReturn : 116.28187561035156\n",
            "Train_StdReturn : 22.156497955322266\n",
            "Train_MaxReturn : 158.65884399414062\n",
            "Train_MinReturn : 77.32948303222656\n",
            "Train_AverageEpLen : 65.58064516129032\n",
            "Train_EnvstepsSoFar : 514671\n",
            "TimeSinceStart : 530.0529117584229\n",
            "Training Loss : 25.166641235351562\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 254 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 105.49693298339844\n",
            "Eval_StdReturn : 24.87089729309082\n",
            "Eval_MaxReturn : 152.17942810058594\n",
            "Eval_MinReturn : 71.79753112792969\n",
            "Eval_AverageEpLen : 60.285714285714285\n",
            "Train_AverageReturn : 118.51265716552734\n",
            "Train_StdReturn : 22.273094177246094\n",
            "Train_MaxReturn : 163.34841918945312\n",
            "Train_MinReturn : 79.08356475830078\n",
            "Train_AverageEpLen : 66.7\n",
            "Train_EnvstepsSoFar : 516672\n",
            "TimeSinceStart : 532.1035842895508\n",
            "Training Loss : 42.02603530883789\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 255 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 111.55365753173828\n",
            "Eval_StdReturn : 13.692035675048828\n",
            "Eval_MaxReturn : 131.25157165527344\n",
            "Eval_MinReturn : 90.88896942138672\n",
            "Eval_AverageEpLen : 63.57142857142857\n",
            "Train_AverageReturn : 113.33401489257812\n",
            "Train_StdReturn : 19.010353088378906\n",
            "Train_MaxReturn : 157.7496337890625\n",
            "Train_MinReturn : 80.3649673461914\n",
            "Train_AverageEpLen : 64.74193548387096\n",
            "Train_EnvstepsSoFar : 518679\n",
            "TimeSinceStart : 534.1521067619324\n",
            "Training Loss : 12.981498718261719\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 256 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 97.48744201660156\n",
            "Eval_StdReturn : 15.137983322143555\n",
            "Eval_MaxReturn : 125.7604751586914\n",
            "Eval_MinReturn : 76.84270477294922\n",
            "Eval_AverageEpLen : 56.5\n",
            "Train_AverageReturn : 113.3379135131836\n",
            "Train_StdReturn : 16.969078063964844\n",
            "Train_MaxReturn : 155.56788635253906\n",
            "Train_MinReturn : 75.78718566894531\n",
            "Train_AverageEpLen : 64.74193548387096\n",
            "Train_EnvstepsSoFar : 520686\n",
            "TimeSinceStart : 536.2835292816162\n",
            "Training Loss : 44.85569763183594\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 257 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.1814193725586\n",
            "Eval_StdReturn : 18.94890594482422\n",
            "Eval_MaxReturn : 141.3374481201172\n",
            "Eval_MinReturn : 85.03470611572266\n",
            "Eval_AverageEpLen : 61.857142857142854\n",
            "Train_AverageReturn : 117.2485580444336\n",
            "Train_StdReturn : 21.389408111572266\n",
            "Train_MaxReturn : 171.89688110351562\n",
            "Train_MinReturn : 84.3564453125\n",
            "Train_AverageEpLen : 66.25806451612904\n",
            "Train_EnvstepsSoFar : 522740\n",
            "TimeSinceStart : 538.4159617424011\n",
            "Training Loss : 42.012203216552734\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 258 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 98.54694366455078\n",
            "Eval_StdReturn : 16.956863403320312\n",
            "Eval_MaxReturn : 118.11955261230469\n",
            "Eval_MinReturn : 66.20104217529297\n",
            "Eval_AverageEpLen : 57.857142857142854\n",
            "Train_AverageReturn : 104.63297271728516\n",
            "Train_StdReturn : 20.319536209106445\n",
            "Train_MaxReturn : 146.62313842773438\n",
            "Train_MinReturn : 72.11017608642578\n",
            "Train_AverageEpLen : 59.88235294117647\n",
            "Train_EnvstepsSoFar : 524776\n",
            "TimeSinceStart : 540.5118985176086\n",
            "Training Loss : 28.272666931152344\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 259 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 104.90084075927734\n",
            "Eval_StdReturn : 20.165483474731445\n",
            "Eval_MaxReturn : 149.71090698242188\n",
            "Eval_MinReturn : 82.95295715332031\n",
            "Eval_AverageEpLen : 60.57142857142857\n",
            "Train_AverageReturn : 101.03731536865234\n",
            "Train_StdReturn : 17.961139678955078\n",
            "Train_MaxReturn : 164.88388061523438\n",
            "Train_MinReturn : 73.87361907958984\n",
            "Train_AverageEpLen : 58.542857142857144\n",
            "Train_EnvstepsSoFar : 526825\n",
            "TimeSinceStart : 542.6438519954681\n",
            "Training Loss : -37.41427993774414\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 260 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 128.8075408935547\n",
            "Eval_StdReturn : 11.824600219726562\n",
            "Eval_MaxReturn : 150.38937377929688\n",
            "Eval_MinReturn : 113.9770278930664\n",
            "Eval_AverageEpLen : 71.66666666666667\n",
            "Train_AverageReturn : 110.48152160644531\n",
            "Train_StdReturn : 22.061670303344727\n",
            "Train_MaxReturn : 155.83804321289062\n",
            "Train_MinReturn : 72.74166870117188\n",
            "Train_AverageEpLen : 63.09375\n",
            "Train_EnvstepsSoFar : 528844\n",
            "TimeSinceStart : 544.7192997932434\n",
            "Training Loss : 51.154083251953125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 261 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 114.91275787353516\n",
            "Eval_StdReturn : 21.204570770263672\n",
            "Eval_MaxReturn : 143.16554260253906\n",
            "Eval_MinReturn : 82.8763198852539\n",
            "Eval_AverageEpLen : 65.71428571428571\n",
            "Train_AverageReturn : 105.84253692626953\n",
            "Train_StdReturn : 19.12623405456543\n",
            "Train_MaxReturn : 145.7810821533203\n",
            "Train_MinReturn : 62.479087829589844\n",
            "Train_AverageEpLen : 61.18181818181818\n",
            "Train_EnvstepsSoFar : 530863\n",
            "TimeSinceStart : 546.8429737091064\n",
            "Training Loss : 18.2037353515625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 262 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 102.69636535644531\n",
            "Eval_StdReturn : 16.58563804626465\n",
            "Eval_MaxReturn : 129.8359375\n",
            "Eval_MinReturn : 77.53966522216797\n",
            "Eval_AverageEpLen : 60.0\n",
            "Train_AverageReturn : 114.00515747070312\n",
            "Train_StdReturn : 17.544424057006836\n",
            "Train_MaxReturn : 152.7348175048828\n",
            "Train_MinReturn : 87.58194732666016\n",
            "Train_AverageEpLen : 65.19354838709677\n",
            "Train_EnvstepsSoFar : 532884\n",
            "TimeSinceStart : 548.9227912425995\n",
            "Training Loss : -29.300609588623047\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 263 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 112.07115936279297\n",
            "Eval_StdReturn : 20.464479446411133\n",
            "Eval_MaxReturn : 142.91807556152344\n",
            "Eval_MinReturn : 83.08914947509766\n",
            "Eval_AverageEpLen : 64.57142857142857\n",
            "Train_AverageReturn : 110.347900390625\n",
            "Train_StdReturn : 19.69788360595703\n",
            "Train_MaxReturn : 153.30287170410156\n",
            "Train_MinReturn : 80.85746002197266\n",
            "Train_AverageEpLen : 63.53125\n",
            "Train_EnvstepsSoFar : 534917\n",
            "TimeSinceStart : 551.0370254516602\n",
            "Training Loss : -40.321781158447266\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 264 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 114.36951446533203\n",
            "Eval_StdReturn : 11.847291946411133\n",
            "Eval_MaxReturn : 132.27996826171875\n",
            "Eval_MinReturn : 104.73650360107422\n",
            "Eval_AverageEpLen : 67.16666666666667\n",
            "Train_AverageReturn : 117.11428833007812\n",
            "Train_StdReturn : 13.717082977294922\n",
            "Train_MaxReturn : 147.15330505371094\n",
            "Train_MinReturn : 88.2662353515625\n",
            "Train_AverageEpLen : 67.66666666666667\n",
            "Train_EnvstepsSoFar : 536947\n",
            "TimeSinceStart : 553.0871534347534\n",
            "Training Loss : 9.119117736816406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 265 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 134.2156524658203\n",
            "Eval_StdReturn : 21.388141632080078\n",
            "Eval_MaxReturn : 167.6201171875\n",
            "Eval_MinReturn : 103.54191589355469\n",
            "Eval_AverageEpLen : 76.5\n",
            "Train_AverageReturn : 121.60748291015625\n",
            "Train_StdReturn : 20.45320701599121\n",
            "Train_MaxReturn : 174.24966430664062\n",
            "Train_MinReturn : 92.96505737304688\n",
            "Train_AverageEpLen : 70.10344827586206\n",
            "Train_EnvstepsSoFar : 538980\n",
            "TimeSinceStart : 555.2157089710236\n",
            "Training Loss : -36.21653747558594\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 266 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 130.1728057861328\n",
            "Eval_StdReturn : 29.0479793548584\n",
            "Eval_MaxReturn : 168.8173828125\n",
            "Eval_MinReturn : 101.21455383300781\n",
            "Eval_AverageEpLen : 73.16666666666667\n",
            "Train_AverageReturn : 128.49624633789062\n",
            "Train_StdReturn : 23.704299926757812\n",
            "Train_MaxReturn : 181.22718811035156\n",
            "Train_MinReturn : 87.2069320678711\n",
            "Train_AverageEpLen : 72.60714285714286\n",
            "Train_EnvstepsSoFar : 541013\n",
            "TimeSinceStart : 557.3634538650513\n",
            "Training Loss : -52.79707717895508\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 267 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 129.4845428466797\n",
            "Eval_StdReturn : 15.507954597473145\n",
            "Eval_MaxReturn : 150.41680908203125\n",
            "Eval_MinReturn : 105.29412078857422\n",
            "Eval_AverageEpLen : 74.33333333333333\n",
            "Train_AverageReturn : 132.14254760742188\n",
            "Train_StdReturn : 23.36935806274414\n",
            "Train_MaxReturn : 177.69166564941406\n",
            "Train_MinReturn : 85.15097045898438\n",
            "Train_AverageEpLen : 75.25925925925925\n",
            "Train_EnvstepsSoFar : 543045\n",
            "TimeSinceStart : 559.4796268939972\n",
            "Training Loss : 34.58819580078125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 268 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 136.04638671875\n",
            "Eval_StdReturn : 16.40617561340332\n",
            "Eval_MaxReturn : 170.4432373046875\n",
            "Eval_MinReturn : 122.8275146484375\n",
            "Eval_AverageEpLen : 77.0\n",
            "Train_AverageReturn : 142.15634155273438\n",
            "Train_StdReturn : 22.592876434326172\n",
            "Train_MaxReturn : 184.45083618164062\n",
            "Train_MinReturn : 110.4813003540039\n",
            "Train_AverageEpLen : 79.61538461538461\n",
            "Train_EnvstepsSoFar : 545115\n",
            "TimeSinceStart : 561.6759495735168\n",
            "Training Loss : -159.33799743652344\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 269 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 155.79141235351562\n",
            "Eval_StdReturn : 22.179763793945312\n",
            "Eval_MaxReturn : 185.62594604492188\n",
            "Eval_MinReturn : 128.42848205566406\n",
            "Eval_AverageEpLen : 87.2\n",
            "Train_AverageReturn : 145.89794921875\n",
            "Train_StdReturn : 25.64335823059082\n",
            "Train_MaxReturn : 185.36964416503906\n",
            "Train_MinReturn : 106.41697692871094\n",
            "Train_AverageEpLen : 81.52\n",
            "Train_EnvstepsSoFar : 547153\n",
            "TimeSinceStart : 563.8156123161316\n",
            "Training Loss : -46.47914123535156\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 270 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 168.7242431640625\n",
            "Eval_StdReturn : 23.012664794921875\n",
            "Eval_MaxReturn : 185.69821166992188\n",
            "Eval_MinReturn : 123.59725952148438\n",
            "Eval_AverageEpLen : 92.2\n",
            "Train_AverageReturn : 153.2136688232422\n",
            "Train_StdReturn : 13.960589408874512\n",
            "Train_MaxReturn : 183.76303100585938\n",
            "Train_MinReturn : 130.08255004882812\n",
            "Train_AverageEpLen : 85.20833333333333\n",
            "Train_EnvstepsSoFar : 549198\n",
            "TimeSinceStart : 565.9865348339081\n",
            "Training Loss : -53.26190185546875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 271 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 169.35153198242188\n",
            "Eval_StdReturn : 12.239229202270508\n",
            "Eval_MaxReturn : 181.3914337158203\n",
            "Eval_MinReturn : 146.7890167236328\n",
            "Eval_AverageEpLen : 90.8\n",
            "Train_AverageReturn : 170.02528381347656\n",
            "Train_StdReturn : 18.657608032226562\n",
            "Train_MaxReturn : 193.7693328857422\n",
            "Train_MinReturn : 123.1220932006836\n",
            "Train_AverageEpLen : 93.0\n",
            "Train_EnvstepsSoFar : 551244\n",
            "TimeSinceStart : 568.1859600543976\n",
            "Training Loss : -13.580551147460938\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 272 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 171.14524841308594\n",
            "Eval_StdReturn : 3.07327938079834\n",
            "Eval_MaxReturn : 175.95799255371094\n",
            "Eval_MinReturn : 166.91387939453125\n",
            "Eval_AverageEpLen : 97.2\n",
            "Train_AverageReturn : 171.11920166015625\n",
            "Train_StdReturn : 15.129541397094727\n",
            "Train_MaxReturn : 193.48846435546875\n",
            "Train_MinReturn : 140.3138427734375\n",
            "Train_AverageEpLen : 94.54545454545455\n",
            "Train_EnvstepsSoFar : 553324\n",
            "TimeSinceStart : 570.4742569923401\n",
            "Training Loss : 24.482616424560547\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 273 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 177.02890014648438\n",
            "Eval_StdReturn : 12.138397216796875\n",
            "Eval_MaxReturn : 193.82801818847656\n",
            "Eval_MinReturn : 158.9838409423828\n",
            "Eval_AverageEpLen : 94.2\n",
            "Train_AverageReturn : 169.65814208984375\n",
            "Train_StdReturn : 14.328788757324219\n",
            "Train_MaxReturn : 192.66256713867188\n",
            "Train_MinReturn : 138.7427978515625\n",
            "Train_AverageEpLen : 96.23809523809524\n",
            "Train_EnvstepsSoFar : 555345\n",
            "TimeSinceStart : 572.6889712810516\n",
            "Training Loss : -49.21851348876953\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 274 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 180.56134033203125\n",
            "Eval_StdReturn : 9.843485832214355\n",
            "Eval_MaxReturn : 192.42550659179688\n",
            "Eval_MinReturn : 164.90260314941406\n",
            "Eval_AverageEpLen : 97.2\n",
            "Train_AverageReturn : 173.32110595703125\n",
            "Train_StdReturn : 10.624844551086426\n",
            "Train_MaxReturn : 193.6333465576172\n",
            "Train_MinReturn : 157.519287109375\n",
            "Train_AverageEpLen : 95.52380952380952\n",
            "Train_EnvstepsSoFar : 557351\n",
            "TimeSinceStart : 574.8603842258453\n",
            "Training Loss : -92.968017578125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 275 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 175.32315063476562\n",
            "Eval_StdReturn : 9.663357734680176\n",
            "Eval_MaxReturn : 185.5861053466797\n",
            "Eval_MinReturn : 161.777099609375\n",
            "Eval_AverageEpLen : 99.0\n",
            "Train_AverageReturn : 164.60337829589844\n",
            "Train_StdReturn : 16.863752365112305\n",
            "Train_MaxReturn : 192.36647033691406\n",
            "Train_MinReturn : 124.96564483642578\n",
            "Train_AverageEpLen : 93.0909090909091\n",
            "Train_EnvstepsSoFar : 559399\n",
            "TimeSinceStart : 577.1063513755798\n",
            "Training Loss : -59.309104919433594\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 276 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 173.10076904296875\n",
            "Eval_StdReturn : 4.820032596588135\n",
            "Eval_MaxReturn : 177.89710998535156\n",
            "Eval_MinReturn : 163.9056854248047\n",
            "Eval_AverageEpLen : 99.2\n",
            "Train_AverageReturn : 175.87265014648438\n",
            "Train_StdReturn : 11.757583618164062\n",
            "Train_MaxReturn : 194.77716064453125\n",
            "Train_MinReturn : 156.56822204589844\n",
            "Train_AverageEpLen : 98.42857142857143\n",
            "Train_EnvstepsSoFar : 561466\n",
            "TimeSinceStart : 579.3287200927734\n",
            "Training Loss : 11.136922836303711\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 277 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 171.95559692382812\n",
            "Eval_StdReturn : 11.223949432373047\n",
            "Eval_MaxReturn : 191.51296997070312\n",
            "Eval_MinReturn : 157.62010192871094\n",
            "Eval_AverageEpLen : 95.8\n",
            "Train_AverageReturn : 173.92330932617188\n",
            "Train_StdReturn : 11.822318077087402\n",
            "Train_MaxReturn : 191.52862548828125\n",
            "Train_MinReturn : 149.82354736328125\n",
            "Train_AverageEpLen : 98.95238095238095\n",
            "Train_EnvstepsSoFar : 563544\n",
            "TimeSinceStart : 581.5839235782623\n",
            "Training Loss : -25.131149291992188\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 278 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 170.75588989257812\n",
            "Eval_StdReturn : 11.384434700012207\n",
            "Eval_MaxReturn : 187.04257202148438\n",
            "Eval_MinReturn : 157.12567138671875\n",
            "Eval_AverageEpLen : 98.0\n",
            "Train_AverageReturn : 172.0531005859375\n",
            "Train_StdReturn : 12.798521995544434\n",
            "Train_MaxReturn : 193.2432403564453\n",
            "Train_MinReturn : 146.23513793945312\n",
            "Train_AverageEpLen : 97.42857142857143\n",
            "Train_EnvstepsSoFar : 565590\n",
            "TimeSinceStart : 583.846663236618\n",
            "Training Loss : 7.4308929443359375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 279 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 165.1881561279297\n",
            "Eval_StdReturn : 13.51485824584961\n",
            "Eval_MaxReturn : 182.61517333984375\n",
            "Eval_MinReturn : 149.68063354492188\n",
            "Eval_AverageEpLen : 92.8\n",
            "Train_AverageReturn : 168.60556030273438\n",
            "Train_StdReturn : 11.852128982543945\n",
            "Train_MaxReturn : 194.28839111328125\n",
            "Train_MinReturn : 150.17819213867188\n",
            "Train_AverageEpLen : 97.14285714285714\n",
            "Train_EnvstepsSoFar : 567630\n",
            "TimeSinceStart : 586.0670216083527\n",
            "Training Loss : 61.07493591308594\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 280 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 167.31600952148438\n",
            "Eval_StdReturn : 8.269634246826172\n",
            "Eval_MaxReturn : 176.0299072265625\n",
            "Eval_MinReturn : 154.28395080566406\n",
            "Eval_AverageEpLen : 97.2\n",
            "Train_AverageReturn : 169.86964416503906\n",
            "Train_StdReturn : 14.512319564819336\n",
            "Train_MaxReturn : 192.40028381347656\n",
            "Train_MinReturn : 143.53359985351562\n",
            "Train_AverageEpLen : 97.42857142857143\n",
            "Train_EnvstepsSoFar : 569676\n",
            "TimeSinceStart : 588.3295447826385\n",
            "Training Loss : 13.505508422851562\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 281 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 177.88385009765625\n",
            "Eval_StdReturn : 8.76392650604248\n",
            "Eval_MaxReturn : 188.2120361328125\n",
            "Eval_MinReturn : 164.06776428222656\n",
            "Eval_AverageEpLen : 104.25\n",
            "Train_AverageReturn : 168.20883178710938\n",
            "Train_StdReturn : 13.83677864074707\n",
            "Train_MaxReturn : 192.56552124023438\n",
            "Train_MinReturn : 140.83609008789062\n",
            "Train_AverageEpLen : 97.61904761904762\n",
            "Train_EnvstepsSoFar : 571726\n",
            "TimeSinceStart : 590.5101597309113\n",
            "Training Loss : 74.40706634521484\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 282 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 161.29039001464844\n",
            "Eval_StdReturn : 16.35955047607422\n",
            "Eval_MaxReturn : 178.69110107421875\n",
            "Eval_MinReturn : 131.49169921875\n",
            "Eval_AverageEpLen : 98.2\n",
            "Train_AverageReturn : 169.1797637939453\n",
            "Train_StdReturn : 15.478760719299316\n",
            "Train_MaxReturn : 203.1048583984375\n",
            "Train_MinReturn : 142.68508911132812\n",
            "Train_AverageEpLen : 98.66666666666667\n",
            "Train_EnvstepsSoFar : 573798\n",
            "TimeSinceStart : 592.8282368183136\n",
            "Training Loss : -92.69053649902344\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 283 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 162.18310546875\n",
            "Eval_StdReturn : 12.90346908569336\n",
            "Eval_MaxReturn : 178.3935546875\n",
            "Eval_MinReturn : 145.726806640625\n",
            "Eval_AverageEpLen : 96.6\n",
            "Train_AverageReturn : 162.94338989257812\n",
            "Train_StdReturn : 12.540800094604492\n",
            "Train_MaxReturn : 187.79470825195312\n",
            "Train_MinReturn : 135.90025329589844\n",
            "Train_AverageEpLen : 94.31818181818181\n",
            "Train_EnvstepsSoFar : 575873\n",
            "TimeSinceStart : 595.0894119739532\n",
            "Training Loss : 32.97586441040039\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 284 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 153.69436645507812\n",
            "Eval_StdReturn : 17.872337341308594\n",
            "Eval_MaxReturn : 173.96231079101562\n",
            "Eval_MinReturn : 121.55450439453125\n",
            "Eval_AverageEpLen : 92.4\n",
            "Train_AverageReturn : 167.78587341308594\n",
            "Train_StdReturn : 14.906525611877441\n",
            "Train_MaxReturn : 193.19058227539062\n",
            "Train_MinReturn : 143.3808135986328\n",
            "Train_AverageEpLen : 98.9047619047619\n",
            "Train_EnvstepsSoFar : 577950\n",
            "TimeSinceStart : 597.3898818492889\n",
            "Training Loss : -38.403873443603516\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 285 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 157.80331420898438\n",
            "Eval_StdReturn : 8.523008346557617\n",
            "Eval_MaxReturn : 169.77224731445312\n",
            "Eval_MinReturn : 149.45120239257812\n",
            "Eval_AverageEpLen : 95.8\n",
            "Train_AverageReturn : 160.76206970214844\n",
            "Train_StdReturn : 13.34896469116211\n",
            "Train_MaxReturn : 188.96292114257812\n",
            "Train_MinReturn : 137.99139404296875\n",
            "Train_AverageEpLen : 95.23809523809524\n",
            "Train_EnvstepsSoFar : 579950\n",
            "TimeSinceStart : 599.5578677654266\n",
            "Training Loss : 34.264312744140625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 286 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 162.0213165283203\n",
            "Eval_StdReturn : 15.13731861114502\n",
            "Eval_MaxReturn : 182.06744384765625\n",
            "Eval_MinReturn : 135.2203369140625\n",
            "Eval_AverageEpLen : 96.0\n",
            "Train_AverageReturn : 158.0405731201172\n",
            "Train_StdReturn : 10.5095853805542\n",
            "Train_MaxReturn : 177.2858123779297\n",
            "Train_MinReturn : 136.1629180908203\n",
            "Train_AverageEpLen : 93.9090909090909\n",
            "Train_EnvstepsSoFar : 582016\n",
            "TimeSinceStart : 601.7962651252747\n",
            "Training Loss : -75.72908020019531\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 287 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 149.8363037109375\n",
            "Eval_StdReturn : 6.041143894195557\n",
            "Eval_MaxReturn : 157.4076385498047\n",
            "Eval_MinReturn : 143.8603515625\n",
            "Eval_AverageEpLen : 92.8\n",
            "Train_AverageReturn : 160.7029571533203\n",
            "Train_StdReturn : 12.736196517944336\n",
            "Train_MaxReturn : 186.99725341796875\n",
            "Train_MinReturn : 137.8091583251953\n",
            "Train_AverageEpLen : 97.33333333333333\n",
            "Train_EnvstepsSoFar : 584060\n",
            "TimeSinceStart : 603.9976441860199\n",
            "Training Loss : -70.07174682617188\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 288 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 142.9653778076172\n",
            "Eval_StdReturn : 13.782401084899902\n",
            "Eval_MaxReturn : 160.7905731201172\n",
            "Eval_MinReturn : 120.21925354003906\n",
            "Eval_AverageEpLen : 87.8\n",
            "Train_AverageReturn : 153.47523498535156\n",
            "Train_StdReturn : 16.47842788696289\n",
            "Train_MaxReturn : 197.45062255859375\n",
            "Train_MinReturn : 127.75459289550781\n",
            "Train_AverageEpLen : 93.0909090909091\n",
            "Train_EnvstepsSoFar : 586108\n",
            "TimeSinceStart : 606.1707406044006\n",
            "Training Loss : -39.374351501464844\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 289 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 156.14706420898438\n",
            "Eval_StdReturn : 16.017770767211914\n",
            "Eval_MaxReturn : 176.90162658691406\n",
            "Eval_MinReturn : 130.30422973632812\n",
            "Eval_AverageEpLen : 97.2\n",
            "Train_AverageReturn : 155.59877014160156\n",
            "Train_StdReturn : 14.250299453735352\n",
            "Train_MaxReturn : 180.66127014160156\n",
            "Train_MinReturn : 126.42877197265625\n",
            "Train_AverageEpLen : 94.72727272727273\n",
            "Train_EnvstepsSoFar : 588192\n",
            "TimeSinceStart : 608.4416291713715\n",
            "Training Loss : 44.32587432861328\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 290 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 158.0249481201172\n",
            "Eval_StdReturn : 9.076531410217285\n",
            "Eval_MaxReturn : 168.49620056152344\n",
            "Eval_MinReturn : 141.6431884765625\n",
            "Eval_AverageEpLen : 97.6\n",
            "Train_AverageReturn : 148.4188232421875\n",
            "Train_StdReturn : 13.210832595825195\n",
            "Train_MaxReturn : 170.99070739746094\n",
            "Train_MinReturn : 115.17506408691406\n",
            "Train_AverageEpLen : 90.82608695652173\n",
            "Train_EnvstepsSoFar : 590281\n",
            "TimeSinceStart : 610.7541387081146\n",
            "Training Loss : -105.93325805664062\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 291 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 165.40467834472656\n",
            "Eval_StdReturn : 9.869585037231445\n",
            "Eval_MaxReturn : 178.2071075439453\n",
            "Eval_MinReturn : 150.4747772216797\n",
            "Eval_AverageEpLen : 101.0\n",
            "Train_AverageReturn : 148.90045166015625\n",
            "Train_StdReturn : 14.236751556396484\n",
            "Train_MaxReturn : 170.8870391845703\n",
            "Train_MinReturn : 121.0794906616211\n",
            "Train_AverageEpLen : 92.18181818181819\n",
            "Train_EnvstepsSoFar : 592309\n",
            "TimeSinceStart : 612.8812828063965\n",
            "Training Loss : -30.620391845703125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 292 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 146.27682495117188\n",
            "Eval_StdReturn : 9.976178169250488\n",
            "Eval_MaxReturn : 163.4875946044922\n",
            "Eval_MinReturn : 133.56805419921875\n",
            "Eval_AverageEpLen : 91.0\n",
            "Train_AverageReturn : 145.57763671875\n",
            "Train_StdReturn : 12.483787536621094\n",
            "Train_MaxReturn : 177.1031036376953\n",
            "Train_MinReturn : 125.22967529296875\n",
            "Train_AverageEpLen : 91.36363636363636\n",
            "Train_EnvstepsSoFar : 594319\n",
            "TimeSinceStart : 615.0308094024658\n",
            "Training Loss : -21.141342163085938\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 293 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 146.89096069335938\n",
            "Eval_StdReturn : 13.822802543640137\n",
            "Eval_MaxReturn : 171.9146728515625\n",
            "Eval_MinReturn : 131.8263702392578\n",
            "Eval_AverageEpLen : 91.4\n",
            "Train_AverageReturn : 151.90481567382812\n",
            "Train_StdReturn : 12.96314811706543\n",
            "Train_MaxReturn : 181.3055877685547\n",
            "Train_MinReturn : 135.3975067138672\n",
            "Train_AverageEpLen : 93.5909090909091\n",
            "Train_EnvstepsSoFar : 596378\n",
            "TimeSinceStart : 617.2629778385162\n",
            "Training Loss : -48.61491012573242\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 294 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 139.28207397460938\n",
            "Eval_StdReturn : 9.408364295959473\n",
            "Eval_MaxReturn : 155.4596405029297\n",
            "Eval_MinReturn : 129.50465393066406\n",
            "Eval_AverageEpLen : 88.4\n",
            "Train_AverageReturn : 145.85723876953125\n",
            "Train_StdReturn : 10.785866737365723\n",
            "Train_MaxReturn : 158.12538146972656\n",
            "Train_MinReturn : 108.49137878417969\n",
            "Train_AverageEpLen : 91.95454545454545\n",
            "Train_EnvstepsSoFar : 598401\n",
            "TimeSinceStart : 619.4155690670013\n",
            "Training Loss : -24.596012115478516\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 295 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 152.0885467529297\n",
            "Eval_StdReturn : 13.094014167785645\n",
            "Eval_MaxReturn : 175.61920166015625\n",
            "Eval_MinReturn : 136.39767456054688\n",
            "Eval_AverageEpLen : 96.2\n",
            "Train_AverageReturn : 145.05026245117188\n",
            "Train_StdReturn : 18.024688720703125\n",
            "Train_MaxReturn : 179.55819702148438\n",
            "Train_MinReturn : 89.744140625\n",
            "Train_AverageEpLen : 92.31818181818181\n",
            "Train_EnvstepsSoFar : 600432\n",
            "TimeSinceStart : 621.6422820091248\n",
            "Training Loss : 52.35749053955078\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 296 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 138.79281616210938\n",
            "Eval_StdReturn : 9.284021377563477\n",
            "Eval_MaxReturn : 156.96949768066406\n",
            "Eval_MinReturn : 131.30357360839844\n",
            "Eval_AverageEpLen : 89.0\n",
            "Train_AverageReturn : 142.2822723388672\n",
            "Train_StdReturn : 12.869376182556152\n",
            "Train_MaxReturn : 158.54600524902344\n",
            "Train_MinReturn : 116.68521118164062\n",
            "Train_AverageEpLen : 91.5909090909091\n",
            "Train_EnvstepsSoFar : 602447\n",
            "TimeSinceStart : 623.8017628192902\n",
            "Training Loss : -10.227533340454102\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 297 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 131.70419311523438\n",
            "Eval_StdReturn : 6.151980876922607\n",
            "Eval_MaxReturn : 138.10723876953125\n",
            "Eval_MinReturn : 124.25325775146484\n",
            "Eval_AverageEpLen : 84.8\n",
            "Train_AverageReturn : 149.63211059570312\n",
            "Train_StdReturn : 13.276185989379883\n",
            "Train_MaxReturn : 171.80027770996094\n",
            "Train_MinReturn : 127.86289978027344\n",
            "Train_AverageEpLen : 96.66666666666667\n",
            "Train_EnvstepsSoFar : 604477\n",
            "TimeSinceStart : 626.0656776428223\n",
            "Training Loss : 69.13346862792969\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 298 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 131.43130493164062\n",
            "Eval_StdReturn : 16.556406021118164\n",
            "Eval_MaxReturn : 150.95323181152344\n",
            "Eval_MinReturn : 104.28478240966797\n",
            "Eval_AverageEpLen : 85.8\n",
            "Train_AverageReturn : 138.7335968017578\n",
            "Train_StdReturn : 12.059966087341309\n",
            "Train_MaxReturn : 160.523681640625\n",
            "Train_MinReturn : 116.67896270751953\n",
            "Train_AverageEpLen : 89.6086956521739\n",
            "Train_EnvstepsSoFar : 606538\n",
            "TimeSinceStart : 628.2378730773926\n",
            "Training Loss : -18.188297271728516\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 299 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 150.6949462890625\n",
            "Eval_StdReturn : 7.119939804077148\n",
            "Eval_MaxReturn : 160.8483428955078\n",
            "Eval_MinReturn : 139.36158752441406\n",
            "Eval_AverageEpLen : 97.6\n",
            "Train_AverageReturn : 142.29335021972656\n",
            "Train_StdReturn : 17.836204528808594\n",
            "Train_MaxReturn : 169.93081665039062\n",
            "Train_MinReturn : 105.48451232910156\n",
            "Train_AverageEpLen : 90.69565217391305\n",
            "Train_EnvstepsSoFar : 608624\n",
            "TimeSinceStart : 630.5168495178223\n",
            "Training Loss : -3.2004318237304688\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name Hopper-v2 --ep_len 1000 \\\n",
        "    --discount 0.99 -n 300 -l 2 -s 32 -b 2000 -lr 0.001 \\\n",
        "    --reward_to_go --nn_baseline \\\n",
        "    --action_noise_std 0.5 --gae_lambda 0 \\\n",
        "    --exp_name q5_b2000_r0.001_lambda0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YQFswFZMotI",
        "outputId": "aac1271f-ec89-4635-cca9-67067e0c553a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Eval_StdReturn : 18.12845230102539\n",
            "Eval_MaxReturn : 247.04405212402344\n",
            "Eval_MinReturn : 197.08059692382812\n",
            "Eval_AverageEpLen : 109.0\n",
            "Train_AverageReturn : 226.01329040527344\n",
            "Train_StdReturn : 11.917474746704102\n",
            "Train_MaxReturn : 245.3939666748047\n",
            "Train_MinReturn : 207.41043090820312\n",
            "Train_AverageEpLen : 107.57894736842105\n",
            "Train_EnvstepsSoFar : 249194\n",
            "TimeSinceStart : 264.4379880428314\n",
            "Training Loss : 62.68819046020508\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 122 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 249.981201171875\n",
            "Eval_StdReturn : 18.770957946777344\n",
            "Eval_MaxReturn : 280.18975830078125\n",
            "Eval_MinReturn : 228.87399291992188\n",
            "Eval_AverageEpLen : 121.75\n",
            "Train_AverageReturn : 211.69091796875\n",
            "Train_StdReturn : 30.488269805908203\n",
            "Train_MaxReturn : 239.5487518310547\n",
            "Train_MinReturn : 96.40721130371094\n",
            "Train_AverageEpLen : 100.1\n",
            "Train_EnvstepsSoFar : 251196\n",
            "TimeSinceStart : 266.60439682006836\n",
            "Training Loss : 6.554370880126953\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 123 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.03311157226562\n",
            "Eval_StdReturn : 8.675150871276855\n",
            "Eval_MaxReturn : 254.06654357910156\n",
            "Eval_MinReturn : 233.70034790039062\n",
            "Eval_AverageEpLen : 120.5\n",
            "Train_AverageReturn : 218.2383270263672\n",
            "Train_StdReturn : 28.625186920166016\n",
            "Train_MaxReturn : 253.18508911132812\n",
            "Train_MinReturn : 119.39659881591797\n",
            "Train_AverageEpLen : 105.52631578947368\n",
            "Train_EnvstepsSoFar : 253201\n",
            "TimeSinceStart : 268.7896387577057\n",
            "Training Loss : 24.20560073852539\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 124 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 217.92454528808594\n",
            "Eval_StdReturn : 24.644641876220703\n",
            "Eval_MaxReturn : 252.7078399658203\n",
            "Eval_MinReturn : 186.5469207763672\n",
            "Eval_AverageEpLen : 112.25\n",
            "Train_AverageReturn : 230.7635040283203\n",
            "Train_StdReturn : 26.126821517944336\n",
            "Train_MaxReturn : 276.94378662109375\n",
            "Train_MinReturn : 178.66314697265625\n",
            "Train_AverageEpLen : 114.05555555555556\n",
            "Train_EnvstepsSoFar : 255254\n",
            "TimeSinceStart : 271.035276889801\n",
            "Training Loss : -70.27436828613281\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 125 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 228.00802612304688\n",
            "Eval_StdReturn : 6.499133586883545\n",
            "Eval_MaxReturn : 236.4625244140625\n",
            "Eval_MinReturn : 218.18276977539062\n",
            "Eval_AverageEpLen : 103.5\n",
            "Train_AverageReturn : 224.0595703125\n",
            "Train_StdReturn : 30.377771377563477\n",
            "Train_MaxReturn : 272.129638671875\n",
            "Train_MinReturn : 133.60301208496094\n",
            "Train_AverageEpLen : 105.1\n",
            "Train_EnvstepsSoFar : 257356\n",
            "TimeSinceStart : 273.3568305969238\n",
            "Training Loss : 78.27603912353516\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 126 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 231.0546875\n",
            "Eval_StdReturn : 22.719533920288086\n",
            "Eval_MaxReturn : 269.1537780761719\n",
            "Eval_MinReturn : 209.95094299316406\n",
            "Eval_AverageEpLen : 114.25\n",
            "Train_AverageReturn : 218.86793518066406\n",
            "Train_StdReturn : 31.216318130493164\n",
            "Train_MaxReturn : 267.66204833984375\n",
            "Train_MinReturn : 140.6472930908203\n",
            "Train_AverageEpLen : 107.36842105263158\n",
            "Train_EnvstepsSoFar : 259396\n",
            "TimeSinceStart : 275.5540175437927\n",
            "Training Loss : 39.406944274902344\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 127 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 228.43576049804688\n",
            "Eval_StdReturn : 8.013476371765137\n",
            "Eval_MaxReturn : 240.25213623046875\n",
            "Eval_MinReturn : 218.59849548339844\n",
            "Eval_AverageEpLen : 110.5\n",
            "Train_AverageReturn : 216.36508178710938\n",
            "Train_StdReturn : 33.27419662475586\n",
            "Train_MaxReturn : 270.49383544921875\n",
            "Train_MinReturn : 100.80255889892578\n",
            "Train_AverageEpLen : 105.94736842105263\n",
            "Train_EnvstepsSoFar : 261409\n",
            "TimeSinceStart : 277.70919919013977\n",
            "Training Loss : -68.42431640625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 128 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.23544311523438\n",
            "Eval_StdReturn : 5.672537326812744\n",
            "Eval_MaxReturn : 243.51710510253906\n",
            "Eval_MinReturn : 228.19009399414062\n",
            "Eval_AverageEpLen : 119.25\n",
            "Train_AverageReturn : 214.48696899414062\n",
            "Train_StdReturn : 29.754419326782227\n",
            "Train_MaxReturn : 264.73114013671875\n",
            "Train_MinReturn : 101.05790710449219\n",
            "Train_AverageEpLen : 103.35\n",
            "Train_EnvstepsSoFar : 263476\n",
            "TimeSinceStart : 279.94732546806335\n",
            "Training Loss : -11.794574737548828\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 129 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 227.0263671875\n",
            "Eval_StdReturn : 18.42960548400879\n",
            "Eval_MaxReturn : 244.15809631347656\n",
            "Eval_MinReturn : 196.2320556640625\n",
            "Eval_AverageEpLen : 105.5\n",
            "Train_AverageReturn : 230.3353271484375\n",
            "Train_StdReturn : 16.10033416748047\n",
            "Train_MaxReturn : 267.70220947265625\n",
            "Train_MinReturn : 209.55929565429688\n",
            "Train_AverageEpLen : 110.26315789473684\n",
            "Train_EnvstepsSoFar : 265571\n",
            "TimeSinceStart : 282.15474677085876\n",
            "Training Loss : -1.6773128509521484\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 130 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 226.485595703125\n",
            "Eval_StdReturn : 22.66830825805664\n",
            "Eval_MaxReturn : 253.72830200195312\n",
            "Eval_MinReturn : 190.90753173828125\n",
            "Eval_AverageEpLen : 113.75\n",
            "Train_AverageReturn : 226.10655212402344\n",
            "Train_StdReturn : 18.307941436767578\n",
            "Train_MaxReturn : 282.6318664550781\n",
            "Train_MinReturn : 197.88714599609375\n",
            "Train_AverageEpLen : 108.84210526315789\n",
            "Train_EnvstepsSoFar : 267639\n",
            "TimeSinceStart : 284.3964650630951\n",
            "Training Loss : -32.81306076049805\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 131 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 246.89920043945312\n",
            "Eval_StdReturn : 5.236333847045898\n",
            "Eval_MaxReturn : 253.30117797851562\n",
            "Eval_MinReturn : 238.72972106933594\n",
            "Eval_AverageEpLen : 124.5\n",
            "Train_AverageReturn : 216.3934783935547\n",
            "Train_StdReturn : 34.3704719543457\n",
            "Train_MaxReturn : 299.728515625\n",
            "Train_MinReturn : 136.75245666503906\n",
            "Train_AverageEpLen : 106.52631578947368\n",
            "Train_EnvstepsSoFar : 269663\n",
            "TimeSinceStart : 286.62636160850525\n",
            "Training Loss : 83.33201599121094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 132 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 228.0494384765625\n",
            "Eval_StdReturn : 10.17245101928711\n",
            "Eval_MaxReturn : 243.36810302734375\n",
            "Eval_MinReturn : 215.10289001464844\n",
            "Eval_AverageEpLen : 103.0\n",
            "Train_AverageReturn : 223.0717315673828\n",
            "Train_StdReturn : 26.859668731689453\n",
            "Train_MaxReturn : 305.9470520019531\n",
            "Train_MinReturn : 178.44631958007812\n",
            "Train_AverageEpLen : 107.05263157894737\n",
            "Train_EnvstepsSoFar : 271697\n",
            "TimeSinceStart : 288.80681252479553\n",
            "Training Loss : -103.6676254272461\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 133 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 240.44366455078125\n",
            "Eval_StdReturn : 10.78532886505127\n",
            "Eval_MaxReturn : 256.85028076171875\n",
            "Eval_MinReturn : 230.04208374023438\n",
            "Eval_AverageEpLen : 113.75\n",
            "Train_AverageReturn : 220.61106872558594\n",
            "Train_StdReturn : 23.89737319946289\n",
            "Train_MaxReturn : 252.13522338867188\n",
            "Train_MinReturn : 149.23855590820312\n",
            "Train_AverageEpLen : 105.3157894736842\n",
            "Train_EnvstepsSoFar : 273698\n",
            "TimeSinceStart : 291.0090100765228\n",
            "Training Loss : 63.4581413269043\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 134 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 213.04336547851562\n",
            "Eval_StdReturn : 7.645365238189697\n",
            "Eval_MaxReturn : 224.46461486816406\n",
            "Eval_MinReturn : 204.41082763671875\n",
            "Eval_AverageEpLen : 105.5\n",
            "Train_AverageReturn : 221.5555419921875\n",
            "Train_StdReturn : 37.400413513183594\n",
            "Train_MaxReturn : 276.11376953125\n",
            "Train_MinReturn : 96.7962646484375\n",
            "Train_AverageEpLen : 107.73684210526316\n",
            "Train_EnvstepsSoFar : 275745\n",
            "TimeSinceStart : 293.2883906364441\n",
            "Training Loss : -70.50595092773438\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 135 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 255.5771484375\n",
            "Eval_StdReturn : 54.79347610473633\n",
            "Eval_MaxReturn : 325.1999206542969\n",
            "Eval_MinReturn : 191.30409240722656\n",
            "Eval_AverageEpLen : 138.66666666666666\n",
            "Train_AverageReturn : 223.46969604492188\n",
            "Train_StdReturn : 23.3758602142334\n",
            "Train_MaxReturn : 270.32501220703125\n",
            "Train_MinReturn : 168.3299102783203\n",
            "Train_AverageEpLen : 105.63157894736842\n",
            "Train_EnvstepsSoFar : 277752\n",
            "TimeSinceStart : 295.463582277298\n",
            "Training Loss : -125.01399230957031\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 136 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.03057861328125\n",
            "Eval_StdReturn : 27.10715675354004\n",
            "Eval_MaxReturn : 283.61932373046875\n",
            "Eval_MinReturn : 216.03842163085938\n",
            "Eval_AverageEpLen : 119.0\n",
            "Train_AverageReturn : 207.76669311523438\n",
            "Train_StdReturn : 38.919612884521484\n",
            "Train_MaxReturn : 275.8134765625\n",
            "Train_MinReturn : 118.5663833618164\n",
            "Train_AverageEpLen : 98.52380952380952\n",
            "Train_EnvstepsSoFar : 279821\n",
            "TimeSinceStart : 297.7775630950928\n",
            "Training Loss : -99.6408462524414\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 137 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 169.57774353027344\n",
            "Eval_StdReturn : 46.60667037963867\n",
            "Eval_MaxReturn : 226.15977478027344\n",
            "Eval_MinReturn : 107.27659606933594\n",
            "Eval_AverageEpLen : 86.2\n",
            "Train_AverageReturn : 229.91433715820312\n",
            "Train_StdReturn : 20.648239135742188\n",
            "Train_MaxReturn : 262.88006591796875\n",
            "Train_MinReturn : 192.89120483398438\n",
            "Train_AverageEpLen : 112.88888888888889\n",
            "Train_EnvstepsSoFar : 281853\n",
            "TimeSinceStart : 299.9849216938019\n",
            "Training Loss : -57.740760803222656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 138 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 201.17662048339844\n",
            "Eval_StdReturn : 51.1766242980957\n",
            "Eval_MaxReturn : 242.25547790527344\n",
            "Eval_MinReturn : 114.3055191040039\n",
            "Eval_AverageEpLen : 100.25\n",
            "Train_AverageReturn : 215.5628662109375\n",
            "Train_StdReturn : 36.80343246459961\n",
            "Train_MaxReturn : 264.33740234375\n",
            "Train_MinReturn : 124.7960205078125\n",
            "Train_AverageEpLen : 102.2\n",
            "Train_EnvstepsSoFar : 283897\n",
            "TimeSinceStart : 302.1439538002014\n",
            "Training Loss : -7.483097076416016\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 139 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 223.78341674804688\n",
            "Eval_StdReturn : 6.967835426330566\n",
            "Eval_MaxReturn : 235.16600036621094\n",
            "Eval_MinReturn : 216.25411987304688\n",
            "Eval_AverageEpLen : 103.0\n",
            "Train_AverageReturn : 223.4479522705078\n",
            "Train_StdReturn : 41.86519241333008\n",
            "Train_MaxReturn : 273.5811462402344\n",
            "Train_MinReturn : 78.10436248779297\n",
            "Train_AverageEpLen : 105.6842105263158\n",
            "Train_EnvstepsSoFar : 285905\n",
            "TimeSinceStart : 304.33490085601807\n",
            "Training Loss : -27.519651412963867\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 140 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 220.25314331054688\n",
            "Eval_StdReturn : 28.178390502929688\n",
            "Eval_MaxReturn : 243.28221130371094\n",
            "Eval_MinReturn : 173.2029571533203\n",
            "Eval_AverageEpLen : 106.75\n",
            "Train_AverageReturn : 225.23129272460938\n",
            "Train_StdReturn : 42.627403259277344\n",
            "Train_MaxReturn : 277.4144592285156\n",
            "Train_MinReturn : 63.13992691040039\n",
            "Train_AverageEpLen : 110.47368421052632\n",
            "Train_EnvstepsSoFar : 288004\n",
            "TimeSinceStart : 306.61976432800293\n",
            "Training Loss : -13.424921035766602\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 141 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 246.24197387695312\n",
            "Eval_StdReturn : 28.544212341308594\n",
            "Eval_MaxReturn : 295.5953063964844\n",
            "Eval_MinReturn : 227.2117462158203\n",
            "Eval_AverageEpLen : 121.0\n",
            "Train_AverageReturn : 213.1298828125\n",
            "Train_StdReturn : 43.479331970214844\n",
            "Train_MaxReturn : 276.99853515625\n",
            "Train_MinReturn : 100.08454895019531\n",
            "Train_AverageEpLen : 106.25\n",
            "Train_EnvstepsSoFar : 290129\n",
            "TimeSinceStart : 308.9047336578369\n",
            "Training Loss : -30.18094253540039\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 142 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.70892333984375\n",
            "Eval_StdReturn : 39.188087463378906\n",
            "Eval_MaxReturn : 267.4718322753906\n",
            "Eval_MinReturn : 168.97276306152344\n",
            "Eval_AverageEpLen : 116.25\n",
            "Train_AverageReturn : 224.7312469482422\n",
            "Train_StdReturn : 28.994487762451172\n",
            "Train_MaxReturn : 277.51202392578125\n",
            "Train_MinReturn : 141.48367309570312\n",
            "Train_AverageEpLen : 110.26315789473684\n",
            "Train_EnvstepsSoFar : 292224\n",
            "TimeSinceStart : 311.15879678726196\n",
            "Training Loss : -10.374197006225586\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 143 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 223.8794403076172\n",
            "Eval_StdReturn : 42.56705093383789\n",
            "Eval_MaxReturn : 278.81781005859375\n",
            "Eval_MinReturn : 148.17001342773438\n",
            "Eval_AverageEpLen : 108.0\n",
            "Train_AverageReturn : 221.8076934814453\n",
            "Train_StdReturn : 21.81814956665039\n",
            "Train_MaxReturn : 278.22491455078125\n",
            "Train_MinReturn : 180.95555114746094\n",
            "Train_AverageEpLen : 106.78947368421052\n",
            "Train_EnvstepsSoFar : 294253\n",
            "TimeSinceStart : 313.3931677341461\n",
            "Training Loss : -32.70143508911133\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 144 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.15963745117188\n",
            "Eval_StdReturn : 25.535497665405273\n",
            "Eval_MaxReturn : 266.856201171875\n",
            "Eval_MinReturn : 195.45318603515625\n",
            "Eval_AverageEpLen : 115.0\n",
            "Train_AverageReturn : 230.56439208984375\n",
            "Train_StdReturn : 25.375513076782227\n",
            "Train_MaxReturn : 285.92120361328125\n",
            "Train_MinReturn : 173.74240112304688\n",
            "Train_AverageEpLen : 112.61111111111111\n",
            "Train_EnvstepsSoFar : 296280\n",
            "TimeSinceStart : 315.62852668762207\n",
            "Training Loss : 44.09319305419922\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 145 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.22276306152344\n",
            "Eval_StdReturn : 12.384758949279785\n",
            "Eval_MaxReturn : 251.632080078125\n",
            "Eval_MinReturn : 217.17117309570312\n",
            "Eval_AverageEpLen : 110.0\n",
            "Train_AverageReturn : 235.49647521972656\n",
            "Train_StdReturn : 25.290273666381836\n",
            "Train_MaxReturn : 296.6698913574219\n",
            "Train_MinReturn : 199.322509765625\n",
            "Train_AverageEpLen : 115.55555555555556\n",
            "Train_EnvstepsSoFar : 298360\n",
            "TimeSinceStart : 317.9392988681793\n",
            "Training Loss : -30.686635971069336\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 146 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 243.11599731445312\n",
            "Eval_StdReturn : 23.209796905517578\n",
            "Eval_MaxReturn : 268.1171875\n",
            "Eval_MinReturn : 211.06393432617188\n",
            "Eval_AverageEpLen : 116.75\n",
            "Train_AverageReturn : 233.85110473632812\n",
            "Train_StdReturn : 20.145835876464844\n",
            "Train_MaxReturn : 271.5372619628906\n",
            "Train_MinReturn : 196.9163818359375\n",
            "Train_AverageEpLen : 111.44444444444444\n",
            "Train_EnvstepsSoFar : 300366\n",
            "TimeSinceStart : 320.1330211162567\n",
            "Training Loss : -55.43097686767578\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 147 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 240.92147827148438\n",
            "Eval_StdReturn : 16.071083068847656\n",
            "Eval_MaxReturn : 264.1820983886719\n",
            "Eval_MinReturn : 222.45863342285156\n",
            "Eval_AverageEpLen : 120.5\n",
            "Train_AverageReturn : 226.4328155517578\n",
            "Train_StdReturn : 39.574588775634766\n",
            "Train_MaxReturn : 275.079833984375\n",
            "Train_MinReturn : 80.37493896484375\n",
            "Train_AverageEpLen : 111.38888888888889\n",
            "Train_EnvstepsSoFar : 302371\n",
            "TimeSinceStart : 322.36201667785645\n",
            "Training Loss : -49.02313995361328\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 148 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 218.07493591308594\n",
            "Eval_StdReturn : 9.321608543395996\n",
            "Eval_MaxReturn : 231.85113525390625\n",
            "Eval_MinReturn : 205.54629516601562\n",
            "Eval_AverageEpLen : 101.25\n",
            "Train_AverageReturn : 235.82864379882812\n",
            "Train_StdReturn : 21.705568313598633\n",
            "Train_MaxReturn : 286.544189453125\n",
            "Train_MinReturn : 202.78253173828125\n",
            "Train_AverageEpLen : 114.72222222222223\n",
            "Train_EnvstepsSoFar : 304436\n",
            "TimeSinceStart : 324.55358362197876\n",
            "Training Loss : 66.48404693603516\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 149 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 221.56980895996094\n",
            "Eval_StdReturn : 10.775835037231445\n",
            "Eval_MaxReturn : 229.09393310546875\n",
            "Eval_MinReturn : 202.95811462402344\n",
            "Eval_AverageEpLen : 102.25\n",
            "Train_AverageReturn : 234.2897491455078\n",
            "Train_StdReturn : 26.1165714263916\n",
            "Train_MaxReturn : 299.3238525390625\n",
            "Train_MinReturn : 177.09584045410156\n",
            "Train_AverageEpLen : 111.57894736842105\n",
            "Train_EnvstepsSoFar : 306556\n",
            "TimeSinceStart : 326.7628016471863\n",
            "Training Loss : -31.464649200439453\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 150 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 230.61090087890625\n",
            "Eval_StdReturn : 14.012571334838867\n",
            "Eval_MaxReturn : 244.4121551513672\n",
            "Eval_MinReturn : 207.40188598632812\n",
            "Eval_AverageEpLen : 108.25\n",
            "Train_AverageReturn : 234.1986541748047\n",
            "Train_StdReturn : 34.025882720947266\n",
            "Train_MaxReturn : 292.1601257324219\n",
            "Train_MinReturn : 131.93038940429688\n",
            "Train_AverageEpLen : 118.47058823529412\n",
            "Train_EnvstepsSoFar : 308570\n",
            "TimeSinceStart : 328.96282267570496\n",
            "Training Loss : -21.245651245117188\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 151 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.44290161132812\n",
            "Eval_StdReturn : 23.536733627319336\n",
            "Eval_MaxReturn : 260.42742919921875\n",
            "Eval_MinReturn : 196.1248321533203\n",
            "Eval_AverageEpLen : 120.75\n",
            "Train_AverageReturn : 226.51657104492188\n",
            "Train_StdReturn : 17.918062210083008\n",
            "Train_MaxReturn : 286.14697265625\n",
            "Train_MinReturn : 195.18429565429688\n",
            "Train_AverageEpLen : 104.9\n",
            "Train_EnvstepsSoFar : 310668\n",
            "TimeSinceStart : 331.27273416519165\n",
            "Training Loss : -140.20213317871094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 152 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 241.2366943359375\n",
            "Eval_StdReturn : 16.876323699951172\n",
            "Eval_MaxReturn : 263.1706848144531\n",
            "Eval_MinReturn : 219.53607177734375\n",
            "Eval_AverageEpLen : 122.5\n",
            "Train_AverageReturn : 232.67713928222656\n",
            "Train_StdReturn : 30.94110679626465\n",
            "Train_MaxReturn : 270.044189453125\n",
            "Train_MinReturn : 133.82028198242188\n",
            "Train_AverageEpLen : 114.72222222222223\n",
            "Train_EnvstepsSoFar : 312733\n",
            "TimeSinceStart : 333.54782342910767\n",
            "Training Loss : -9.111177444458008\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 153 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 231.65408325195312\n",
            "Eval_StdReturn : 14.558533668518066\n",
            "Eval_MaxReturn : 255.86935424804688\n",
            "Eval_MinReturn : 217.23941040039062\n",
            "Eval_AverageEpLen : 113.5\n",
            "Train_AverageReturn : 218.1278076171875\n",
            "Train_StdReturn : 59.80110168457031\n",
            "Train_MaxReturn : 283.872314453125\n",
            "Train_MinReturn : 27.594669342041016\n",
            "Train_AverageEpLen : 110.05263157894737\n",
            "Train_EnvstepsSoFar : 314824\n",
            "TimeSinceStart : 335.81997561454773\n",
            "Training Loss : 13.264799118041992\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 154 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.38726806640625\n",
            "Eval_StdReturn : 17.1335391998291\n",
            "Eval_MaxReturn : 265.48785400390625\n",
            "Eval_MinReturn : 221.82484436035156\n",
            "Eval_AverageEpLen : 116.75\n",
            "Train_AverageReturn : 227.08944702148438\n",
            "Train_StdReturn : 31.068626403808594\n",
            "Train_MaxReturn : 321.382080078125\n",
            "Train_MinReturn : 170.07513427734375\n",
            "Train_AverageEpLen : 113.11111111111111\n",
            "Train_EnvstepsSoFar : 316860\n",
            "TimeSinceStart : 338.0703959465027\n",
            "Training Loss : -89.13925170898438\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 155 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 246.26785278320312\n",
            "Eval_StdReturn : 4.591031074523926\n",
            "Eval_MaxReturn : 251.0341339111328\n",
            "Eval_MinReturn : 239.15972900390625\n",
            "Eval_AverageEpLen : 121.75\n",
            "Train_AverageReturn : 238.2775115966797\n",
            "Train_StdReturn : 41.64106750488281\n",
            "Train_MaxReturn : 307.7358093261719\n",
            "Train_MinReturn : 113.74424743652344\n",
            "Train_AverageEpLen : 118.58823529411765\n",
            "Train_EnvstepsSoFar : 318876\n",
            "TimeSinceStart : 340.3647937774658\n",
            "Training Loss : -30.36619758605957\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 156 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.3824920654297\n",
            "Eval_StdReturn : 18.884708404541016\n",
            "Eval_MaxReturn : 252.23353576660156\n",
            "Eval_MinReturn : 204.85252380371094\n",
            "Eval_AverageEpLen : 107.5\n",
            "Train_AverageReturn : 237.82058715820312\n",
            "Train_StdReturn : 55.62744140625\n",
            "Train_MaxReturn : 337.2607116699219\n",
            "Train_MinReturn : 100.7731704711914\n",
            "Train_AverageEpLen : 127.0625\n",
            "Train_EnvstepsSoFar : 320909\n",
            "TimeSinceStart : 342.61901664733887\n",
            "Training Loss : 25.037078857421875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 157 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 249.1739501953125\n",
            "Eval_StdReturn : 11.950505256652832\n",
            "Eval_MaxReturn : 264.5733642578125\n",
            "Eval_MinReturn : 235.75735473632812\n",
            "Eval_AverageEpLen : 126.5\n",
            "Train_AverageReturn : 229.52105712890625\n",
            "Train_StdReturn : 31.324905395507812\n",
            "Train_MaxReturn : 287.7120361328125\n",
            "Train_MinReturn : 156.30337524414062\n",
            "Train_AverageEpLen : 112.38888888888889\n",
            "Train_EnvstepsSoFar : 322932\n",
            "TimeSinceStart : 344.88981199264526\n",
            "Training Loss : -106.21623229980469\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 158 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.56350708007812\n",
            "Eval_StdReturn : 35.40343475341797\n",
            "Eval_MaxReturn : 266.6664733886719\n",
            "Eval_MinReturn : 179.30239868164062\n",
            "Eval_AverageEpLen : 106.75\n",
            "Train_AverageReturn : 248.9328155517578\n",
            "Train_StdReturn : 35.14560317993164\n",
            "Train_MaxReturn : 365.82293701171875\n",
            "Train_MinReturn : 209.87548828125\n",
            "Train_AverageEpLen : 120.82352941176471\n",
            "Train_EnvstepsSoFar : 324986\n",
            "TimeSinceStart : 347.1350464820862\n",
            "Training Loss : -17.485095977783203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 159 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 238.3939208984375\n",
            "Eval_StdReturn : 14.255083084106445\n",
            "Eval_MaxReturn : 251.20126342773438\n",
            "Eval_MinReturn : 215.48013305664062\n",
            "Eval_AverageEpLen : 115.0\n",
            "Train_AverageReturn : 234.18663024902344\n",
            "Train_StdReturn : 21.745983123779297\n",
            "Train_MaxReturn : 282.6505432128906\n",
            "Train_MinReturn : 194.94888305664062\n",
            "Train_AverageEpLen : 118.41176470588235\n",
            "Train_EnvstepsSoFar : 326999\n",
            "TimeSinceStart : 349.3697690963745\n",
            "Training Loss : -110.54923248291016\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 160 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 256.9562072753906\n",
            "Eval_StdReturn : 16.80744171142578\n",
            "Eval_MaxReturn : 273.94189453125\n",
            "Eval_MinReturn : 237.14404296875\n",
            "Eval_AverageEpLen : 127.0\n",
            "Train_AverageReturn : 245.9841766357422\n",
            "Train_StdReturn : 29.182138442993164\n",
            "Train_MaxReturn : 298.213623046875\n",
            "Train_MinReturn : 185.40797424316406\n",
            "Train_AverageEpLen : 119.0\n",
            "Train_EnvstepsSoFar : 329022\n",
            "TimeSinceStart : 351.6117603778839\n",
            "Training Loss : -49.60200119018555\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 161 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 213.4381866455078\n",
            "Eval_StdReturn : 56.5256233215332\n",
            "Eval_MaxReturn : 259.0733642578125\n",
            "Eval_MinReturn : 116.6175537109375\n",
            "Eval_AverageEpLen : 103.25\n",
            "Train_AverageReturn : 237.34246826171875\n",
            "Train_StdReturn : 28.633241653442383\n",
            "Train_MaxReturn : 304.79254150390625\n",
            "Train_MinReturn : 206.447265625\n",
            "Train_AverageEpLen : 117.5\n",
            "Train_EnvstepsSoFar : 331137\n",
            "TimeSinceStart : 353.86055755615234\n",
            "Training Loss : -12.700141906738281\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 162 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 247.2486572265625\n",
            "Eval_StdReturn : 29.918596267700195\n",
            "Eval_MaxReturn : 288.1937255859375\n",
            "Eval_MinReturn : 217.53981018066406\n",
            "Eval_AverageEpLen : 137.66666666666666\n",
            "Train_AverageReturn : 241.6091766357422\n",
            "Train_StdReturn : 24.56427001953125\n",
            "Train_MaxReturn : 311.389892578125\n",
            "Train_MinReturn : 207.79489135742188\n",
            "Train_AverageEpLen : 121.23529411764706\n",
            "Train_EnvstepsSoFar : 333198\n",
            "TimeSinceStart : 356.1223065853119\n",
            "Training Loss : 59.48316955566406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 163 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 253.2544403076172\n",
            "Eval_StdReturn : 6.587462902069092\n",
            "Eval_MaxReturn : 262.51739501953125\n",
            "Eval_MinReturn : 245.2799530029297\n",
            "Eval_AverageEpLen : 125.75\n",
            "Train_AverageReturn : 231.15960693359375\n",
            "Train_StdReturn : 56.5065803527832\n",
            "Train_MaxReturn : 272.44952392578125\n",
            "Train_MinReturn : 13.690664291381836\n",
            "Train_AverageEpLen : 114.83333333333333\n",
            "Train_EnvstepsSoFar : 335265\n",
            "TimeSinceStart : 358.4872510433197\n",
            "Training Loss : -89.21174621582031\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 164 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 262.6195983886719\n",
            "Eval_StdReturn : 42.376930236816406\n",
            "Eval_MaxReturn : 331.34765625\n",
            "Eval_MinReturn : 218.66775512695312\n",
            "Eval_AverageEpLen : 130.5\n",
            "Train_AverageReturn : 227.94192504882812\n",
            "Train_StdReturn : 45.550018310546875\n",
            "Train_MaxReturn : 275.6378173828125\n",
            "Train_MinReturn : 64.50968170166016\n",
            "Train_AverageEpLen : 113.27777777777777\n",
            "Train_EnvstepsSoFar : 337304\n",
            "TimeSinceStart : 360.7699511051178\n",
            "Training Loss : -15.595283508300781\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 165 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 220.20147705078125\n",
            "Eval_StdReturn : 23.494266510009766\n",
            "Eval_MaxReturn : 259.96649169921875\n",
            "Eval_MinReturn : 199.83572387695312\n",
            "Eval_AverageEpLen : 112.75\n",
            "Train_AverageReturn : 235.62815856933594\n",
            "Train_StdReturn : 29.19513702392578\n",
            "Train_MaxReturn : 315.86212158203125\n",
            "Train_MinReturn : 197.76304626464844\n",
            "Train_AverageEpLen : 119.17647058823529\n",
            "Train_EnvstepsSoFar : 339330\n",
            "TimeSinceStart : 363.05136251449585\n",
            "Training Loss : 135.2154083251953\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 166 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 230.0423126220703\n",
            "Eval_StdReturn : 12.98507022857666\n",
            "Eval_MaxReturn : 239.52377319335938\n",
            "Eval_MinReturn : 207.73883056640625\n",
            "Eval_AverageEpLen : 106.5\n",
            "Train_AverageReturn : 237.33335876464844\n",
            "Train_StdReturn : 17.66553497314453\n",
            "Train_MaxReturn : 274.6824951171875\n",
            "Train_MinReturn : 215.90997314453125\n",
            "Train_AverageEpLen : 115.61111111111111\n",
            "Train_EnvstepsSoFar : 341411\n",
            "TimeSinceStart : 365.2871720790863\n",
            "Training Loss : 19.742158889770508\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 167 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.97816467285156\n",
            "Eval_StdReturn : 16.43025779724121\n",
            "Eval_MaxReturn : 255.11305236816406\n",
            "Eval_MinReturn : 214.74301147460938\n",
            "Eval_AverageEpLen : 118.5\n",
            "Train_AverageReturn : 244.5926513671875\n",
            "Train_StdReturn : 40.54145431518555\n",
            "Train_MaxReturn : 307.1763000488281\n",
            "Train_MinReturn : 116.76399230957031\n",
            "Train_AverageEpLen : 122.58823529411765\n",
            "Train_EnvstepsSoFar : 343495\n",
            "TimeSinceStart : 367.5999572277069\n",
            "Training Loss : 32.307273864746094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 168 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 222.3528289794922\n",
            "Eval_StdReturn : 50.92816162109375\n",
            "Eval_MaxReturn : 258.3607482910156\n",
            "Eval_MinReturn : 134.55889892578125\n",
            "Eval_AverageEpLen : 109.75\n",
            "Train_AverageReturn : 251.35934448242188\n",
            "Train_StdReturn : 56.94997024536133\n",
            "Train_MaxReturn : 370.9111328125\n",
            "Train_MinReturn : 90.22428131103516\n",
            "Train_AverageEpLen : 123.05882352941177\n",
            "Train_EnvstepsSoFar : 345587\n",
            "TimeSinceStart : 369.91423296928406\n",
            "Training Loss : -68.3276138305664\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 169 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.62716674804688\n",
            "Eval_StdReturn : 24.537322998046875\n",
            "Eval_MaxReturn : 264.4840087890625\n",
            "Eval_MinReturn : 205.52015686035156\n",
            "Eval_AverageEpLen : 128.0\n",
            "Train_AverageReturn : 247.0236053466797\n",
            "Train_StdReturn : 36.8721809387207\n",
            "Train_MaxReturn : 327.060302734375\n",
            "Train_MinReturn : 175.4217987060547\n",
            "Train_AverageEpLen : 123.41176470588235\n",
            "Train_EnvstepsSoFar : 347685\n",
            "TimeSinceStart : 372.29010105133057\n",
            "Training Loss : -13.743617057800293\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 170 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 230.18902587890625\n",
            "Eval_StdReturn : 53.798927307128906\n",
            "Eval_MaxReturn : 275.1461181640625\n",
            "Eval_MinReturn : 138.51617431640625\n",
            "Eval_AverageEpLen : 108.25\n",
            "Train_AverageReturn : 253.16725158691406\n",
            "Train_StdReturn : 44.50662612915039\n",
            "Train_MaxReturn : 320.474609375\n",
            "Train_MinReturn : 140.10491943359375\n",
            "Train_AverageEpLen : 129.0625\n",
            "Train_EnvstepsSoFar : 349750\n",
            "TimeSinceStart : 374.5862681865692\n",
            "Training Loss : -39.508087158203125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 171 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.05999755859375\n",
            "Eval_StdReturn : 14.067659378051758\n",
            "Eval_MaxReturn : 265.7038879394531\n",
            "Eval_MinReturn : 229.7459259033203\n",
            "Eval_AverageEpLen : 122.0\n",
            "Train_AverageReturn : 247.6529998779297\n",
            "Train_StdReturn : 54.607208251953125\n",
            "Train_MaxReturn : 353.30316162109375\n",
            "Train_MinReturn : 81.46080780029297\n",
            "Train_AverageEpLen : 123.76470588235294\n",
            "Train_EnvstepsSoFar : 351854\n",
            "TimeSinceStart : 376.949102640152\n",
            "Training Loss : -33.052364349365234\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 172 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 262.9207458496094\n",
            "Eval_StdReturn : 12.960474967956543\n",
            "Eval_MaxReturn : 283.923828125\n",
            "Eval_MinReturn : 250.67214965820312\n",
            "Eval_AverageEpLen : 128.5\n",
            "Train_AverageReturn : 257.32470703125\n",
            "Train_StdReturn : 24.194704055786133\n",
            "Train_MaxReturn : 326.2644958496094\n",
            "Train_MinReturn : 219.69174194335938\n",
            "Train_AverageEpLen : 125.8125\n",
            "Train_EnvstepsSoFar : 353867\n",
            "TimeSinceStart : 379.2223525047302\n",
            "Training Loss : -6.532871246337891\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 173 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 257.8235778808594\n",
            "Eval_StdReturn : 27.32244300842285\n",
            "Eval_MaxReturn : 295.1809387207031\n",
            "Eval_MinReturn : 218.00706481933594\n",
            "Eval_AverageEpLen : 117.75\n",
            "Train_AverageReturn : 250.72193908691406\n",
            "Train_StdReturn : 38.86774444580078\n",
            "Train_MaxReturn : 318.6195373535156\n",
            "Train_MinReturn : 185.3605499267578\n",
            "Train_AverageEpLen : 125.25\n",
            "Train_EnvstepsSoFar : 355871\n",
            "TimeSinceStart : 381.48015427589417\n",
            "Training Loss : -135.55128479003906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 174 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 265.2412109375\n",
            "Eval_StdReturn : 29.048736572265625\n",
            "Eval_MaxReturn : 314.724853515625\n",
            "Eval_MinReturn : 242.07366943359375\n",
            "Eval_AverageEpLen : 139.25\n",
            "Train_AverageReturn : 269.845703125\n",
            "Train_StdReturn : 29.68227767944336\n",
            "Train_MaxReturn : 332.5196228027344\n",
            "Train_MinReturn : 207.8161163330078\n",
            "Train_AverageEpLen : 136.93333333333334\n",
            "Train_EnvstepsSoFar : 357925\n",
            "TimeSinceStart : 383.86397194862366\n",
            "Training Loss : 64.18860626220703\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 175 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 240.30355834960938\n",
            "Eval_StdReturn : 15.651122093200684\n",
            "Eval_MaxReturn : 265.9037170410156\n",
            "Eval_MinReturn : 224.33596801757812\n",
            "Eval_AverageEpLen : 113.0\n",
            "Train_AverageReturn : 271.00042724609375\n",
            "Train_StdReturn : 59.32801818847656\n",
            "Train_MaxReturn : 360.0008239746094\n",
            "Train_MinReturn : 115.10618591308594\n",
            "Train_AverageEpLen : 137.53333333333333\n",
            "Train_EnvstepsSoFar : 359988\n",
            "TimeSinceStart : 386.1906020641327\n",
            "Training Loss : -13.843917846679688\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 176 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 229.01458740234375\n",
            "Eval_StdReturn : 16.70214080810547\n",
            "Eval_MaxReturn : 253.6465301513672\n",
            "Eval_MinReturn : 207.83116149902344\n",
            "Eval_AverageEpLen : 112.5\n",
            "Train_AverageReturn : 273.62982177734375\n",
            "Train_StdReturn : 31.38349151611328\n",
            "Train_MaxReturn : 344.9852294921875\n",
            "Train_MinReturn : 234.6380157470703\n",
            "Train_AverageEpLen : 134.33333333333334\n",
            "Train_EnvstepsSoFar : 362003\n",
            "TimeSinceStart : 388.50206565856934\n",
            "Training Loss : 2.962514877319336\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 177 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 213.19607543945312\n",
            "Eval_StdReturn : 65.22186279296875\n",
            "Eval_MaxReturn : 299.2706298828125\n",
            "Eval_MinReturn : 115.60311126708984\n",
            "Eval_AverageEpLen : 117.5\n",
            "Train_AverageReturn : 264.8049011230469\n",
            "Train_StdReturn : 47.71934127807617\n",
            "Train_MaxReturn : 355.27203369140625\n",
            "Train_MinReturn : 206.12612915039062\n",
            "Train_AverageEpLen : 134.2\n",
            "Train_EnvstepsSoFar : 364016\n",
            "TimeSinceStart : 390.80895590782166\n",
            "Training Loss : 21.683101654052734\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 178 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 300.0570983886719\n",
            "Eval_StdReturn : 27.908418655395508\n",
            "Eval_MaxReturn : 338.27337646484375\n",
            "Eval_MinReturn : 272.4074401855469\n",
            "Eval_AverageEpLen : 165.33333333333334\n",
            "Train_AverageReturn : 263.45733642578125\n",
            "Train_StdReturn : 56.1466178894043\n",
            "Train_MaxReturn : 347.2813720703125\n",
            "Train_MinReturn : 98.75112915039062\n",
            "Train_AverageEpLen : 130.9375\n",
            "Train_EnvstepsSoFar : 366111\n",
            "TimeSinceStart : 393.2282359600067\n",
            "Training Loss : 29.87676429748535\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 179 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 280.1653747558594\n",
            "Eval_StdReturn : 26.00069808959961\n",
            "Eval_MaxReturn : 315.3822021484375\n",
            "Eval_MinReturn : 253.39805603027344\n",
            "Eval_AverageEpLen : 157.66666666666666\n",
            "Train_AverageReturn : 249.17294311523438\n",
            "Train_StdReturn : 54.19297790527344\n",
            "Train_MaxReturn : 344.391357421875\n",
            "Train_MinReturn : 128.46725463867188\n",
            "Train_AverageEpLen : 129.1875\n",
            "Train_EnvstepsSoFar : 368178\n",
            "TimeSinceStart : 395.5707278251648\n",
            "Training Loss : -31.876842498779297\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 180 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 324.5971374511719\n",
            "Eval_StdReturn : 38.58978271484375\n",
            "Eval_MaxReturn : 365.0089416503906\n",
            "Eval_MinReturn : 272.6277160644531\n",
            "Eval_AverageEpLen : 164.0\n",
            "Train_AverageReturn : 246.50347900390625\n",
            "Train_StdReturn : 89.121337890625\n",
            "Train_MaxReturn : 361.1524353027344\n",
            "Train_MinReturn : 53.015724182128906\n",
            "Train_AverageEpLen : 136.6\n",
            "Train_EnvstepsSoFar : 370227\n",
            "TimeSinceStart : 397.9180648326874\n",
            "Training Loss : -55.54462814331055\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 181 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 288.8291931152344\n",
            "Eval_StdReturn : 14.666501998901367\n",
            "Eval_MaxReturn : 309.38323974609375\n",
            "Eval_MinReturn : 276.142333984375\n",
            "Eval_AverageEpLen : 140.66666666666666\n",
            "Train_AverageReturn : 301.6743469238281\n",
            "Train_StdReturn : 71.84425354003906\n",
            "Train_MaxReturn : 441.712646484375\n",
            "Train_MinReturn : 183.0018768310547\n",
            "Train_AverageEpLen : 157.6153846153846\n",
            "Train_EnvstepsSoFar : 372276\n",
            "TimeSinceStart : 400.26768922805786\n",
            "Training Loss : -73.75352478027344\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 182 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 248.4617919921875\n",
            "Eval_StdReturn : 111.7682876586914\n",
            "Eval_MaxReturn : 338.18914794921875\n",
            "Eval_MinReturn : 90.90394592285156\n",
            "Eval_AverageEpLen : 134.66666666666666\n",
            "Train_AverageReturn : 271.7362060546875\n",
            "Train_StdReturn : 42.18816375732422\n",
            "Train_MaxReturn : 350.2410583496094\n",
            "Train_MinReturn : 183.7160186767578\n",
            "Train_AverageEpLen : 133.6875\n",
            "Train_EnvstepsSoFar : 374415\n",
            "TimeSinceStart : 402.54496812820435\n",
            "Training Loss : 27.540504455566406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 183 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 291.031982421875\n",
            "Eval_StdReturn : 5.592763423919678\n",
            "Eval_MaxReturn : 297.3205871582031\n",
            "Eval_MinReturn : 283.73333740234375\n",
            "Eval_AverageEpLen : 147.66666666666666\n",
            "Train_AverageReturn : 288.61077880859375\n",
            "Train_StdReturn : 56.70355987548828\n",
            "Train_MaxReturn : 404.175537109375\n",
            "Train_MinReturn : 206.56082153320312\n",
            "Train_AverageEpLen : 151.35714285714286\n",
            "Train_EnvstepsSoFar : 376534\n",
            "TimeSinceStart : 404.91366815567017\n",
            "Training Loss : 46.42869567871094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 184 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 284.7472839355469\n",
            "Eval_StdReturn : 4.630867958068848\n",
            "Eval_MaxReturn : 288.7902526855469\n",
            "Eval_MinReturn : 278.2639465332031\n",
            "Eval_AverageEpLen : 141.33333333333334\n",
            "Train_AverageReturn : 272.2451477050781\n",
            "Train_StdReturn : 41.94057083129883\n",
            "Train_MaxReturn : 322.2270202636719\n",
            "Train_MinReturn : 152.5557098388672\n",
            "Train_AverageEpLen : 143.28571428571428\n",
            "Train_EnvstepsSoFar : 378540\n",
            "TimeSinceStart : 407.1626229286194\n",
            "Training Loss : -63.21399688720703\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 185 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 247.564697265625\n",
            "Eval_StdReturn : 38.751953125\n",
            "Eval_MaxReturn : 309.46490478515625\n",
            "Eval_MinReturn : 202.8040771484375\n",
            "Eval_AverageEpLen : 124.25\n",
            "Train_AverageReturn : 306.79425048828125\n",
            "Train_StdReturn : 108.41202545166016\n",
            "Train_MaxReturn : 559.0574951171875\n",
            "Train_MinReturn : 152.60977172851562\n",
            "Train_AverageEpLen : 170.33333333333334\n",
            "Train_EnvstepsSoFar : 380584\n",
            "TimeSinceStart : 409.5576844215393\n",
            "Training Loss : -89.81784057617188\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 186 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 383.1934814453125\n",
            "Eval_StdReturn : 87.99735260009766\n",
            "Eval_MaxReturn : 504.8429870605469\n",
            "Eval_MinReturn : 299.6454772949219\n",
            "Eval_AverageEpLen : 174.66666666666666\n",
            "Train_AverageReturn : 297.8472595214844\n",
            "Train_StdReturn : 59.07487106323242\n",
            "Train_MaxReturn : 384.6419372558594\n",
            "Train_MinReturn : 171.378173828125\n",
            "Train_AverageEpLen : 150.71428571428572\n",
            "Train_EnvstepsSoFar : 382694\n",
            "TimeSinceStart : 412.0391583442688\n",
            "Training Loss : -66.03616333007812\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 187 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 202.06919860839844\n",
            "Eval_StdReturn : 54.95780563354492\n",
            "Eval_MaxReturn : 288.7117919921875\n",
            "Eval_MinReturn : 153.3762664794922\n",
            "Eval_AverageEpLen : 119.25\n",
            "Train_AverageReturn : 329.2922058105469\n",
            "Train_StdReturn : 107.01600646972656\n",
            "Train_MaxReturn : 503.6431579589844\n",
            "Train_MinReturn : 113.03422546386719\n",
            "Train_AverageEpLen : 173.5\n",
            "Train_EnvstepsSoFar : 384776\n",
            "TimeSinceStart : 414.48016929626465\n",
            "Training Loss : -73.70645141601562\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 188 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 310.8502197265625\n",
            "Eval_StdReturn : 27.264617919921875\n",
            "Eval_MaxReturn : 332.7646484375\n",
            "Eval_MinReturn : 272.4183349609375\n",
            "Eval_AverageEpLen : 143.0\n",
            "Train_AverageReturn : 286.11724853515625\n",
            "Train_StdReturn : 62.58769226074219\n",
            "Train_MaxReturn : 394.1901550292969\n",
            "Train_MinReturn : 186.60537719726562\n",
            "Train_AverageEpLen : 151.57142857142858\n",
            "Train_EnvstepsSoFar : 386898\n",
            "TimeSinceStart : 416.80419421195984\n",
            "Training Loss : -53.07831954956055\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 189 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 311.9184875488281\n",
            "Eval_StdReturn : 58.90544128417969\n",
            "Eval_MaxReturn : 375.6305847167969\n",
            "Eval_MinReturn : 233.58285522460938\n",
            "Eval_AverageEpLen : 157.33333333333334\n",
            "Train_AverageReturn : 309.4114685058594\n",
            "Train_StdReturn : 66.52262115478516\n",
            "Train_MaxReturn : 441.4163513183594\n",
            "Train_MinReturn : 199.2469024658203\n",
            "Train_AverageEpLen : 150.28571428571428\n",
            "Train_EnvstepsSoFar : 389002\n",
            "TimeSinceStart : 419.163685798645\n",
            "Training Loss : 3.6353816986083984\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 190 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 369.5538024902344\n",
            "Eval_StdReturn : 44.21053695678711\n",
            "Eval_MaxReturn : 402.3492736816406\n",
            "Eval_MinReturn : 307.05615234375\n",
            "Eval_AverageEpLen : 175.66666666666666\n",
            "Train_AverageReturn : 360.3130798339844\n",
            "Train_StdReturn : 101.0705337524414\n",
            "Train_MaxReturn : 586.13671875\n",
            "Train_MinReturn : 232.0170135498047\n",
            "Train_AverageEpLen : 185.8181818181818\n",
            "Train_EnvstepsSoFar : 391046\n",
            "TimeSinceStart : 421.62890625\n",
            "Training Loss : -3.597379684448242\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 191 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 420.4898986816406\n",
            "Eval_StdReturn : 123.43900299072266\n",
            "Eval_MaxReturn : 558.635986328125\n",
            "Eval_MinReturn : 258.9910888671875\n",
            "Eval_AverageEpLen : 218.33333333333334\n",
            "Train_AverageReturn : 344.03314208984375\n",
            "Train_StdReturn : 128.2571258544922\n",
            "Train_MaxReturn : 724.4013671875\n",
            "Train_MinReturn : 147.4268341064453\n",
            "Train_AverageEpLen : 162.07692307692307\n",
            "Train_EnvstepsSoFar : 393153\n",
            "TimeSinceStart : 424.2577290534973\n",
            "Training Loss : -14.771568298339844\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 192 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 378.2291259765625\n",
            "Eval_StdReturn : 125.50518035888672\n",
            "Eval_MaxReturn : 503.73431396484375\n",
            "Eval_MinReturn : 252.7239532470703\n",
            "Eval_AverageEpLen : 248.0\n",
            "Train_AverageReturn : 277.0521545410156\n",
            "Train_StdReturn : 141.7249298095703\n",
            "Train_MaxReturn : 614.99072265625\n",
            "Train_MinReturn : 87.0595703125\n",
            "Train_AverageEpLen : 163.30769230769232\n",
            "Train_EnvstepsSoFar : 395276\n",
            "TimeSinceStart : 426.77270126342773\n",
            "Training Loss : 63.9947624206543\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 193 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 252.48585510253906\n",
            "Eval_StdReturn : 102.78646087646484\n",
            "Eval_MaxReturn : 381.2640686035156\n",
            "Eval_MinReturn : 129.70399475097656\n",
            "Eval_AverageEpLen : 172.66666666666666\n",
            "Train_AverageReturn : 368.60430908203125\n",
            "Train_StdReturn : 168.5734100341797\n",
            "Train_MaxReturn : 736.61474609375\n",
            "Train_MinReturn : 73.12492370605469\n",
            "Train_AverageEpLen : 218.4\n",
            "Train_EnvstepsSoFar : 397460\n",
            "TimeSinceStart : 429.44727778434753\n",
            "Training Loss : -14.952997207641602\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 194 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 460.7259826660156\n",
            "Eval_StdReturn : 43.652313232421875\n",
            "Eval_MaxReturn : 504.3782958984375\n",
            "Eval_MinReturn : 417.07366943359375\n",
            "Eval_AverageEpLen : 236.5\n",
            "Train_AverageReturn : 320.1570129394531\n",
            "Train_StdReturn : 106.73628234863281\n",
            "Train_MaxReturn : 533.0708618164062\n",
            "Train_MinReturn : 156.320556640625\n",
            "Train_AverageEpLen : 177.66666666666666\n",
            "Train_EnvstepsSoFar : 399592\n",
            "TimeSinceStart : 431.9380695819855\n",
            "Training Loss : -81.70635986328125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 195 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 381.9285583496094\n",
            "Eval_StdReturn : 7.45602560043335\n",
            "Eval_MaxReturn : 392.29571533203125\n",
            "Eval_MinReturn : 375.07757568359375\n",
            "Eval_AverageEpLen : 175.66666666666666\n",
            "Train_AverageReturn : 360.2840270996094\n",
            "Train_StdReturn : 92.17369079589844\n",
            "Train_MaxReturn : 492.560791015625\n",
            "Train_MinReturn : 169.4912109375\n",
            "Train_AverageEpLen : 182.0\n",
            "Train_EnvstepsSoFar : 401594\n",
            "TimeSinceStart : 434.3237497806549\n",
            "Training Loss : -22.337589263916016\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 196 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 331.8699951171875\n",
            "Eval_StdReturn : 66.10224151611328\n",
            "Eval_MaxReturn : 419.09783935546875\n",
            "Eval_MinReturn : 259.14013671875\n",
            "Eval_AverageEpLen : 165.33333333333334\n",
            "Train_AverageReturn : 292.14349365234375\n",
            "Train_StdReturn : 117.68325805664062\n",
            "Train_MaxReturn : 439.9627990722656\n",
            "Train_MinReturn : 59.9112663269043\n",
            "Train_AverageEpLen : 150.78571428571428\n",
            "Train_EnvstepsSoFar : 403705\n",
            "TimeSinceStart : 436.8146677017212\n",
            "Training Loss : -1.2200469970703125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 197 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 263.7686767578125\n",
            "Eval_StdReturn : 74.35865783691406\n",
            "Eval_MaxReturn : 330.50152587890625\n",
            "Eval_MinReturn : 137.68331909179688\n",
            "Eval_AverageEpLen : 132.0\n",
            "Train_AverageReturn : 360.09515380859375\n",
            "Train_StdReturn : 94.38944244384766\n",
            "Train_MaxReturn : 527.6837158203125\n",
            "Train_MinReturn : 226.03866577148438\n",
            "Train_AverageEpLen : 191.27272727272728\n",
            "Train_EnvstepsSoFar : 405809\n",
            "TimeSinceStart : 439.4193124771118\n",
            "Training Loss : 9.740304946899414\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 198 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 339.7580261230469\n",
            "Eval_StdReturn : 131.58421325683594\n",
            "Eval_MaxReturn : 523.022216796875\n",
            "Eval_MinReturn : 220.156494140625\n",
            "Eval_AverageEpLen : 158.33333333333334\n",
            "Train_AverageReturn : 277.3491516113281\n",
            "Train_StdReturn : 113.15345001220703\n",
            "Train_MaxReturn : 500.9116516113281\n",
            "Train_MinReturn : 128.08062744140625\n",
            "Train_AverageEpLen : 154.71428571428572\n",
            "Train_EnvstepsSoFar : 407975\n",
            "TimeSinceStart : 441.88941621780396\n",
            "Training Loss : -78.04521179199219\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 199 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 337.4759826660156\n",
            "Eval_StdReturn : 128.35781860351562\n",
            "Eval_MaxReturn : 484.3315734863281\n",
            "Eval_MinReturn : 171.6432647705078\n",
            "Eval_AverageEpLen : 176.66666666666666\n",
            "Train_AverageReturn : 365.4426574707031\n",
            "Train_StdReturn : 75.16268157958984\n",
            "Train_MaxReturn : 459.3319091796875\n",
            "Train_MinReturn : 218.11932373046875\n",
            "Train_AverageEpLen : 201.36363636363637\n",
            "Train_EnvstepsSoFar : 410190\n",
            "TimeSinceStart : 444.5318765640259\n",
            "Training Loss : 6.496433258056641\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 200 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 386.98773193359375\n",
            "Eval_StdReturn : 121.37211608886719\n",
            "Eval_MaxReturn : 508.3598327636719\n",
            "Eval_MinReturn : 265.6156005859375\n",
            "Eval_AverageEpLen : 219.0\n",
            "Train_AverageReturn : 295.3910827636719\n",
            "Train_StdReturn : 112.8966293334961\n",
            "Train_MaxReturn : 508.6047058105469\n",
            "Train_MinReturn : 74.20006561279297\n",
            "Train_AverageEpLen : 168.83333333333334\n",
            "Train_EnvstepsSoFar : 412216\n",
            "TimeSinceStart : 446.88650941848755\n",
            "Training Loss : 4.15374755859375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 201 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 426.55596923828125\n",
            "Eval_StdReturn : 7.6191558837890625\n",
            "Eval_MaxReturn : 434.1751403808594\n",
            "Eval_MinReturn : 418.93682861328125\n",
            "Eval_AverageEpLen : 212.0\n",
            "Train_AverageReturn : 343.0299987792969\n",
            "Train_StdReturn : 92.72125244140625\n",
            "Train_MaxReturn : 438.2927551269531\n",
            "Train_MinReturn : 133.06771850585938\n",
            "Train_AverageEpLen : 183.36363636363637\n",
            "Train_EnvstepsSoFar : 414233\n",
            "TimeSinceStart : 449.25875306129456\n",
            "Training Loss : -24.829591751098633\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 202 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 289.2383117675781\n",
            "Eval_StdReturn : 93.53462982177734\n",
            "Eval_MaxReturn : 388.973876953125\n",
            "Eval_MinReturn : 164.1195831298828\n",
            "Eval_AverageEpLen : 146.33333333333334\n",
            "Train_AverageReturn : 322.6689453125\n",
            "Train_StdReturn : 153.6475067138672\n",
            "Train_MaxReturn : 642.2009887695312\n",
            "Train_MinReturn : 7.084813117980957\n",
            "Train_AverageEpLen : 170.41666666666666\n",
            "Train_EnvstepsSoFar : 416278\n",
            "TimeSinceStart : 451.80271768569946\n",
            "Training Loss : 12.823734283447266\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 203 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 399.958251953125\n",
            "Eval_StdReturn : 28.63346290588379\n",
            "Eval_MaxReturn : 439.31109619140625\n",
            "Eval_MinReturn : 372.01568603515625\n",
            "Eval_AverageEpLen : 190.66666666666666\n",
            "Train_AverageReturn : 335.7674560546875\n",
            "Train_StdReturn : 168.32928466796875\n",
            "Train_MaxReturn : 659.4598999023438\n",
            "Train_MinReturn : 91.92512512207031\n",
            "Train_AverageEpLen : 186.27272727272728\n",
            "Train_EnvstepsSoFar : 418327\n",
            "TimeSinceStart : 454.4366989135742\n",
            "Training Loss : -30.128013610839844\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 204 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 364.9005126953125\n",
            "Eval_StdReturn : 47.10547637939453\n",
            "Eval_MaxReturn : 407.6518859863281\n",
            "Eval_MinReturn : 299.27972412109375\n",
            "Eval_AverageEpLen : 176.0\n",
            "Train_AverageReturn : 353.71246337890625\n",
            "Train_StdReturn : 158.95716857910156\n",
            "Train_MaxReturn : 600.2872314453125\n",
            "Train_MinReturn : 69.94164276123047\n",
            "Train_AverageEpLen : 191.72727272727272\n",
            "Train_EnvstepsSoFar : 420436\n",
            "TimeSinceStart : 457.03047132492065\n",
            "Training Loss : -31.23188018798828\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 205 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 296.1229248046875\n",
            "Eval_StdReturn : 111.71334838867188\n",
            "Eval_MaxReturn : 487.97064208984375\n",
            "Eval_MinReturn : 210.6830596923828\n",
            "Eval_AverageEpLen : 169.0\n",
            "Train_AverageReturn : 366.863525390625\n",
            "Train_StdReturn : 115.56777954101562\n",
            "Train_MaxReturn : 555.745361328125\n",
            "Train_MinReturn : 88.68087005615234\n",
            "Train_AverageEpLen : 177.5\n",
            "Train_EnvstepsSoFar : 422566\n",
            "TimeSinceStart : 459.6817135810852\n",
            "Training Loss : 13.235715866088867\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 206 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 378.8045349121094\n",
            "Eval_StdReturn : 204.74407958984375\n",
            "Eval_MaxReturn : 643.5794677734375\n",
            "Eval_MinReturn : 144.923828125\n",
            "Eval_AverageEpLen : 186.66666666666666\n",
            "Train_AverageReturn : 340.36297607421875\n",
            "Train_StdReturn : 96.83561706542969\n",
            "Train_MaxReturn : 465.0306396484375\n",
            "Train_MinReturn : 71.99595642089844\n",
            "Train_AverageEpLen : 176.08333333333334\n",
            "Train_EnvstepsSoFar : 424679\n",
            "TimeSinceStart : 462.2207295894623\n",
            "Training Loss : 42.1146240234375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 207 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 479.9099426269531\n",
            "Eval_StdReturn : 157.4689483642578\n",
            "Eval_MaxReturn : 700.94189453125\n",
            "Eval_MinReturn : 345.8702087402344\n",
            "Eval_AverageEpLen : 281.3333333333333\n",
            "Train_AverageReturn : 326.58795166015625\n",
            "Train_StdReturn : 171.6542205810547\n",
            "Train_MaxReturn : 705.8541259765625\n",
            "Train_MinReturn : 53.455745697021484\n",
            "Train_AverageEpLen : 168.33333333333334\n",
            "Train_EnvstepsSoFar : 426699\n",
            "TimeSinceStart : 464.9450194835663\n",
            "Training Loss : -73.33993530273438\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 208 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 253.84820556640625\n",
            "Eval_StdReturn : 97.3418960571289\n",
            "Eval_MaxReturn : 330.639892578125\n",
            "Eval_MinReturn : 90.52383422851562\n",
            "Eval_AverageEpLen : 148.25\n",
            "Train_AverageReturn : 362.0066833496094\n",
            "Train_StdReturn : 94.84380340576172\n",
            "Train_MaxReturn : 522.9534301757812\n",
            "Train_MinReturn : 180.48959350585938\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 428899\n",
            "TimeSinceStart : 467.6239914894104\n",
            "Training Loss : 25.361263275146484\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 209 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 449.9163818359375\n",
            "Eval_StdReturn : 24.151123046875\n",
            "Eval_MaxReturn : 474.0675048828125\n",
            "Eval_MinReturn : 425.7652587890625\n",
            "Eval_AverageEpLen : 229.5\n",
            "Train_AverageReturn : 384.63116455078125\n",
            "Train_StdReturn : 103.25912475585938\n",
            "Train_MaxReturn : 532.892333984375\n",
            "Train_MinReturn : 121.3722915649414\n",
            "Train_AverageEpLen : 210.5\n",
            "Train_EnvstepsSoFar : 431004\n",
            "TimeSinceStart : 470.1928083896637\n",
            "Training Loss : 104.57845306396484\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 210 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 398.8677978515625\n",
            "Eval_StdReturn : 165.29722595214844\n",
            "Eval_MaxReturn : 614.1724243164062\n",
            "Eval_MinReturn : 212.3631134033203\n",
            "Eval_AverageEpLen : 244.0\n",
            "Train_AverageReturn : 353.8725280761719\n",
            "Train_StdReturn : 69.5936279296875\n",
            "Train_MaxReturn : 445.1944885253906\n",
            "Train_MinReturn : 219.20362854003906\n",
            "Train_AverageEpLen : 171.83333333333334\n",
            "Train_EnvstepsSoFar : 433066\n",
            "TimeSinceStart : 472.81277108192444\n",
            "Training Loss : -2.834259033203125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 211 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 270.7330017089844\n",
            "Eval_StdReturn : 49.6009635925293\n",
            "Eval_MaxReturn : 340.26220703125\n",
            "Eval_MinReturn : 227.92788696289062\n",
            "Eval_AverageEpLen : 134.66666666666666\n",
            "Train_AverageReturn : 381.4612121582031\n",
            "Train_StdReturn : 118.41039276123047\n",
            "Train_MaxReturn : 600.6982421875\n",
            "Train_MinReturn : 138.1711883544922\n",
            "Train_AverageEpLen : 191.1818181818182\n",
            "Train_EnvstepsSoFar : 435169\n",
            "TimeSinceStart : 475.3060050010681\n",
            "Training Loss : 42.29917907714844\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 212 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 532.03271484375\n",
            "Eval_StdReturn : 96.47946166992188\n",
            "Eval_MaxReturn : 628.51220703125\n",
            "Eval_MinReturn : 435.55328369140625\n",
            "Eval_AverageEpLen : 317.0\n",
            "Train_AverageReturn : 404.96026611328125\n",
            "Train_StdReturn : 80.73250579833984\n",
            "Train_MaxReturn : 512.614990234375\n",
            "Train_MinReturn : 201.5633087158203\n",
            "Train_AverageEpLen : 202.27272727272728\n",
            "Train_EnvstepsSoFar : 437394\n",
            "TimeSinceStart : 478.1407754421234\n",
            "Training Loss : -64.72145080566406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 213 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 457.7105712890625\n",
            "Eval_StdReturn : 148.4893798828125\n",
            "Eval_MaxReturn : 606.199951171875\n",
            "Eval_MinReturn : 309.22119140625\n",
            "Eval_AverageEpLen : 210.5\n",
            "Train_AverageReturn : 359.5225524902344\n",
            "Train_StdReturn : 101.94721221923828\n",
            "Train_MaxReturn : 525.1030883789062\n",
            "Train_MinReturn : 134.30149841308594\n",
            "Train_AverageEpLen : 174.25\n",
            "Train_EnvstepsSoFar : 439485\n",
            "TimeSinceStart : 480.5345413684845\n",
            "Training Loss : -71.75018310546875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 214 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 375.0389099121094\n",
            "Eval_StdReturn : 54.536827087402344\n",
            "Eval_MaxReturn : 447.0857849121094\n",
            "Eval_MinReturn : 315.17572021484375\n",
            "Eval_AverageEpLen : 172.0\n",
            "Train_AverageReturn : 387.1420593261719\n",
            "Train_StdReturn : 134.18850708007812\n",
            "Train_MaxReturn : 718.551513671875\n",
            "Train_MinReturn : 156.56704711914062\n",
            "Train_AverageEpLen : 210.54545454545453\n",
            "Train_EnvstepsSoFar : 441801\n",
            "TimeSinceStart : 483.38099932670593\n",
            "Training Loss : 101.32002258300781\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 215 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 367.873779296875\n",
            "Eval_StdReturn : 53.36929702758789\n",
            "Eval_MaxReturn : 440.18475341796875\n",
            "Eval_MinReturn : 312.9895324707031\n",
            "Eval_AverageEpLen : 186.0\n",
            "Train_AverageReturn : 435.86175537109375\n",
            "Train_StdReturn : 123.4398422241211\n",
            "Train_MaxReturn : 703.5150756835938\n",
            "Train_MinReturn : 295.9185791015625\n",
            "Train_AverageEpLen : 229.88888888888889\n",
            "Train_EnvstepsSoFar : 443870\n",
            "TimeSinceStart : 486.0731964111328\n",
            "Training Loss : 10.023914337158203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 216 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 563.2093505859375\n",
            "Eval_StdReturn : 45.574981689453125\n",
            "Eval_MaxReturn : 608.7843017578125\n",
            "Eval_MinReturn : 517.6343383789062\n",
            "Eval_AverageEpLen : 305.5\n",
            "Train_AverageReturn : 318.06439208984375\n",
            "Train_StdReturn : 119.54859924316406\n",
            "Train_MaxReturn : 576.52099609375\n",
            "Train_MinReturn : 100.85458374023438\n",
            "Train_AverageEpLen : 159.15384615384616\n",
            "Train_EnvstepsSoFar : 445939\n",
            "TimeSinceStart : 488.5970139503479\n",
            "Training Loss : 34.94335174560547\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 217 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 366.2809143066406\n",
            "Eval_StdReturn : 20.820344924926758\n",
            "Eval_MaxReturn : 385.94854736328125\n",
            "Eval_MinReturn : 337.4703369140625\n",
            "Eval_AverageEpLen : 184.0\n",
            "Train_AverageReturn : 392.8705749511719\n",
            "Train_StdReturn : 124.9993667602539\n",
            "Train_MaxReturn : 664.487060546875\n",
            "Train_MinReturn : 143.11322021484375\n",
            "Train_AverageEpLen : 192.1818181818182\n",
            "Train_EnvstepsSoFar : 448053\n",
            "TimeSinceStart : 491.2366940975189\n",
            "Training Loss : -104.84323120117188\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 218 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 412.1636962890625\n",
            "Eval_StdReturn : 84.35567474365234\n",
            "Eval_MaxReturn : 519.177734375\n",
            "Eval_MinReturn : 312.99688720703125\n",
            "Eval_AverageEpLen : 209.66666666666666\n",
            "Train_AverageReturn : 417.9907531738281\n",
            "Train_StdReturn : 70.76591491699219\n",
            "Train_MaxReturn : 538.8076782226562\n",
            "Train_MinReturn : 301.19256591796875\n",
            "Train_AverageEpLen : 196.0909090909091\n",
            "Train_EnvstepsSoFar : 450210\n",
            "TimeSinceStart : 493.94679713249207\n",
            "Training Loss : 37.63485336303711\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 219 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 413.0101318359375\n",
            "Eval_StdReturn : 15.56011962890625\n",
            "Eval_MaxReturn : 428.57025146484375\n",
            "Eval_MinReturn : 397.45001220703125\n",
            "Eval_AverageEpLen : 213.0\n",
            "Train_AverageReturn : 404.1212158203125\n",
            "Train_StdReturn : 82.57393646240234\n",
            "Train_MaxReturn : 559.6676025390625\n",
            "Train_MinReturn : 286.62939453125\n",
            "Train_AverageEpLen : 212.9\n",
            "Train_EnvstepsSoFar : 452339\n",
            "TimeSinceStart : 496.6004946231842\n",
            "Training Loss : -28.44333267211914\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 220 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 350.8459167480469\n",
            "Eval_StdReturn : 77.00386810302734\n",
            "Eval_MaxReturn : 457.58612060546875\n",
            "Eval_MinReturn : 278.7864990234375\n",
            "Eval_AverageEpLen : 186.0\n",
            "Train_AverageReturn : 384.56756591796875\n",
            "Train_StdReturn : 117.08670806884766\n",
            "Train_MaxReturn : 487.82708740234375\n",
            "Train_MinReturn : 107.37903594970703\n",
            "Train_AverageEpLen : 224.1\n",
            "Train_EnvstepsSoFar : 454580\n",
            "TimeSinceStart : 499.4696388244629\n",
            "Training Loss : 13.415878295898438\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 221 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 346.0919189453125\n",
            "Eval_StdReturn : 28.816783905029297\n",
            "Eval_MaxReturn : 386.760009765625\n",
            "Eval_MinReturn : 323.4794921875\n",
            "Eval_AverageEpLen : 157.0\n",
            "Train_AverageReturn : 328.3348388671875\n",
            "Train_StdReturn : 150.5465087890625\n",
            "Train_MaxReturn : 522.3143920898438\n",
            "Train_MinReturn : 104.67221069335938\n",
            "Train_AverageEpLen : 176.83333333333334\n",
            "Train_EnvstepsSoFar : 456702\n",
            "TimeSinceStart : 501.9732196331024\n",
            "Training Loss : -94.3984375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 222 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 315.3444519042969\n",
            "Eval_StdReturn : 107.93809509277344\n",
            "Eval_MaxReturn : 487.0982971191406\n",
            "Eval_MinReturn : 219.22518920898438\n",
            "Eval_AverageEpLen : 163.75\n",
            "Train_AverageReturn : 383.5809631347656\n",
            "Train_StdReturn : 101.25013732910156\n",
            "Train_MaxReturn : 586.1383056640625\n",
            "Train_MinReturn : 226.48570251464844\n",
            "Train_AverageEpLen : 190.8181818181818\n",
            "Train_EnvstepsSoFar : 458801\n",
            "TimeSinceStart : 504.6850337982178\n",
            "Training Loss : 27.697967529296875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 223 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 349.0622253417969\n",
            "Eval_StdReturn : 44.71236801147461\n",
            "Eval_MaxReturn : 412.263671875\n",
            "Eval_MinReturn : 315.7369079589844\n",
            "Eval_AverageEpLen : 150.33333333333334\n",
            "Train_AverageReturn : 391.1791076660156\n",
            "Train_StdReturn : 145.48202514648438\n",
            "Train_MaxReturn : 654.30126953125\n",
            "Train_MinReturn : 155.4723358154297\n",
            "Train_AverageEpLen : 194.63636363636363\n",
            "Train_EnvstepsSoFar : 460942\n",
            "TimeSinceStart : 507.2803530693054\n",
            "Training Loss : -51.389442443847656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 224 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 414.8533630371094\n",
            "Eval_StdReturn : 73.1056900024414\n",
            "Eval_MaxReturn : 515.690185546875\n",
            "Eval_MinReturn : 344.6710205078125\n",
            "Eval_AverageEpLen : 204.0\n",
            "Train_AverageReturn : 355.2793884277344\n",
            "Train_StdReturn : 146.59963989257812\n",
            "Train_MaxReturn : 566.135498046875\n",
            "Train_MinReturn : 92.37651062011719\n",
            "Train_AverageEpLen : 180.16666666666666\n",
            "Train_EnvstepsSoFar : 463104\n",
            "TimeSinceStart : 509.955593585968\n",
            "Training Loss : -112.38835144042969\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 225 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 374.3069152832031\n",
            "Eval_StdReturn : 22.057992935180664\n",
            "Eval_MaxReturn : 403.2450866699219\n",
            "Eval_MinReturn : 349.749755859375\n",
            "Eval_AverageEpLen : 193.66666666666666\n",
            "Train_AverageReturn : 369.3597412109375\n",
            "Train_StdReturn : 129.29824829101562\n",
            "Train_MaxReturn : 578.0950317382812\n",
            "Train_MinReturn : 195.12948608398438\n",
            "Train_AverageEpLen : 188.36363636363637\n",
            "Train_EnvstepsSoFar : 465176\n",
            "TimeSinceStart : 512.5417857170105\n",
            "Training Loss : -95.73808288574219\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 226 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 337.84423828125\n",
            "Eval_StdReturn : 12.124176025390625\n",
            "Eval_MaxReturn : 354.82159423828125\n",
            "Eval_MinReturn : 327.2769775390625\n",
            "Eval_AverageEpLen : 160.0\n",
            "Train_AverageReturn : 327.13201904296875\n",
            "Train_StdReturn : 129.29710388183594\n",
            "Train_MaxReturn : 678.1021728515625\n",
            "Train_MinReturn : 182.22288513183594\n",
            "Train_AverageEpLen : 165.6153846153846\n",
            "Train_EnvstepsSoFar : 467329\n",
            "TimeSinceStart : 515.0558876991272\n",
            "Training Loss : -4.451454162597656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 227 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 270.0024719238281\n",
            "Eval_StdReturn : 25.177011489868164\n",
            "Eval_MaxReturn : 289.03851318359375\n",
            "Eval_MinReturn : 234.42596435546875\n",
            "Eval_AverageEpLen : 141.33333333333334\n",
            "Train_AverageReturn : 345.0564880371094\n",
            "Train_StdReturn : 98.20028686523438\n",
            "Train_MaxReturn : 515.891357421875\n",
            "Train_MinReturn : 111.90850830078125\n",
            "Train_AverageEpLen : 168.0\n",
            "Train_EnvstepsSoFar : 469345\n",
            "TimeSinceStart : 517.3758533000946\n",
            "Training Loss : 67.61183166503906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 228 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 374.2450256347656\n",
            "Eval_StdReturn : 67.259033203125\n",
            "Eval_MaxReturn : 467.7449645996094\n",
            "Eval_MinReturn : 312.36273193359375\n",
            "Eval_AverageEpLen : 177.66666666666666\n",
            "Train_AverageReturn : 375.02734375\n",
            "Train_StdReturn : 139.18544006347656\n",
            "Train_MaxReturn : 567.826416015625\n",
            "Train_MinReturn : 51.28422927856445\n",
            "Train_AverageEpLen : 192.0909090909091\n",
            "Train_EnvstepsSoFar : 471458\n",
            "TimeSinceStart : 519.944313287735\n",
            "Training Loss : -4.179354667663574\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 229 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 429.8408203125\n",
            "Eval_StdReturn : 34.9454345703125\n",
            "Eval_MaxReturn : 464.7862548828125\n",
            "Eval_MinReturn : 394.8953857421875\n",
            "Eval_AverageEpLen : 211.5\n",
            "Train_AverageReturn : 380.6959533691406\n",
            "Train_StdReturn : 77.49430847167969\n",
            "Train_MaxReturn : 510.09857177734375\n",
            "Train_MinReturn : 176.02078247070312\n",
            "Train_AverageEpLen : 176.33333333333334\n",
            "Train_EnvstepsSoFar : 473574\n",
            "TimeSinceStart : 522.3584439754486\n",
            "Training Loss : 24.224746704101562\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 230 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 486.4132995605469\n",
            "Eval_StdReturn : 125.88388061523438\n",
            "Eval_MaxReturn : 612.2971801757812\n",
            "Eval_MinReturn : 360.5294189453125\n",
            "Eval_AverageEpLen : 246.0\n",
            "Train_AverageReturn : 344.6711730957031\n",
            "Train_StdReturn : 104.4981689453125\n",
            "Train_MaxReturn : 540.1370239257812\n",
            "Train_MinReturn : 138.2538299560547\n",
            "Train_AverageEpLen : 177.25\n",
            "Train_EnvstepsSoFar : 475701\n",
            "TimeSinceStart : 524.8553471565247\n",
            "Training Loss : -105.24645233154297\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 231 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 358.3863525390625\n",
            "Eval_StdReturn : 119.17079162597656\n",
            "Eval_MaxReturn : 494.703125\n",
            "Eval_MinReturn : 204.4036102294922\n",
            "Eval_AverageEpLen : 153.33333333333334\n",
            "Train_AverageReturn : 388.35205078125\n",
            "Train_StdReturn : 65.95506286621094\n",
            "Train_MaxReturn : 488.0813903808594\n",
            "Train_MinReturn : 266.21820068359375\n",
            "Train_AverageEpLen : 191.0\n",
            "Train_EnvstepsSoFar : 477802\n",
            "TimeSinceStart : 527.350932598114\n",
            "Training Loss : 15.803817749023438\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 232 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 427.04461669921875\n",
            "Eval_StdReturn : 58.67222595214844\n",
            "Eval_MaxReturn : 485.7168273925781\n",
            "Eval_MinReturn : 368.37237548828125\n",
            "Eval_AverageEpLen : 224.5\n",
            "Train_AverageReturn : 372.9330139160156\n",
            "Train_StdReturn : 52.933570861816406\n",
            "Train_MaxReturn : 463.24371337890625\n",
            "Train_MinReturn : 298.23956298828125\n",
            "Train_AverageEpLen : 182.5\n",
            "Train_EnvstepsSoFar : 479992\n",
            "TimeSinceStart : 529.853438615799\n",
            "Training Loss : -44.049224853515625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 233 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 340.0811462402344\n",
            "Eval_StdReturn : 21.764131546020508\n",
            "Eval_MaxReturn : 361.5233459472656\n",
            "Eval_MinReturn : 310.23699951171875\n",
            "Eval_AverageEpLen : 172.66666666666666\n",
            "Train_AverageReturn : 321.8626403808594\n",
            "Train_StdReturn : 119.05802917480469\n",
            "Train_MaxReturn : 526.0132446289062\n",
            "Train_MinReturn : 85.76770782470703\n",
            "Train_AverageEpLen : 162.84615384615384\n",
            "Train_EnvstepsSoFar : 482109\n",
            "TimeSinceStart : 532.3878729343414\n",
            "Training Loss : -72.20220184326172\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 234 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 429.1690368652344\n",
            "Eval_StdReturn : 75.82328796386719\n",
            "Eval_MaxReturn : 536.0667724609375\n",
            "Eval_MinReturn : 368.411865234375\n",
            "Eval_AverageEpLen : 212.33333333333334\n",
            "Train_AverageReturn : 382.5829162597656\n",
            "Train_StdReturn : 85.43887329101562\n",
            "Train_MaxReturn : 540.3359985351562\n",
            "Train_MinReturn : 188.76507568359375\n",
            "Train_AverageEpLen : 187.8181818181818\n",
            "Train_EnvstepsSoFar : 484175\n",
            "TimeSinceStart : 534.9803972244263\n",
            "Training Loss : 19.726715087890625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 235 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 387.4358825683594\n",
            "Eval_StdReturn : 88.32530975341797\n",
            "Eval_MaxReturn : 469.22003173828125\n",
            "Eval_MinReturn : 264.778564453125\n",
            "Eval_AverageEpLen : 175.0\n",
            "Train_AverageReturn : 401.5445556640625\n",
            "Train_StdReturn : 57.86270523071289\n",
            "Train_MaxReturn : 488.1744384765625\n",
            "Train_MinReturn : 330.4143371582031\n",
            "Train_AverageEpLen : 190.1818181818182\n",
            "Train_EnvstepsSoFar : 486267\n",
            "TimeSinceStart : 537.5141980648041\n",
            "Training Loss : -61.914188385009766\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 236 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 380.3283996582031\n",
            "Eval_StdReturn : 55.21452713012695\n",
            "Eval_MaxReturn : 451.51556396484375\n",
            "Eval_MinReturn : 316.9453125\n",
            "Eval_AverageEpLen : 174.66666666666666\n",
            "Train_AverageReturn : 349.8964538574219\n",
            "Train_StdReturn : 86.44953155517578\n",
            "Train_MaxReturn : 449.070068359375\n",
            "Train_MinReturn : 164.78233337402344\n",
            "Train_AverageEpLen : 176.08333333333334\n",
            "Train_EnvstepsSoFar : 488380\n",
            "TimeSinceStart : 540.0198707580566\n",
            "Training Loss : 35.83698272705078\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 237 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 340.8349304199219\n",
            "Eval_StdReturn : 86.80113983154297\n",
            "Eval_MaxReturn : 463.5494384765625\n",
            "Eval_MinReturn : 276.7353515625\n",
            "Eval_AverageEpLen : 150.33333333333334\n",
            "Train_AverageReturn : 421.12548828125\n",
            "Train_StdReturn : 123.68243408203125\n",
            "Train_MaxReturn : 676.0079345703125\n",
            "Train_MinReturn : 213.7828369140625\n",
            "Train_AverageEpLen : 209.5\n",
            "Train_EnvstepsSoFar : 490475\n",
            "TimeSinceStart : 542.5521750450134\n",
            "Training Loss : -43.42323303222656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 238 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 418.06976318359375\n",
            "Eval_StdReturn : 109.82188415527344\n",
            "Eval_MaxReturn : 527.8916625976562\n",
            "Eval_MinReturn : 308.2478942871094\n",
            "Eval_AverageEpLen : 230.0\n",
            "Train_AverageReturn : 316.78057861328125\n",
            "Train_StdReturn : 97.67701721191406\n",
            "Train_MaxReturn : 425.4332275390625\n",
            "Train_MinReturn : 123.51736450195312\n",
            "Train_AverageEpLen : 159.07692307692307\n",
            "Train_EnvstepsSoFar : 492543\n",
            "TimeSinceStart : 544.9322228431702\n",
            "Training Loss : -38.323951721191406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 239 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 349.4253234863281\n",
            "Eval_StdReturn : 9.929461479187012\n",
            "Eval_MaxReturn : 362.48492431640625\n",
            "Eval_MinReturn : 338.426025390625\n",
            "Eval_AverageEpLen : 153.0\n",
            "Train_AverageReturn : 392.5270690917969\n",
            "Train_StdReturn : 99.41678619384766\n",
            "Train_MaxReturn : 531.17041015625\n",
            "Train_MinReturn : 199.50338745117188\n",
            "Train_AverageEpLen : 191.0\n",
            "Train_EnvstepsSoFar : 494644\n",
            "TimeSinceStart : 547.4751296043396\n",
            "Training Loss : 71.29290771484375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 240 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 399.9482727050781\n",
            "Eval_StdReturn : 18.989559173583984\n",
            "Eval_MaxReturn : 415.652587890625\n",
            "Eval_MinReturn : 373.2298583984375\n",
            "Eval_AverageEpLen : 187.33333333333334\n",
            "Train_AverageReturn : 321.7957763671875\n",
            "Train_StdReturn : 42.720001220703125\n",
            "Train_MaxReturn : 375.2900085449219\n",
            "Train_MinReturn : 222.35177612304688\n",
            "Train_AverageEpLen : 164.3846153846154\n",
            "Train_EnvstepsSoFar : 496781\n",
            "TimeSinceStart : 549.9831764698029\n",
            "Training Loss : -5.0646772384643555\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 241 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 518.75244140625\n",
            "Eval_StdReturn : 24.022796630859375\n",
            "Eval_MaxReturn : 542.7752685546875\n",
            "Eval_MinReturn : 494.72967529296875\n",
            "Eval_AverageEpLen : 243.0\n",
            "Train_AverageReturn : 390.6070556640625\n",
            "Train_StdReturn : 95.07567596435547\n",
            "Train_MaxReturn : 637.5856323242188\n",
            "Train_MinReturn : 295.08349609375\n",
            "Train_AverageEpLen : 198.0\n",
            "Train_EnvstepsSoFar : 498959\n",
            "TimeSinceStart : 552.5656001567841\n",
            "Training Loss : -66.22218322753906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 242 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 297.7718811035156\n",
            "Eval_StdReturn : 144.65060424804688\n",
            "Eval_MaxReturn : 458.296630859375\n",
            "Eval_MinReturn : 107.6935043334961\n",
            "Eval_AverageEpLen : 157.33333333333334\n",
            "Train_AverageReturn : 387.3348693847656\n",
            "Train_StdReturn : 68.73432922363281\n",
            "Train_MaxReturn : 497.4844970703125\n",
            "Train_MinReturn : 308.4327392578125\n",
            "Train_AverageEpLen : 197.27272727272728\n",
            "Train_EnvstepsSoFar : 501129\n",
            "TimeSinceStart : 555.1051082611084\n",
            "Training Loss : -49.20106506347656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 243 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 332.4897155761719\n",
            "Eval_StdReturn : 94.05830383300781\n",
            "Eval_MaxReturn : 436.63592529296875\n",
            "Eval_MinReturn : 208.75335693359375\n",
            "Eval_AverageEpLen : 160.66666666666666\n",
            "Train_AverageReturn : 390.6754150390625\n",
            "Train_StdReturn : 116.58317565917969\n",
            "Train_MaxReturn : 650.5905151367188\n",
            "Train_MinReturn : 218.69703674316406\n",
            "Train_AverageEpLen : 184.58333333333334\n",
            "Train_EnvstepsSoFar : 503344\n",
            "TimeSinceStart : 557.6689784526825\n",
            "Training Loss : -23.34352684020996\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 244 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 428.70721435546875\n",
            "Eval_StdReturn : 92.40765380859375\n",
            "Eval_MaxReturn : 521.1148681640625\n",
            "Eval_MinReturn : 336.299560546875\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 375.97772216796875\n",
            "Train_StdReturn : 139.823974609375\n",
            "Train_MaxReturn : 606.8200073242188\n",
            "Train_MinReturn : 163.18307495117188\n",
            "Train_AverageEpLen : 193.45454545454547\n",
            "Train_EnvstepsSoFar : 505472\n",
            "TimeSinceStart : 560.1833181381226\n",
            "Training Loss : -119.30367279052734\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 245 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 311.7405700683594\n",
            "Eval_StdReturn : 128.80079650878906\n",
            "Eval_MaxReturn : 488.69110107421875\n",
            "Eval_MinReturn : 185.83734130859375\n",
            "Eval_AverageEpLen : 148.66666666666666\n",
            "Train_AverageReturn : 345.1716003417969\n",
            "Train_StdReturn : 115.62776947021484\n",
            "Train_MaxReturn : 576.7486572265625\n",
            "Train_MinReturn : 117.4115982055664\n",
            "Train_AverageEpLen : 169.23076923076923\n",
            "Train_EnvstepsSoFar : 507672\n",
            "TimeSinceStart : 562.7073278427124\n",
            "Training Loss : -46.2448616027832\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 246 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 438.7412109375\n",
            "Eval_StdReturn : 68.5452880859375\n",
            "Eval_MaxReturn : 507.2864990234375\n",
            "Eval_MinReturn : 370.1959228515625\n",
            "Eval_AverageEpLen : 213.0\n",
            "Train_AverageReturn : 460.1642150878906\n",
            "Train_StdReturn : 224.8218536376953\n",
            "Train_MaxReturn : 824.012939453125\n",
            "Train_MinReturn : 167.8304901123047\n",
            "Train_AverageEpLen : 254.11111111111111\n",
            "Train_EnvstepsSoFar : 509959\n",
            "TimeSinceStart : 565.6868903636932\n",
            "Training Loss : 13.84109878540039\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 247 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 436.833251953125\n",
            "Eval_StdReturn : 35.653167724609375\n",
            "Eval_MaxReturn : 472.4864196777344\n",
            "Eval_MinReturn : 401.1800842285156\n",
            "Eval_AverageEpLen : 232.5\n",
            "Train_AverageReturn : 335.0180969238281\n",
            "Train_StdReturn : 88.4183120727539\n",
            "Train_MaxReturn : 452.48748779296875\n",
            "Train_MinReturn : 77.80690002441406\n",
            "Train_AverageEpLen : 156.46153846153845\n",
            "Train_EnvstepsSoFar : 511993\n",
            "TimeSinceStart : 568.0370578765869\n",
            "Training Loss : -113.51082611083984\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 248 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 405.0643005371094\n",
            "Eval_StdReturn : 141.32273864746094\n",
            "Eval_MaxReturn : 581.2645263671875\n",
            "Eval_MinReturn : 235.2740020751953\n",
            "Eval_AverageEpLen : 193.66666666666666\n",
            "Train_AverageReturn : 353.4809265136719\n",
            "Train_StdReturn : 72.18541717529297\n",
            "Train_MaxReturn : 424.2448425292969\n",
            "Train_MinReturn : 158.21456909179688\n",
            "Train_AverageEpLen : 176.58333333333334\n",
            "Train_EnvstepsSoFar : 514112\n",
            "TimeSinceStart : 570.5927081108093\n",
            "Training Loss : -43.04837417602539\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 249 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 294.6243591308594\n",
            "Eval_StdReturn : 48.867610931396484\n",
            "Eval_MaxReturn : 346.5970764160156\n",
            "Eval_MinReturn : 229.18939208984375\n",
            "Eval_AverageEpLen : 134.33333333333334\n",
            "Train_AverageReturn : 395.8059387207031\n",
            "Train_StdReturn : 112.83562469482422\n",
            "Train_MaxReturn : 596.5382080078125\n",
            "Train_MinReturn : 211.7530059814453\n",
            "Train_AverageEpLen : 187.36363636363637\n",
            "Train_EnvstepsSoFar : 516173\n",
            "TimeSinceStart : 572.9991488456726\n",
            "Training Loss : -37.36686706542969\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 250 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 310.0643310546875\n",
            "Eval_StdReturn : 74.4446792602539\n",
            "Eval_MaxReturn : 415.29986572265625\n",
            "Eval_MinReturn : 254.77700805664062\n",
            "Eval_AverageEpLen : 154.33333333333334\n",
            "Train_AverageReturn : 358.1461486816406\n",
            "Train_StdReturn : 99.81259155273438\n",
            "Train_MaxReturn : 540.5474243164062\n",
            "Train_MinReturn : 110.14714813232422\n",
            "Train_AverageEpLen : 164.76923076923077\n",
            "Train_EnvstepsSoFar : 518315\n",
            "TimeSinceStart : 575.4264616966248\n",
            "Training Loss : -69.17320251464844\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 251 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 366.8328552246094\n",
            "Eval_StdReturn : 56.93852996826172\n",
            "Eval_MaxReturn : 444.7401123046875\n",
            "Eval_MinReturn : 310.24859619140625\n",
            "Eval_AverageEpLen : 191.33333333333334\n",
            "Train_AverageReturn : 374.0177307128906\n",
            "Train_StdReturn : 72.38445281982422\n",
            "Train_MaxReturn : 555.8194580078125\n",
            "Train_MinReturn : 304.4092102050781\n",
            "Train_AverageEpLen : 170.91666666666666\n",
            "Train_EnvstepsSoFar : 520366\n",
            "TimeSinceStart : 577.8695068359375\n",
            "Training Loss : -107.37348937988281\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 252 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 324.0510559082031\n",
            "Eval_StdReturn : 22.98104476928711\n",
            "Eval_MaxReturn : 352.03802490234375\n",
            "Eval_MinReturn : 295.74884033203125\n",
            "Eval_AverageEpLen : 143.66666666666666\n",
            "Train_AverageReturn : 431.36981201171875\n",
            "Train_StdReturn : 129.767333984375\n",
            "Train_MaxReturn : 717.9550170898438\n",
            "Train_MinReturn : 297.6156005859375\n",
            "Train_AverageEpLen : 200.7\n",
            "Train_EnvstepsSoFar : 522373\n",
            "TimeSinceStart : 580.2531678676605\n",
            "Training Loss : -31.78554916381836\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 253 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 390.44317626953125\n",
            "Eval_StdReturn : 332.01202392578125\n",
            "Eval_MaxReturn : 722.4552001953125\n",
            "Eval_MinReturn : 58.4311637878418\n",
            "Eval_AverageEpLen : 235.0\n",
            "Train_AverageReturn : 356.7666320800781\n",
            "Train_StdReturn : 101.920654296875\n",
            "Train_MaxReturn : 608.7850341796875\n",
            "Train_MinReturn : 237.33082580566406\n",
            "Train_AverageEpLen : 166.3846153846154\n",
            "Train_EnvstepsSoFar : 524536\n",
            "TimeSinceStart : 582.768895149231\n",
            "Training Loss : 41.22085952758789\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 254 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 312.508056640625\n",
            "Eval_StdReturn : 4.225513458251953\n",
            "Eval_MaxReturn : 317.45208740234375\n",
            "Eval_MinReturn : 307.1291809082031\n",
            "Eval_AverageEpLen : 145.66666666666666\n",
            "Train_AverageReturn : 382.4586181640625\n",
            "Train_StdReturn : 69.43940734863281\n",
            "Train_MaxReturn : 552.3883056640625\n",
            "Train_MinReturn : 299.3907470703125\n",
            "Train_AverageEpLen : 190.54545454545453\n",
            "Train_EnvstepsSoFar : 526632\n",
            "TimeSinceStart : 585.206286907196\n",
            "Training Loss : 16.642715454101562\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 255 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 404.0394592285156\n",
            "Eval_StdReturn : 114.9793472290039\n",
            "Eval_MaxReturn : 562.7034912109375\n",
            "Eval_MinReturn : 293.8907470703125\n",
            "Eval_AverageEpLen : 175.0\n",
            "Train_AverageReturn : 352.0010681152344\n",
            "Train_StdReturn : 76.84014129638672\n",
            "Train_MaxReturn : 517.43408203125\n",
            "Train_MinReturn : 223.31533813476562\n",
            "Train_AverageEpLen : 169.16666666666666\n",
            "Train_EnvstepsSoFar : 528662\n",
            "TimeSinceStart : 587.6184139251709\n",
            "Training Loss : 22.136266708374023\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 256 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 367.7521057128906\n",
            "Eval_StdReturn : 31.41655158996582\n",
            "Eval_MaxReturn : 404.812255859375\n",
            "Eval_MinReturn : 327.99920654296875\n",
            "Eval_AverageEpLen : 165.66666666666666\n",
            "Train_AverageReturn : 379.152099609375\n",
            "Train_StdReturn : 74.57622528076172\n",
            "Train_MaxReturn : 537.9751586914062\n",
            "Train_MinReturn : 227.42428588867188\n",
            "Train_AverageEpLen : 176.08333333333334\n",
            "Train_EnvstepsSoFar : 530775\n",
            "TimeSinceStart : 590.0955481529236\n",
            "Training Loss : 85.34270477294922\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 257 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 328.3184814453125\n",
            "Eval_StdReturn : 33.725128173828125\n",
            "Eval_MaxReturn : 373.5041198730469\n",
            "Eval_MinReturn : 292.505615234375\n",
            "Eval_AverageEpLen : 169.33333333333334\n",
            "Train_AverageReturn : 391.5904541015625\n",
            "Train_StdReturn : 125.63414001464844\n",
            "Train_MaxReturn : 696.1180419921875\n",
            "Train_MinReturn : 249.51089477539062\n",
            "Train_AverageEpLen : 181.25\n",
            "Train_EnvstepsSoFar : 532950\n",
            "TimeSinceStart : 592.7023701667786\n",
            "Training Loss : 10.560551643371582\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 258 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 352.895751953125\n",
            "Eval_StdReturn : 41.78437423706055\n",
            "Eval_MaxReturn : 410.86016845703125\n",
            "Eval_MinReturn : 313.96380615234375\n",
            "Eval_AverageEpLen : 161.33333333333334\n",
            "Train_AverageReturn : 411.0732421875\n",
            "Train_StdReturn : 116.66009521484375\n",
            "Train_MaxReturn : 607.8526611328125\n",
            "Train_MinReturn : 225.41201782226562\n",
            "Train_AverageEpLen : 188.63636363636363\n",
            "Train_EnvstepsSoFar : 535025\n",
            "TimeSinceStart : 595.213134765625\n",
            "Training Loss : -128.13473510742188\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 259 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 233.8529510498047\n",
            "Eval_StdReturn : 108.04400634765625\n",
            "Eval_MaxReturn : 415.85357666015625\n",
            "Eval_MinReturn : 142.4844970703125\n",
            "Eval_AverageEpLen : 115.75\n",
            "Train_AverageReturn : 327.4312744140625\n",
            "Train_StdReturn : 101.9753646850586\n",
            "Train_MaxReturn : 477.11029052734375\n",
            "Train_MinReturn : 123.70247650146484\n",
            "Train_AverageEpLen : 158.6153846153846\n",
            "Train_EnvstepsSoFar : 537087\n",
            "TimeSinceStart : 597.6034500598907\n",
            "Training Loss : -91.42732238769531\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 260 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 384.9418029785156\n",
            "Eval_StdReturn : 54.0692138671875\n",
            "Eval_MaxReturn : 460.80078125\n",
            "Eval_MinReturn : 338.6888122558594\n",
            "Eval_AverageEpLen : 174.66666666666666\n",
            "Train_AverageReturn : 357.6612548828125\n",
            "Train_StdReturn : 67.17993927001953\n",
            "Train_MaxReturn : 507.01531982421875\n",
            "Train_MinReturn : 258.8731689453125\n",
            "Train_AverageEpLen : 164.15384615384616\n",
            "Train_EnvstepsSoFar : 539221\n",
            "TimeSinceStart : 600.1257016658783\n",
            "Training Loss : 18.097095489501953\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 261 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 362.4409484863281\n",
            "Eval_StdReturn : 62.696044921875\n",
            "Eval_MaxReturn : 445.69927978515625\n",
            "Eval_MinReturn : 294.40667724609375\n",
            "Eval_AverageEpLen : 176.33333333333334\n",
            "Train_AverageReturn : 345.0584716796875\n",
            "Train_StdReturn : 112.03472137451172\n",
            "Train_MaxReturn : 695.1041870117188\n",
            "Train_MinReturn : 232.44410705566406\n",
            "Train_AverageEpLen : 157.6153846153846\n",
            "Train_EnvstepsSoFar : 541270\n",
            "TimeSinceStart : 602.5783874988556\n",
            "Training Loss : -63.89044189453125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 262 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 337.76019287109375\n",
            "Eval_StdReturn : 61.85475158691406\n",
            "Eval_MaxReturn : 408.13128662109375\n",
            "Eval_MinReturn : 257.5752258300781\n",
            "Eval_AverageEpLen : 153.33333333333334\n",
            "Train_AverageReturn : 342.2708435058594\n",
            "Train_StdReturn : 93.81136322021484\n",
            "Train_MaxReturn : 466.9291076660156\n",
            "Train_MinReturn : 156.6131134033203\n",
            "Train_AverageEpLen : 167.66666666666666\n",
            "Train_EnvstepsSoFar : 543282\n",
            "TimeSinceStart : 604.9558174610138\n",
            "Training Loss : 23.21371841430664\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 263 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 379.5626220703125\n",
            "Eval_StdReturn : 11.300444602966309\n",
            "Eval_MaxReturn : 387.6455078125\n",
            "Eval_MinReturn : 363.58172607421875\n",
            "Eval_AverageEpLen : 177.66666666666666\n",
            "Train_AverageReturn : 365.435791015625\n",
            "Train_StdReturn : 122.82223510742188\n",
            "Train_MaxReturn : 575.87060546875\n",
            "Train_MinReturn : 94.32805633544922\n",
            "Train_AverageEpLen : 177.66666666666666\n",
            "Train_EnvstepsSoFar : 545414\n",
            "TimeSinceStart : 607.614706993103\n",
            "Training Loss : -165.43283081054688\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 264 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 303.44781494140625\n",
            "Eval_StdReturn : 83.25033569335938\n",
            "Eval_MaxReturn : 381.5382995605469\n",
            "Eval_MinReturn : 164.6697998046875\n",
            "Eval_AverageEpLen : 141.0\n",
            "Train_AverageReturn : 330.0936279296875\n",
            "Train_StdReturn : 134.09970092773438\n",
            "Train_MaxReturn : 545.6536254882812\n",
            "Train_MinReturn : 117.82817840576172\n",
            "Train_AverageEpLen : 156.53846153846155\n",
            "Train_EnvstepsSoFar : 547449\n",
            "TimeSinceStart : 610.1041395664215\n",
            "Training Loss : 13.342636108398438\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 265 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 383.7975158691406\n",
            "Eval_StdReturn : 99.24172973632812\n",
            "Eval_MaxReturn : 523.486328125\n",
            "Eval_MinReturn : 302.1778564453125\n",
            "Eval_AverageEpLen : 174.66666666666666\n",
            "Train_AverageReturn : 375.8051452636719\n",
            "Train_StdReturn : 53.44132995605469\n",
            "Train_MaxReturn : 459.4673156738281\n",
            "Train_MinReturn : 273.19158935546875\n",
            "Train_AverageEpLen : 175.58333333333334\n",
            "Train_EnvstepsSoFar : 549556\n",
            "TimeSinceStart : 612.5670077800751\n",
            "Training Loss : -36.44127655029297\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 266 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 362.399658203125\n",
            "Eval_StdReturn : 68.10653686523438\n",
            "Eval_MaxReturn : 438.8377990722656\n",
            "Eval_MinReturn : 273.42962646484375\n",
            "Eval_AverageEpLen : 172.66666666666666\n",
            "Train_AverageReturn : 381.1069030761719\n",
            "Train_StdReturn : 53.07449722290039\n",
            "Train_MaxReturn : 524.7085571289062\n",
            "Train_MinReturn : 308.4137268066406\n",
            "Train_AverageEpLen : 185.27272727272728\n",
            "Train_EnvstepsSoFar : 551594\n",
            "TimeSinceStart : 615.0919878482819\n",
            "Training Loss : 79.7386474609375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 267 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 430.892822265625\n",
            "Eval_StdReturn : 98.65355682373047\n",
            "Eval_MaxReturn : 568.3319091796875\n",
            "Eval_MinReturn : 341.39691162109375\n",
            "Eval_AverageEpLen : 228.0\n",
            "Train_AverageReturn : 338.1665344238281\n",
            "Train_StdReturn : 123.06664276123047\n",
            "Train_MaxReturn : 631.91162109375\n",
            "Train_MinReturn : 179.1171417236328\n",
            "Train_AverageEpLen : 173.66666666666666\n",
            "Train_EnvstepsSoFar : 553678\n",
            "TimeSinceStart : 617.7447361946106\n",
            "Training Loss : -7.03040885925293\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 268 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 245.88174438476562\n",
            "Eval_StdReturn : 23.668048858642578\n",
            "Eval_MaxReturn : 282.8468933105469\n",
            "Eval_MinReturn : 221.43359375\n",
            "Eval_AverageEpLen : 126.25\n",
            "Train_AverageReturn : 366.3877258300781\n",
            "Train_StdReturn : 72.93804931640625\n",
            "Train_MaxReturn : 524.2017822265625\n",
            "Train_MinReturn : 255.53086853027344\n",
            "Train_AverageEpLen : 174.91666666666666\n",
            "Train_EnvstepsSoFar : 555777\n",
            "TimeSinceStart : 620.1856453418732\n",
            "Training Loss : -117.76373291015625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 269 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 456.20379638671875\n",
            "Eval_StdReturn : 74.51495361328125\n",
            "Eval_MaxReturn : 530.71875\n",
            "Eval_MinReturn : 381.6888427734375\n",
            "Eval_AverageEpLen : 201.5\n",
            "Train_AverageReturn : 370.0740661621094\n",
            "Train_StdReturn : 52.31222152709961\n",
            "Train_MaxReturn : 450.5608825683594\n",
            "Train_MinReturn : 289.33447265625\n",
            "Train_AverageEpLen : 173.41666666666666\n",
            "Train_EnvstepsSoFar : 557858\n",
            "TimeSinceStart : 622.5461421012878\n",
            "Training Loss : 10.272848129272461\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 270 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 307.9322814941406\n",
            "Eval_StdReturn : 73.91177368164062\n",
            "Eval_MaxReturn : 385.0169982910156\n",
            "Eval_MinReturn : 208.25167846679688\n",
            "Eval_AverageEpLen : 138.0\n",
            "Train_AverageReturn : 308.7781677246094\n",
            "Train_StdReturn : 101.24835968017578\n",
            "Train_MaxReturn : 482.48114013671875\n",
            "Train_MinReturn : 129.40638732910156\n",
            "Train_AverageEpLen : 155.46153846153845\n",
            "Train_EnvstepsSoFar : 559879\n",
            "TimeSinceStart : 624.8636620044708\n",
            "Training Loss : -50.58619689941406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 271 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 455.0942077636719\n",
            "Eval_StdReturn : 99.78694152832031\n",
            "Eval_MaxReturn : 584.7882080078125\n",
            "Eval_MinReturn : 342.07305908203125\n",
            "Eval_AverageEpLen : 196.0\n",
            "Train_AverageReturn : 340.1683044433594\n",
            "Train_StdReturn : 86.45332336425781\n",
            "Train_MaxReturn : 460.5821533203125\n",
            "Train_MinReturn : 96.04541015625\n",
            "Train_AverageEpLen : 160.84615384615384\n",
            "Train_EnvstepsSoFar : 561970\n",
            "TimeSinceStart : 627.4096720218658\n",
            "Training Loss : -39.80416488647461\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 272 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 326.7008056640625\n",
            "Eval_StdReturn : 13.988940238952637\n",
            "Eval_MaxReturn : 344.69671630859375\n",
            "Eval_MinReturn : 310.58624267578125\n",
            "Eval_AverageEpLen : 160.66666666666666\n",
            "Train_AverageReturn : 434.28033447265625\n",
            "Train_StdReturn : 152.6747283935547\n",
            "Train_MaxReturn : 795.5802001953125\n",
            "Train_MinReturn : 272.208251953125\n",
            "Train_AverageEpLen : 215.5\n",
            "Train_EnvstepsSoFar : 564125\n",
            "TimeSinceStart : 630.1535801887512\n",
            "Training Loss : -109.85968017578125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 273 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 723.913818359375\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 723.913818359375\n",
            "Eval_MinReturn : 723.913818359375\n",
            "Eval_AverageEpLen : 502.0\n",
            "Train_AverageReturn : 360.8349609375\n",
            "Train_StdReturn : 62.10181427001953\n",
            "Train_MaxReturn : 455.8890075683594\n",
            "Train_MinReturn : 257.31634521484375\n",
            "Train_AverageEpLen : 172.0\n",
            "Train_EnvstepsSoFar : 566189\n",
            "TimeSinceStart : 632.6171534061432\n",
            "Training Loss : -65.4885482788086\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 274 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 369.407958984375\n",
            "Eval_StdReturn : 24.03590202331543\n",
            "Eval_MaxReturn : 396.23834228515625\n",
            "Eval_MinReturn : 337.9183349609375\n",
            "Eval_AverageEpLen : 180.0\n",
            "Train_AverageReturn : 390.6091613769531\n",
            "Train_StdReturn : 133.9026641845703\n",
            "Train_MaxReturn : 764.646728515625\n",
            "Train_MinReturn : 243.5381317138672\n",
            "Train_AverageEpLen : 184.54545454545453\n",
            "Train_EnvstepsSoFar : 568219\n",
            "TimeSinceStart : 635.1399872303009\n",
            "Training Loss : -96.25018310546875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 275 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 332.8415832519531\n",
            "Eval_StdReturn : 116.8291244506836\n",
            "Eval_MaxReturn : 476.2080078125\n",
            "Eval_MinReturn : 190.03793334960938\n",
            "Eval_AverageEpLen : 159.0\n",
            "Train_AverageReturn : 353.3033752441406\n",
            "Train_StdReturn : 82.09391021728516\n",
            "Train_MaxReturn : 568.31005859375\n",
            "Train_MinReturn : 203.347900390625\n",
            "Train_AverageEpLen : 173.25\n",
            "Train_EnvstepsSoFar : 570298\n",
            "TimeSinceStart : 637.5796716213226\n",
            "Training Loss : -18.402021408081055\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 276 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 367.3546142578125\n",
            "Eval_StdReturn : 42.77259063720703\n",
            "Eval_MaxReturn : 424.9609375\n",
            "Eval_MinReturn : 322.57098388671875\n",
            "Eval_AverageEpLen : 174.66666666666666\n",
            "Train_AverageReturn : 374.50830078125\n",
            "Train_StdReturn : 90.72086334228516\n",
            "Train_MaxReturn : 619.1466064453125\n",
            "Train_MinReturn : 247.10397338867188\n",
            "Train_AverageEpLen : 169.15384615384616\n",
            "Train_EnvstepsSoFar : 572497\n",
            "TimeSinceStart : 640.1781017780304\n",
            "Training Loss : 38.05428695678711\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 277 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 428.199462890625\n",
            "Eval_StdReturn : 50.675479888916016\n",
            "Eval_MaxReturn : 493.4450988769531\n",
            "Eval_MinReturn : 369.90057373046875\n",
            "Eval_AverageEpLen : 184.33333333333334\n",
            "Train_AverageReturn : 386.8822937011719\n",
            "Train_StdReturn : 66.43301391601562\n",
            "Train_MaxReturn : 530.7733764648438\n",
            "Train_MinReturn : 305.5693054199219\n",
            "Train_AverageEpLen : 189.36363636363637\n",
            "Train_EnvstepsSoFar : 574580\n",
            "TimeSinceStart : 642.7281641960144\n",
            "Training Loss : -6.956926345825195\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 278 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 333.8382873535156\n",
            "Eval_StdReturn : 34.298091888427734\n",
            "Eval_MaxReturn : 366.798095703125\n",
            "Eval_MinReturn : 286.5399475097656\n",
            "Eval_AverageEpLen : 160.66666666666666\n",
            "Train_AverageReturn : 332.25738525390625\n",
            "Train_StdReturn : 108.26316833496094\n",
            "Train_MaxReturn : 508.32623291015625\n",
            "Train_MinReturn : 145.59381103515625\n",
            "Train_AverageEpLen : 168.25\n",
            "Train_EnvstepsSoFar : 576599\n",
            "TimeSinceStart : 645.1380865573883\n",
            "Training Loss : -54.87493133544922\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 279 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 482.7872314453125\n",
            "Eval_StdReturn : 43.42649841308594\n",
            "Eval_MaxReturn : 526.2137451171875\n",
            "Eval_MinReturn : 439.3607482910156\n",
            "Eval_AverageEpLen : 236.5\n",
            "Train_AverageReturn : 369.6604919433594\n",
            "Train_StdReturn : 108.44605255126953\n",
            "Train_MaxReturn : 543.2835693359375\n",
            "Train_MinReturn : 140.93234252929688\n",
            "Train_AverageEpLen : 174.58333333333334\n",
            "Train_EnvstepsSoFar : 578694\n",
            "TimeSinceStart : 647.6593449115753\n",
            "Training Loss : -92.7877197265625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 280 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 249.50289916992188\n",
            "Eval_StdReturn : 128.4060821533203\n",
            "Eval_MaxReturn : 425.369384765625\n",
            "Eval_MinReturn : 62.671241760253906\n",
            "Eval_AverageEpLen : 121.0\n",
            "Train_AverageReturn : 396.1595153808594\n",
            "Train_StdReturn : 132.57949829101562\n",
            "Train_MaxReturn : 723.1058959960938\n",
            "Train_MinReturn : 172.2745361328125\n",
            "Train_AverageEpLen : 186.08333333333334\n",
            "Train_EnvstepsSoFar : 580927\n",
            "TimeSinceStart : 650.3532772064209\n",
            "Training Loss : -2.337635040283203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 281 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 381.8574523925781\n",
            "Eval_StdReturn : 47.8842887878418\n",
            "Eval_MaxReturn : 445.7897033691406\n",
            "Eval_MinReturn : 330.555908203125\n",
            "Eval_AverageEpLen : 178.33333333333334\n",
            "Train_AverageReturn : 408.5120849609375\n",
            "Train_StdReturn : 98.95140838623047\n",
            "Train_MaxReturn : 551.521484375\n",
            "Train_MinReturn : 254.52642822265625\n",
            "Train_AverageEpLen : 186.36363636363637\n",
            "Train_EnvstepsSoFar : 582977\n",
            "TimeSinceStart : 652.9340636730194\n",
            "Training Loss : 7.940019607543945\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 282 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 233.3338623046875\n",
            "Eval_StdReturn : 89.17186737060547\n",
            "Eval_MaxReturn : 318.7955322265625\n",
            "Eval_MinReturn : 84.686767578125\n",
            "Eval_AverageEpLen : 110.25\n",
            "Train_AverageReturn : 377.6505432128906\n",
            "Train_StdReturn : 151.3406219482422\n",
            "Train_MaxReturn : 668.0327758789062\n",
            "Train_MinReturn : 66.1480941772461\n",
            "Train_AverageEpLen : 182.16666666666666\n",
            "Train_EnvstepsSoFar : 585163\n",
            "TimeSinceStart : 655.5313448905945\n",
            "Training Loss : 32.229637145996094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 283 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 375.76171875\n",
            "Eval_StdReturn : 38.287864685058594\n",
            "Eval_MaxReturn : 428.30047607421875\n",
            "Eval_MinReturn : 338.147705078125\n",
            "Eval_AverageEpLen : 175.33333333333334\n",
            "Train_AverageReturn : 386.4388122558594\n",
            "Train_StdReturn : 87.70381164550781\n",
            "Train_MaxReturn : 534.4763793945312\n",
            "Train_MinReturn : 185.80148315429688\n",
            "Train_AverageEpLen : 170.75\n",
            "Train_EnvstepsSoFar : 587212\n",
            "TimeSinceStart : 658.029988527298\n",
            "Training Loss : 60.0428581237793\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 284 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 808.7413330078125\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 808.7413330078125\n",
            "Eval_MinReturn : 808.7413330078125\n",
            "Eval_AverageEpLen : 460.0\n",
            "Train_AverageReturn : 391.1052551269531\n",
            "Train_StdReturn : 97.4009780883789\n",
            "Train_MaxReturn : 575.5257568359375\n",
            "Train_MinReturn : 163.24020385742188\n",
            "Train_AverageEpLen : 198.63636363636363\n",
            "Train_EnvstepsSoFar : 589397\n",
            "TimeSinceStart : 660.6282951831818\n",
            "Training Loss : 54.178070068359375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 285 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 448.1647644042969\n",
            "Eval_StdReturn : 61.37498474121094\n",
            "Eval_MaxReturn : 501.010498046875\n",
            "Eval_MinReturn : 362.1111145019531\n",
            "Eval_AverageEpLen : 194.66666666666666\n",
            "Train_AverageReturn : 342.6361389160156\n",
            "Train_StdReturn : 97.3690414428711\n",
            "Train_MaxReturn : 427.83953857421875\n",
            "Train_MinReturn : 115.96762084960938\n",
            "Train_AverageEpLen : 154.57142857142858\n",
            "Train_EnvstepsSoFar : 591561\n",
            "TimeSinceStart : 663.1461663246155\n",
            "Training Loss : -152.45431518554688\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 286 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 362.7124938964844\n",
            "Eval_StdReturn : 115.1851806640625\n",
            "Eval_MaxReturn : 520.53759765625\n",
            "Eval_MinReturn : 248.8733673095703\n",
            "Eval_AverageEpLen : 184.66666666666666\n",
            "Train_AverageReturn : 402.7711181640625\n",
            "Train_StdReturn : 79.95565032958984\n",
            "Train_MaxReturn : 561.2730712890625\n",
            "Train_MinReturn : 280.7829895019531\n",
            "Train_AverageEpLen : 190.8181818181818\n",
            "Train_EnvstepsSoFar : 593660\n",
            "TimeSinceStart : 665.7035760879517\n",
            "Training Loss : -41.592063903808594\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 287 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 388.3754577636719\n",
            "Eval_StdReturn : 178.24842834472656\n",
            "Eval_MaxReturn : 566.6239013671875\n",
            "Eval_MinReturn : 210.1270294189453\n",
            "Eval_AverageEpLen : 224.0\n",
            "Train_AverageReturn : 382.4893493652344\n",
            "Train_StdReturn : 121.92353057861328\n",
            "Train_MaxReturn : 590.774658203125\n",
            "Train_MinReturn : 131.32720947265625\n",
            "Train_AverageEpLen : 176.91666666666666\n",
            "Train_EnvstepsSoFar : 595783\n",
            "TimeSinceStart : 668.222060918808\n",
            "Training Loss : -72.00263977050781\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 288 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 347.2474670410156\n",
            "Eval_StdReturn : 28.133020401000977\n",
            "Eval_MaxReturn : 381.828857421875\n",
            "Eval_MinReturn : 312.918701171875\n",
            "Eval_AverageEpLen : 145.66666666666666\n",
            "Train_AverageReturn : 391.7415466308594\n",
            "Train_StdReturn : 154.81304931640625\n",
            "Train_MaxReturn : 705.306640625\n",
            "Train_MinReturn : 101.55168914794922\n",
            "Train_AverageEpLen : 182.58333333333334\n",
            "Train_EnvstepsSoFar : 597974\n",
            "TimeSinceStart : 670.7368609905243\n",
            "Training Loss : -0.39272308349609375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 289 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 444.07672119140625\n",
            "Eval_StdReturn : 50.77490234375\n",
            "Eval_MaxReturn : 494.85162353515625\n",
            "Eval_MinReturn : 393.30181884765625\n",
            "Eval_AverageEpLen : 209.0\n",
            "Train_AverageReturn : 372.1771545410156\n",
            "Train_StdReturn : 104.35862731933594\n",
            "Train_MaxReturn : 525.7637939453125\n",
            "Train_MinReturn : 165.97569274902344\n",
            "Train_AverageEpLen : 177.75\n",
            "Train_EnvstepsSoFar : 600107\n",
            "TimeSinceStart : 673.1720817089081\n",
            "Training Loss : -14.99893569946289\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 290 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 418.73828125\n",
            "Eval_StdReturn : 186.2099609375\n",
            "Eval_MaxReturn : 604.9482421875\n",
            "Eval_MinReturn : 232.52830505371094\n",
            "Eval_AverageEpLen : 203.5\n",
            "Train_AverageReturn : 398.5063781738281\n",
            "Train_StdReturn : 107.75444793701172\n",
            "Train_MaxReturn : 578.306884765625\n",
            "Train_MinReturn : 210.6936492919922\n",
            "Train_AverageEpLen : 205.7\n",
            "Train_EnvstepsSoFar : 602164\n",
            "TimeSinceStart : 675.6194515228271\n",
            "Training Loss : -2.9399356842041016\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 291 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 299.3090515136719\n",
            "Eval_StdReturn : 69.435302734375\n",
            "Eval_MaxReturn : 396.7147216796875\n",
            "Eval_MinReturn : 239.83619689941406\n",
            "Eval_AverageEpLen : 144.66666666666666\n",
            "Train_AverageReturn : 354.92724609375\n",
            "Train_StdReturn : 118.50260925292969\n",
            "Train_MaxReturn : 613.4366455078125\n",
            "Train_MinReturn : 138.90643310546875\n",
            "Train_AverageEpLen : 170.75\n",
            "Train_EnvstepsSoFar : 604213\n",
            "TimeSinceStart : 678.0097887516022\n",
            "Training Loss : 28.585494995117188\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 292 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 410.5476989746094\n",
            "Eval_StdReturn : 63.28610610961914\n",
            "Eval_MaxReturn : 499.95947265625\n",
            "Eval_MinReturn : 362.4002990722656\n",
            "Eval_AverageEpLen : 184.0\n",
            "Train_AverageReturn : 359.2886657714844\n",
            "Train_StdReturn : 135.91249084472656\n",
            "Train_MaxReturn : 645.8905029296875\n",
            "Train_MinReturn : 118.36180877685547\n",
            "Train_AverageEpLen : 170.33333333333334\n",
            "Train_EnvstepsSoFar : 606257\n",
            "TimeSinceStart : 680.5102808475494\n",
            "Training Loss : 61.15000534057617\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 293 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 285.40045166015625\n",
            "Eval_StdReturn : 107.58403015136719\n",
            "Eval_MaxReturn : 377.40069580078125\n",
            "Eval_MinReturn : 106.28146362304688\n",
            "Eval_AverageEpLen : 128.75\n",
            "Train_AverageReturn : 394.14013671875\n",
            "Train_StdReturn : 97.94290924072266\n",
            "Train_MaxReturn : 619.66015625\n",
            "Train_MinReturn : 270.2394714355469\n",
            "Train_AverageEpLen : 177.08333333333334\n",
            "Train_EnvstepsSoFar : 608382\n",
            "TimeSinceStart : 683.0129549503326\n",
            "Training Loss : -135.6697998046875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 294 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 349.0603332519531\n",
            "Eval_StdReturn : 64.12444305419922\n",
            "Eval_MaxReturn : 438.969970703125\n",
            "Eval_MinReturn : 293.8531494140625\n",
            "Eval_AverageEpLen : 177.33333333333334\n",
            "Train_AverageReturn : 380.5049743652344\n",
            "Train_StdReturn : 86.95679473876953\n",
            "Train_MaxReturn : 475.2782287597656\n",
            "Train_MinReturn : 186.44056701660156\n",
            "Train_AverageEpLen : 178.08333333333334\n",
            "Train_EnvstepsSoFar : 610519\n",
            "TimeSinceStart : 685.5179996490479\n",
            "Training Loss : 16.04093360900879\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 295 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 330.7886047363281\n",
            "Eval_StdReturn : 83.83191680908203\n",
            "Eval_MaxReturn : 391.35504150390625\n",
            "Eval_MinReturn : 212.24176025390625\n",
            "Eval_AverageEpLen : 155.0\n",
            "Train_AverageReturn : 365.5403747558594\n",
            "Train_StdReturn : 104.0508804321289\n",
            "Train_MaxReturn : 517.1312866210938\n",
            "Train_MinReturn : 186.97642517089844\n",
            "Train_AverageEpLen : 174.58333333333334\n",
            "Train_EnvstepsSoFar : 612614\n",
            "TimeSinceStart : 687.9463677406311\n",
            "Training Loss : -120.33534240722656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 296 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 353.8966369628906\n",
            "Eval_StdReturn : 38.86594009399414\n",
            "Eval_MaxReturn : 408.70166015625\n",
            "Eval_MinReturn : 322.86785888671875\n",
            "Eval_AverageEpLen : 156.66666666666666\n",
            "Train_AverageReturn : 378.4703674316406\n",
            "Train_StdReturn : 84.3733901977539\n",
            "Train_MaxReturn : 547.8701782226562\n",
            "Train_MinReturn : 179.8727264404297\n",
            "Train_AverageEpLen : 170.83333333333334\n",
            "Train_EnvstepsSoFar : 614664\n",
            "TimeSinceStart : 690.3084719181061\n",
            "Training Loss : -26.340030670166016\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 297 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 927.9071044921875\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 927.9071044921875\n",
            "Eval_MinReturn : 927.9071044921875\n",
            "Eval_AverageEpLen : 426.0\n",
            "Train_AverageReturn : 353.2720947265625\n",
            "Train_StdReturn : 138.9250946044922\n",
            "Train_MaxReturn : 576.867431640625\n",
            "Train_MinReturn : 141.8123321533203\n",
            "Train_AverageEpLen : 172.0\n",
            "Train_EnvstepsSoFar : 616728\n",
            "TimeSinceStart : 692.7933466434479\n",
            "Training Loss : 3.2490081787109375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 298 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 486.08892822265625\n",
            "Eval_StdReturn : 14.164596557617188\n",
            "Eval_MaxReturn : 500.2535095214844\n",
            "Eval_MinReturn : 471.92431640625\n",
            "Eval_AverageEpLen : 218.0\n",
            "Train_AverageReturn : 468.4693908691406\n",
            "Train_StdReturn : 107.93941497802734\n",
            "Train_MaxReturn : 622.277099609375\n",
            "Train_MinReturn : 282.6239318847656\n",
            "Train_AverageEpLen : 225.33333333333334\n",
            "Train_EnvstepsSoFar : 618756\n",
            "TimeSinceStart : 695.2654287815094\n",
            "Training Loss : 24.779151916503906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 299 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 296.47113037109375\n",
            "Eval_StdReturn : 124.28213500976562\n",
            "Eval_MaxReturn : 458.6587829589844\n",
            "Eval_MinReturn : 116.54742431640625\n",
            "Eval_AverageEpLen : 132.25\n",
            "Train_AverageReturn : 383.4978332519531\n",
            "Train_StdReturn : 97.43017578125\n",
            "Train_MaxReturn : 558.493896484375\n",
            "Train_MinReturn : 227.51856994628906\n",
            "Train_AverageEpLen : 172.16666666666666\n",
            "Train_EnvstepsSoFar : 620822\n",
            "TimeSinceStart : 697.7242619991302\n",
            "Training Loss : 36.506866455078125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name Hopper-v2 --ep_len 1000 \\\n",
        "    --discount 0.99 -n 300 -l 2 -s 32 -b 2000 -lr 0.001 \\\n",
        "    --reward_to_go --nn_baseline \\\n",
        "    --action_noise_std 0.5 --gae_lambda 0.95 \\\n",
        "    --exp_name q5_b2000_r0.001_lambda0.95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cVW6bx2Mo1a",
        "outputId": "2e6f0a41-50a6-47c1-83ae-ed0ccf34f83e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Eval_StdReturn : 7.099106311798096\n",
            "Eval_MaxReturn : 248.5886688232422\n",
            "Eval_MinReturn : 228.90505981445312\n",
            "Eval_AverageEpLen : 108.5\n",
            "Train_AverageReturn : 211.4699249267578\n",
            "Train_StdReturn : 38.39091491699219\n",
            "Train_MaxReturn : 253.72024536132812\n",
            "Train_MinReturn : 82.70963287353516\n",
            "Train_AverageEpLen : 101.95\n",
            "Train_EnvstepsSoFar : 248860\n",
            "TimeSinceStart : 264.21912693977356\n",
            "Training Loss : 91.31234741210938\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 122 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 221.60128784179688\n",
            "Eval_StdReturn : 12.135037422180176\n",
            "Eval_MaxReturn : 243.84072875976562\n",
            "Eval_MinReturn : 206.68112182617188\n",
            "Eval_AverageEpLen : 99.6\n",
            "Train_AverageReturn : 222.08485412597656\n",
            "Train_StdReturn : 26.269250869750977\n",
            "Train_MaxReturn : 271.5321960449219\n",
            "Train_MinReturn : 139.10264587402344\n",
            "Train_AverageEpLen : 105.52631578947368\n",
            "Train_EnvstepsSoFar : 250865\n",
            "TimeSinceStart : 266.466032743454\n",
            "Training Loss : 13.158697128295898\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 123 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 218.9756317138672\n",
            "Eval_StdReturn : 12.679557800292969\n",
            "Eval_MaxReturn : 238.11041259765625\n",
            "Eval_MinReturn : 202.58035278320312\n",
            "Eval_AverageEpLen : 101.5\n",
            "Train_AverageReturn : 230.95433044433594\n",
            "Train_StdReturn : 16.19448471069336\n",
            "Train_MaxReturn : 267.7730407714844\n",
            "Train_MinReturn : 200.29904174804688\n",
            "Train_AverageEpLen : 110.36842105263158\n",
            "Train_EnvstepsSoFar : 252962\n",
            "TimeSinceStart : 268.7437858581543\n",
            "Training Loss : -22.250167846679688\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 124 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 206.80662536621094\n",
            "Eval_StdReturn : 50.9943733215332\n",
            "Eval_MaxReturn : 243.34027099609375\n",
            "Eval_MinReturn : 118.84562683105469\n",
            "Eval_AverageEpLen : 100.25\n",
            "Train_AverageReturn : 229.455322265625\n",
            "Train_StdReturn : 25.71839141845703\n",
            "Train_MaxReturn : 287.74005126953125\n",
            "Train_MinReturn : 165.87939453125\n",
            "Train_AverageEpLen : 112.33333333333333\n",
            "Train_EnvstepsSoFar : 254984\n",
            "TimeSinceStart : 270.8949365615845\n",
            "Training Loss : 4.732816696166992\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 125 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 205.3634490966797\n",
            "Eval_StdReturn : 34.84397888183594\n",
            "Eval_MaxReturn : 226.732666015625\n",
            "Eval_MinReturn : 136.54766845703125\n",
            "Eval_AverageEpLen : 94.2\n",
            "Train_AverageReturn : 232.30776977539062\n",
            "Train_StdReturn : 14.298796653747559\n",
            "Train_MaxReturn : 263.68310546875\n",
            "Train_MinReturn : 207.2871551513672\n",
            "Train_AverageEpLen : 109.21052631578948\n",
            "Train_EnvstepsSoFar : 257059\n",
            "TimeSinceStart : 273.1875214576721\n",
            "Training Loss : -5.9015350341796875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 126 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 230.19113159179688\n",
            "Eval_StdReturn : 12.180928230285645\n",
            "Eval_MaxReturn : 251.25845336914062\n",
            "Eval_MinReturn : 222.22068786621094\n",
            "Eval_AverageEpLen : 106.5\n",
            "Train_AverageReturn : 233.17913818359375\n",
            "Train_StdReturn : 32.81096649169922\n",
            "Train_MaxReturn : 301.09869384765625\n",
            "Train_MinReturn : 153.59007263183594\n",
            "Train_AverageEpLen : 114.88888888888889\n",
            "Train_EnvstepsSoFar : 259127\n",
            "TimeSinceStart : 275.43654012680054\n",
            "Training Loss : 61.5103759765625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 127 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 240.3058624267578\n",
            "Eval_StdReturn : 31.599346160888672\n",
            "Eval_MaxReturn : 274.28338623046875\n",
            "Eval_MinReturn : 206.5110626220703\n",
            "Eval_AverageEpLen : 120.25\n",
            "Train_AverageReturn : 232.3282012939453\n",
            "Train_StdReturn : 15.014923095703125\n",
            "Train_MaxReturn : 265.009521484375\n",
            "Train_MinReturn : 210.35897827148438\n",
            "Train_AverageEpLen : 111.33333333333333\n",
            "Train_EnvstepsSoFar : 261131\n",
            "TimeSinceStart : 277.6676642894745\n",
            "Training Loss : 11.097265243530273\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 128 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 179.382568359375\n",
            "Eval_StdReturn : 64.2591552734375\n",
            "Eval_MaxReturn : 239.69960021972656\n",
            "Eval_MinReturn : 67.79621887207031\n",
            "Eval_AverageEpLen : 93.0\n",
            "Train_AverageReturn : 227.1610107421875\n",
            "Train_StdReturn : 13.360801696777344\n",
            "Train_MaxReturn : 251.75177001953125\n",
            "Train_MinReturn : 192.48165893554688\n",
            "Train_AverageEpLen : 105.36842105263158\n",
            "Train_EnvstepsSoFar : 263133\n",
            "TimeSinceStart : 279.9096438884735\n",
            "Training Loss : -34.40793228149414\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 129 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 229.29360961914062\n",
            "Eval_StdReturn : 13.577272415161133\n",
            "Eval_MaxReturn : 252.54913330078125\n",
            "Eval_MinReturn : 219.68006896972656\n",
            "Eval_AverageEpLen : 110.5\n",
            "Train_AverageReturn : 239.7223358154297\n",
            "Train_StdReturn : 28.965831756591797\n",
            "Train_MaxReturn : 313.5540771484375\n",
            "Train_MinReturn : 196.00955200195312\n",
            "Train_AverageEpLen : 119.76470588235294\n",
            "Train_EnvstepsSoFar : 265169\n",
            "TimeSinceStart : 282.19540643692017\n",
            "Training Loss : 34.49333953857422\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 130 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.9125518798828\n",
            "Eval_StdReturn : 27.51982307434082\n",
            "Eval_MaxReturn : 284.20281982421875\n",
            "Eval_MinReturn : 211.86912536621094\n",
            "Eval_AverageEpLen : 114.25\n",
            "Train_AverageReturn : 221.8064422607422\n",
            "Train_StdReturn : 27.536752700805664\n",
            "Train_MaxReturn : 253.41571044921875\n",
            "Train_MinReturn : 125.86940002441406\n",
            "Train_AverageEpLen : 106.89473684210526\n",
            "Train_EnvstepsSoFar : 267200\n",
            "TimeSinceStart : 284.404568195343\n",
            "Training Loss : 44.18458557128906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 131 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 212.82598876953125\n",
            "Eval_StdReturn : 25.77304458618164\n",
            "Eval_MaxReturn : 239.67092895507812\n",
            "Eval_MinReturn : 186.138427734375\n",
            "Eval_AverageEpLen : 103.25\n",
            "Train_AverageReturn : 243.03826904296875\n",
            "Train_StdReturn : 21.53693199157715\n",
            "Train_MaxReturn : 294.419677734375\n",
            "Train_MinReturn : 212.98300170898438\n",
            "Train_AverageEpLen : 117.61111111111111\n",
            "Train_EnvstepsSoFar : 269317\n",
            "TimeSinceStart : 286.74944972991943\n",
            "Training Loss : 13.410362243652344\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 132 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.2632598876953\n",
            "Eval_StdReturn : 10.770930290222168\n",
            "Eval_MaxReturn : 243.26625061035156\n",
            "Eval_MinReturn : 215.2470703125\n",
            "Eval_AverageEpLen : 110.25\n",
            "Train_AverageReturn : 221.5537872314453\n",
            "Train_StdReturn : 36.7369384765625\n",
            "Train_MaxReturn : 268.4735107421875\n",
            "Train_MinReturn : 106.93726348876953\n",
            "Train_AverageEpLen : 109.05263157894737\n",
            "Train_EnvstepsSoFar : 271389\n",
            "TimeSinceStart : 289.0229706764221\n",
            "Training Loss : -24.311344146728516\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 133 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.14260864257812\n",
            "Eval_StdReturn : 11.446742057800293\n",
            "Eval_MaxReturn : 256.0508117675781\n",
            "Eval_MinReturn : 227.74359130859375\n",
            "Eval_AverageEpLen : 113.25\n",
            "Train_AverageReturn : 225.89614868164062\n",
            "Train_StdReturn : 21.71493148803711\n",
            "Train_MaxReturn : 256.76019287109375\n",
            "Train_MinReturn : 172.09707641601562\n",
            "Train_AverageEpLen : 105.73684210526316\n",
            "Train_EnvstepsSoFar : 273398\n",
            "TimeSinceStart : 291.2697458267212\n",
            "Training Loss : -39.512657165527344\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 134 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 252.528076171875\n",
            "Eval_StdReturn : 22.90019989013672\n",
            "Eval_MaxReturn : 285.81329345703125\n",
            "Eval_MinReturn : 222.41876220703125\n",
            "Eval_AverageEpLen : 123.5\n",
            "Train_AverageReturn : 231.26429748535156\n",
            "Train_StdReturn : 17.325044631958008\n",
            "Train_MaxReturn : 260.90582275390625\n",
            "Train_MinReturn : 191.39541625976562\n",
            "Train_AverageEpLen : 111.22222222222223\n",
            "Train_EnvstepsSoFar : 275400\n",
            "TimeSinceStart : 293.5084683895111\n",
            "Training Loss : 18.406654357910156\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 135 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 215.7095184326172\n",
            "Eval_StdReturn : 9.936803817749023\n",
            "Eval_MaxReturn : 229.97998046875\n",
            "Eval_MinReturn : 204.30569458007812\n",
            "Eval_AverageEpLen : 95.6\n",
            "Train_AverageReturn : 230.79075622558594\n",
            "Train_StdReturn : 26.63997459411621\n",
            "Train_MaxReturn : 289.2336730957031\n",
            "Train_MinReturn : 176.7794647216797\n",
            "Train_AverageEpLen : 111.0\n",
            "Train_EnvstepsSoFar : 277509\n",
            "TimeSinceStart : 295.86135363578796\n",
            "Training Loss : 2.6940574645996094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 136 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 231.03768920898438\n",
            "Eval_StdReturn : 5.740368843078613\n",
            "Eval_MaxReturn : 236.7864532470703\n",
            "Eval_MinReturn : 221.49986267089844\n",
            "Eval_AverageEpLen : 106.25\n",
            "Train_AverageReturn : 228.97067260742188\n",
            "Train_StdReturn : 35.161964416503906\n",
            "Train_MaxReturn : 304.8286437988281\n",
            "Train_MinReturn : 147.88693237304688\n",
            "Train_AverageEpLen : 111.21052631578948\n",
            "Train_EnvstepsSoFar : 279622\n",
            "TimeSinceStart : 298.13334035873413\n",
            "Training Loss : -66.04924011230469\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 137 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 241.23960876464844\n",
            "Eval_StdReturn : 17.277978897094727\n",
            "Eval_MaxReturn : 261.26580810546875\n",
            "Eval_MinReturn : 222.01144409179688\n",
            "Eval_AverageEpLen : 115.75\n",
            "Train_AverageReturn : 237.9640350341797\n",
            "Train_StdReturn : 20.188264846801758\n",
            "Train_MaxReturn : 281.0501403808594\n",
            "Train_MinReturn : 211.35409545898438\n",
            "Train_AverageEpLen : 113.5\n",
            "Train_EnvstepsSoFar : 281665\n",
            "TimeSinceStart : 300.38387846946716\n",
            "Training Loss : 89.58563995361328\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 138 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 223.7777862548828\n",
            "Eval_StdReturn : 4.3049187660217285\n",
            "Eval_MaxReturn : 227.61253356933594\n",
            "Eval_MinReturn : 216.6876678466797\n",
            "Eval_AverageEpLen : 103.5\n",
            "Train_AverageReturn : 221.2183074951172\n",
            "Train_StdReturn : 33.58926773071289\n",
            "Train_MaxReturn : 263.57391357421875\n",
            "Train_MinReturn : 128.66241455078125\n",
            "Train_AverageEpLen : 105.8\n",
            "Train_EnvstepsSoFar : 283781\n",
            "TimeSinceStart : 302.6311762332916\n",
            "Training Loss : 10.540143966674805\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 139 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 210.3029022216797\n",
            "Eval_StdReturn : 43.1939811706543\n",
            "Eval_MaxReturn : 244.64891052246094\n",
            "Eval_MinReturn : 125.19835662841797\n",
            "Eval_AverageEpLen : 97.8\n",
            "Train_AverageReturn : 226.89114379882812\n",
            "Train_StdReturn : 33.82032775878906\n",
            "Train_MaxReturn : 282.98260498046875\n",
            "Train_MinReturn : 130.168701171875\n",
            "Train_AverageEpLen : 112.11111111111111\n",
            "Train_EnvstepsSoFar : 285799\n",
            "TimeSinceStart : 304.9118301868439\n",
            "Training Loss : 37.588714599609375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 140 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 209.06588745117188\n",
            "Eval_StdReturn : 43.88214111328125\n",
            "Eval_MaxReturn : 247.16844177246094\n",
            "Eval_MinReturn : 123.4486083984375\n",
            "Eval_AverageEpLen : 100.2\n",
            "Train_AverageReturn : 227.33773803710938\n",
            "Train_StdReturn : 27.376567840576172\n",
            "Train_MaxReturn : 294.3941650390625\n",
            "Train_MinReturn : 152.8609161376953\n",
            "Train_AverageEpLen : 107.05263157894737\n",
            "Train_EnvstepsSoFar : 287833\n",
            "TimeSinceStart : 307.2087330818176\n",
            "Training Loss : 57.35305404663086\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 141 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 207.15048217773438\n",
            "Eval_StdReturn : 71.86422729492188\n",
            "Eval_MaxReturn : 290.1290283203125\n",
            "Eval_MinReturn : 92.15074920654297\n",
            "Eval_AverageEpLen : 100.5\n",
            "Train_AverageReturn : 212.408203125\n",
            "Train_StdReturn : 42.51227569580078\n",
            "Train_MaxReturn : 261.0802001953125\n",
            "Train_MinReturn : 96.54842376708984\n",
            "Train_AverageEpLen : 103.4\n",
            "Train_EnvstepsSoFar : 289901\n",
            "TimeSinceStart : 309.4024107456207\n",
            "Training Loss : -75.23306274414062\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 142 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 223.07801818847656\n",
            "Eval_StdReturn : 11.051946640014648\n",
            "Eval_MaxReturn : 238.3743896484375\n",
            "Eval_MinReturn : 207.3826141357422\n",
            "Eval_AverageEpLen : 103.25\n",
            "Train_AverageReturn : 226.0096893310547\n",
            "Train_StdReturn : 26.90335464477539\n",
            "Train_MaxReturn : 277.4205322265625\n",
            "Train_MinReturn : 137.91082763671875\n",
            "Train_AverageEpLen : 105.78947368421052\n",
            "Train_EnvstepsSoFar : 291911\n",
            "TimeSinceStart : 311.5525789260864\n",
            "Training Loss : -14.151506423950195\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 143 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 219.40640258789062\n",
            "Eval_StdReturn : 6.765259742736816\n",
            "Eval_MaxReturn : 228.29702758789062\n",
            "Eval_MinReturn : 207.91896057128906\n",
            "Eval_AverageEpLen : 98.6\n",
            "Train_AverageReturn : 231.30491638183594\n",
            "Train_StdReturn : 17.203811645507812\n",
            "Train_MaxReturn : 270.4093933105469\n",
            "Train_MinReturn : 213.23793029785156\n",
            "Train_AverageEpLen : 109.10526315789474\n",
            "Train_EnvstepsSoFar : 293984\n",
            "TimeSinceStart : 313.83154129981995\n",
            "Training Loss : 91.5647964477539\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 144 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 229.43624877929688\n",
            "Eval_StdReturn : 12.955545425415039\n",
            "Eval_MaxReturn : 243.34201049804688\n",
            "Eval_MinReturn : 209.4425506591797\n",
            "Eval_AverageEpLen : 108.0\n",
            "Train_AverageReturn : 222.14044189453125\n",
            "Train_StdReturn : 36.9900016784668\n",
            "Train_MaxReturn : 272.5557556152344\n",
            "Train_MinReturn : 107.37608337402344\n",
            "Train_AverageEpLen : 107.0\n",
            "Train_EnvstepsSoFar : 296017\n",
            "TimeSinceStart : 316.07054233551025\n",
            "Training Loss : -120.88540649414062\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 145 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 236.1605224609375\n",
            "Eval_StdReturn : 4.569928169250488\n",
            "Eval_MaxReturn : 243.58206176757812\n",
            "Eval_MinReturn : 231.21180725097656\n",
            "Eval_AverageEpLen : 112.0\n",
            "Train_AverageReturn : 223.2677764892578\n",
            "Train_StdReturn : 31.761638641357422\n",
            "Train_MaxReturn : 277.7028503417969\n",
            "Train_MinReturn : 146.53660583496094\n",
            "Train_AverageEpLen : 108.21052631578948\n",
            "Train_EnvstepsSoFar : 298073\n",
            "TimeSinceStart : 318.3282480239868\n",
            "Training Loss : -23.780899047851562\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 146 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 229.12559509277344\n",
            "Eval_StdReturn : 21.157075881958008\n",
            "Eval_MaxReturn : 256.51715087890625\n",
            "Eval_MinReturn : 204.1971893310547\n",
            "Eval_AverageEpLen : 110.25\n",
            "Train_AverageReturn : 227.22242736816406\n",
            "Train_StdReturn : 27.42896842956543\n",
            "Train_MaxReturn : 270.9889831542969\n",
            "Train_MinReturn : 162.91583251953125\n",
            "Train_AverageEpLen : 109.57894736842105\n",
            "Train_EnvstepsSoFar : 300155\n",
            "TimeSinceStart : 320.61616015434265\n",
            "Training Loss : 40.69132995605469\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 147 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.9572296142578\n",
            "Eval_StdReturn : 10.24299144744873\n",
            "Eval_MaxReturn : 240.17587280273438\n",
            "Eval_MinReturn : 215.27511596679688\n",
            "Eval_AverageEpLen : 109.0\n",
            "Train_AverageReturn : 225.94895935058594\n",
            "Train_StdReturn : 34.594661712646484\n",
            "Train_MaxReturn : 272.0252685546875\n",
            "Train_MinReturn : 106.26704406738281\n",
            "Train_AverageEpLen : 110.73684210526316\n",
            "Train_EnvstepsSoFar : 302259\n",
            "TimeSinceStart : 322.95209670066833\n",
            "Training Loss : 23.957639694213867\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 148 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 241.96319580078125\n",
            "Eval_StdReturn : 14.820358276367188\n",
            "Eval_MaxReturn : 262.4504089355469\n",
            "Eval_MinReturn : 227.32565307617188\n",
            "Eval_AverageEpLen : 119.25\n",
            "Train_AverageReturn : 229.7789306640625\n",
            "Train_StdReturn : 15.70583724975586\n",
            "Train_MaxReturn : 274.2694091796875\n",
            "Train_MinReturn : 198.42965698242188\n",
            "Train_AverageEpLen : 108.36842105263158\n",
            "Train_EnvstepsSoFar : 304318\n",
            "TimeSinceStart : 325.24646496772766\n",
            "Training Loss : 54.873172760009766\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 149 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 246.36782836914062\n",
            "Eval_StdReturn : 19.743446350097656\n",
            "Eval_MaxReturn : 267.25738525390625\n",
            "Eval_MinReturn : 221.13046264648438\n",
            "Eval_AverageEpLen : 118.25\n",
            "Train_AverageReturn : 232.4536590576172\n",
            "Train_StdReturn : 14.212121963500977\n",
            "Train_MaxReturn : 251.67922973632812\n",
            "Train_MinReturn : 195.5442352294922\n",
            "Train_AverageEpLen : 110.10526315789474\n",
            "Train_EnvstepsSoFar : 306410\n",
            "TimeSinceStart : 327.5519013404846\n",
            "Training Loss : 41.01557159423828\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 150 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.90045166015625\n",
            "Eval_StdReturn : 26.108200073242188\n",
            "Eval_MaxReturn : 246.31455993652344\n",
            "Eval_MinReturn : 181.81600952148438\n",
            "Eval_AverageEpLen : 115.0\n",
            "Train_AverageReturn : 223.2183837890625\n",
            "Train_StdReturn : 40.07221603393555\n",
            "Train_MaxReturn : 295.76947021484375\n",
            "Train_MinReturn : 85.56210327148438\n",
            "Train_AverageEpLen : 107.52631578947368\n",
            "Train_EnvstepsSoFar : 308453\n",
            "TimeSinceStart : 329.8082377910614\n",
            "Training Loss : -45.08344268798828\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 151 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 239.5130157470703\n",
            "Eval_StdReturn : 8.718679428100586\n",
            "Eval_MaxReturn : 248.3834228515625\n",
            "Eval_MinReturn : 225.4335479736328\n",
            "Eval_AverageEpLen : 112.75\n",
            "Train_AverageReturn : 221.9733123779297\n",
            "Train_StdReturn : 24.511110305786133\n",
            "Train_MaxReturn : 259.20361328125\n",
            "Train_MinReturn : 132.13526916503906\n",
            "Train_AverageEpLen : 103.65\n",
            "Train_EnvstepsSoFar : 310526\n",
            "TimeSinceStart : 332.07969760894775\n",
            "Training Loss : -26.748586654663086\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 152 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 197.7412109375\n",
            "Eval_StdReturn : 55.19076156616211\n",
            "Eval_MaxReturn : 242.18362426757812\n",
            "Eval_MinReturn : 89.65382385253906\n",
            "Eval_AverageEpLen : 94.2\n",
            "Train_AverageReturn : 224.75296020507812\n",
            "Train_StdReturn : 31.778791427612305\n",
            "Train_MaxReturn : 279.5604248046875\n",
            "Train_MinReturn : 130.17050170898438\n",
            "Train_AverageEpLen : 107.78947368421052\n",
            "Train_EnvstepsSoFar : 312574\n",
            "TimeSinceStart : 334.3738932609558\n",
            "Training Loss : -48.56150817871094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 153 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 223.4921875\n",
            "Eval_StdReturn : 14.13000202178955\n",
            "Eval_MaxReturn : 242.07855224609375\n",
            "Eval_MinReturn : 205.40631103515625\n",
            "Eval_AverageEpLen : 113.25\n",
            "Train_AverageReturn : 223.00668334960938\n",
            "Train_StdReturn : 40.814483642578125\n",
            "Train_MaxReturn : 293.4161376953125\n",
            "Train_MinReturn : 124.37554931640625\n",
            "Train_AverageEpLen : 109.05263157894737\n",
            "Train_EnvstepsSoFar : 314646\n",
            "TimeSinceStart : 336.6642689704895\n",
            "Training Loss : -12.243001937866211\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 154 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.943359375\n",
            "Eval_StdReturn : 8.848395347595215\n",
            "Eval_MaxReturn : 237.29734802246094\n",
            "Eval_MinReturn : 213.2024688720703\n",
            "Eval_AverageEpLen : 101.6\n",
            "Train_AverageReturn : 236.895263671875\n",
            "Train_StdReturn : 19.040443420410156\n",
            "Train_MaxReturn : 288.7465515136719\n",
            "Train_MinReturn : 209.4853057861328\n",
            "Train_AverageEpLen : 112.44444444444444\n",
            "Train_EnvstepsSoFar : 316670\n",
            "TimeSinceStart : 338.94202065467834\n",
            "Training Loss : 5.48520565032959\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 155 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 236.0048065185547\n",
            "Eval_StdReturn : 25.554807662963867\n",
            "Eval_MaxReturn : 277.559326171875\n",
            "Eval_MinReturn : 211.33819580078125\n",
            "Eval_AverageEpLen : 113.0\n",
            "Train_AverageReturn : 239.68125915527344\n",
            "Train_StdReturn : 22.068180084228516\n",
            "Train_MaxReturn : 286.8004150390625\n",
            "Train_MinReturn : 210.715087890625\n",
            "Train_AverageEpLen : 115.22222222222223\n",
            "Train_EnvstepsSoFar : 318744\n",
            "TimeSinceStart : 341.2601511478424\n",
            "Training Loss : -86.17866516113281\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 156 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 248.18280029296875\n",
            "Eval_StdReturn : 24.388473510742188\n",
            "Eval_MaxReturn : 289.819580078125\n",
            "Eval_MinReturn : 227.6497039794922\n",
            "Eval_AverageEpLen : 123.5\n",
            "Train_AverageReturn : 229.94789123535156\n",
            "Train_StdReturn : 42.49020004272461\n",
            "Train_MaxReturn : 271.70013427734375\n",
            "Train_MinReturn : 70.07420349121094\n",
            "Train_AverageEpLen : 111.16666666666667\n",
            "Train_EnvstepsSoFar : 320745\n",
            "TimeSinceStart : 343.5310263633728\n",
            "Training Loss : 19.24871826171875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 157 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 243.1687774658203\n",
            "Eval_StdReturn : 10.467309951782227\n",
            "Eval_MaxReturn : 254.67674255371094\n",
            "Eval_MinReturn : 226.2264862060547\n",
            "Eval_AverageEpLen : 119.75\n",
            "Train_AverageReturn : 233.60032653808594\n",
            "Train_StdReturn : 17.61675262451172\n",
            "Train_MaxReturn : 284.6400451660156\n",
            "Train_MinReturn : 206.8002471923828\n",
            "Train_AverageEpLen : 110.47368421052632\n",
            "Train_EnvstepsSoFar : 322844\n",
            "TimeSinceStart : 345.87118697166443\n",
            "Training Loss : -90.87699127197266\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 158 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 236.21417236328125\n",
            "Eval_StdReturn : 28.846012115478516\n",
            "Eval_MaxReturn : 282.41033935546875\n",
            "Eval_MinReturn : 208.07373046875\n",
            "Eval_AverageEpLen : 114.75\n",
            "Train_AverageReturn : 227.8607177734375\n",
            "Train_StdReturn : 18.20168113708496\n",
            "Train_MaxReturn : 259.04901123046875\n",
            "Train_MinReturn : 181.24984741210938\n",
            "Train_AverageEpLen : 107.73684210526316\n",
            "Train_EnvstepsSoFar : 324891\n",
            "TimeSinceStart : 348.1276504993439\n",
            "Training Loss : -89.54608154296875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 159 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 227.59718322753906\n",
            "Eval_StdReturn : 20.27863311767578\n",
            "Eval_MaxReturn : 255.78060913085938\n",
            "Eval_MinReturn : 207.32272338867188\n",
            "Eval_AverageEpLen : 108.0\n",
            "Train_AverageReturn : 230.4125518798828\n",
            "Train_StdReturn : 16.330257415771484\n",
            "Train_MaxReturn : 257.19146728515625\n",
            "Train_MinReturn : 197.644775390625\n",
            "Train_AverageEpLen : 107.73684210526316\n",
            "Train_EnvstepsSoFar : 326938\n",
            "TimeSinceStart : 350.3743329048157\n",
            "Training Loss : -17.906572341918945\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 160 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 241.88284301757812\n",
            "Eval_StdReturn : 19.77968978881836\n",
            "Eval_MaxReturn : 264.0384521484375\n",
            "Eval_MinReturn : 221.14608764648438\n",
            "Eval_AverageEpLen : 118.75\n",
            "Train_AverageReturn : 231.48538208007812\n",
            "Train_StdReturn : 39.75027847290039\n",
            "Train_MaxReturn : 292.14178466796875\n",
            "Train_MinReturn : 113.26339721679688\n",
            "Train_AverageEpLen : 112.94444444444444\n",
            "Train_EnvstepsSoFar : 328971\n",
            "TimeSinceStart : 352.6671795845032\n",
            "Training Loss : -1.6474075317382812\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 161 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 228.963623046875\n",
            "Eval_StdReturn : 12.193679809570312\n",
            "Eval_MaxReturn : 244.78262329101562\n",
            "Eval_MinReturn : 213.4921417236328\n",
            "Eval_AverageEpLen : 107.0\n",
            "Train_AverageReturn : 243.4747772216797\n",
            "Train_StdReturn : 20.310029983520508\n",
            "Train_MaxReturn : 294.720947265625\n",
            "Train_MinReturn : 218.1227569580078\n",
            "Train_AverageEpLen : 116.55555555555556\n",
            "Train_EnvstepsSoFar : 331069\n",
            "TimeSinceStart : 354.95527935028076\n",
            "Training Loss : 7.233222961425781\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 162 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 243.92758178710938\n",
            "Eval_StdReturn : 24.886770248413086\n",
            "Eval_MaxReturn : 286.3241271972656\n",
            "Eval_MinReturn : 222.7359161376953\n",
            "Eval_AverageEpLen : 121.25\n",
            "Train_AverageReturn : 233.00958251953125\n",
            "Train_StdReturn : 13.012144088745117\n",
            "Train_MaxReturn : 266.59228515625\n",
            "Train_MinReturn : 210.41082763671875\n",
            "Train_AverageEpLen : 110.05263157894737\n",
            "Train_EnvstepsSoFar : 333160\n",
            "TimeSinceStart : 357.3331468105316\n",
            "Training Loss : -24.346847534179688\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 163 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.03158569335938\n",
            "Eval_StdReturn : 12.291706085205078\n",
            "Eval_MaxReturn : 254.30152893066406\n",
            "Eval_MinReturn : 222.08888244628906\n",
            "Eval_AverageEpLen : 114.25\n",
            "Train_AverageReturn : 217.0306854248047\n",
            "Train_StdReturn : 49.35316467285156\n",
            "Train_MaxReturn : 256.386962890625\n",
            "Train_MinReturn : 58.146263122558594\n",
            "Train_AverageEpLen : 105.57894736842105\n",
            "Train_EnvstepsSoFar : 335166\n",
            "TimeSinceStart : 359.5286087989807\n",
            "Training Loss : -132.78652954101562\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 164 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 243.9351043701172\n",
            "Eval_StdReturn : 10.614021301269531\n",
            "Eval_MaxReturn : 257.4581604003906\n",
            "Eval_MinReturn : 227.77264404296875\n",
            "Eval_AverageEpLen : 115.75\n",
            "Train_AverageReturn : 238.09405517578125\n",
            "Train_StdReturn : 16.369680404663086\n",
            "Train_MaxReturn : 270.10528564453125\n",
            "Train_MinReturn : 200.05068969726562\n",
            "Train_AverageEpLen : 113.16666666666667\n",
            "Train_EnvstepsSoFar : 337203\n",
            "TimeSinceStart : 361.7841145992279\n",
            "Training Loss : 65.89636993408203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 165 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.95281982421875\n",
            "Eval_StdReturn : 21.49443817138672\n",
            "Eval_MaxReturn : 253.5894775390625\n",
            "Eval_MinReturn : 193.71783447265625\n",
            "Eval_AverageEpLen : 107.25\n",
            "Train_AverageReturn : 244.98040771484375\n",
            "Train_StdReturn : 20.077795028686523\n",
            "Train_MaxReturn : 284.0633850097656\n",
            "Train_MinReturn : 213.529052734375\n",
            "Train_AverageEpLen : 119.23529411764706\n",
            "Train_EnvstepsSoFar : 339230\n",
            "TimeSinceStart : 364.0868561267853\n",
            "Training Loss : 102.84515380859375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 166 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.05355834960938\n",
            "Eval_StdReturn : 17.76108169555664\n",
            "Eval_MaxReturn : 260.584228515625\n",
            "Eval_MinReturn : 215.1527557373047\n",
            "Eval_AverageEpLen : 107.5\n",
            "Train_AverageReturn : 225.63214111328125\n",
            "Train_StdReturn : 37.50838851928711\n",
            "Train_MaxReturn : 267.69830322265625\n",
            "Train_MinReturn : 86.67755889892578\n",
            "Train_AverageEpLen : 109.21052631578948\n",
            "Train_EnvstepsSoFar : 341305\n",
            "TimeSinceStart : 366.34394693374634\n",
            "Training Loss : -18.613296508789062\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 167 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.6876220703125\n",
            "Eval_StdReturn : 5.732539176940918\n",
            "Eval_MaxReturn : 243.16055297851562\n",
            "Eval_MinReturn : 228.49452209472656\n",
            "Eval_AverageEpLen : 114.5\n",
            "Train_AverageReturn : 240.4575958251953\n",
            "Train_StdReturn : 24.3429012298584\n",
            "Train_MaxReturn : 301.19671630859375\n",
            "Train_MinReturn : 211.51449584960938\n",
            "Train_AverageEpLen : 116.05555555555556\n",
            "Train_EnvstepsSoFar : 343394\n",
            "TimeSinceStart : 368.7019901275635\n",
            "Training Loss : 77.79275512695312\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 168 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 218.79518127441406\n",
            "Eval_StdReturn : 19.142934799194336\n",
            "Eval_MaxReturn : 230.8728790283203\n",
            "Eval_MinReturn : 185.65933227539062\n",
            "Eval_AverageEpLen : 101.0\n",
            "Train_AverageReturn : 243.5748291015625\n",
            "Train_StdReturn : 27.670907974243164\n",
            "Train_MaxReturn : 301.61029052734375\n",
            "Train_MinReturn : 205.99630737304688\n",
            "Train_AverageEpLen : 119.76470588235294\n",
            "Train_EnvstepsSoFar : 345430\n",
            "TimeSinceStart : 370.9840843677521\n",
            "Training Loss : 17.63249969482422\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 169 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 248.65892028808594\n",
            "Eval_StdReturn : 9.062369346618652\n",
            "Eval_MaxReturn : 260.52264404296875\n",
            "Eval_MinReturn : 238.3768310546875\n",
            "Eval_AverageEpLen : 121.5\n",
            "Train_AverageReturn : 245.7725372314453\n",
            "Train_StdReturn : 21.479076385498047\n",
            "Train_MaxReturn : 310.78509521484375\n",
            "Train_MinReturn : 219.8952178955078\n",
            "Train_AverageEpLen : 116.88888888888889\n",
            "Train_EnvstepsSoFar : 347534\n",
            "TimeSinceStart : 373.36656618118286\n",
            "Training Loss : -122.24075317382812\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 170 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 240.06832885742188\n",
            "Eval_StdReturn : 17.120582580566406\n",
            "Eval_MaxReturn : 264.85986328125\n",
            "Eval_MinReturn : 223.71908569335938\n",
            "Eval_AverageEpLen : 108.25\n",
            "Train_AverageReturn : 233.4803009033203\n",
            "Train_StdReturn : 33.03046417236328\n",
            "Train_MaxReturn : 271.191162109375\n",
            "Train_MinReturn : 126.86298370361328\n",
            "Train_AverageEpLen : 112.44444444444444\n",
            "Train_EnvstepsSoFar : 349558\n",
            "TimeSinceStart : 375.6336407661438\n",
            "Training Loss : 64.26629638671875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 171 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 277.6581115722656\n",
            "Eval_StdReturn : 25.318716049194336\n",
            "Eval_MaxReturn : 303.04901123046875\n",
            "Eval_MinReturn : 243.09869384765625\n",
            "Eval_AverageEpLen : 151.0\n",
            "Train_AverageReturn : 235.4305419921875\n",
            "Train_StdReturn : 22.300016403198242\n",
            "Train_MaxReturn : 292.1227111816406\n",
            "Train_MinReturn : 202.76161193847656\n",
            "Train_AverageEpLen : 110.42105263157895\n",
            "Train_EnvstepsSoFar : 351656\n",
            "TimeSinceStart : 377.99192786216736\n",
            "Training Loss : -34.58726501464844\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 172 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 238.4299774169922\n",
            "Eval_StdReturn : 3.5945286750793457\n",
            "Eval_MaxReturn : 241.5811309814453\n",
            "Eval_MinReturn : 232.55667114257812\n",
            "Eval_AverageEpLen : 105.5\n",
            "Train_AverageReturn : 242.9048614501953\n",
            "Train_StdReturn : 17.467994689941406\n",
            "Train_MaxReturn : 295.5557861328125\n",
            "Train_MinReturn : 217.3277587890625\n",
            "Train_AverageEpLen : 115.72222222222223\n",
            "Train_EnvstepsSoFar : 353739\n",
            "TimeSinceStart : 380.28512620925903\n",
            "Training Loss : 35.678985595703125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 173 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.33157348632812\n",
            "Eval_StdReturn : 19.249454498291016\n",
            "Eval_MaxReturn : 247.1181182861328\n",
            "Eval_MinReturn : 195.3117218017578\n",
            "Eval_AverageEpLen : 102.25\n",
            "Train_AverageReturn : 246.50355529785156\n",
            "Train_StdReturn : 18.135116577148438\n",
            "Train_MaxReturn : 291.50726318359375\n",
            "Train_MinReturn : 222.48109436035156\n",
            "Train_AverageEpLen : 115.27777777777777\n",
            "Train_EnvstepsSoFar : 355814\n",
            "TimeSinceStart : 382.6270864009857\n",
            "Training Loss : -18.754928588867188\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 174 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 239.44952392578125\n",
            "Eval_StdReturn : 22.306665420532227\n",
            "Eval_MaxReturn : 267.8612976074219\n",
            "Eval_MinReturn : 208.19505310058594\n",
            "Eval_AverageEpLen : 115.5\n",
            "Train_AverageReturn : 235.5329132080078\n",
            "Train_StdReturn : 19.87941551208496\n",
            "Train_MaxReturn : 277.2940368652344\n",
            "Train_MinReturn : 204.1730499267578\n",
            "Train_AverageEpLen : 110.10526315789474\n",
            "Train_EnvstepsSoFar : 357906\n",
            "TimeSinceStart : 384.9562954902649\n",
            "Training Loss : 49.76644515991211\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 175 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.13743591308594\n",
            "Eval_StdReturn : 28.5555362701416\n",
            "Eval_MaxReturn : 287.7988586425781\n",
            "Eval_MinReturn : 209.8784942626953\n",
            "Eval_AverageEpLen : 110.25\n",
            "Train_AverageReturn : 242.29251098632812\n",
            "Train_StdReturn : 14.850229263305664\n",
            "Train_MaxReturn : 269.1546630859375\n",
            "Train_MinReturn : 205.8921356201172\n",
            "Train_AverageEpLen : 115.61111111111111\n",
            "Train_EnvstepsSoFar : 359987\n",
            "TimeSinceStart : 387.2731156349182\n",
            "Training Loss : -72.80663299560547\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 176 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 235.73060607910156\n",
            "Eval_StdReturn : 13.850879669189453\n",
            "Eval_MaxReturn : 255.0785675048828\n",
            "Eval_MinReturn : 216.5919647216797\n",
            "Eval_AverageEpLen : 111.0\n",
            "Train_AverageReturn : 228.57460021972656\n",
            "Train_StdReturn : 22.64311981201172\n",
            "Train_MaxReturn : 261.8260192871094\n",
            "Train_MinReturn : 163.73171997070312\n",
            "Train_AverageEpLen : 109.52631578947368\n",
            "Train_EnvstepsSoFar : 362068\n",
            "TimeSinceStart : 389.57730650901794\n",
            "Training Loss : -59.65762710571289\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 177 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.22955322265625\n",
            "Eval_StdReturn : 3.936072826385498\n",
            "Eval_MaxReturn : 239.60302734375\n",
            "Eval_MinReturn : 228.51162719726562\n",
            "Eval_AverageEpLen : 108.5\n",
            "Train_AverageReturn : 237.0178680419922\n",
            "Train_StdReturn : 12.767538070678711\n",
            "Train_MaxReturn : 265.911376953125\n",
            "Train_MinReturn : 215.3781280517578\n",
            "Train_AverageEpLen : 108.84210526315789\n",
            "Train_EnvstepsSoFar : 364136\n",
            "TimeSinceStart : 391.8222589492798\n",
            "Training Loss : -57.84415817260742\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 178 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.2052459716797\n",
            "Eval_StdReturn : 17.796463012695312\n",
            "Eval_MaxReturn : 262.83056640625\n",
            "Eval_MinReturn : 217.94415283203125\n",
            "Eval_AverageEpLen : 108.5\n",
            "Train_AverageReturn : 233.6014862060547\n",
            "Train_StdReturn : 25.808473587036133\n",
            "Train_MaxReturn : 294.63201904296875\n",
            "Train_MinReturn : 173.21697998046875\n",
            "Train_AverageEpLen : 111.72222222222223\n",
            "Train_EnvstepsSoFar : 366147\n",
            "TimeSinceStart : 394.1213541030884\n",
            "Training Loss : 26.27379035949707\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 179 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 243.11514282226562\n",
            "Eval_StdReturn : 8.310506820678711\n",
            "Eval_MaxReturn : 250.03875732421875\n",
            "Eval_MinReturn : 229.2756805419922\n",
            "Eval_AverageEpLen : 113.5\n",
            "Train_AverageReturn : 240.0250701904297\n",
            "Train_StdReturn : 23.975955963134766\n",
            "Train_MaxReturn : 287.0442810058594\n",
            "Train_MinReturn : 179.60768127441406\n",
            "Train_AverageEpLen : 114.5\n",
            "Train_EnvstepsSoFar : 368208\n",
            "TimeSinceStart : 396.43775963783264\n",
            "Training Loss : 76.70707702636719\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 180 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.65489196777344\n",
            "Eval_StdReturn : 53.78383255004883\n",
            "Eval_MaxReturn : 284.7825622558594\n",
            "Eval_MinReturn : 148.96310424804688\n",
            "Eval_AverageEpLen : 104.0\n",
            "Train_AverageReturn : 246.11045837402344\n",
            "Train_StdReturn : 16.168428421020508\n",
            "Train_MaxReturn : 270.39752197265625\n",
            "Train_MinReturn : 216.69178771972656\n",
            "Train_AverageEpLen : 115.5\n",
            "Train_EnvstepsSoFar : 370287\n",
            "TimeSinceStart : 398.7408084869385\n",
            "Training Loss : -35.69044494628906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 181 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 274.8065185546875\n",
            "Eval_StdReturn : 29.585161209106445\n",
            "Eval_MaxReturn : 313.01617431640625\n",
            "Eval_MinReturn : 240.9389190673828\n",
            "Eval_AverageEpLen : 137.66666666666666\n",
            "Train_AverageReturn : 244.4249267578125\n",
            "Train_StdReturn : 26.253408432006836\n",
            "Train_MaxReturn : 316.29669189453125\n",
            "Train_MinReturn : 201.53382873535156\n",
            "Train_AverageEpLen : 117.70588235294117\n",
            "Train_EnvstepsSoFar : 372288\n",
            "TimeSinceStart : 400.9771018028259\n",
            "Training Loss : 61.98432159423828\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 182 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.15545654296875\n",
            "Eval_StdReturn : 7.593422889709473\n",
            "Eval_MaxReturn : 246.828125\n",
            "Eval_MinReturn : 227.02035522460938\n",
            "Eval_AverageEpLen : 112.5\n",
            "Train_AverageReturn : 233.7948760986328\n",
            "Train_StdReturn : 30.13887596130371\n",
            "Train_MaxReturn : 267.17742919921875\n",
            "Train_MinReturn : 121.326171875\n",
            "Train_AverageEpLen : 110.15789473684211\n",
            "Train_EnvstepsSoFar : 374381\n",
            "TimeSinceStart : 403.3107342720032\n",
            "Training Loss : -59.34040069580078\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 183 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.37103271484375\n",
            "Eval_StdReturn : 28.128154754638672\n",
            "Eval_MaxReturn : 277.2811279296875\n",
            "Eval_MinReturn : 201.66488647460938\n",
            "Eval_AverageEpLen : 119.0\n",
            "Train_AverageReturn : 241.17794799804688\n",
            "Train_StdReturn : 13.976932525634766\n",
            "Train_MaxReturn : 271.6059265136719\n",
            "Train_MinReturn : 217.8240966796875\n",
            "Train_AverageEpLen : 114.72222222222223\n",
            "Train_EnvstepsSoFar : 376446\n",
            "TimeSinceStart : 405.63356137275696\n",
            "Training Loss : -6.880993843078613\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 184 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 249.73345947265625\n",
            "Eval_StdReturn : 7.991330146789551\n",
            "Eval_MaxReturn : 261.3102111816406\n",
            "Eval_MinReturn : 238.75418090820312\n",
            "Eval_AverageEpLen : 121.0\n",
            "Train_AverageReturn : 241.90806579589844\n",
            "Train_StdReturn : 18.790447235107422\n",
            "Train_MaxReturn : 279.59539794921875\n",
            "Train_MinReturn : 204.28355407714844\n",
            "Train_AverageEpLen : 113.55555555555556\n",
            "Train_EnvstepsSoFar : 378490\n",
            "TimeSinceStart : 407.95924162864685\n",
            "Training Loss : -17.60811424255371\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 185 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 269.2749328613281\n",
            "Eval_StdReturn : 6.3846869468688965\n",
            "Eval_MaxReturn : 277.19390869140625\n",
            "Eval_MinReturn : 261.5586242675781\n",
            "Eval_AverageEpLen : 138.0\n",
            "Train_AverageReturn : 249.61209106445312\n",
            "Train_StdReturn : 22.700822830200195\n",
            "Train_MaxReturn : 295.48834228515625\n",
            "Train_MinReturn : 214.55274963378906\n",
            "Train_AverageEpLen : 116.94444444444444\n",
            "Train_EnvstepsSoFar : 380595\n",
            "TimeSinceStart : 410.28916811943054\n",
            "Training Loss : -5.481850624084473\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 186 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 245.46603393554688\n",
            "Eval_StdReturn : 23.367347717285156\n",
            "Eval_MaxReturn : 273.996337890625\n",
            "Eval_MinReturn : 218.80038452148438\n",
            "Eval_AverageEpLen : 115.5\n",
            "Train_AverageReturn : 238.5437469482422\n",
            "Train_StdReturn : 8.444387435913086\n",
            "Train_MaxReturn : 254.3131103515625\n",
            "Train_MinReturn : 224.0510711669922\n",
            "Train_AverageEpLen : 110.52631578947368\n",
            "Train_EnvstepsSoFar : 382695\n",
            "TimeSinceStart : 412.6504147052765\n",
            "Training Loss : -4.852771759033203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 187 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 255.98240661621094\n",
            "Eval_StdReturn : 15.56934928894043\n",
            "Eval_MaxReturn : 282.75958251953125\n",
            "Eval_MinReturn : 244.12469482421875\n",
            "Eval_AverageEpLen : 119.0\n",
            "Train_AverageReturn : 263.1273193359375\n",
            "Train_StdReturn : 21.81001853942871\n",
            "Train_MaxReturn : 299.59307861328125\n",
            "Train_MinReturn : 226.4990234375\n",
            "Train_AverageEpLen : 130.6875\n",
            "Train_EnvstepsSoFar : 384786\n",
            "TimeSinceStart : 415.04944252967834\n",
            "Training Loss : 51.61067581176758\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 188 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 250.6772003173828\n",
            "Eval_StdReturn : 21.894372940063477\n",
            "Eval_MaxReturn : 285.4241027832031\n",
            "Eval_MinReturn : 227.9156036376953\n",
            "Eval_AverageEpLen : 119.0\n",
            "Train_AverageReturn : 246.1229705810547\n",
            "Train_StdReturn : 17.19036293029785\n",
            "Train_MaxReturn : 281.56524658203125\n",
            "Train_MinReturn : 202.6703643798828\n",
            "Train_AverageEpLen : 117.66666666666667\n",
            "Train_EnvstepsSoFar : 386904\n",
            "TimeSinceStart : 417.3999011516571\n",
            "Training Loss : 18.630661010742188\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 189 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 238.932373046875\n",
            "Eval_StdReturn : 20.159666061401367\n",
            "Eval_MaxReturn : 268.8895263671875\n",
            "Eval_MinReturn : 212.47555541992188\n",
            "Eval_AverageEpLen : 108.25\n",
            "Train_AverageReturn : 243.7630157470703\n",
            "Train_StdReturn : 36.28776931762695\n",
            "Train_MaxReturn : 285.4682922363281\n",
            "Train_MinReturn : 119.64873504638672\n",
            "Train_AverageEpLen : 117.16666666666667\n",
            "Train_EnvstepsSoFar : 389013\n",
            "TimeSinceStart : 419.8474609851837\n",
            "Training Loss : 29.598478317260742\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 190 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 255.73599243164062\n",
            "Eval_StdReturn : 10.64227294921875\n",
            "Eval_MaxReturn : 268.143310546875\n",
            "Eval_MinReturn : 241.63986206054688\n",
            "Eval_AverageEpLen : 123.25\n",
            "Train_AverageReturn : 252.88143920898438\n",
            "Train_StdReturn : 29.26482582092285\n",
            "Train_MaxReturn : 285.9889831542969\n",
            "Train_MinReturn : 158.01547241210938\n",
            "Train_AverageEpLen : 121.70588235294117\n",
            "Train_EnvstepsSoFar : 391082\n",
            "TimeSinceStart : 422.1933419704437\n",
            "Training Loss : -84.72499084472656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 191 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 240.6446533203125\n",
            "Eval_StdReturn : 42.19597244262695\n",
            "Eval_MaxReturn : 289.1475830078125\n",
            "Eval_MinReturn : 174.44631958007812\n",
            "Eval_AverageEpLen : 122.25\n",
            "Train_AverageReturn : 249.87020874023438\n",
            "Train_StdReturn : 34.53294372558594\n",
            "Train_MaxReturn : 316.8366394042969\n",
            "Train_MinReturn : 146.32139587402344\n",
            "Train_AverageEpLen : 121.76470588235294\n",
            "Train_EnvstepsSoFar : 393152\n",
            "TimeSinceStart : 424.5162088871002\n",
            "Training Loss : 92.06733703613281\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 192 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 270.3753662109375\n",
            "Eval_StdReturn : 20.797670364379883\n",
            "Eval_MaxReturn : 296.59326171875\n",
            "Eval_MinReturn : 245.7216796875\n",
            "Eval_AverageEpLen : 140.0\n",
            "Train_AverageReturn : 256.8943786621094\n",
            "Train_StdReturn : 29.703001022338867\n",
            "Train_MaxReturn : 311.2756042480469\n",
            "Train_MinReturn : 209.84780883789062\n",
            "Train_AverageEpLen : 125.125\n",
            "Train_EnvstepsSoFar : 395154\n",
            "TimeSinceStart : 426.7484426498413\n",
            "Training Loss : 67.76338195800781\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 193 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 270.696533203125\n",
            "Eval_StdReturn : 5.645020008087158\n",
            "Eval_MaxReturn : 278.6437683105469\n",
            "Eval_MinReturn : 266.0667419433594\n",
            "Eval_AverageEpLen : 134.66666666666666\n",
            "Train_AverageReturn : 266.69940185546875\n",
            "Train_StdReturn : 22.471269607543945\n",
            "Train_MaxReturn : 319.5430603027344\n",
            "Train_MinReturn : 231.64642333984375\n",
            "Train_AverageEpLen : 131.4375\n",
            "Train_EnvstepsSoFar : 397257\n",
            "TimeSinceStart : 429.1099581718445\n",
            "Training Loss : -32.7448616027832\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 194 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 209.32000732421875\n",
            "Eval_StdReturn : 95.883056640625\n",
            "Eval_MaxReturn : 283.007080078125\n",
            "Eval_MinReturn : 44.57365798950195\n",
            "Eval_AverageEpLen : 108.25\n",
            "Train_AverageReturn : 264.18377685546875\n",
            "Train_StdReturn : 25.888853073120117\n",
            "Train_MaxReturn : 314.46795654296875\n",
            "Train_MinReturn : 230.33282470703125\n",
            "Train_AverageEpLen : 129.9375\n",
            "Train_EnvstepsSoFar : 399336\n",
            "TimeSinceStart : 431.42428755760193\n",
            "Training Loss : -12.308389663696289\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 195 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 295.084716796875\n",
            "Eval_StdReturn : 25.81948471069336\n",
            "Eval_MaxReturn : 322.996826171875\n",
            "Eval_MinReturn : 260.7410583496094\n",
            "Eval_AverageEpLen : 143.66666666666666\n",
            "Train_AverageReturn : 259.070068359375\n",
            "Train_StdReturn : 34.85161590576172\n",
            "Train_MaxReturn : 332.74749755859375\n",
            "Train_MinReturn : 216.8158721923828\n",
            "Train_AverageEpLen : 127.1875\n",
            "Train_EnvstepsSoFar : 401371\n",
            "TimeSinceStart : 433.70789527893066\n",
            "Training Loss : -117.46560668945312\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 196 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 266.4677429199219\n",
            "Eval_StdReturn : 31.903791427612305\n",
            "Eval_MaxReturn : 321.2042541503906\n",
            "Eval_MinReturn : 241.6696014404297\n",
            "Eval_AverageEpLen : 125.25\n",
            "Train_AverageReturn : 265.4627380371094\n",
            "Train_StdReturn : 24.112289428710938\n",
            "Train_MaxReturn : 304.69012451171875\n",
            "Train_MinReturn : 203.81246948242188\n",
            "Train_AverageEpLen : 132.125\n",
            "Train_EnvstepsSoFar : 403485\n",
            "TimeSinceStart : 436.15319538116455\n",
            "Training Loss : 59.08460998535156\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 197 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 248.84371948242188\n",
            "Eval_StdReturn : 21.771547317504883\n",
            "Eval_MaxReturn : 283.69427490234375\n",
            "Eval_MinReturn : 224.1116943359375\n",
            "Eval_AverageEpLen : 119.25\n",
            "Train_AverageReturn : 262.090087890625\n",
            "Train_StdReturn : 23.581928253173828\n",
            "Train_MaxReturn : 314.41131591796875\n",
            "Train_MinReturn : 226.1923828125\n",
            "Train_AverageEpLen : 126.4375\n",
            "Train_EnvstepsSoFar : 405508\n",
            "TimeSinceStart : 438.4731013774872\n",
            "Training Loss : 13.209630012512207\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 198 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 270.82232666015625\n",
            "Eval_StdReturn : 20.094993591308594\n",
            "Eval_MaxReturn : 294.76239013671875\n",
            "Eval_MinReturn : 241.26516723632812\n",
            "Eval_AverageEpLen : 131.25\n",
            "Train_AverageReturn : 268.2275390625\n",
            "Train_StdReturn : 34.21809005737305\n",
            "Train_MaxReturn : 321.79034423828125\n",
            "Train_MinReturn : 210.9105682373047\n",
            "Train_AverageEpLen : 127.5\n",
            "Train_EnvstepsSoFar : 407548\n",
            "TimeSinceStart : 440.8676164150238\n",
            "Training Loss : 68.17791748046875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 199 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 265.6700439453125\n",
            "Eval_StdReturn : 7.750579357147217\n",
            "Eval_MaxReturn : 278.3038330078125\n",
            "Eval_MinReturn : 258.94476318359375\n",
            "Eval_AverageEpLen : 125.0\n",
            "Train_AverageReturn : 268.1629638671875\n",
            "Train_StdReturn : 27.967594146728516\n",
            "Train_MaxReturn : 326.1797790527344\n",
            "Train_MinReturn : 205.3382568359375\n",
            "Train_AverageEpLen : 126.625\n",
            "Train_EnvstepsSoFar : 409574\n",
            "TimeSinceStart : 443.26235795021057\n",
            "Training Loss : -74.72335052490234\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 200 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 286.2010803222656\n",
            "Eval_StdReturn : 16.683027267456055\n",
            "Eval_MaxReturn : 305.6706848144531\n",
            "Eval_MinReturn : 264.9256591796875\n",
            "Eval_AverageEpLen : 147.0\n",
            "Train_AverageReturn : 265.5045471191406\n",
            "Train_StdReturn : 26.984586715698242\n",
            "Train_MaxReturn : 347.7699890136719\n",
            "Train_MinReturn : 217.55615234375\n",
            "Train_AverageEpLen : 126.1875\n",
            "Train_EnvstepsSoFar : 411593\n",
            "TimeSinceStart : 445.5572352409363\n",
            "Training Loss : -8.473052978515625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 201 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 290.64862060546875\n",
            "Eval_StdReturn : 29.647199630737305\n",
            "Eval_MaxReturn : 332.57586669921875\n",
            "Eval_MinReturn : 269.5682067871094\n",
            "Eval_AverageEpLen : 148.0\n",
            "Train_AverageReturn : 276.2262268066406\n",
            "Train_StdReturn : 33.441551208496094\n",
            "Train_MaxReturn : 341.77410888671875\n",
            "Train_MinReturn : 224.0662078857422\n",
            "Train_AverageEpLen : 133.6\n",
            "Train_EnvstepsSoFar : 413597\n",
            "TimeSinceStart : 447.8419303894043\n",
            "Training Loss : -37.02351379394531\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 202 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 282.8240661621094\n",
            "Eval_StdReturn : 47.78375244140625\n",
            "Eval_MaxReturn : 348.735595703125\n",
            "Eval_MinReturn : 236.95770263671875\n",
            "Eval_AverageEpLen : 135.0\n",
            "Train_AverageReturn : 275.5548095703125\n",
            "Train_StdReturn : 19.47665023803711\n",
            "Train_MaxReturn : 320.74603271484375\n",
            "Train_MinReturn : 244.01602172851562\n",
            "Train_AverageEpLen : 130.0625\n",
            "Train_EnvstepsSoFar : 415678\n",
            "TimeSinceStart : 450.1340765953064\n",
            "Training Loss : -114.82319641113281\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 203 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 257.03399658203125\n",
            "Eval_StdReturn : 23.600109100341797\n",
            "Eval_MaxReturn : 295.710693359375\n",
            "Eval_MinReturn : 231.67483520507812\n",
            "Eval_AverageEpLen : 123.75\n",
            "Train_AverageReturn : 265.9949951171875\n",
            "Train_StdReturn : 38.193904876708984\n",
            "Train_MaxReturn : 342.6773681640625\n",
            "Train_MinReturn : 169.99835205078125\n",
            "Train_AverageEpLen : 127.125\n",
            "Train_EnvstepsSoFar : 417712\n",
            "TimeSinceStart : 452.4700095653534\n",
            "Training Loss : 74.66374206542969\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 204 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 263.9228210449219\n",
            "Eval_StdReturn : 7.624081134796143\n",
            "Eval_MaxReturn : 273.4752197265625\n",
            "Eval_MinReturn : 254.81607055664062\n",
            "Eval_AverageEpLen : 134.33333333333334\n",
            "Train_AverageReturn : 282.0123596191406\n",
            "Train_StdReturn : 25.463254928588867\n",
            "Train_MaxReturn : 326.77667236328125\n",
            "Train_MinReturn : 234.02487182617188\n",
            "Train_AverageEpLen : 139.06666666666666\n",
            "Train_EnvstepsSoFar : 419798\n",
            "TimeSinceStart : 454.87504291534424\n",
            "Training Loss : -4.50969123840332\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 205 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 262.394775390625\n",
            "Eval_StdReturn : 20.11849594116211\n",
            "Eval_MaxReturn : 284.57159423828125\n",
            "Eval_MinReturn : 231.21986389160156\n",
            "Eval_AverageEpLen : 128.75\n",
            "Train_AverageReturn : 270.4436950683594\n",
            "Train_StdReturn : 39.50690460205078\n",
            "Train_MaxReturn : 338.0028991699219\n",
            "Train_MinReturn : 166.1518096923828\n",
            "Train_AverageEpLen : 130.0625\n",
            "Train_EnvstepsSoFar : 421879\n",
            "TimeSinceStart : 457.2873566150665\n",
            "Training Loss : -17.24380874633789\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 206 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 283.79644775390625\n",
            "Eval_StdReturn : 23.58302879333496\n",
            "Eval_MaxReturn : 314.5364990234375\n",
            "Eval_MinReturn : 259.80633544921875\n",
            "Eval_AverageEpLen : 134.0\n",
            "Train_AverageReturn : 282.80328369140625\n",
            "Train_StdReturn : 25.919391632080078\n",
            "Train_MaxReturn : 324.63714599609375\n",
            "Train_MinReturn : 236.63816833496094\n",
            "Train_AverageEpLen : 136.73333333333332\n",
            "Train_EnvstepsSoFar : 423930\n",
            "TimeSinceStart : 459.6570529937744\n",
            "Training Loss : 9.619117736816406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 207 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 253.63909912109375\n",
            "Eval_StdReturn : 40.0991325378418\n",
            "Eval_MaxReturn : 299.5291748046875\n",
            "Eval_MinReturn : 195.45616149902344\n",
            "Eval_AverageEpLen : 129.25\n",
            "Train_AverageReturn : 256.1097717285156\n",
            "Train_StdReturn : 38.65446472167969\n",
            "Train_MaxReturn : 325.4398498535156\n",
            "Train_MinReturn : 154.5140838623047\n",
            "Train_AverageEpLen : 127.5625\n",
            "Train_EnvstepsSoFar : 425971\n",
            "TimeSinceStart : 462.1117134094238\n",
            "Training Loss : -72.94065856933594\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 208 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 295.3927917480469\n",
            "Eval_StdReturn : 31.640275955200195\n",
            "Eval_MaxReturn : 330.956298828125\n",
            "Eval_MinReturn : 254.0932159423828\n",
            "Eval_AverageEpLen : 149.66666666666666\n",
            "Train_AverageReturn : 268.9693298339844\n",
            "Train_StdReturn : 63.39139175415039\n",
            "Train_MaxReturn : 352.0860595703125\n",
            "Train_MinReturn : 124.15091705322266\n",
            "Train_AverageEpLen : 135.53333333333333\n",
            "Train_EnvstepsSoFar : 428004\n",
            "TimeSinceStart : 464.42460441589355\n",
            "Training Loss : -64.52737426757812\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 209 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 285.9884338378906\n",
            "Eval_StdReturn : 25.460552215576172\n",
            "Eval_MaxReturn : 314.1612243652344\n",
            "Eval_MinReturn : 252.48348999023438\n",
            "Eval_AverageEpLen : 140.0\n",
            "Train_AverageReturn : 298.7273864746094\n",
            "Train_StdReturn : 32.63360595703125\n",
            "Train_MaxReturn : 339.5445556640625\n",
            "Train_MinReturn : 234.3159942626953\n",
            "Train_AverageEpLen : 144.92857142857142\n",
            "Train_EnvstepsSoFar : 430033\n",
            "TimeSinceStart : 466.7731909751892\n",
            "Training Loss : 59.343936920166016\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 210 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 263.53131103515625\n",
            "Eval_StdReturn : 57.44679641723633\n",
            "Eval_MaxReturn : 337.7899475097656\n",
            "Eval_MinReturn : 182.89793395996094\n",
            "Eval_AverageEpLen : 125.75\n",
            "Train_AverageReturn : 298.10113525390625\n",
            "Train_StdReturn : 33.73793411254883\n",
            "Train_MaxReturn : 369.2498474121094\n",
            "Train_MinReturn : 255.3256378173828\n",
            "Train_AverageEpLen : 149.42857142857142\n",
            "Train_EnvstepsSoFar : 432125\n",
            "TimeSinceStart : 469.22822523117065\n",
            "Training Loss : -58.2127799987793\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 211 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 306.2344970703125\n",
            "Eval_StdReturn : 36.09614562988281\n",
            "Eval_MaxReturn : 338.21197509765625\n",
            "Eval_MinReturn : 255.78594970703125\n",
            "Eval_AverageEpLen : 149.66666666666666\n",
            "Train_AverageReturn : 278.27947998046875\n",
            "Train_StdReturn : 37.287132263183594\n",
            "Train_MaxReturn : 364.92974853515625\n",
            "Train_MinReturn : 234.6904754638672\n",
            "Train_AverageEpLen : 139.2\n",
            "Train_EnvstepsSoFar : 434213\n",
            "TimeSinceStart : 471.60254883766174\n",
            "Training Loss : -107.1955795288086\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 212 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 283.27508544921875\n",
            "Eval_StdReturn : 43.88863754272461\n",
            "Eval_MaxReturn : 333.97052001953125\n",
            "Eval_MinReturn : 228.5215606689453\n",
            "Eval_AverageEpLen : 132.5\n",
            "Train_AverageReturn : 293.5918884277344\n",
            "Train_StdReturn : 42.17091369628906\n",
            "Train_MaxReturn : 347.0765380859375\n",
            "Train_MinReturn : 180.2175750732422\n",
            "Train_AverageEpLen : 144.71428571428572\n",
            "Train_EnvstepsSoFar : 436239\n",
            "TimeSinceStart : 474.048499584198\n",
            "Training Loss : 32.4371337890625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 213 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 329.125\n",
            "Eval_StdReturn : 27.040246963500977\n",
            "Eval_MaxReturn : 367.365478515625\n",
            "Eval_MinReturn : 309.8912658691406\n",
            "Eval_AverageEpLen : 171.0\n",
            "Train_AverageReturn : 289.4344177246094\n",
            "Train_StdReturn : 27.072019577026367\n",
            "Train_MaxReturn : 361.6512756347656\n",
            "Train_MinReturn : 255.0421600341797\n",
            "Train_AverageEpLen : 133.1875\n",
            "Train_EnvstepsSoFar : 438370\n",
            "TimeSinceStart : 476.52305150032043\n",
            "Training Loss : -25.026641845703125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 214 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 308.4434814453125\n",
            "Eval_StdReturn : 13.459261894226074\n",
            "Eval_MaxReturn : 320.42364501953125\n",
            "Eval_MinReturn : 289.64385986328125\n",
            "Eval_AverageEpLen : 155.33333333333334\n",
            "Train_AverageReturn : 288.1606140136719\n",
            "Train_StdReturn : 47.08681106567383\n",
            "Train_MaxReturn : 356.51641845703125\n",
            "Train_MinReturn : 180.234619140625\n",
            "Train_AverageEpLen : 139.2\n",
            "Train_EnvstepsSoFar : 440458\n",
            "TimeSinceStart : 478.8853061199188\n",
            "Training Loss : -27.001625061035156\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 215 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 258.8995361328125\n",
            "Eval_StdReturn : 58.9180793762207\n",
            "Eval_MaxReturn : 327.6487121582031\n",
            "Eval_MinReturn : 175.32077026367188\n",
            "Eval_AverageEpLen : 131.5\n",
            "Train_AverageReturn : 300.0047302246094\n",
            "Train_StdReturn : 43.95690155029297\n",
            "Train_MaxReturn : 364.09368896484375\n",
            "Train_MinReturn : 180.3641815185547\n",
            "Train_AverageEpLen : 149.07142857142858\n",
            "Train_EnvstepsSoFar : 442545\n",
            "TimeSinceStart : 481.3352463245392\n",
            "Training Loss : 74.0007095336914\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 216 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 277.3139343261719\n",
            "Eval_StdReturn : 114.80189514160156\n",
            "Eval_MaxReturn : 387.28851318359375\n",
            "Eval_MinReturn : 87.69456481933594\n",
            "Eval_AverageEpLen : 140.5\n",
            "Train_AverageReturn : 295.3186340332031\n",
            "Train_StdReturn : 38.77896499633789\n",
            "Train_MaxReturn : 348.54180908203125\n",
            "Train_MinReturn : 205.9845733642578\n",
            "Train_AverageEpLen : 142.46666666666667\n",
            "Train_EnvstepsSoFar : 444682\n",
            "TimeSinceStart : 483.81131076812744\n",
            "Training Loss : 88.34761810302734\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 217 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 256.693603515625\n",
            "Eval_StdReturn : 57.680145263671875\n",
            "Eval_MaxReturn : 337.4256896972656\n",
            "Eval_MinReturn : 182.74844360351562\n",
            "Eval_AverageEpLen : 126.75\n",
            "Train_AverageReturn : 303.59100341796875\n",
            "Train_StdReturn : 40.57844161987305\n",
            "Train_MaxReturn : 343.2163391113281\n",
            "Train_MinReturn : 199.9499053955078\n",
            "Train_AverageEpLen : 148.64285714285714\n",
            "Train_EnvstepsSoFar : 446763\n",
            "TimeSinceStart : 486.24571442604065\n",
            "Training Loss : 6.571828842163086\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 218 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 344.1045227050781\n",
            "Eval_StdReturn : 18.54456329345703\n",
            "Eval_MaxReturn : 363.7764892578125\n",
            "Eval_MinReturn : 319.2481689453125\n",
            "Eval_AverageEpLen : 179.66666666666666\n",
            "Train_AverageReturn : 296.8226013183594\n",
            "Train_StdReturn : 36.408599853515625\n",
            "Train_MaxReturn : 342.2516174316406\n",
            "Train_MinReturn : 214.3116455078125\n",
            "Train_AverageEpLen : 147.78571428571428\n",
            "Train_EnvstepsSoFar : 448832\n",
            "TimeSinceStart : 488.6459665298462\n",
            "Training Loss : -44.23647689819336\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 219 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 323.3697204589844\n",
            "Eval_StdReturn : 58.592342376708984\n",
            "Eval_MaxReturn : 383.5130920410156\n",
            "Eval_MinReturn : 243.93533325195312\n",
            "Eval_AverageEpLen : 164.66666666666666\n",
            "Train_AverageReturn : 301.68914794921875\n",
            "Train_StdReturn : 33.143470764160156\n",
            "Train_MaxReturn : 348.6638488769531\n",
            "Train_MinReturn : 245.9791717529297\n",
            "Train_AverageEpLen : 145.28571428571428\n",
            "Train_EnvstepsSoFar : 450866\n",
            "TimeSinceStart : 491.0425033569336\n",
            "Training Loss : -5.357278823852539\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 220 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 380.42095947265625\n",
            "Eval_StdReturn : 57.49769592285156\n",
            "Eval_MaxReturn : 437.91864013671875\n",
            "Eval_MinReturn : 322.9232482910156\n",
            "Eval_AverageEpLen : 211.5\n",
            "Train_AverageReturn : 313.8138427734375\n",
            "Train_StdReturn : 31.221899032592773\n",
            "Train_MaxReturn : 355.1520080566406\n",
            "Train_MinReturn : 233.038818359375\n",
            "Train_AverageEpLen : 155.23076923076923\n",
            "Train_EnvstepsSoFar : 452884\n",
            "TimeSinceStart : 493.3607726097107\n",
            "Training Loss : -54.0081901550293\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 221 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 325.7375183105469\n",
            "Eval_StdReturn : 29.246463775634766\n",
            "Eval_MaxReturn : 355.1685485839844\n",
            "Eval_MinReturn : 285.85467529296875\n",
            "Eval_AverageEpLen : 175.66666666666666\n",
            "Train_AverageReturn : 311.6585388183594\n",
            "Train_StdReturn : 69.45340728759766\n",
            "Train_MaxReturn : 407.77728271484375\n",
            "Train_MinReturn : 139.9795684814453\n",
            "Train_AverageEpLen : 157.15384615384616\n",
            "Train_EnvstepsSoFar : 454927\n",
            "TimeSinceStart : 495.9046366214752\n",
            "Training Loss : -104.85296630859375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 222 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 338.7921447753906\n",
            "Eval_StdReturn : 25.615739822387695\n",
            "Eval_MaxReturn : 363.6188659667969\n",
            "Eval_MinReturn : 303.5320129394531\n",
            "Eval_AverageEpLen : 167.33333333333334\n",
            "Train_AverageReturn : 324.4989318847656\n",
            "Train_StdReturn : 54.46564865112305\n",
            "Train_MaxReturn : 442.0409240722656\n",
            "Train_MinReturn : 262.9073181152344\n",
            "Train_AverageEpLen : 167.5\n",
            "Train_EnvstepsSoFar : 456937\n",
            "TimeSinceStart : 498.30874705314636\n",
            "Training Loss : -45.79602813720703\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 223 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 331.32305908203125\n",
            "Eval_StdReturn : 19.889575958251953\n",
            "Eval_MaxReturn : 357.8114013671875\n",
            "Eval_MinReturn : 309.88323974609375\n",
            "Eval_AverageEpLen : 160.0\n",
            "Train_AverageReturn : 324.6141052246094\n",
            "Train_StdReturn : 50.50998306274414\n",
            "Train_MaxReturn : 417.5396728515625\n",
            "Train_MinReturn : 250.9214630126953\n",
            "Train_AverageEpLen : 163.07692307692307\n",
            "Train_EnvstepsSoFar : 459057\n",
            "TimeSinceStart : 500.83033752441406\n",
            "Training Loss : 57.275970458984375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 224 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 291.5744323730469\n",
            "Eval_StdReturn : 15.342194557189941\n",
            "Eval_MaxReturn : 309.0655517578125\n",
            "Eval_MinReturn : 271.7104187011719\n",
            "Eval_AverageEpLen : 137.66666666666666\n",
            "Train_AverageReturn : 293.4247741699219\n",
            "Train_StdReturn : 61.382450103759766\n",
            "Train_MaxReturn : 387.19305419921875\n",
            "Train_MinReturn : 159.26846313476562\n",
            "Train_AverageEpLen : 143.5\n",
            "Train_EnvstepsSoFar : 461066\n",
            "TimeSinceStart : 503.1524136066437\n",
            "Training Loss : -33.50065612792969\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 225 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 299.1318664550781\n",
            "Eval_StdReturn : 31.799884796142578\n",
            "Eval_MaxReturn : 341.0574035644531\n",
            "Eval_MinReturn : 264.07879638671875\n",
            "Eval_AverageEpLen : 152.0\n",
            "Train_AverageReturn : 315.4555969238281\n",
            "Train_StdReturn : 63.099327087402344\n",
            "Train_MaxReturn : 432.801513671875\n",
            "Train_MinReturn : 158.1968231201172\n",
            "Train_AverageEpLen : 161.23076923076923\n",
            "Train_EnvstepsSoFar : 463162\n",
            "TimeSinceStart : 505.59436225891113\n",
            "Training Loss : -83.59535217285156\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 226 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 320.4511413574219\n",
            "Eval_StdReturn : 33.7825927734375\n",
            "Eval_MaxReturn : 368.2269592285156\n",
            "Eval_MinReturn : 296.55670166015625\n",
            "Eval_AverageEpLen : 157.66666666666666\n",
            "Train_AverageReturn : 302.04949951171875\n",
            "Train_StdReturn : 61.65877151489258\n",
            "Train_MaxReturn : 400.0164794921875\n",
            "Train_MinReturn : 135.0605010986328\n",
            "Train_AverageEpLen : 148.42857142857142\n",
            "Train_EnvstepsSoFar : 465240\n",
            "TimeSinceStart : 508.0046362876892\n",
            "Training Loss : -28.42383575439453\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 227 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 297.5792236328125\n",
            "Eval_StdReturn : 9.325159072875977\n",
            "Eval_MaxReturn : 309.95770263671875\n",
            "Eval_MinReturn : 287.4507141113281\n",
            "Eval_AverageEpLen : 147.0\n",
            "Train_AverageReturn : 328.1232604980469\n",
            "Train_StdReturn : 31.295856475830078\n",
            "Train_MaxReturn : 413.14105224609375\n",
            "Train_MinReturn : 280.0334167480469\n",
            "Train_AverageEpLen : 160.07692307692307\n",
            "Train_EnvstepsSoFar : 467321\n",
            "TimeSinceStart : 510.42334485054016\n",
            "Training Loss : -8.788070678710938\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 228 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 333.5511474609375\n",
            "Eval_StdReturn : 32.89506912231445\n",
            "Eval_MaxReturn : 374.0989990234375\n",
            "Eval_MinReturn : 293.5279846191406\n",
            "Eval_AverageEpLen : 166.33333333333334\n",
            "Train_AverageReturn : 321.07977294921875\n",
            "Train_StdReturn : 37.180416107177734\n",
            "Train_MaxReturn : 384.21453857421875\n",
            "Train_MinReturn : 256.1334533691406\n",
            "Train_AverageEpLen : 153.92307692307693\n",
            "Train_EnvstepsSoFar : 469322\n",
            "TimeSinceStart : 512.8906283378601\n",
            "Training Loss : 6.214727401733398\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 229 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 320.4632568359375\n",
            "Eval_StdReturn : 35.299564361572266\n",
            "Eval_MaxReturn : 359.224365234375\n",
            "Eval_MinReturn : 273.8380432128906\n",
            "Eval_AverageEpLen : 154.0\n",
            "Train_AverageReturn : 312.2377014160156\n",
            "Train_StdReturn : 40.39714431762695\n",
            "Train_MaxReturn : 373.11212158203125\n",
            "Train_MinReturn : 251.64952087402344\n",
            "Train_AverageEpLen : 154.3846153846154\n",
            "Train_EnvstepsSoFar : 471329\n",
            "TimeSinceStart : 515.2044620513916\n",
            "Training Loss : -32.795204162597656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 230 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 321.7347106933594\n",
            "Eval_StdReturn : 36.07123947143555\n",
            "Eval_MaxReturn : 356.0386657714844\n",
            "Eval_MinReturn : 271.8851623535156\n",
            "Eval_AverageEpLen : 150.33333333333334\n",
            "Train_AverageReturn : 333.3498229980469\n",
            "Train_StdReturn : 43.473365783691406\n",
            "Train_MaxReturn : 388.1343994140625\n",
            "Train_MinReturn : 223.70289611816406\n",
            "Train_AverageEpLen : 160.0\n",
            "Train_EnvstepsSoFar : 473409\n",
            "TimeSinceStart : 517.6445112228394\n",
            "Training Loss : 91.2950668334961\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 231 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 348.1580505371094\n",
            "Eval_StdReturn : 13.32199764251709\n",
            "Eval_MaxReturn : 359.27044677734375\n",
            "Eval_MinReturn : 329.4261474609375\n",
            "Eval_AverageEpLen : 164.0\n",
            "Train_AverageReturn : 350.2670593261719\n",
            "Train_StdReturn : 28.599931716918945\n",
            "Train_MaxReturn : 415.1244201660156\n",
            "Train_MinReturn : 315.875732421875\n",
            "Train_AverageEpLen : 172.0\n",
            "Train_EnvstepsSoFar : 475473\n",
            "TimeSinceStart : 520.0946681499481\n",
            "Training Loss : -35.492591857910156\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 232 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 319.9140319824219\n",
            "Eval_StdReturn : 42.151493072509766\n",
            "Eval_MaxReturn : 379.26031494140625\n",
            "Eval_MinReturn : 285.3789978027344\n",
            "Eval_AverageEpLen : 154.33333333333334\n",
            "Train_AverageReturn : 310.2065124511719\n",
            "Train_StdReturn : 49.46765899658203\n",
            "Train_MaxReturn : 354.5716552734375\n",
            "Train_MinReturn : 160.74179077148438\n",
            "Train_AverageEpLen : 156.84615384615384\n",
            "Train_EnvstepsSoFar : 477512\n",
            "TimeSinceStart : 522.4832401275635\n",
            "Training Loss : -74.85687255859375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 233 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 348.9495544433594\n",
            "Eval_StdReturn : 36.9328727722168\n",
            "Eval_MaxReturn : 398.19293212890625\n",
            "Eval_MinReturn : 309.24896240234375\n",
            "Eval_AverageEpLen : 168.66666666666666\n",
            "Train_AverageReturn : 333.45989990234375\n",
            "Train_StdReturn : 55.8409538269043\n",
            "Train_MaxReturn : 418.51947021484375\n",
            "Train_MinReturn : 183.50567626953125\n",
            "Train_AverageEpLen : 165.53846153846155\n",
            "Train_EnvstepsSoFar : 479664\n",
            "TimeSinceStart : 525.0339460372925\n",
            "Training Loss : 3.189617156982422\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 234 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 318.4519348144531\n",
            "Eval_StdReturn : 3.6799275875091553\n",
            "Eval_MaxReturn : 321.59515380859375\n",
            "Eval_MinReturn : 313.28826904296875\n",
            "Eval_AverageEpLen : 159.0\n",
            "Train_AverageReturn : 341.07720947265625\n",
            "Train_StdReturn : 21.258419036865234\n",
            "Train_MaxReturn : 371.60809326171875\n",
            "Train_MinReturn : 294.4534606933594\n",
            "Train_AverageEpLen : 164.6153846153846\n",
            "Train_EnvstepsSoFar : 481804\n",
            "TimeSinceStart : 527.5255873203278\n",
            "Training Loss : 55.78864669799805\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 235 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 339.8842468261719\n",
            "Eval_StdReturn : 29.450166702270508\n",
            "Eval_MaxReturn : 376.8153991699219\n",
            "Eval_MinReturn : 304.7442626953125\n",
            "Eval_AverageEpLen : 155.33333333333334\n",
            "Train_AverageReturn : 339.07183837890625\n",
            "Train_StdReturn : 23.92057228088379\n",
            "Train_MaxReturn : 388.09197998046875\n",
            "Train_MinReturn : 298.615966796875\n",
            "Train_AverageEpLen : 165.0\n",
            "Train_EnvstepsSoFar : 483949\n",
            "TimeSinceStart : 530.0881309509277\n",
            "Training Loss : 19.91037368774414\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 236 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 299.31884765625\n",
            "Eval_StdReturn : 71.70819854736328\n",
            "Eval_MaxReturn : 360.57012939453125\n",
            "Eval_MinReturn : 198.69813537597656\n",
            "Eval_AverageEpLen : 134.33333333333334\n",
            "Train_AverageReturn : 359.783447265625\n",
            "Train_StdReturn : 29.12206268310547\n",
            "Train_MaxReturn : 411.2733459472656\n",
            "Train_MinReturn : 299.23876953125\n",
            "Train_AverageEpLen : 179.33333333333334\n",
            "Train_EnvstepsSoFar : 486101\n",
            "TimeSinceStart : 532.6577117443085\n",
            "Training Loss : 27.97183609008789\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 237 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 323.7870788574219\n",
            "Eval_StdReturn : 30.59081268310547\n",
            "Eval_MaxReturn : 357.6124267578125\n",
            "Eval_MinReturn : 283.5167236328125\n",
            "Eval_AverageEpLen : 152.33333333333334\n",
            "Train_AverageReturn : 318.6230773925781\n",
            "Train_StdReturn : 75.52066040039062\n",
            "Train_MaxReturn : 406.60888671875\n",
            "Train_MinReturn : 122.87857055664062\n",
            "Train_AverageEpLen : 156.07692307692307\n",
            "Train_EnvstepsSoFar : 488130\n",
            "TimeSinceStart : 535.0915126800537\n",
            "Training Loss : -35.68052673339844\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 238 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 312.3243103027344\n",
            "Eval_StdReturn : 32.79356384277344\n",
            "Eval_MaxReturn : 346.7460632324219\n",
            "Eval_MinReturn : 268.19720458984375\n",
            "Eval_AverageEpLen : 160.0\n",
            "Train_AverageReturn : 337.9757385253906\n",
            "Train_StdReturn : 46.85978317260742\n",
            "Train_MaxReturn : 410.3345031738281\n",
            "Train_MinReturn : 208.14511108398438\n",
            "Train_AverageEpLen : 169.83333333333334\n",
            "Train_EnvstepsSoFar : 490168\n",
            "TimeSinceStart : 537.5458197593689\n",
            "Training Loss : -2.6160430908203125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 239 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 364.9396667480469\n",
            "Eval_StdReturn : 29.52245330810547\n",
            "Eval_MaxReturn : 394.88323974609375\n",
            "Eval_MinReturn : 324.7706604003906\n",
            "Eval_AverageEpLen : 189.66666666666666\n",
            "Train_AverageReturn : 315.7392883300781\n",
            "Train_StdReturn : 79.6261215209961\n",
            "Train_MaxReturn : 440.2669677734375\n",
            "Train_MinReturn : 142.8171844482422\n",
            "Train_AverageEpLen : 154.76923076923077\n",
            "Train_EnvstepsSoFar : 492180\n",
            "TimeSinceStart : 540.0424084663391\n",
            "Training Loss : -39.17731857299805\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 240 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 329.2402648925781\n",
            "Eval_StdReturn : 9.61645793914795\n",
            "Eval_MaxReturn : 336.4818115234375\n",
            "Eval_MinReturn : 315.65032958984375\n",
            "Eval_AverageEpLen : 154.66666666666666\n",
            "Train_AverageReturn : 355.496826171875\n",
            "Train_StdReturn : 35.99702072143555\n",
            "Train_MaxReturn : 398.67620849609375\n",
            "Train_MinReturn : 277.8302001953125\n",
            "Train_AverageEpLen : 173.91666666666666\n",
            "Train_EnvstepsSoFar : 494267\n",
            "TimeSinceStart : 542.5898044109344\n",
            "Training Loss : -35.34638214111328\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 241 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 352.9605407714844\n",
            "Eval_StdReturn : 19.329425811767578\n",
            "Eval_MaxReturn : 378.606689453125\n",
            "Eval_MinReturn : 331.94317626953125\n",
            "Eval_AverageEpLen : 165.66666666666666\n",
            "Train_AverageReturn : 339.4230041503906\n",
            "Train_StdReturn : 42.128395080566406\n",
            "Train_MaxReturn : 426.1830749511719\n",
            "Train_MinReturn : 248.96743774414062\n",
            "Train_AverageEpLen : 162.30769230769232\n",
            "Train_EnvstepsSoFar : 496377\n",
            "TimeSinceStart : 545.0922076702118\n",
            "Training Loss : -59.89105224609375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 242 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 348.4272155761719\n",
            "Eval_StdReturn : 26.750410079956055\n",
            "Eval_MaxReturn : 375.64080810546875\n",
            "Eval_MinReturn : 312.06207275390625\n",
            "Eval_AverageEpLen : 163.33333333333334\n",
            "Train_AverageReturn : 332.3019104003906\n",
            "Train_StdReturn : 60.67350769042969\n",
            "Train_MaxReturn : 394.683837890625\n",
            "Train_MinReturn : 163.6630401611328\n",
            "Train_AverageEpLen : 161.53846153846155\n",
            "Train_EnvstepsSoFar : 498477\n",
            "TimeSinceStart : 547.6868298053741\n",
            "Training Loss : 35.659114837646484\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 243 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 312.94183349609375\n",
            "Eval_StdReturn : 123.63861846923828\n",
            "Eval_MaxReturn : 432.7048645019531\n",
            "Eval_MinReturn : 142.73182678222656\n",
            "Eval_AverageEpLen : 166.33333333333334\n",
            "Train_AverageReturn : 298.0175476074219\n",
            "Train_StdReturn : 78.03070831298828\n",
            "Train_MaxReturn : 391.8973388671875\n",
            "Train_MinReturn : 96.76116180419922\n",
            "Train_AverageEpLen : 143.0\n",
            "Train_EnvstepsSoFar : 500479\n",
            "TimeSinceStart : 550.3050932884216\n",
            "Training Loss : 9.492171287536621\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 244 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 288.9490661621094\n",
            "Eval_StdReturn : 97.25206756591797\n",
            "Eval_MaxReturn : 390.89239501953125\n",
            "Eval_MinReturn : 158.0235595703125\n",
            "Eval_AverageEpLen : 147.66666666666666\n",
            "Train_AverageReturn : 327.4248046875\n",
            "Train_StdReturn : 74.37630462646484\n",
            "Train_MaxReturn : 411.1568298339844\n",
            "Train_MinReturn : 164.10386657714844\n",
            "Train_AverageEpLen : 162.76923076923077\n",
            "Train_EnvstepsSoFar : 502595\n",
            "TimeSinceStart : 552.8683505058289\n",
            "Training Loss : 185.62367248535156\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 245 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 395.2788391113281\n",
            "Eval_StdReturn : 42.25536346435547\n",
            "Eval_MaxReturn : 444.9647216796875\n",
            "Eval_MinReturn : 341.6824951171875\n",
            "Eval_AverageEpLen : 201.33333333333334\n",
            "Train_AverageReturn : 321.4474182128906\n",
            "Train_StdReturn : 55.864376068115234\n",
            "Train_MaxReturn : 372.03094482421875\n",
            "Train_MinReturn : 176.29600524902344\n",
            "Train_AverageEpLen : 155.76923076923077\n",
            "Train_EnvstepsSoFar : 504620\n",
            "TimeSinceStart : 555.4359602928162\n",
            "Training Loss : -4.736057281494141\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 246 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 301.4410400390625\n",
            "Eval_StdReturn : 58.261661529541016\n",
            "Eval_MaxReturn : 349.4912109375\n",
            "Eval_MinReturn : 219.45028686523438\n",
            "Eval_AverageEpLen : 151.33333333333334\n",
            "Train_AverageReturn : 304.52374267578125\n",
            "Train_StdReturn : 69.88440704345703\n",
            "Train_MaxReturn : 402.6448669433594\n",
            "Train_MinReturn : 97.62792205810547\n",
            "Train_AverageEpLen : 156.15384615384616\n",
            "Train_EnvstepsSoFar : 506650\n",
            "TimeSinceStart : 558.0624215602875\n",
            "Training Loss : -81.73872375488281\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 247 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 317.3124084472656\n",
            "Eval_StdReturn : 21.720672607421875\n",
            "Eval_MaxReturn : 341.4111633300781\n",
            "Eval_MinReturn : 288.7669982910156\n",
            "Eval_AverageEpLen : 157.0\n",
            "Train_AverageReturn : 311.0675354003906\n",
            "Train_StdReturn : 77.37642669677734\n",
            "Train_MaxReturn : 383.41650390625\n",
            "Train_MinReturn : 161.45217895507812\n",
            "Train_AverageEpLen : 154.07142857142858\n",
            "Train_EnvstepsSoFar : 508807\n",
            "TimeSinceStart : 560.9175033569336\n",
            "Training Loss : -17.040451049804688\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 248 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 354.6147155761719\n",
            "Eval_StdReturn : 23.914016723632812\n",
            "Eval_MaxReturn : 374.53863525390625\n",
            "Eval_MinReturn : 320.9863586425781\n",
            "Eval_AverageEpLen : 163.0\n",
            "Train_AverageReturn : 330.2641296386719\n",
            "Train_StdReturn : 38.52001953125\n",
            "Train_MaxReturn : 399.0361022949219\n",
            "Train_MinReturn : 251.9246368408203\n",
            "Train_AverageEpLen : 160.23076923076923\n",
            "Train_EnvstepsSoFar : 510890\n",
            "TimeSinceStart : 563.5615336894989\n",
            "Training Loss : 11.526166915893555\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 249 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 269.8373718261719\n",
            "Eval_StdReturn : 79.71760559082031\n",
            "Eval_MaxReturn : 343.3331604003906\n",
            "Eval_MinReturn : 159.05487060546875\n",
            "Eval_AverageEpLen : 134.33333333333334\n",
            "Train_AverageReturn : 326.6015319824219\n",
            "Train_StdReturn : 51.64571762084961\n",
            "Train_MaxReturn : 436.6619873046875\n",
            "Train_MinReturn : 246.3437957763672\n",
            "Train_AverageEpLen : 161.6153846153846\n",
            "Train_EnvstepsSoFar : 512991\n",
            "TimeSinceStart : 565.9801738262177\n",
            "Training Loss : -62.411170959472656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 250 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 319.83392333984375\n",
            "Eval_StdReturn : 47.317264556884766\n",
            "Eval_MaxReturn : 361.55987548828125\n",
            "Eval_MinReturn : 253.66537475585938\n",
            "Eval_AverageEpLen : 164.33333333333334\n",
            "Train_AverageReturn : 326.3206787109375\n",
            "Train_StdReturn : 46.36586380004883\n",
            "Train_MaxReturn : 373.297607421875\n",
            "Train_MinReturn : 190.90042114257812\n",
            "Train_AverageEpLen : 156.6153846153846\n",
            "Train_EnvstepsSoFar : 515027\n",
            "TimeSinceStart : 568.3741958141327\n",
            "Training Loss : -4.504663467407227\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 251 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 392.4679260253906\n",
            "Eval_StdReturn : 21.536048889160156\n",
            "Eval_MaxReturn : 420.71844482421875\n",
            "Eval_MinReturn : 368.4870300292969\n",
            "Eval_AverageEpLen : 185.33333333333334\n",
            "Train_AverageReturn : 330.26483154296875\n",
            "Train_StdReturn : 80.05266571044922\n",
            "Train_MaxReturn : 470.61395263671875\n",
            "Train_MinReturn : 213.71124267578125\n",
            "Train_AverageEpLen : 165.23076923076923\n",
            "Train_EnvstepsSoFar : 517175\n",
            "TimeSinceStart : 570.9992995262146\n",
            "Training Loss : -0.3535480499267578\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 252 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 314.32623291015625\n",
            "Eval_StdReturn : 30.83043098449707\n",
            "Eval_MaxReturn : 337.2870788574219\n",
            "Eval_MinReturn : 270.74639892578125\n",
            "Eval_AverageEpLen : 145.0\n",
            "Train_AverageReturn : 344.1180725097656\n",
            "Train_StdReturn : 61.79127502441406\n",
            "Train_MaxReturn : 453.7592468261719\n",
            "Train_MinReturn : 251.2347869873047\n",
            "Train_AverageEpLen : 173.91666666666666\n",
            "Train_EnvstepsSoFar : 519262\n",
            "TimeSinceStart : 573.4516959190369\n",
            "Training Loss : 34.64118194580078\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 253 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 348.072021484375\n",
            "Eval_StdReturn : 5.374849319458008\n",
            "Eval_MaxReturn : 355.6684875488281\n",
            "Eval_MinReturn : 344.0418701171875\n",
            "Eval_AverageEpLen : 168.0\n",
            "Train_AverageReturn : 312.80712890625\n",
            "Train_StdReturn : 34.38124465942383\n",
            "Train_MaxReturn : 370.7220458984375\n",
            "Train_MinReturn : 215.4551544189453\n",
            "Train_AverageEpLen : 148.0\n",
            "Train_EnvstepsSoFar : 521334\n",
            "TimeSinceStart : 575.8285624980927\n",
            "Training Loss : -37.23214340209961\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 254 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 336.4892272949219\n",
            "Eval_StdReturn : 12.736391067504883\n",
            "Eval_MaxReturn : 350.5399475097656\n",
            "Eval_MinReturn : 319.70391845703125\n",
            "Eval_AverageEpLen : 154.66666666666666\n",
            "Train_AverageReturn : 313.18511962890625\n",
            "Train_StdReturn : 60.218502044677734\n",
            "Train_MaxReturn : 412.5792236328125\n",
            "Train_MinReturn : 147.66412353515625\n",
            "Train_AverageEpLen : 154.57142857142858\n",
            "Train_EnvstepsSoFar : 523498\n",
            "TimeSinceStart : 578.2697043418884\n",
            "Training Loss : -27.77385711669922\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 255 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 313.1660461425781\n",
            "Eval_StdReturn : 7.428713798522949\n",
            "Eval_MaxReturn : 321.3849792480469\n",
            "Eval_MinReturn : 303.3895263671875\n",
            "Eval_AverageEpLen : 145.33333333333334\n",
            "Train_AverageReturn : 324.4726257324219\n",
            "Train_StdReturn : 38.75149917602539\n",
            "Train_MaxReturn : 379.9200439453125\n",
            "Train_MinReturn : 231.9837188720703\n",
            "Train_AverageEpLen : 158.3846153846154\n",
            "Train_EnvstepsSoFar : 525557\n",
            "TimeSinceStart : 580.6546132564545\n",
            "Training Loss : -6.675924301147461\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 256 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 291.3316955566406\n",
            "Eval_StdReturn : 79.55598449707031\n",
            "Eval_MaxReturn : 351.5537109375\n",
            "Eval_MinReturn : 178.91810607910156\n",
            "Eval_AverageEpLen : 145.0\n",
            "Train_AverageReturn : 367.3919677734375\n",
            "Train_StdReturn : 61.07354736328125\n",
            "Train_MaxReturn : 498.31109619140625\n",
            "Train_MinReturn : 276.9403076171875\n",
            "Train_AverageEpLen : 169.5\n",
            "Train_EnvstepsSoFar : 527591\n",
            "TimeSinceStart : 583.0528581142426\n",
            "Training Loss : -63.05134582519531\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 257 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 293.7039794921875\n",
            "Eval_StdReturn : 20.288646697998047\n",
            "Eval_MaxReturn : 317.89910888671875\n",
            "Eval_MinReturn : 268.2501220703125\n",
            "Eval_AverageEpLen : 142.66666666666666\n",
            "Train_AverageReturn : 324.158203125\n",
            "Train_StdReturn : 62.64854431152344\n",
            "Train_MaxReturn : 379.13385009765625\n",
            "Train_MinReturn : 115.67962646484375\n",
            "Train_AverageEpLen : 153.57142857142858\n",
            "Train_EnvstepsSoFar : 529741\n",
            "TimeSinceStart : 585.5516760349274\n",
            "Training Loss : 67.54563903808594\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 258 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 346.22216796875\n",
            "Eval_StdReturn : 50.46176528930664\n",
            "Eval_MaxReturn : 403.51055908203125\n",
            "Eval_MinReturn : 280.7253723144531\n",
            "Eval_AverageEpLen : 172.66666666666666\n",
            "Train_AverageReturn : 354.40313720703125\n",
            "Train_StdReturn : 84.19661712646484\n",
            "Train_MaxReturn : 471.0545349121094\n",
            "Train_MinReturn : 152.658447265625\n",
            "Train_AverageEpLen : 183.0\n",
            "Train_EnvstepsSoFar : 531754\n",
            "TimeSinceStart : 588.035703420639\n",
            "Training Loss : 96.69505310058594\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 259 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 335.6028137207031\n",
            "Eval_StdReturn : 25.595548629760742\n",
            "Eval_MaxReturn : 369.94793701171875\n",
            "Eval_MinReturn : 308.5303649902344\n",
            "Eval_AverageEpLen : 154.33333333333334\n",
            "Train_AverageReturn : 326.1725769042969\n",
            "Train_StdReturn : 58.35360336303711\n",
            "Train_MaxReturn : 403.70526123046875\n",
            "Train_MinReturn : 152.64622497558594\n",
            "Train_AverageEpLen : 154.30769230769232\n",
            "Train_EnvstepsSoFar : 533760\n",
            "TimeSinceStart : 590.3489787578583\n",
            "Training Loss : -33.402740478515625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 260 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 367.4974365234375\n",
            "Eval_StdReturn : 36.27364730834961\n",
            "Eval_MaxReturn : 409.07293701171875\n",
            "Eval_MinReturn : 320.6851806640625\n",
            "Eval_AverageEpLen : 173.0\n",
            "Train_AverageReturn : 348.4835510253906\n",
            "Train_StdReturn : 94.01605987548828\n",
            "Train_MaxReturn : 516.917236328125\n",
            "Train_MinReturn : 168.82928466796875\n",
            "Train_AverageEpLen : 166.0\n",
            "Train_EnvstepsSoFar : 535918\n",
            "TimeSinceStart : 592.9044208526611\n",
            "Training Loss : -50.42396545410156\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 261 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 305.2190856933594\n",
            "Eval_StdReturn : 122.31442260742188\n",
            "Eval_MaxReturn : 422.7813415527344\n",
            "Eval_MinReturn : 136.54908752441406\n",
            "Eval_AverageEpLen : 152.66666666666666\n",
            "Train_AverageReturn : 337.7015075683594\n",
            "Train_StdReturn : 67.75093841552734\n",
            "Train_MaxReturn : 445.768798828125\n",
            "Train_MinReturn : 181.54957580566406\n",
            "Train_AverageEpLen : 163.23076923076923\n",
            "Train_EnvstepsSoFar : 538040\n",
            "TimeSinceStart : 595.3947730064392\n",
            "Training Loss : -20.744590759277344\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 262 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 361.998291015625\n",
            "Eval_StdReturn : 25.57391357421875\n",
            "Eval_MaxReturn : 389.2511901855469\n",
            "Eval_MinReturn : 327.7806396484375\n",
            "Eval_AverageEpLen : 168.0\n",
            "Train_AverageReturn : 321.97222900390625\n",
            "Train_StdReturn : 80.99496459960938\n",
            "Train_MaxReturn : 460.1007385253906\n",
            "Train_MinReturn : 120.42221069335938\n",
            "Train_AverageEpLen : 155.5\n",
            "Train_EnvstepsSoFar : 540217\n",
            "TimeSinceStart : 597.8913934230804\n",
            "Training Loss : 20.629470825195312\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 263 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 322.6347351074219\n",
            "Eval_StdReturn : 104.3014144897461\n",
            "Eval_MaxReturn : 421.9822692871094\n",
            "Eval_MinReturn : 178.53782653808594\n",
            "Eval_AverageEpLen : 159.66666666666666\n",
            "Train_AverageReturn : 346.76220703125\n",
            "Train_StdReturn : 73.36756896972656\n",
            "Train_MaxReturn : 423.7948913574219\n",
            "Train_MinReturn : 131.53390502929688\n",
            "Train_AverageEpLen : 162.76923076923077\n",
            "Train_EnvstepsSoFar : 542333\n",
            "TimeSinceStart : 600.3185038566589\n",
            "Training Loss : 59.33623504638672\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 264 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 350.9657287597656\n",
            "Eval_StdReturn : 28.725929260253906\n",
            "Eval_MaxReturn : 388.7350769042969\n",
            "Eval_MinReturn : 319.1243591308594\n",
            "Eval_AverageEpLen : 164.33333333333334\n",
            "Train_AverageReturn : 324.3707275390625\n",
            "Train_StdReturn : 75.11834716796875\n",
            "Train_MaxReturn : 410.4251708984375\n",
            "Train_MinReturn : 157.03945922851562\n",
            "Train_AverageEpLen : 157.6153846153846\n",
            "Train_EnvstepsSoFar : 544382\n",
            "TimeSinceStart : 602.7396278381348\n",
            "Training Loss : -85.4544677734375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 265 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 407.8914794921875\n",
            "Eval_StdReturn : 67.31919860839844\n",
            "Eval_MaxReturn : 475.210693359375\n",
            "Eval_MinReturn : 340.5722961425781\n",
            "Eval_AverageEpLen : 200.5\n",
            "Train_AverageReturn : 330.9336242675781\n",
            "Train_StdReturn : 101.91825866699219\n",
            "Train_MaxReturn : 479.632080078125\n",
            "Train_MinReturn : 101.32164001464844\n",
            "Train_AverageEpLen : 158.07692307692307\n",
            "Train_EnvstepsSoFar : 546437\n",
            "TimeSinceStart : 605.087726354599\n",
            "Training Loss : 27.885847091674805\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 266 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 366.473388671875\n",
            "Eval_StdReturn : 12.086791038513184\n",
            "Eval_MaxReturn : 383.34271240234375\n",
            "Eval_MinReturn : 355.65020751953125\n",
            "Eval_AverageEpLen : 163.0\n",
            "Train_AverageReturn : 369.2734680175781\n",
            "Train_StdReturn : 36.65754699707031\n",
            "Train_MaxReturn : 450.6233825683594\n",
            "Train_MinReturn : 316.5846862792969\n",
            "Train_AverageEpLen : 176.16666666666666\n",
            "Train_EnvstepsSoFar : 548551\n",
            "TimeSinceStart : 607.6185522079468\n",
            "Training Loss : 45.28662109375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 267 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 420.10198974609375\n",
            "Eval_StdReturn : 56.23341369628906\n",
            "Eval_MaxReturn : 476.33538818359375\n",
            "Eval_MinReturn : 363.8685607910156\n",
            "Eval_AverageEpLen : 202.5\n",
            "Train_AverageReturn : 332.7900390625\n",
            "Train_StdReturn : 46.42458724975586\n",
            "Train_MaxReturn : 402.7135009765625\n",
            "Train_MinReturn : 223.72314453125\n",
            "Train_AverageEpLen : 159.84615384615384\n",
            "Train_EnvstepsSoFar : 550629\n",
            "TimeSinceStart : 609.9556767940521\n",
            "Training Loss : 57.06610107421875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 268 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 368.3941955566406\n",
            "Eval_StdReturn : 29.99500274658203\n",
            "Eval_MaxReturn : 410.8135070800781\n",
            "Eval_MinReturn : 347.16314697265625\n",
            "Eval_AverageEpLen : 172.0\n",
            "Train_AverageReturn : 301.9167785644531\n",
            "Train_StdReturn : 107.8131103515625\n",
            "Train_MaxReturn : 459.7459716796875\n",
            "Train_MinReturn : 67.79896545410156\n",
            "Train_AverageEpLen : 143.8\n",
            "Train_EnvstepsSoFar : 552786\n",
            "TimeSinceStart : 612.4321835041046\n",
            "Training Loss : 95.58547973632812\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 269 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 368.5159606933594\n",
            "Eval_StdReturn : 26.24338722229004\n",
            "Eval_MaxReturn : 399.69940185546875\n",
            "Eval_MinReturn : 335.49530029296875\n",
            "Eval_AverageEpLen : 175.0\n",
            "Train_AverageReturn : 332.34442138671875\n",
            "Train_StdReturn : 100.15774536132812\n",
            "Train_MaxReturn : 538.4547119140625\n",
            "Train_MinReturn : 155.41905212402344\n",
            "Train_AverageEpLen : 159.53846153846155\n",
            "Train_EnvstepsSoFar : 554860\n",
            "TimeSinceStart : 615.0150182247162\n",
            "Training Loss : -144.60748291015625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 270 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 346.9813232421875\n",
            "Eval_StdReturn : 35.93614959716797\n",
            "Eval_MaxReturn : 388.73876953125\n",
            "Eval_MinReturn : 301.01580810546875\n",
            "Eval_AverageEpLen : 176.0\n",
            "Train_AverageReturn : 352.5908203125\n",
            "Train_StdReturn : 42.86161804199219\n",
            "Train_MaxReturn : 429.9847717285156\n",
            "Train_MinReturn : 276.68072509765625\n",
            "Train_AverageEpLen : 162.30769230769232\n",
            "Train_EnvstepsSoFar : 556970\n",
            "TimeSinceStart : 617.510409116745\n",
            "Training Loss : -90.53282928466797\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 271 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 304.3489685058594\n",
            "Eval_StdReturn : 68.59597778320312\n",
            "Eval_MaxReturn : 361.0455627441406\n",
            "Eval_MinReturn : 207.83006286621094\n",
            "Eval_AverageEpLen : 144.0\n",
            "Train_AverageReturn : 320.7552185058594\n",
            "Train_StdReturn : 76.2647476196289\n",
            "Train_MaxReturn : 440.1131591796875\n",
            "Train_MinReturn : 123.78839874267578\n",
            "Train_AverageEpLen : 155.78571428571428\n",
            "Train_EnvstepsSoFar : 559151\n",
            "TimeSinceStart : 619.931676864624\n",
            "Training Loss : -4.952911376953125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 272 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 384.4480285644531\n",
            "Eval_StdReturn : 65.49462890625\n",
            "Eval_MaxReturn : 466.0504150390625\n",
            "Eval_MinReturn : 305.6980895996094\n",
            "Eval_AverageEpLen : 180.0\n",
            "Train_AverageReturn : 342.3851318359375\n",
            "Train_StdReturn : 76.51119995117188\n",
            "Train_MaxReturn : 446.466796875\n",
            "Train_MinReturn : 130.11181640625\n",
            "Train_AverageEpLen : 160.92307692307693\n",
            "Train_EnvstepsSoFar : 561243\n",
            "TimeSinceStart : 622.4768795967102\n",
            "Training Loss : 76.94705200195312\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 273 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 373.5538024902344\n",
            "Eval_StdReturn : 20.803958892822266\n",
            "Eval_MaxReturn : 399.3208312988281\n",
            "Eval_MinReturn : 348.371826171875\n",
            "Eval_AverageEpLen : 182.33333333333334\n",
            "Train_AverageReturn : 305.8447265625\n",
            "Train_StdReturn : 69.10093688964844\n",
            "Train_MaxReturn : 405.7693786621094\n",
            "Train_MinReturn : 151.25942993164062\n",
            "Train_AverageEpLen : 149.35714285714286\n",
            "Train_EnvstepsSoFar : 563334\n",
            "TimeSinceStart : 624.9289758205414\n",
            "Training Loss : -27.212657928466797\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 274 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 345.5274963378906\n",
            "Eval_StdReturn : 4.6998443603515625\n",
            "Eval_MaxReturn : 352.17303466796875\n",
            "Eval_MinReturn : 342.1016845703125\n",
            "Eval_AverageEpLen : 163.0\n",
            "Train_AverageReturn : 375.2961120605469\n",
            "Train_StdReturn : 66.28617858886719\n",
            "Train_MaxReturn : 452.5643310546875\n",
            "Train_MinReturn : 220.42483520507812\n",
            "Train_AverageEpLen : 176.33333333333334\n",
            "Train_EnvstepsSoFar : 565450\n",
            "TimeSinceStart : 627.4281053543091\n",
            "Training Loss : -45.598812103271484\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 275 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 404.9427795410156\n",
            "Eval_StdReturn : 87.06648254394531\n",
            "Eval_MaxReturn : 513.458740234375\n",
            "Eval_MinReturn : 300.29559326171875\n",
            "Eval_AverageEpLen : 182.66666666666666\n",
            "Train_AverageReturn : 358.9246520996094\n",
            "Train_StdReturn : 46.264678955078125\n",
            "Train_MaxReturn : 453.1816711425781\n",
            "Train_MinReturn : 290.1887512207031\n",
            "Train_AverageEpLen : 164.6153846153846\n",
            "Train_EnvstepsSoFar : 567590\n",
            "TimeSinceStart : 629.9345240592957\n",
            "Training Loss : -50.169952392578125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 276 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 376.9211120605469\n",
            "Eval_StdReturn : 30.192928314208984\n",
            "Eval_MaxReturn : 398.76953125\n",
            "Eval_MinReturn : 334.22576904296875\n",
            "Eval_AverageEpLen : 176.33333333333334\n",
            "Train_AverageReturn : 306.1860656738281\n",
            "Train_StdReturn : 99.05958557128906\n",
            "Train_MaxReturn : 421.70965576171875\n",
            "Train_MinReturn : 116.56041717529297\n",
            "Train_AverageEpLen : 152.5\n",
            "Train_EnvstepsSoFar : 569725\n",
            "TimeSinceStart : 632.4267482757568\n",
            "Training Loss : -74.42112731933594\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 277 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 306.54278564453125\n",
            "Eval_StdReturn : 32.355369567871094\n",
            "Eval_MaxReturn : 346.40679931640625\n",
            "Eval_MinReturn : 267.156982421875\n",
            "Eval_AverageEpLen : 144.33333333333334\n",
            "Train_AverageReturn : 374.0307312011719\n",
            "Train_StdReturn : 59.74748992919922\n",
            "Train_MaxReturn : 457.2354736328125\n",
            "Train_MinReturn : 224.5610809326172\n",
            "Train_AverageEpLen : 184.0\n",
            "Train_EnvstepsSoFar : 571749\n",
            "TimeSinceStart : 634.8360855579376\n",
            "Training Loss : -58.074005126953125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 278 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 310.5557556152344\n",
            "Eval_StdReturn : 77.7417984008789\n",
            "Eval_MaxReturn : 376.564208984375\n",
            "Eval_MinReturn : 201.40792846679688\n",
            "Eval_AverageEpLen : 155.0\n",
            "Train_AverageReturn : 405.1587219238281\n",
            "Train_StdReturn : 86.45387268066406\n",
            "Train_MaxReturn : 571.64404296875\n",
            "Train_MinReturn : 319.75274658203125\n",
            "Train_AverageEpLen : 188.1818181818182\n",
            "Train_EnvstepsSoFar : 573819\n",
            "TimeSinceStart : 637.3151776790619\n",
            "Training Loss : -75.32942199707031\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 279 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 341.4925842285156\n",
            "Eval_StdReturn : 36.80643081665039\n",
            "Eval_MaxReturn : 374.6651611328125\n",
            "Eval_MinReturn : 290.16790771484375\n",
            "Eval_AverageEpLen : 163.0\n",
            "Train_AverageReturn : 378.70654296875\n",
            "Train_StdReturn : 78.74205017089844\n",
            "Train_MaxReturn : 556.2587890625\n",
            "Train_MinReturn : 242.3922882080078\n",
            "Train_AverageEpLen : 186.33333333333334\n",
            "Train_EnvstepsSoFar : 576055\n",
            "TimeSinceStart : 639.9910130500793\n",
            "Training Loss : 21.320602416992188\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 280 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 377.6412048339844\n",
            "Eval_StdReturn : 54.243309020996094\n",
            "Eval_MaxReturn : 454.34222412109375\n",
            "Eval_MinReturn : 338.18560791015625\n",
            "Eval_AverageEpLen : 185.66666666666666\n",
            "Train_AverageReturn : 389.6478576660156\n",
            "Train_StdReturn : 81.09195709228516\n",
            "Train_MaxReturn : 618.9638671875\n",
            "Train_MinReturn : 317.73614501953125\n",
            "Train_AverageEpLen : 192.1818181818182\n",
            "Train_EnvstepsSoFar : 578169\n",
            "TimeSinceStart : 642.6268861293793\n",
            "Training Loss : 20.504533767700195\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 281 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 352.4410705566406\n",
            "Eval_StdReturn : 46.203590393066406\n",
            "Eval_MaxReturn : 414.74346923828125\n",
            "Eval_MinReturn : 304.2321472167969\n",
            "Eval_AverageEpLen : 166.66666666666666\n",
            "Train_AverageReturn : 335.1494140625\n",
            "Train_StdReturn : 97.06718444824219\n",
            "Train_MaxReturn : 551.47021484375\n",
            "Train_MinReturn : 187.24176025390625\n",
            "Train_AverageEpLen : 159.30769230769232\n",
            "Train_EnvstepsSoFar : 580240\n",
            "TimeSinceStart : 645.0451090335846\n",
            "Training Loss : 60.11511993408203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 282 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 300.09765625\n",
            "Eval_StdReturn : 143.00767517089844\n",
            "Eval_MaxReturn : 491.53167724609375\n",
            "Eval_MinReturn : 147.88681030273438\n",
            "Eval_AverageEpLen : 159.0\n",
            "Train_AverageReturn : 407.7644958496094\n",
            "Train_StdReturn : 92.6311264038086\n",
            "Train_MaxReturn : 562.3286743164062\n",
            "Train_MinReturn : 241.90875244140625\n",
            "Train_AverageEpLen : 204.2\n",
            "Train_EnvstepsSoFar : 582282\n",
            "TimeSinceStart : 647.5446979999542\n",
            "Training Loss : 39.635772705078125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 283 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 409.6239318847656\n",
            "Eval_StdReturn : 35.832828521728516\n",
            "Eval_MaxReturn : 450.65313720703125\n",
            "Eval_MinReturn : 363.35198974609375\n",
            "Eval_AverageEpLen : 209.33333333333334\n",
            "Train_AverageReturn : 359.078369140625\n",
            "Train_StdReturn : 81.99474334716797\n",
            "Train_MaxReturn : 457.8629455566406\n",
            "Train_MinReturn : 218.55630493164062\n",
            "Train_AverageEpLen : 174.58333333333334\n",
            "Train_EnvstepsSoFar : 584377\n",
            "TimeSinceStart : 650.1293880939484\n",
            "Training Loss : -5.987152099609375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 284 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 544.5450439453125\n",
            "Eval_StdReturn : 45.233795166015625\n",
            "Eval_MaxReturn : 589.77880859375\n",
            "Eval_MinReturn : 499.31121826171875\n",
            "Eval_AverageEpLen : 272.0\n",
            "Train_AverageReturn : 339.93878173828125\n",
            "Train_StdReturn : 77.5481185913086\n",
            "Train_MaxReturn : 452.795654296875\n",
            "Train_MinReturn : 135.99267578125\n",
            "Train_AverageEpLen : 163.23076923076923\n",
            "Train_EnvstepsSoFar : 586499\n",
            "TimeSinceStart : 652.6597888469696\n",
            "Training Loss : 13.340646743774414\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 285 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 394.5442810058594\n",
            "Eval_StdReturn : 55.25994110107422\n",
            "Eval_MaxReturn : 469.4356994628906\n",
            "Eval_MinReturn : 337.7608642578125\n",
            "Eval_AverageEpLen : 203.66666666666666\n",
            "Train_AverageReturn : 361.0804443359375\n",
            "Train_StdReturn : 77.96156311035156\n",
            "Train_MaxReturn : 498.4615783691406\n",
            "Train_MinReturn : 192.13906860351562\n",
            "Train_AverageEpLen : 181.9090909090909\n",
            "Train_EnvstepsSoFar : 588500\n",
            "TimeSinceStart : 655.2580826282501\n",
            "Training Loss : -0.1981964111328125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 286 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 391.5600891113281\n",
            "Eval_StdReturn : 52.96779251098633\n",
            "Eval_MaxReturn : 450.33489990234375\n",
            "Eval_MinReturn : 321.9542541503906\n",
            "Eval_AverageEpLen : 172.66666666666666\n",
            "Train_AverageReturn : 386.6204833984375\n",
            "Train_StdReturn : 53.44997787475586\n",
            "Train_MaxReturn : 491.011474609375\n",
            "Train_MinReturn : 315.8436584472656\n",
            "Train_AverageEpLen : 175.83333333333334\n",
            "Train_EnvstepsSoFar : 590610\n",
            "TimeSinceStart : 657.8428797721863\n",
            "Training Loss : 10.595569610595703\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 287 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 321.44622802734375\n",
            "Eval_StdReturn : 53.5712890625\n",
            "Eval_MaxReturn : 370.324951171875\n",
            "Eval_MinReturn : 246.87725830078125\n",
            "Eval_AverageEpLen : 149.0\n",
            "Train_AverageReturn : 371.2425537109375\n",
            "Train_StdReturn : 115.4138412475586\n",
            "Train_MaxReturn : 581.0322875976562\n",
            "Train_MinReturn : 89.49423217773438\n",
            "Train_AverageEpLen : 183.0\n",
            "Train_EnvstepsSoFar : 592623\n",
            "TimeSinceStart : 660.2651393413544\n",
            "Training Loss : 42.438873291015625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 288 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 365.6828918457031\n",
            "Eval_StdReturn : 56.28682327270508\n",
            "Eval_MaxReturn : 439.02532958984375\n",
            "Eval_MinReturn : 302.21661376953125\n",
            "Eval_AverageEpLen : 168.33333333333334\n",
            "Train_AverageReturn : 386.0028991699219\n",
            "Train_StdReturn : 56.78030014038086\n",
            "Train_MaxReturn : 496.2784118652344\n",
            "Train_MinReturn : 299.32427978515625\n",
            "Train_AverageEpLen : 185.9090909090909\n",
            "Train_EnvstepsSoFar : 594668\n",
            "TimeSinceStart : 662.7237331867218\n",
            "Training Loss : 13.716224670410156\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 289 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 388.08935546875\n",
            "Eval_StdReturn : 37.633033752441406\n",
            "Eval_MaxReturn : 440.6902160644531\n",
            "Eval_MinReturn : 354.7724304199219\n",
            "Eval_AverageEpLen : 173.33333333333334\n",
            "Train_AverageReturn : 396.90191650390625\n",
            "Train_StdReturn : 52.08725357055664\n",
            "Train_MaxReturn : 474.2174377441406\n",
            "Train_MinReturn : 291.62872314453125\n",
            "Train_AverageEpLen : 202.8\n",
            "Train_EnvstepsSoFar : 596696\n",
            "TimeSinceStart : 665.2081546783447\n",
            "Training Loss : -64.83039093017578\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 290 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 493.51348876953125\n",
            "Eval_StdReturn : 1.6304931640625\n",
            "Eval_MaxReturn : 495.14398193359375\n",
            "Eval_MinReturn : 491.88299560546875\n",
            "Eval_AverageEpLen : 264.5\n",
            "Train_AverageReturn : 337.9222412109375\n",
            "Train_StdReturn : 112.05699920654297\n",
            "Train_MaxReturn : 535.8228759765625\n",
            "Train_MinReturn : 101.57763671875\n",
            "Train_AverageEpLen : 162.0\n",
            "Train_EnvstepsSoFar : 598802\n",
            "TimeSinceStart : 667.7148044109344\n",
            "Training Loss : -21.198223114013672\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 291 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 473.28485107421875\n",
            "Eval_StdReturn : 196.32818603515625\n",
            "Eval_MaxReturn : 669.613037109375\n",
            "Eval_MinReturn : 276.9566650390625\n",
            "Eval_AverageEpLen : 222.5\n",
            "Train_AverageReturn : 429.2676696777344\n",
            "Train_StdReturn : 71.18730163574219\n",
            "Train_MaxReturn : 602.4912719726562\n",
            "Train_MinReturn : 363.7687683105469\n",
            "Train_AverageEpLen : 203.0\n",
            "Train_EnvstepsSoFar : 600832\n",
            "TimeSinceStart : 670.1600916385651\n",
            "Training Loss : 6.479547500610352\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 292 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 458.5005187988281\n",
            "Eval_StdReturn : 101.12924194335938\n",
            "Eval_MaxReturn : 559.6297607421875\n",
            "Eval_MinReturn : 357.37127685546875\n",
            "Eval_AverageEpLen : 216.5\n",
            "Train_AverageReturn : 387.4167785644531\n",
            "Train_StdReturn : 86.49217987060547\n",
            "Train_MaxReturn : 549.689697265625\n",
            "Train_MinReturn : 178.13858032226562\n",
            "Train_AverageEpLen : 205.0\n",
            "Train_EnvstepsSoFar : 602882\n",
            "TimeSinceStart : 672.6361224651337\n",
            "Training Loss : -31.119388580322266\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 293 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 277.4310607910156\n",
            "Eval_StdReturn : 110.25414276123047\n",
            "Eval_MaxReturn : 386.5677185058594\n",
            "Eval_MinReturn : 126.4217758178711\n",
            "Eval_AverageEpLen : 140.33333333333334\n",
            "Train_AverageReturn : 366.0433349609375\n",
            "Train_StdReturn : 96.63408660888672\n",
            "Train_MaxReturn : 468.5505065917969\n",
            "Train_MinReturn : 101.78553771972656\n",
            "Train_AverageEpLen : 183.8181818181818\n",
            "Train_EnvstepsSoFar : 604904\n",
            "TimeSinceStart : 675.0343339443207\n",
            "Training Loss : -108.67266082763672\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 294 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 326.8222351074219\n",
            "Eval_StdReturn : 109.06422424316406\n",
            "Eval_MaxReturn : 479.82293701171875\n",
            "Eval_MinReturn : 233.4222412109375\n",
            "Eval_AverageEpLen : 166.33333333333334\n",
            "Train_AverageReturn : 337.1872253417969\n",
            "Train_StdReturn : 91.9625473022461\n",
            "Train_MaxReturn : 455.1356201171875\n",
            "Train_MinReturn : 146.56814575195312\n",
            "Train_AverageEpLen : 163.53846153846155\n",
            "Train_EnvstepsSoFar : 607030\n",
            "TimeSinceStart : 677.5171382427216\n",
            "Training Loss : 21.751035690307617\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 295 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 390.967529296875\n",
            "Eval_StdReturn : 104.8241195678711\n",
            "Eval_MaxReturn : 503.6964416503906\n",
            "Eval_MinReturn : 251.2286834716797\n",
            "Eval_AverageEpLen : 185.33333333333334\n",
            "Train_AverageReturn : 351.5914001464844\n",
            "Train_StdReturn : 86.48473358154297\n",
            "Train_MaxReturn : 459.88995361328125\n",
            "Train_MinReturn : 150.5730438232422\n",
            "Train_AverageEpLen : 179.41666666666666\n",
            "Train_EnvstepsSoFar : 609183\n",
            "TimeSinceStart : 680.0762505531311\n",
            "Training Loss : 34.210418701171875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 296 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 414.6817321777344\n",
            "Eval_StdReturn : 25.86975860595703\n",
            "Eval_MaxReturn : 451.19134521484375\n",
            "Eval_MinReturn : 394.38946533203125\n",
            "Eval_AverageEpLen : 193.33333333333334\n",
            "Train_AverageReturn : 410.5180358886719\n",
            "Train_StdReturn : 69.733642578125\n",
            "Train_MaxReturn : 552.4658813476562\n",
            "Train_MinReturn : 331.2571105957031\n",
            "Train_AverageEpLen : 198.45454545454547\n",
            "Train_EnvstepsSoFar : 611366\n",
            "TimeSinceStart : 682.8051514625549\n",
            "Training Loss : 114.74213409423828\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 297 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 439.3321228027344\n",
            "Eval_StdReturn : 76.53311157226562\n",
            "Eval_MaxReturn : 515.865234375\n",
            "Eval_MinReturn : 362.79901123046875\n",
            "Eval_AverageEpLen : 224.0\n",
            "Train_AverageReturn : 378.97021484375\n",
            "Train_StdReturn : 73.01683044433594\n",
            "Train_MaxReturn : 501.8483581542969\n",
            "Train_MinReturn : 258.6069030761719\n",
            "Train_AverageEpLen : 180.66666666666666\n",
            "Train_EnvstepsSoFar : 613534\n",
            "TimeSinceStart : 685.3309171199799\n",
            "Training Loss : -11.903244018554688\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 298 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 383.8399353027344\n",
            "Eval_StdReturn : 14.822220802307129\n",
            "Eval_MaxReturn : 404.3107604980469\n",
            "Eval_MinReturn : 369.6986083984375\n",
            "Eval_AverageEpLen : 191.33333333333334\n",
            "Train_AverageReturn : 467.8235778808594\n",
            "Train_StdReturn : 113.11982727050781\n",
            "Train_MaxReturn : 615.736572265625\n",
            "Train_MinReturn : 313.90850830078125\n",
            "Train_AverageEpLen : 222.77777777777777\n",
            "Train_EnvstepsSoFar : 615539\n",
            "TimeSinceStart : 687.9271502494812\n",
            "Training Loss : 83.48701477050781\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 299 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 450.1703186035156\n",
            "Eval_StdReturn : 101.85723114013672\n",
            "Eval_MaxReturn : 527.7664794921875\n",
            "Eval_MinReturn : 306.2700500488281\n",
            "Eval_AverageEpLen : 215.0\n",
            "Train_AverageReturn : 373.5655822753906\n",
            "Train_StdReturn : 71.42321014404297\n",
            "Train_MaxReturn : 519.3626708984375\n",
            "Train_MinReturn : 209.10916137695312\n",
            "Train_AverageEpLen : 175.25\n",
            "Train_EnvstepsSoFar : 617642\n",
            "TimeSinceStart : 690.5069160461426\n",
            "Training Loss : 39.28999328613281\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name Hopper-v2 --ep_len 1000 \\\n",
        "    --discount 0.99 -n 300 -l 2 -s 32 -b 2000 -lr 0.001 \\\n",
        "    --reward_to_go --nn_baseline \\\n",
        "    --action_noise_std 0.5 --gae_lambda 0.99 \\\n",
        "    --exp_name q5_b2000_r0.001_lambda0.99"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LjeSRZDMv-U",
        "outputId": "5c5ce3e2-0970-4033-f27b-028984cfd16e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Eval_StdReturn : 21.066314697265625\n",
            "Eval_MaxReturn : 243.6533966064453\n",
            "Eval_MinReturn : 190.63345336914062\n",
            "Eval_AverageEpLen : 107.0\n",
            "Train_AverageReturn : 205.5409393310547\n",
            "Train_StdReturn : 40.78237533569336\n",
            "Train_MaxReturn : 244.72576904296875\n",
            "Train_MinReturn : 64.4131851196289\n",
            "Train_AverageEpLen : 96.14285714285714\n",
            "Train_EnvstepsSoFar : 249109\n",
            "TimeSinceStart : 264.61988711357117\n",
            "Training Loss : -53.376380920410156\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 122 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 218.9279022216797\n",
            "Eval_StdReturn : 11.610203742980957\n",
            "Eval_MaxReturn : 231.35955810546875\n",
            "Eval_MinReturn : 201.13613891601562\n",
            "Eval_AverageEpLen : 100.0\n",
            "Train_AverageReturn : 213.43014526367188\n",
            "Train_StdReturn : 9.874857902526855\n",
            "Train_MaxReturn : 231.51666259765625\n",
            "Train_MinReturn : 192.2667694091797\n",
            "Train_AverageEpLen : 97.57142857142857\n",
            "Train_EnvstepsSoFar : 251158\n",
            "TimeSinceStart : 266.8720645904541\n",
            "Training Loss : 128.191650390625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 123 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 214.9218292236328\n",
            "Eval_StdReturn : 6.593715667724609\n",
            "Eval_MaxReturn : 225.6709442138672\n",
            "Eval_MinReturn : 206.7337646484375\n",
            "Eval_AverageEpLen : 99.8\n",
            "Train_AverageReturn : 212.32875061035156\n",
            "Train_StdReturn : 11.23720932006836\n",
            "Train_MaxReturn : 238.48892211914062\n",
            "Train_MinReturn : 196.73182678222656\n",
            "Train_AverageEpLen : 97.04761904761905\n",
            "Train_EnvstepsSoFar : 253196\n",
            "TimeSinceStart : 269.13252449035645\n",
            "Training Loss : -10.311920166015625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 124 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 207.81680297851562\n",
            "Eval_StdReturn : 13.165326118469238\n",
            "Eval_MaxReturn : 228.84231567382812\n",
            "Eval_MinReturn : 190.16082763671875\n",
            "Eval_AverageEpLen : 92.8\n",
            "Train_AverageReturn : 219.99508666992188\n",
            "Train_StdReturn : 12.821290016174316\n",
            "Train_MaxReturn : 244.5751190185547\n",
            "Train_MinReturn : 201.14768981933594\n",
            "Train_AverageEpLen : 102.8\n",
            "Train_EnvstepsSoFar : 255252\n",
            "TimeSinceStart : 271.3836085796356\n",
            "Training Loss : -21.90854263305664\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 125 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 189.3002471923828\n",
            "Eval_StdReturn : 59.562232971191406\n",
            "Eval_MaxReturn : 230.73548889160156\n",
            "Eval_MinReturn : 70.96292114257812\n",
            "Eval_AverageEpLen : 89.8\n",
            "Train_AverageReturn : 208.18603515625\n",
            "Train_StdReturn : 30.33045196533203\n",
            "Train_MaxReturn : 245.37767028808594\n",
            "Train_MinReturn : 86.11408233642578\n",
            "Train_AverageEpLen : 95.23809523809524\n",
            "Train_EnvstepsSoFar : 257252\n",
            "TimeSinceStart : 273.57290863990784\n",
            "Training Loss : -113.66983795166016\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 126 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 202.16244506835938\n",
            "Eval_StdReturn : 29.1711368560791\n",
            "Eval_MaxReturn : 228.33372497558594\n",
            "Eval_MinReturn : 146.21778869628906\n",
            "Eval_AverageEpLen : 91.8\n",
            "Train_AverageReturn : 207.79225158691406\n",
            "Train_StdReturn : 42.136253356933594\n",
            "Train_MaxReturn : 249.09352111816406\n",
            "Train_MinReturn : 28.730796813964844\n",
            "Train_AverageEpLen : 97.0\n",
            "Train_EnvstepsSoFar : 259289\n",
            "TimeSinceStart : 275.805624961853\n",
            "Training Loss : 2.638193130493164\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 127 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.09619140625\n",
            "Eval_StdReturn : 8.949198722839355\n",
            "Eval_MaxReturn : 238.04779052734375\n",
            "Eval_MinReturn : 213.26280212402344\n",
            "Eval_AverageEpLen : 101.25\n",
            "Train_AverageReturn : 211.4462127685547\n",
            "Train_StdReturn : 24.95550537109375\n",
            "Train_MaxReturn : 252.89175415039062\n",
            "Train_MinReturn : 115.2950439453125\n",
            "Train_AverageEpLen : 98.04761904761905\n",
            "Train_EnvstepsSoFar : 261348\n",
            "TimeSinceStart : 277.98705649375916\n",
            "Training Loss : 6.451595306396484\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 128 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 215.60986328125\n",
            "Eval_StdReturn : 8.657402992248535\n",
            "Eval_MaxReturn : 228.93963623046875\n",
            "Eval_MinReturn : 204.27285766601562\n",
            "Eval_AverageEpLen : 96.4\n",
            "Train_AverageReturn : 208.64862060546875\n",
            "Train_StdReturn : 42.26688003540039\n",
            "Train_MaxReturn : 244.0824432373047\n",
            "Train_MinReturn : 35.33902359008789\n",
            "Train_AverageEpLen : 98.47619047619048\n",
            "Train_EnvstepsSoFar : 263416\n",
            "TimeSinceStart : 280.2478346824646\n",
            "Training Loss : -0.5072612762451172\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 129 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 214.6763916015625\n",
            "Eval_StdReturn : 10.82741641998291\n",
            "Eval_MaxReturn : 223.4844512939453\n",
            "Eval_MinReturn : 194.10252380371094\n",
            "Eval_AverageEpLen : 99.4\n",
            "Train_AverageReturn : 217.2803192138672\n",
            "Train_StdReturn : 18.544960021972656\n",
            "Train_MaxReturn : 249.01693725585938\n",
            "Train_MinReturn : 178.4558563232422\n",
            "Train_AverageEpLen : 100.85\n",
            "Train_EnvstepsSoFar : 265433\n",
            "TimeSinceStart : 282.4678325653076\n",
            "Training Loss : 79.58445739746094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 130 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 174.89305114746094\n",
            "Eval_StdReturn : 75.31861114501953\n",
            "Eval_MaxReturn : 224.43930053710938\n",
            "Eval_MinReturn : 25.331710815429688\n",
            "Eval_AverageEpLen : 80.8\n",
            "Train_AverageReturn : 218.5558319091797\n",
            "Train_StdReturn : 9.776703834533691\n",
            "Train_MaxReturn : 235.01524353027344\n",
            "Train_MinReturn : 201.53561401367188\n",
            "Train_AverageEpLen : 99.61904761904762\n",
            "Train_EnvstepsSoFar : 267525\n",
            "TimeSinceStart : 284.6700031757355\n",
            "Training Loss : 17.445388793945312\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 131 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 215.73159790039062\n",
            "Eval_StdReturn : 18.552234649658203\n",
            "Eval_MaxReturn : 237.78781127929688\n",
            "Eval_MinReturn : 186.60342407226562\n",
            "Eval_AverageEpLen : 100.75\n",
            "Train_AverageReturn : 220.3485107421875\n",
            "Train_StdReturn : 13.71159553527832\n",
            "Train_MaxReturn : 243.2514190673828\n",
            "Train_MinReturn : 195.83433532714844\n",
            "Train_AverageEpLen : 102.8\n",
            "Train_EnvstepsSoFar : 269581\n",
            "TimeSinceStart : 286.8668131828308\n",
            "Training Loss : 25.489255905151367\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 132 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 211.3191375732422\n",
            "Eval_StdReturn : 16.580974578857422\n",
            "Eval_MaxReturn : 226.5692138671875\n",
            "Eval_MinReturn : 179.90338134765625\n",
            "Eval_AverageEpLen : 94.6\n",
            "Train_AverageReturn : 207.19329833984375\n",
            "Train_StdReturn : 39.4996337890625\n",
            "Train_MaxReturn : 233.88714599609375\n",
            "Train_MinReturn : 33.16140365600586\n",
            "Train_AverageEpLen : 95.18181818181819\n",
            "Train_EnvstepsSoFar : 271675\n",
            "TimeSinceStart : 289.143905878067\n",
            "Training Loss : -69.68386840820312\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 133 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 229.80889892578125\n",
            "Eval_StdReturn : 24.534931182861328\n",
            "Eval_MaxReturn : 270.5953063964844\n",
            "Eval_MinReturn : 208.3821563720703\n",
            "Eval_AverageEpLen : 107.75\n",
            "Train_AverageReturn : 215.3148651123047\n",
            "Train_StdReturn : 12.011116981506348\n",
            "Train_MaxReturn : 241.6868438720703\n",
            "Train_MinReturn : 187.1140899658203\n",
            "Train_AverageEpLen : 98.61904761904762\n",
            "Train_EnvstepsSoFar : 273746\n",
            "TimeSinceStart : 291.3535487651825\n",
            "Training Loss : -24.849193572998047\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 134 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 219.383056640625\n",
            "Eval_StdReturn : 12.484336853027344\n",
            "Eval_MaxReturn : 237.05584716796875\n",
            "Eval_MinReturn : 202.2381134033203\n",
            "Eval_AverageEpLen : 100.0\n",
            "Train_AverageReturn : 221.4134521484375\n",
            "Train_StdReturn : 12.792460441589355\n",
            "Train_MaxReturn : 249.64620971679688\n",
            "Train_MinReturn : 200.00645446777344\n",
            "Train_AverageEpLen : 103.15\n",
            "Train_EnvstepsSoFar : 275809\n",
            "TimeSinceStart : 293.5612471103668\n",
            "Training Loss : -23.82703399658203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 135 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 188.9918670654297\n",
            "Eval_StdReturn : 57.11111831665039\n",
            "Eval_MaxReturn : 225.9669647216797\n",
            "Eval_MinReturn : 75.12584686279297\n",
            "Eval_AverageEpLen : 94.6\n",
            "Train_AverageReturn : 217.3416748046875\n",
            "Train_StdReturn : 13.559704780578613\n",
            "Train_MaxReturn : 242.51797485351562\n",
            "Train_MinReturn : 186.6099853515625\n",
            "Train_AverageEpLen : 100.14285714285714\n",
            "Train_EnvstepsSoFar : 277912\n",
            "TimeSinceStart : 295.8353760242462\n",
            "Training Loss : 25.949939727783203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 136 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 227.02981567382812\n",
            "Eval_StdReturn : 10.912003517150879\n",
            "Eval_MaxReturn : 243.48631286621094\n",
            "Eval_MinReturn : 213.31646728515625\n",
            "Eval_AverageEpLen : 109.0\n",
            "Train_AverageReturn : 208.18887329101562\n",
            "Train_StdReturn : 43.48842239379883\n",
            "Train_MaxReturn : 237.78623962402344\n",
            "Train_MinReturn : 24.734643936157227\n",
            "Train_AverageEpLen : 96.38095238095238\n",
            "Train_EnvstepsSoFar : 279936\n",
            "TimeSinceStart : 297.9945933818817\n",
            "Training Loss : -62.2213134765625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 137 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 205.1232147216797\n",
            "Eval_StdReturn : 30.270158767700195\n",
            "Eval_MaxReturn : 225.42453002929688\n",
            "Eval_MinReturn : 145.0819549560547\n",
            "Eval_AverageEpLen : 94.2\n",
            "Train_AverageReturn : 217.83203125\n",
            "Train_StdReturn : 20.512361526489258\n",
            "Train_MaxReturn : 252.6104278564453\n",
            "Train_MinReturn : 145.3603515625\n",
            "Train_AverageEpLen : 102.4\n",
            "Train_EnvstepsSoFar : 281984\n",
            "TimeSinceStart : 300.2251863479614\n",
            "Training Loss : -6.147495269775391\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 138 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 222.88267517089844\n",
            "Eval_StdReturn : 5.760285377502441\n",
            "Eval_MaxReturn : 227.6354522705078\n",
            "Eval_MinReturn : 213.38253784179688\n",
            "Eval_AverageEpLen : 100.5\n",
            "Train_AverageReturn : 222.1752166748047\n",
            "Train_StdReturn : 12.46634292602539\n",
            "Train_MaxReturn : 246.34156799316406\n",
            "Train_MinReturn : 194.82601928710938\n",
            "Train_AverageEpLen : 102.75\n",
            "Train_EnvstepsSoFar : 284039\n",
            "TimeSinceStart : 302.38759565353394\n",
            "Training Loss : -44.09803771972656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 139 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 227.72488403320312\n",
            "Eval_StdReturn : 21.385723114013672\n",
            "Eval_MaxReturn : 269.9982604980469\n",
            "Eval_MinReturn : 213.67364501953125\n",
            "Eval_AverageEpLen : 105.8\n",
            "Train_AverageReturn : 213.03665161132812\n",
            "Train_StdReturn : 33.41727066040039\n",
            "Train_MaxReturn : 237.6822052001953\n",
            "Train_MinReturn : 71.26606750488281\n",
            "Train_AverageEpLen : 98.52380952380952\n",
            "Train_EnvstepsSoFar : 286108\n",
            "TimeSinceStart : 304.66808891296387\n",
            "Training Loss : -66.01640319824219\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 140 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 204.36209106445312\n",
            "Eval_StdReturn : 20.968704223632812\n",
            "Eval_MaxReturn : 226.3251190185547\n",
            "Eval_MinReturn : 167.1189422607422\n",
            "Eval_AverageEpLen : 91.8\n",
            "Train_AverageReturn : 211.2959442138672\n",
            "Train_StdReturn : 24.65048599243164\n",
            "Train_MaxReturn : 228.2682647705078\n",
            "Train_MinReturn : 108.80551147460938\n",
            "Train_AverageEpLen : 96.95238095238095\n",
            "Train_EnvstepsSoFar : 288144\n",
            "TimeSinceStart : 306.8561532497406\n",
            "Training Loss : -51.08390808105469\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 141 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 216.27197265625\n",
            "Eval_StdReturn : 4.566721439361572\n",
            "Eval_MaxReturn : 220.5646514892578\n",
            "Eval_MinReturn : 207.93310546875\n",
            "Eval_AverageEpLen : 96.4\n",
            "Train_AverageReturn : 217.66806030273438\n",
            "Train_StdReturn : 19.827733993530273\n",
            "Train_MaxReturn : 255.0922088623047\n",
            "Train_MinReturn : 143.30906677246094\n",
            "Train_AverageEpLen : 102.8\n",
            "Train_EnvstepsSoFar : 290200\n",
            "TimeSinceStart : 309.159143447876\n",
            "Training Loss : -20.12417984008789\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 142 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 219.7767791748047\n",
            "Eval_StdReturn : 7.15883207321167\n",
            "Eval_MaxReturn : 227.21060180664062\n",
            "Eval_MinReturn : 209.4060516357422\n",
            "Eval_AverageEpLen : 99.6\n",
            "Train_AverageReturn : 221.44808959960938\n",
            "Train_StdReturn : 8.359236717224121\n",
            "Train_MaxReturn : 239.56069946289062\n",
            "Train_MinReturn : 207.1346435546875\n",
            "Train_AverageEpLen : 102.75\n",
            "Train_EnvstepsSoFar : 292255\n",
            "TimeSinceStart : 311.4782564640045\n",
            "Training Loss : -31.212791442871094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 143 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 216.8290557861328\n",
            "Eval_StdReturn : 5.340940952301025\n",
            "Eval_MaxReturn : 221.5808563232422\n",
            "Eval_MinReturn : 207.76983642578125\n",
            "Eval_AverageEpLen : 102.25\n",
            "Train_AverageReturn : 216.1875762939453\n",
            "Train_StdReturn : 8.948657989501953\n",
            "Train_MaxReturn : 230.3994903564453\n",
            "Train_MinReturn : 197.96282958984375\n",
            "Train_AverageEpLen : 98.95238095238095\n",
            "Train_EnvstepsSoFar : 294333\n",
            "TimeSinceStart : 313.71246242523193\n",
            "Training Loss : 86.48783874511719\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 144 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.63380432128906\n",
            "Eval_StdReturn : 15.173291206359863\n",
            "Eval_MaxReturn : 249.224853515625\n",
            "Eval_MinReturn : 208.33863830566406\n",
            "Eval_AverageEpLen : 102.5\n",
            "Train_AverageReturn : 222.87905883789062\n",
            "Train_StdReturn : 12.103761672973633\n",
            "Train_MaxReturn : 257.3952331542969\n",
            "Train_MinReturn : 198.75103759765625\n",
            "Train_AverageEpLen : 104.45\n",
            "Train_EnvstepsSoFar : 296422\n",
            "TimeSinceStart : 315.94596672058105\n",
            "Training Loss : 27.144439697265625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 145 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 214.9561004638672\n",
            "Eval_StdReturn : 33.80518341064453\n",
            "Eval_MaxReturn : 245.02383422851562\n",
            "Eval_MinReturn : 150.7650909423828\n",
            "Eval_AverageEpLen : 102.8\n",
            "Train_AverageReturn : 220.56045532226562\n",
            "Train_StdReturn : 6.071222305297852\n",
            "Train_MaxReturn : 231.0855712890625\n",
            "Train_MinReturn : 202.4064483642578\n",
            "Train_AverageEpLen : 100.55\n",
            "Train_EnvstepsSoFar : 298433\n",
            "TimeSinceStart : 318.19174575805664\n",
            "Training Loss : 86.56909942626953\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 146 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 228.8449249267578\n",
            "Eval_StdReturn : 6.579433917999268\n",
            "Eval_MaxReturn : 238.7740478515625\n",
            "Eval_MinReturn : 222.6225128173828\n",
            "Eval_AverageEpLen : 108.0\n",
            "Train_AverageReturn : 222.2203826904297\n",
            "Train_StdReturn : 9.032286643981934\n",
            "Train_MaxReturn : 236.27041625976562\n",
            "Train_MinReturn : 196.59982299804688\n",
            "Train_AverageEpLen : 103.15\n",
            "Train_EnvstepsSoFar : 300496\n",
            "TimeSinceStart : 320.45153737068176\n",
            "Training Loss : 0.5365562438964844\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 147 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 218.3428497314453\n",
            "Eval_StdReturn : 10.595478057861328\n",
            "Eval_MaxReturn : 234.93931579589844\n",
            "Eval_MinReturn : 202.5689239501953\n",
            "Eval_AverageEpLen : 101.4\n",
            "Train_AverageReturn : 222.6745147705078\n",
            "Train_StdReturn : 15.353787422180176\n",
            "Train_MaxReturn : 262.1484375\n",
            "Train_MinReturn : 178.31814575195312\n",
            "Train_AverageEpLen : 102.2\n",
            "Train_EnvstepsSoFar : 302540\n",
            "TimeSinceStart : 322.7614231109619\n",
            "Training Loss : -96.71904754638672\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 148 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 220.18673706054688\n",
            "Eval_StdReturn : 9.79798412322998\n",
            "Eval_MaxReturn : 232.81727600097656\n",
            "Eval_MinReturn : 204.1160430908203\n",
            "Eval_AverageEpLen : 98.6\n",
            "Train_AverageReturn : 220.06216430664062\n",
            "Train_StdReturn : 8.783227920532227\n",
            "Train_MaxReturn : 239.95448303222656\n",
            "Train_MinReturn : 210.2254638671875\n",
            "Train_AverageEpLen : 100.15\n",
            "Train_EnvstepsSoFar : 304543\n",
            "TimeSinceStart : 324.9745571613312\n",
            "Training Loss : -47.41095733642578\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 149 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 222.90501403808594\n",
            "Eval_StdReturn : 8.45140266418457\n",
            "Eval_MaxReturn : 235.63916015625\n",
            "Eval_MinReturn : 212.4490966796875\n",
            "Eval_AverageEpLen : 101.25\n",
            "Train_AverageReturn : 219.8614959716797\n",
            "Train_StdReturn : 10.795629501342773\n",
            "Train_MaxReturn : 241.22608947753906\n",
            "Train_MinReturn : 201.22303771972656\n",
            "Train_AverageEpLen : 100.45\n",
            "Train_EnvstepsSoFar : 306552\n",
            "TimeSinceStart : 327.13989663124084\n",
            "Training Loss : -28.410507202148438\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 150 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 206.3857879638672\n",
            "Eval_StdReturn : 29.564598083496094\n",
            "Eval_MaxReturn : 223.48155212402344\n",
            "Eval_MinReturn : 147.3176727294922\n",
            "Eval_AverageEpLen : 95.6\n",
            "Train_AverageReturn : 221.7684326171875\n",
            "Train_StdReturn : 8.547995567321777\n",
            "Train_MaxReturn : 243.62623596191406\n",
            "Train_MinReturn : 206.15684509277344\n",
            "Train_AverageEpLen : 103.3\n",
            "Train_EnvstepsSoFar : 308618\n",
            "TimeSinceStart : 329.42726612091064\n",
            "Training Loss : 67.65472412109375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 151 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 227.2151336669922\n",
            "Eval_StdReturn : 16.108930587768555\n",
            "Eval_MaxReturn : 254.95809936523438\n",
            "Eval_MinReturn : 215.9529571533203\n",
            "Eval_AverageEpLen : 106.25\n",
            "Train_AverageReturn : 217.48619079589844\n",
            "Train_StdReturn : 9.493517875671387\n",
            "Train_MaxReturn : 232.9095916748047\n",
            "Train_MinReturn : 194.7255401611328\n",
            "Train_AverageEpLen : 99.0\n",
            "Train_EnvstepsSoFar : 310697\n",
            "TimeSinceStart : 331.65629839897156\n",
            "Training Loss : -8.584867477416992\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 152 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 230.21937561035156\n",
            "Eval_StdReturn : 14.47533130645752\n",
            "Eval_MaxReturn : 253.3121337890625\n",
            "Eval_MinReturn : 213.328125\n",
            "Eval_AverageEpLen : 108.5\n",
            "Train_AverageReturn : 212.8147735595703\n",
            "Train_StdReturn : 27.4633731842041\n",
            "Train_MaxReturn : 247.65480041503906\n",
            "Train_MinReturn : 121.18787384033203\n",
            "Train_AverageEpLen : 101.3\n",
            "Train_EnvstepsSoFar : 312723\n",
            "TimeSinceStart : 333.8450536727905\n",
            "Training Loss : -41.79683303833008\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 153 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.98495483398438\n",
            "Eval_StdReturn : 5.684786796569824\n",
            "Eval_MaxReturn : 232.5018310546875\n",
            "Eval_MinReturn : 216.5425567626953\n",
            "Eval_AverageEpLen : 104.25\n",
            "Train_AverageReturn : 215.1109619140625\n",
            "Train_StdReturn : 22.5251522064209\n",
            "Train_MaxReturn : 246.95938110351562\n",
            "Train_MinReturn : 131.8135986328125\n",
            "Train_AverageEpLen : 100.45\n",
            "Train_EnvstepsSoFar : 314732\n",
            "TimeSinceStart : 336.00344014167786\n",
            "Training Loss : -11.95065689086914\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 154 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 217.412841796875\n",
            "Eval_StdReturn : 8.62376594543457\n",
            "Eval_MaxReturn : 227.501953125\n",
            "Eval_MinReturn : 203.62307739257812\n",
            "Eval_AverageEpLen : 97.8\n",
            "Train_AverageReturn : 217.1377716064453\n",
            "Train_StdReturn : 9.330995559692383\n",
            "Train_MaxReturn : 231.78781127929688\n",
            "Train_MinReturn : 196.12680053710938\n",
            "Train_AverageEpLen : 99.57142857142857\n",
            "Train_EnvstepsSoFar : 316823\n",
            "TimeSinceStart : 338.26491022109985\n",
            "Training Loss : -109.02672576904297\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 155 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 217.08831787109375\n",
            "Eval_StdReturn : 14.179316520690918\n",
            "Eval_MaxReturn : 230.33689880371094\n",
            "Eval_MinReturn : 193.83721923828125\n",
            "Eval_AverageEpLen : 101.0\n",
            "Train_AverageReturn : 221.8477020263672\n",
            "Train_StdReturn : 11.091560363769531\n",
            "Train_MaxReturn : 245.00302124023438\n",
            "Train_MinReturn : 193.91351318359375\n",
            "Train_AverageEpLen : 104.15\n",
            "Train_EnvstepsSoFar : 318906\n",
            "TimeSinceStart : 340.4902787208557\n",
            "Training Loss : -36.41009521484375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 156 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 221.77188110351562\n",
            "Eval_StdReturn : 3.972513437271118\n",
            "Eval_MaxReturn : 227.25741577148438\n",
            "Eval_MinReturn : 216.33863830566406\n",
            "Eval_AverageEpLen : 102.75\n",
            "Train_AverageReturn : 221.6387176513672\n",
            "Train_StdReturn : 13.877228736877441\n",
            "Train_MaxReturn : 262.7098388671875\n",
            "Train_MinReturn : 193.1363067626953\n",
            "Train_AverageEpLen : 102.85\n",
            "Train_EnvstepsSoFar : 320963\n",
            "TimeSinceStart : 342.70256209373474\n",
            "Training Loss : -10.964977264404297\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 157 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 216.62368774414062\n",
            "Eval_StdReturn : 6.028322219848633\n",
            "Eval_MaxReturn : 227.56626892089844\n",
            "Eval_MinReturn : 210.72735595703125\n",
            "Eval_AverageEpLen : 98.0\n",
            "Train_AverageReturn : 217.17031860351562\n",
            "Train_StdReturn : 12.466041564941406\n",
            "Train_MaxReturn : 239.62124633789062\n",
            "Train_MinReturn : 183.5565643310547\n",
            "Train_AverageEpLen : 98.66666666666667\n",
            "Train_EnvstepsSoFar : 323035\n",
            "TimeSinceStart : 344.97492957115173\n",
            "Training Loss : 83.93362426757812\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 158 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 209.3392791748047\n",
            "Eval_StdReturn : 8.329288482666016\n",
            "Eval_MaxReturn : 220.97299194335938\n",
            "Eval_MinReturn : 201.22039794921875\n",
            "Eval_AverageEpLen : 95.4\n",
            "Train_AverageReturn : 221.04696655273438\n",
            "Train_StdReturn : 10.567723274230957\n",
            "Train_MaxReturn : 248.6808319091797\n",
            "Train_MinReturn : 205.42840576171875\n",
            "Train_AverageEpLen : 102.75\n",
            "Train_EnvstepsSoFar : 325090\n",
            "TimeSinceStart : 347.23230600357056\n",
            "Training Loss : 71.69525146484375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 159 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 217.53414916992188\n",
            "Eval_StdReturn : 5.339870929718018\n",
            "Eval_MaxReturn : 222.8674774169922\n",
            "Eval_MinReturn : 208.86605834960938\n",
            "Eval_AverageEpLen : 100.5\n",
            "Train_AverageReturn : 217.904296875\n",
            "Train_StdReturn : 16.607383728027344\n",
            "Train_MaxReturn : 239.74496459960938\n",
            "Train_MinReturn : 160.15113830566406\n",
            "Train_AverageEpLen : 100.15\n",
            "Train_EnvstepsSoFar : 327093\n",
            "TimeSinceStart : 349.3595426082611\n",
            "Training Loss : -142.04949951171875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 160 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 228.2135009765625\n",
            "Eval_StdReturn : 10.937040328979492\n",
            "Eval_MaxReturn : 246.24099731445312\n",
            "Eval_MinReturn : 216.7518310546875\n",
            "Eval_AverageEpLen : 107.75\n",
            "Train_AverageReturn : 217.3887481689453\n",
            "Train_StdReturn : 21.731210708618164\n",
            "Train_MaxReturn : 246.2624053955078\n",
            "Train_MinReturn : 146.5423583984375\n",
            "Train_AverageEpLen : 101.95\n",
            "Train_EnvstepsSoFar : 329132\n",
            "TimeSinceStart : 351.54290771484375\n",
            "Training Loss : -19.54048728942871\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 161 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 218.06231689453125\n",
            "Eval_StdReturn : 9.530362129211426\n",
            "Eval_MaxReturn : 232.6228790283203\n",
            "Eval_MinReturn : 206.00567626953125\n",
            "Eval_AverageEpLen : 101.0\n",
            "Train_AverageReturn : 224.984375\n",
            "Train_StdReturn : 14.91049575805664\n",
            "Train_MaxReturn : 259.8660583496094\n",
            "Train_MinReturn : 206.55245971679688\n",
            "Train_AverageEpLen : 104.85\n",
            "Train_EnvstepsSoFar : 331229\n",
            "TimeSinceStart : 353.8003315925598\n",
            "Training Loss : -88.57160186767578\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 162 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.6903076171875\n",
            "Eval_StdReturn : 14.208747863769531\n",
            "Eval_MaxReturn : 245.88641357421875\n",
            "Eval_MinReturn : 207.20785522460938\n",
            "Eval_AverageEpLen : 105.75\n",
            "Train_AverageReturn : 217.13986206054688\n",
            "Train_StdReturn : 6.282845497131348\n",
            "Train_MaxReturn : 226.3585205078125\n",
            "Train_MinReturn : 204.3644256591797\n",
            "Train_AverageEpLen : 98.19047619047619\n",
            "Train_EnvstepsSoFar : 333291\n",
            "TimeSinceStart : 355.9820291996002\n",
            "Training Loss : 32.40386962890625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 163 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.1516876220703\n",
            "Eval_StdReturn : 12.692878723144531\n",
            "Eval_MaxReturn : 249.90701293945312\n",
            "Eval_MinReturn : 216.39161682128906\n",
            "Eval_AverageEpLen : 105.6\n",
            "Train_AverageReturn : 215.25892639160156\n",
            "Train_StdReturn : 13.542688369750977\n",
            "Train_MaxReturn : 228.7808380126953\n",
            "Train_MinReturn : 164.1062774658203\n",
            "Train_AverageEpLen : 97.71428571428571\n",
            "Train_EnvstepsSoFar : 335343\n",
            "TimeSinceStart : 358.22854113578796\n",
            "Training Loss : -130.4293670654297\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 164 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.3018341064453\n",
            "Eval_StdReturn : 11.850264549255371\n",
            "Eval_MaxReturn : 235.94117736816406\n",
            "Eval_MinReturn : 205.2384796142578\n",
            "Eval_AverageEpLen : 104.25\n",
            "Train_AverageReturn : 222.61569213867188\n",
            "Train_StdReturn : 8.689127922058105\n",
            "Train_MaxReturn : 245.28883361816406\n",
            "Train_MinReturn : 210.16697692871094\n",
            "Train_AverageEpLen : 101.85\n",
            "Train_EnvstepsSoFar : 337380\n",
            "TimeSinceStart : 360.40845131874084\n",
            "Training Loss : -50.97351837158203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 165 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 205.0104522705078\n",
            "Eval_StdReturn : 7.919824600219727\n",
            "Eval_MaxReturn : 217.4619903564453\n",
            "Eval_MinReturn : 197.30245971679688\n",
            "Eval_AverageEpLen : 92.4\n",
            "Train_AverageReturn : 220.7296600341797\n",
            "Train_StdReturn : 8.064330101013184\n",
            "Train_MaxReturn : 232.25326538085938\n",
            "Train_MinReturn : 204.143798828125\n",
            "Train_AverageEpLen : 100.85\n",
            "Train_EnvstepsSoFar : 339397\n",
            "TimeSinceStart : 362.59822368621826\n",
            "Training Loss : -8.538562774658203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 166 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 212.48330688476562\n",
            "Eval_StdReturn : 15.972764015197754\n",
            "Eval_MaxReturn : 224.77713012695312\n",
            "Eval_MinReturn : 181.43495178222656\n",
            "Eval_AverageEpLen : 96.0\n",
            "Train_AverageReturn : 222.2249755859375\n",
            "Train_StdReturn : 9.227962493896484\n",
            "Train_MaxReturn : 241.6366729736328\n",
            "Train_MinReturn : 205.0860137939453\n",
            "Train_AverageEpLen : 103.1\n",
            "Train_EnvstepsSoFar : 341459\n",
            "TimeSinceStart : 364.8373153209686\n",
            "Training Loss : 11.449188232421875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 167 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.30490112304688\n",
            "Eval_StdReturn : 3.810882091522217\n",
            "Eval_MaxReturn : 229.80810546875\n",
            "Eval_MinReturn : 220.48036193847656\n",
            "Eval_AverageEpLen : 105.25\n",
            "Train_AverageReturn : 221.2139892578125\n",
            "Train_StdReturn : 9.2987642288208\n",
            "Train_MaxReturn : 240.91839599609375\n",
            "Train_MinReturn : 205.8234100341797\n",
            "Train_AverageEpLen : 100.5\n",
            "Train_EnvstepsSoFar : 343469\n",
            "TimeSinceStart : 366.9881269931793\n",
            "Training Loss : -17.347110748291016\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 168 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 216.00949096679688\n",
            "Eval_StdReturn : 6.617063522338867\n",
            "Eval_MaxReturn : 223.7233123779297\n",
            "Eval_MinReturn : 207.5216827392578\n",
            "Eval_AverageEpLen : 98.0\n",
            "Train_AverageReturn : 217.3468780517578\n",
            "Train_StdReturn : 31.529293060302734\n",
            "Train_MaxReturn : 257.2004699707031\n",
            "Train_MinReturn : 124.60810852050781\n",
            "Train_AverageEpLen : 102.05\n",
            "Train_EnvstepsSoFar : 345510\n",
            "TimeSinceStart : 369.3076660633087\n",
            "Training Loss : -178.77931213378906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 169 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.25466918945312\n",
            "Eval_StdReturn : 8.879597663879395\n",
            "Eval_MaxReturn : 246.48997497558594\n",
            "Eval_MinReturn : 222.6874237060547\n",
            "Eval_AverageEpLen : 111.25\n",
            "Train_AverageReturn : 223.1595916748047\n",
            "Train_StdReturn : 10.839577674865723\n",
            "Train_MaxReturn : 244.29617309570312\n",
            "Train_MinReturn : 198.5989990234375\n",
            "Train_AverageEpLen : 101.25\n",
            "Train_EnvstepsSoFar : 347535\n",
            "TimeSinceStart : 371.4940915107727\n",
            "Training Loss : -14.23794174194336\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 170 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 218.67950439453125\n",
            "Eval_StdReturn : 8.590356826782227\n",
            "Eval_MaxReturn : 227.29141235351562\n",
            "Eval_MinReturn : 206.04747009277344\n",
            "Eval_AverageEpLen : 101.25\n",
            "Train_AverageReturn : 223.546142578125\n",
            "Train_StdReturn : 13.836481094360352\n",
            "Train_MaxReturn : 245.68336486816406\n",
            "Train_MinReturn : 174.90179443359375\n",
            "Train_AverageEpLen : 103.5\n",
            "Train_EnvstepsSoFar : 349605\n",
            "TimeSinceStart : 373.73517537117004\n",
            "Training Loss : -31.705198287963867\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 171 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 219.7858428955078\n",
            "Eval_StdReturn : 8.720232963562012\n",
            "Eval_MaxReturn : 229.54852294921875\n",
            "Eval_MinReturn : 205.43377685546875\n",
            "Eval_AverageEpLen : 98.4\n",
            "Train_AverageReturn : 225.57046508789062\n",
            "Train_StdReturn : 19.266271591186523\n",
            "Train_MaxReturn : 279.2663269042969\n",
            "Train_MinReturn : 200.87049865722656\n",
            "Train_AverageEpLen : 106.8\n",
            "Train_EnvstepsSoFar : 351741\n",
            "TimeSinceStart : 376.0630645751953\n",
            "Training Loss : 56.09868240356445\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 172 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 222.63255310058594\n",
            "Eval_StdReturn : 4.403542518615723\n",
            "Eval_MaxReturn : 226.5647735595703\n",
            "Eval_MinReturn : 215.6031951904297\n",
            "Eval_AverageEpLen : 100.0\n",
            "Train_AverageReturn : 220.6683349609375\n",
            "Train_StdReturn : 8.614397048950195\n",
            "Train_MaxReturn : 232.21273803710938\n",
            "Train_MinReturn : 193.73046875\n",
            "Train_AverageEpLen : 102.8\n",
            "Train_EnvstepsSoFar : 353797\n",
            "TimeSinceStart : 378.2208914756775\n",
            "Training Loss : -17.334341049194336\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 173 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 190.5699462890625\n",
            "Eval_StdReturn : 51.959190368652344\n",
            "Eval_MaxReturn : 226.75180053710938\n",
            "Eval_MinReturn : 87.73040771484375\n",
            "Eval_AverageEpLen : 89.6\n",
            "Train_AverageReturn : 219.48779296875\n",
            "Train_StdReturn : 17.5125675201416\n",
            "Train_MaxReturn : 235.77410888671875\n",
            "Train_MinReturn : 149.25881958007812\n",
            "Train_AverageEpLen : 101.1\n",
            "Train_EnvstepsSoFar : 355819\n",
            "TimeSinceStart : 380.41774320602417\n",
            "Training Loss : 53.93743896484375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 174 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 213.56375122070312\n",
            "Eval_StdReturn : 31.258777618408203\n",
            "Eval_MaxReturn : 237.82408142089844\n",
            "Eval_MinReturn : 153.58526611328125\n",
            "Eval_AverageEpLen : 100.8\n",
            "Train_AverageReturn : 220.24281311035156\n",
            "Train_StdReturn : 8.991083145141602\n",
            "Train_MaxReturn : 232.49566650390625\n",
            "Train_MinReturn : 196.8623809814453\n",
            "Train_AverageEpLen : 99.23809523809524\n",
            "Train_EnvstepsSoFar : 357903\n",
            "TimeSinceStart : 382.82625007629395\n",
            "Training Loss : -24.00387954711914\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 175 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 222.92681884765625\n",
            "Eval_StdReturn : 8.49657154083252\n",
            "Eval_MaxReturn : 231.36355590820312\n",
            "Eval_MinReturn : 210.87728881835938\n",
            "Eval_AverageEpLen : 103.25\n",
            "Train_AverageReturn : 223.1841583251953\n",
            "Train_StdReturn : 8.058971405029297\n",
            "Train_MaxReturn : 240.92352294921875\n",
            "Train_MinReturn : 210.47744750976562\n",
            "Train_AverageEpLen : 103.0\n",
            "Train_EnvstepsSoFar : 359963\n",
            "TimeSinceStart : 385.0346128940582\n",
            "Training Loss : -81.74193572998047\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 176 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 216.9258270263672\n",
            "Eval_StdReturn : 15.891172409057617\n",
            "Eval_MaxReturn : 231.749755859375\n",
            "Eval_MinReturn : 187.6376495361328\n",
            "Eval_AverageEpLen : 99.2\n",
            "Train_AverageReturn : 217.5865478515625\n",
            "Train_StdReturn : 14.912802696228027\n",
            "Train_MaxReturn : 239.61688232421875\n",
            "Train_MinReturn : 164.4062042236328\n",
            "Train_AverageEpLen : 99.42857142857143\n",
            "Train_EnvstepsSoFar : 362051\n",
            "TimeSinceStart : 387.3163962364197\n",
            "Training Loss : -20.1622257232666\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 177 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.31600952148438\n",
            "Eval_StdReturn : 6.457918167114258\n",
            "Eval_MaxReturn : 232.78347778320312\n",
            "Eval_MinReturn : 215.00765991210938\n",
            "Eval_AverageEpLen : 100.5\n",
            "Train_AverageReturn : 221.189697265625\n",
            "Train_StdReturn : 8.765584945678711\n",
            "Train_MaxReturn : 240.40823364257812\n",
            "Train_MinReturn : 196.97116088867188\n",
            "Train_AverageEpLen : 100.15\n",
            "Train_EnvstepsSoFar : 364054\n",
            "TimeSinceStart : 389.52319502830505\n",
            "Training Loss : -27.124284744262695\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 178 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 229.04531860351562\n",
            "Eval_StdReturn : 13.957747459411621\n",
            "Eval_MaxReturn : 252.79501342773438\n",
            "Eval_MinReturn : 217.8370361328125\n",
            "Eval_AverageEpLen : 107.25\n",
            "Train_AverageReturn : 221.81063842773438\n",
            "Train_StdReturn : 11.905400276184082\n",
            "Train_MaxReturn : 247.043212890625\n",
            "Train_MinReturn : 203.778564453125\n",
            "Train_AverageEpLen : 101.9\n",
            "Train_EnvstepsSoFar : 366092\n",
            "TimeSinceStart : 391.73037910461426\n",
            "Training Loss : 17.452049255371094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 179 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 222.9468994140625\n",
            "Eval_StdReturn : 3.893982410430908\n",
            "Eval_MaxReturn : 227.44168090820312\n",
            "Eval_MinReturn : 216.03941345214844\n",
            "Eval_AverageEpLen : 100.6\n",
            "Train_AverageReturn : 212.0374755859375\n",
            "Train_StdReturn : 22.74241828918457\n",
            "Train_MaxReturn : 232.28993225097656\n",
            "Train_MinReturn : 141.55479431152344\n",
            "Train_AverageEpLen : 97.47619047619048\n",
            "Train_EnvstepsSoFar : 368139\n",
            "TimeSinceStart : 393.99041414260864\n",
            "Training Loss : -70.373779296875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 180 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 236.68197631835938\n",
            "Eval_StdReturn : 14.76144027709961\n",
            "Eval_MaxReturn : 250.6364288330078\n",
            "Eval_MinReturn : 214.19561767578125\n",
            "Eval_AverageEpLen : 110.75\n",
            "Train_AverageReturn : 228.39157104492188\n",
            "Train_StdReturn : 10.293763160705566\n",
            "Train_MaxReturn : 249.9093017578125\n",
            "Train_MinReturn : 210.57933044433594\n",
            "Train_AverageEpLen : 107.26315789473684\n",
            "Train_EnvstepsSoFar : 370177\n",
            "TimeSinceStart : 396.20421266555786\n",
            "Training Loss : -46.82936096191406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 181 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.72532653808594\n",
            "Eval_StdReturn : 12.630081176757812\n",
            "Eval_MaxReturn : 252.35105895996094\n",
            "Eval_MinReturn : 217.09767150878906\n",
            "Eval_AverageEpLen : 110.5\n",
            "Train_AverageReturn : 224.15615844726562\n",
            "Train_StdReturn : 16.653560638427734\n",
            "Train_MaxReturn : 264.1813049316406\n",
            "Train_MinReturn : 187.21127319335938\n",
            "Train_AverageEpLen : 102.85\n",
            "Train_EnvstepsSoFar : 372234\n",
            "TimeSinceStart : 398.4139904975891\n",
            "Training Loss : -156.07217407226562\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 182 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 233.0594482421875\n",
            "Eval_StdReturn : 5.921343803405762\n",
            "Eval_MaxReturn : 240.28001403808594\n",
            "Eval_MinReturn : 224.12278747558594\n",
            "Eval_AverageEpLen : 106.5\n",
            "Train_AverageReturn : 226.38064575195312\n",
            "Train_StdReturn : 10.46855354309082\n",
            "Train_MaxReturn : 251.14048767089844\n",
            "Train_MinReturn : 210.81602478027344\n",
            "Train_AverageEpLen : 104.65\n",
            "Train_EnvstepsSoFar : 374327\n",
            "TimeSinceStart : 400.66883611679077\n",
            "Training Loss : 12.345212936401367\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 183 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 222.72222900390625\n",
            "Eval_StdReturn : 14.447701454162598\n",
            "Eval_MaxReturn : 244.38955688476562\n",
            "Eval_MinReturn : 203.7417755126953\n",
            "Eval_AverageEpLen : 102.75\n",
            "Train_AverageReturn : 229.27171325683594\n",
            "Train_StdReturn : 12.554259300231934\n",
            "Train_MaxReturn : 258.2156982421875\n",
            "Train_MinReturn : 207.77276611328125\n",
            "Train_AverageEpLen : 106.3157894736842\n",
            "Train_EnvstepsSoFar : 376347\n",
            "TimeSinceStart : 402.8313581943512\n",
            "Training Loss : 26.472251892089844\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 184 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.7967071533203\n",
            "Eval_StdReturn : 24.677413940429688\n",
            "Eval_MaxReturn : 265.9330749511719\n",
            "Eval_MinReturn : 198.61241149902344\n",
            "Eval_AverageEpLen : 110.5\n",
            "Train_AverageReturn : 222.0056610107422\n",
            "Train_StdReturn : 17.131084442138672\n",
            "Train_MaxReturn : 259.02728271484375\n",
            "Train_MinReturn : 177.77439880371094\n",
            "Train_AverageEpLen : 102.15\n",
            "Train_EnvstepsSoFar : 378390\n",
            "TimeSinceStart : 405.0739393234253\n",
            "Training Loss : 13.227838516235352\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 185 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 216.45169067382812\n",
            "Eval_StdReturn : 22.552114486694336\n",
            "Eval_MaxReturn : 244.1371612548828\n",
            "Eval_MinReturn : 175.8660125732422\n",
            "Eval_AverageEpLen : 99.8\n",
            "Train_AverageReturn : 226.81015014648438\n",
            "Train_StdReturn : 11.161978721618652\n",
            "Train_MaxReturn : 258.54541015625\n",
            "Train_MinReturn : 210.0760955810547\n",
            "Train_AverageEpLen : 104.9\n",
            "Train_EnvstepsSoFar : 380488\n",
            "TimeSinceStart : 407.40643548965454\n",
            "Training Loss : -28.883377075195312\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 186 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 219.69467163085938\n",
            "Eval_StdReturn : 8.72115421295166\n",
            "Eval_MaxReturn : 230.76296997070312\n",
            "Eval_MinReturn : 208.37051391601562\n",
            "Eval_AverageEpLen : 101.0\n",
            "Train_AverageReturn : 222.66433715820312\n",
            "Train_StdReturn : 14.73657512664795\n",
            "Train_MaxReturn : 248.4338836669922\n",
            "Train_MinReturn : 174.14585876464844\n",
            "Train_AverageEpLen : 102.45\n",
            "Train_EnvstepsSoFar : 382537\n",
            "TimeSinceStart : 409.65684604644775\n",
            "Training Loss : -17.142589569091797\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 187 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.9896240234375\n",
            "Eval_StdReturn : 3.6548783779144287\n",
            "Eval_MaxReturn : 230.11534118652344\n",
            "Eval_MinReturn : 221.6903533935547\n",
            "Eval_AverageEpLen : 103.75\n",
            "Train_AverageReturn : 227.17405700683594\n",
            "Train_StdReturn : 15.925335884094238\n",
            "Train_MaxReturn : 261.1247863769531\n",
            "Train_MinReturn : 185.23565673828125\n",
            "Train_AverageEpLen : 105.42105263157895\n",
            "Train_EnvstepsSoFar : 384540\n",
            "TimeSinceStart : 411.83259320259094\n",
            "Training Loss : -154.20651245117188\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 188 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 226.78158569335938\n",
            "Eval_StdReturn : 5.580252170562744\n",
            "Eval_MaxReturn : 235.04434204101562\n",
            "Eval_MinReturn : 221.2091522216797\n",
            "Eval_AverageEpLen : 103.0\n",
            "Train_AverageReturn : 228.58653259277344\n",
            "Train_StdReturn : 11.085649490356445\n",
            "Train_MaxReturn : 255.52015686035156\n",
            "Train_MinReturn : 209.2267303466797\n",
            "Train_AverageEpLen : 105.47368421052632\n",
            "Train_EnvstepsSoFar : 386544\n",
            "TimeSinceStart : 414.05996441841125\n",
            "Training Loss : 64.5880355834961\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 189 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.875244140625\n",
            "Eval_StdReturn : 10.227227210998535\n",
            "Eval_MaxReturn : 248.97186279296875\n",
            "Eval_MinReturn : 220.55128479003906\n",
            "Eval_AverageEpLen : 112.0\n",
            "Train_AverageReturn : 225.32821655273438\n",
            "Train_StdReturn : 15.572935104370117\n",
            "Train_MaxReturn : 249.1344757080078\n",
            "Train_MinReturn : 171.93467712402344\n",
            "Train_AverageEpLen : 103.3\n",
            "Train_EnvstepsSoFar : 388610\n",
            "TimeSinceStart : 416.37573313713074\n",
            "Training Loss : 53.72578811645508\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 190 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 244.03140258789062\n",
            "Eval_StdReturn : 20.153886795043945\n",
            "Eval_MaxReturn : 271.6133728027344\n",
            "Eval_MinReturn : 222.97763061523438\n",
            "Eval_AverageEpLen : 119.25\n",
            "Train_AverageReturn : 226.91046142578125\n",
            "Train_StdReturn : 26.110319137573242\n",
            "Train_MaxReturn : 257.61279296875\n",
            "Train_MinReturn : 126.68851470947266\n",
            "Train_AverageEpLen : 106.10526315789474\n",
            "Train_EnvstepsSoFar : 390626\n",
            "TimeSinceStart : 418.684033870697\n",
            "Training Loss : 11.102486610412598\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 191 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 223.0081787109375\n",
            "Eval_StdReturn : 9.05601978302002\n",
            "Eval_MaxReturn : 232.99951171875\n",
            "Eval_MinReturn : 210.16348266601562\n",
            "Eval_AverageEpLen : 100.5\n",
            "Train_AverageReturn : 225.99722290039062\n",
            "Train_StdReturn : 12.560792922973633\n",
            "Train_MaxReturn : 245.85733032226562\n",
            "Train_MinReturn : 182.4853515625\n",
            "Train_AverageEpLen : 104.2\n",
            "Train_EnvstepsSoFar : 392710\n",
            "TimeSinceStart : 421.01891016960144\n",
            "Training Loss : 7.734491348266602\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 192 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.34959411621094\n",
            "Eval_StdReturn : 12.104982376098633\n",
            "Eval_MaxReturn : 247.43310546875\n",
            "Eval_MinReturn : 220.7212677001953\n",
            "Eval_AverageEpLen : 116.75\n",
            "Train_AverageReturn : 230.27798461914062\n",
            "Train_StdReturn : 13.33041000366211\n",
            "Train_MaxReturn : 263.9405517578125\n",
            "Train_MinReturn : 207.22647094726562\n",
            "Train_AverageEpLen : 107.57894736842105\n",
            "Train_EnvstepsSoFar : 394754\n",
            "TimeSinceStart : 423.3855848312378\n",
            "Training Loss : -97.91468811035156\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 193 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 239.89161682128906\n",
            "Eval_StdReturn : 16.204408645629883\n",
            "Eval_MaxReturn : 264.83392333984375\n",
            "Eval_MinReturn : 224.3557891845703\n",
            "Eval_AverageEpLen : 117.75\n",
            "Train_AverageReturn : 228.94287109375\n",
            "Train_StdReturn : 24.819976806640625\n",
            "Train_MaxReturn : 256.9892578125\n",
            "Train_MinReturn : 132.1097412109375\n",
            "Train_AverageEpLen : 110.15789473684211\n",
            "Train_EnvstepsSoFar : 396847\n",
            "TimeSinceStart : 425.76956391334534\n",
            "Training Loss : -98.26487731933594\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 194 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 221.7104949951172\n",
            "Eval_StdReturn : 6.144206523895264\n",
            "Eval_MaxReturn : 229.86611938476562\n",
            "Eval_MinReturn : 214.00787353515625\n",
            "Eval_AverageEpLen : 100.75\n",
            "Train_AverageReturn : 237.15066528320312\n",
            "Train_StdReturn : 15.544608116149902\n",
            "Train_MaxReturn : 268.88555908203125\n",
            "Train_MinReturn : 216.50204467773438\n",
            "Train_AverageEpLen : 113.88888888888889\n",
            "Train_EnvstepsSoFar : 398897\n",
            "TimeSinceStart : 428.0999879837036\n",
            "Training Loss : 50.09217834472656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 195 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 216.1848602294922\n",
            "Eval_StdReturn : 11.666949272155762\n",
            "Eval_MaxReturn : 230.35667419433594\n",
            "Eval_MinReturn : 199.5821990966797\n",
            "Eval_AverageEpLen : 101.25\n",
            "Train_AverageReturn : 233.93389892578125\n",
            "Train_StdReturn : 14.146934509277344\n",
            "Train_MaxReturn : 260.296142578125\n",
            "Train_MinReturn : 212.53627014160156\n",
            "Train_AverageEpLen : 111.22222222222223\n",
            "Train_EnvstepsSoFar : 400899\n",
            "TimeSinceStart : 430.36904883384705\n",
            "Training Loss : 12.459651947021484\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 196 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 229.4235076904297\n",
            "Eval_StdReturn : 6.865018367767334\n",
            "Eval_MaxReturn : 235.17042541503906\n",
            "Eval_MinReturn : 218.329345703125\n",
            "Eval_AverageEpLen : 104.25\n",
            "Train_AverageReturn : 234.26370239257812\n",
            "Train_StdReturn : 15.351966857910156\n",
            "Train_MaxReturn : 256.91632080078125\n",
            "Train_MinReturn : 188.2030029296875\n",
            "Train_AverageEpLen : 112.11111111111111\n",
            "Train_EnvstepsSoFar : 402917\n",
            "TimeSinceStart : 432.65853571891785\n",
            "Training Loss : -96.95366668701172\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 197 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 253.52056884765625\n",
            "Eval_StdReturn : 18.83162498474121\n",
            "Eval_MaxReturn : 280.8074035644531\n",
            "Eval_MinReturn : 235.61000061035156\n",
            "Eval_AverageEpLen : 127.5\n",
            "Train_AverageReturn : 229.0003662109375\n",
            "Train_StdReturn : 13.275888442993164\n",
            "Train_MaxReturn : 259.5456237792969\n",
            "Train_MinReturn : 206.2187042236328\n",
            "Train_AverageEpLen : 106.47368421052632\n",
            "Train_EnvstepsSoFar : 404940\n",
            "TimeSinceStart : 435.00220489501953\n",
            "Training Loss : -49.621002197265625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 198 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 229.21359252929688\n",
            "Eval_StdReturn : 13.16666030883789\n",
            "Eval_MaxReturn : 244.41619873046875\n",
            "Eval_MinReturn : 208.5009002685547\n",
            "Eval_AverageEpLen : 105.5\n",
            "Train_AverageReturn : 226.73329162597656\n",
            "Train_StdReturn : 33.08057403564453\n",
            "Train_MaxReturn : 281.0763244628906\n",
            "Train_MinReturn : 114.13617706298828\n",
            "Train_AverageEpLen : 108.36842105263158\n",
            "Train_EnvstepsSoFar : 406999\n",
            "TimeSinceStart : 437.29653334617615\n",
            "Training Loss : -8.309700012207031\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 199 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 223.3549041748047\n",
            "Eval_StdReturn : 15.531401634216309\n",
            "Eval_MaxReturn : 241.69235229492188\n",
            "Eval_MinReturn : 200.9761199951172\n",
            "Eval_AverageEpLen : 106.0\n",
            "Train_AverageReturn : 231.8936309814453\n",
            "Train_StdReturn : 18.086877822875977\n",
            "Train_MaxReturn : 262.1279296875\n",
            "Train_MinReturn : 174.66949462890625\n",
            "Train_AverageEpLen : 109.57894736842105\n",
            "Train_EnvstepsSoFar : 409081\n",
            "TimeSinceStart : 439.61831283569336\n",
            "Training Loss : -52.25075149536133\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 200 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 223.04031372070312\n",
            "Eval_StdReturn : 11.356217384338379\n",
            "Eval_MaxReturn : 243.4070281982422\n",
            "Eval_MinReturn : 212.21011352539062\n",
            "Eval_AverageEpLen : 104.2\n",
            "Train_AverageReturn : 228.9443359375\n",
            "Train_StdReturn : 7.466824054718018\n",
            "Train_MaxReturn : 249.12400817871094\n",
            "Train_MinReturn : 216.23622131347656\n",
            "Train_AverageEpLen : 104.4\n",
            "Train_EnvstepsSoFar : 411169\n",
            "TimeSinceStart : 442.0097486972809\n",
            "Training Loss : -48.28839874267578\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 201 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 213.3342742919922\n",
            "Eval_StdReturn : 47.708431243896484\n",
            "Eval_MaxReturn : 255.2938232421875\n",
            "Eval_MinReturn : 135.6387481689453\n",
            "Eval_AverageEpLen : 103.25\n",
            "Train_AverageReturn : 237.46530151367188\n",
            "Train_StdReturn : 12.693350791931152\n",
            "Train_MaxReturn : 265.4990234375\n",
            "Train_MinReturn : 220.43731689453125\n",
            "Train_AverageEpLen : 115.66666666666667\n",
            "Train_EnvstepsSoFar : 413251\n",
            "TimeSinceStart : 444.34620237350464\n",
            "Training Loss : 61.35237503051758\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 202 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 228.26168823242188\n",
            "Eval_StdReturn : 10.779906272888184\n",
            "Eval_MaxReturn : 246.14988708496094\n",
            "Eval_MinReturn : 217.45106506347656\n",
            "Eval_AverageEpLen : 107.5\n",
            "Train_AverageReturn : 231.1312255859375\n",
            "Train_StdReturn : 10.073512077331543\n",
            "Train_MaxReturn : 250.506103515625\n",
            "Train_MinReturn : 212.9680633544922\n",
            "Train_AverageEpLen : 108.3157894736842\n",
            "Train_EnvstepsSoFar : 415309\n",
            "TimeSinceStart : 446.6119155883789\n",
            "Training Loss : 109.5241928100586\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 203 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 223.1791229248047\n",
            "Eval_StdReturn : 11.205902099609375\n",
            "Eval_MaxReturn : 237.0848846435547\n",
            "Eval_MinReturn : 205.86663818359375\n",
            "Eval_AverageEpLen : 106.75\n",
            "Train_AverageReturn : 225.3191375732422\n",
            "Train_StdReturn : 35.544010162353516\n",
            "Train_MaxReturn : 268.591064453125\n",
            "Train_MinReturn : 95.28074645996094\n",
            "Train_AverageEpLen : 108.21052631578948\n",
            "Train_EnvstepsSoFar : 417365\n",
            "TimeSinceStart : 448.8734016418457\n",
            "Training Loss : -28.38210678100586\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 204 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 230.00440979003906\n",
            "Eval_StdReturn : 12.0172758102417\n",
            "Eval_MaxReturn : 246.99485778808594\n",
            "Eval_MinReturn : 213.55538940429688\n",
            "Eval_AverageEpLen : 105.75\n",
            "Train_AverageReturn : 226.45838928222656\n",
            "Train_StdReturn : 38.58060836791992\n",
            "Train_MaxReturn : 286.7165222167969\n",
            "Train_MinReturn : 109.28540802001953\n",
            "Train_AverageEpLen : 110.94736842105263\n",
            "Train_EnvstepsSoFar : 419473\n",
            "TimeSinceStart : 451.19321727752686\n",
            "Training Loss : 2.557422637939453\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 205 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 233.42987060546875\n",
            "Eval_StdReturn : 8.113677978515625\n",
            "Eval_MaxReturn : 245.67678833007812\n",
            "Eval_MinReturn : 223.15478515625\n",
            "Eval_AverageEpLen : 107.75\n",
            "Train_AverageReturn : 229.67965698242188\n",
            "Train_StdReturn : 24.184354782104492\n",
            "Train_MaxReturn : 256.1270751953125\n",
            "Train_MinReturn : 136.49810791015625\n",
            "Train_AverageEpLen : 109.57894736842105\n",
            "Train_EnvstepsSoFar : 421555\n",
            "TimeSinceStart : 453.48012948036194\n",
            "Training Loss : 51.588775634765625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 206 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.2340087890625\n",
            "Eval_StdReturn : 13.525362014770508\n",
            "Eval_MaxReturn : 252.27101135253906\n",
            "Eval_MinReturn : 220.3307342529297\n",
            "Eval_AverageEpLen : 113.5\n",
            "Train_AverageReturn : 233.69186401367188\n",
            "Train_StdReturn : 10.429131507873535\n",
            "Train_MaxReturn : 250.38844299316406\n",
            "Train_MinReturn : 219.859619140625\n",
            "Train_AverageEpLen : 110.3157894736842\n",
            "Train_EnvstepsSoFar : 423651\n",
            "TimeSinceStart : 455.7532947063446\n",
            "Training Loss : -61.477760314941406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 207 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 238.82119750976562\n",
            "Eval_StdReturn : 14.60173511505127\n",
            "Eval_MaxReturn : 261.7430114746094\n",
            "Eval_MinReturn : 221.12417602539062\n",
            "Eval_AverageEpLen : 114.25\n",
            "Train_AverageReturn : 236.780029296875\n",
            "Train_StdReturn : 18.809213638305664\n",
            "Train_MaxReturn : 289.21868896484375\n",
            "Train_MinReturn : 208.20559692382812\n",
            "Train_AverageEpLen : 113.33333333333333\n",
            "Train_EnvstepsSoFar : 425691\n",
            "TimeSinceStart : 457.9887020587921\n",
            "Training Loss : 13.1554594039917\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 208 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.8050537109375\n",
            "Eval_StdReturn : 22.65128517150879\n",
            "Eval_MaxReturn : 244.699951171875\n",
            "Eval_MinReturn : 186.33970642089844\n",
            "Eval_AverageEpLen : 105.5\n",
            "Train_AverageReturn : 234.34664916992188\n",
            "Train_StdReturn : 17.595073699951172\n",
            "Train_MaxReturn : 281.33819580078125\n",
            "Train_MinReturn : 208.27944946289062\n",
            "Train_AverageEpLen : 113.22222222222223\n",
            "Train_EnvstepsSoFar : 427729\n",
            "TimeSinceStart : 460.2632887363434\n",
            "Training Loss : 24.44245719909668\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 209 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 231.41876220703125\n",
            "Eval_StdReturn : 9.755319595336914\n",
            "Eval_MaxReturn : 248.27212524414062\n",
            "Eval_MinReturn : 225.0660858154297\n",
            "Eval_AverageEpLen : 106.5\n",
            "Train_AverageReturn : 240.17721557617188\n",
            "Train_StdReturn : 11.991480827331543\n",
            "Train_MaxReturn : 260.47882080078125\n",
            "Train_MinReturn : 210.50936889648438\n",
            "Train_AverageEpLen : 116.72222222222223\n",
            "Train_EnvstepsSoFar : 429830\n",
            "TimeSinceStart : 462.6985285282135\n",
            "Training Loss : 60.63126754760742\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 210 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 236.01971435546875\n",
            "Eval_StdReturn : 10.468140602111816\n",
            "Eval_MaxReturn : 250.65000915527344\n",
            "Eval_MinReturn : 222.333251953125\n",
            "Eval_AverageEpLen : 113.75\n",
            "Train_AverageReturn : 236.80287170410156\n",
            "Train_StdReturn : 13.324662208557129\n",
            "Train_MaxReturn : 261.8904113769531\n",
            "Train_MinReturn : 214.65835571289062\n",
            "Train_AverageEpLen : 115.22222222222223\n",
            "Train_EnvstepsSoFar : 431904\n",
            "TimeSinceStart : 464.98835921287537\n",
            "Training Loss : 3.0186901092529297\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 211 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 249.4647674560547\n",
            "Eval_StdReturn : 2.902113199234009\n",
            "Eval_MaxReturn : 252.7989501953125\n",
            "Eval_MinReturn : 245.37918090820312\n",
            "Eval_AverageEpLen : 121.75\n",
            "Train_AverageReturn : 233.43592834472656\n",
            "Train_StdReturn : 16.190811157226562\n",
            "Train_MaxReturn : 259.46636962890625\n",
            "Train_MinReturn : 183.43600463867188\n",
            "Train_AverageEpLen : 109.36842105263158\n",
            "Train_EnvstepsSoFar : 433982\n",
            "TimeSinceStart : 467.31479954719543\n",
            "Training Loss : 6.157683849334717\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 212 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 238.58653259277344\n",
            "Eval_StdReturn : 5.305295467376709\n",
            "Eval_MaxReturn : 244.3072967529297\n",
            "Eval_MinReturn : 231.90151977539062\n",
            "Eval_AverageEpLen : 108.25\n",
            "Train_AverageReturn : 236.6077423095703\n",
            "Train_StdReturn : 14.350604057312012\n",
            "Train_MaxReturn : 264.49951171875\n",
            "Train_MinReturn : 204.6905517578125\n",
            "Train_AverageEpLen : 111.55555555555556\n",
            "Train_EnvstepsSoFar : 435990\n",
            "TimeSinceStart : 469.5216770172119\n",
            "Training Loss : -51.458580017089844\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 213 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.28787231445312\n",
            "Eval_StdReturn : 6.90444278717041\n",
            "Eval_MaxReturn : 235.40072631835938\n",
            "Eval_MinReturn : 214.9213409423828\n",
            "Eval_AverageEpLen : 102.2\n",
            "Train_AverageReturn : 239.1148223876953\n",
            "Train_StdReturn : 15.317167282104492\n",
            "Train_MaxReturn : 271.9251708984375\n",
            "Train_MinReturn : 221.63381958007812\n",
            "Train_AverageEpLen : 114.33333333333333\n",
            "Train_EnvstepsSoFar : 438048\n",
            "TimeSinceStart : 471.84539794921875\n",
            "Training Loss : 86.23112487792969\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 214 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 226.464111328125\n",
            "Eval_StdReturn : 3.7881736755371094\n",
            "Eval_MaxReturn : 232.8847198486328\n",
            "Eval_MinReturn : 223.06637573242188\n",
            "Eval_AverageEpLen : 101.75\n",
            "Train_AverageReturn : 232.88401794433594\n",
            "Train_StdReturn : 10.343145370483398\n",
            "Train_MaxReturn : 251.03048706054688\n",
            "Train_MinReturn : 212.51914978027344\n",
            "Train_AverageEpLen : 108.47368421052632\n",
            "Train_EnvstepsSoFar : 440109\n",
            "TimeSinceStart : 474.1281716823578\n",
            "Training Loss : 35.445674896240234\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 215 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.64697265625\n",
            "Eval_StdReturn : 29.058944702148438\n",
            "Eval_MaxReturn : 253.07945251464844\n",
            "Eval_MinReturn : 177.2493438720703\n",
            "Eval_AverageEpLen : 107.0\n",
            "Train_AverageReturn : 236.11790466308594\n",
            "Train_StdReturn : 11.701531410217285\n",
            "Train_MaxReturn : 252.9311065673828\n",
            "Train_MinReturn : 206.4933319091797\n",
            "Train_AverageEpLen : 110.63157894736842\n",
            "Train_EnvstepsSoFar : 442211\n",
            "TimeSinceStart : 476.3696291446686\n",
            "Training Loss : 67.51395416259766\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 216 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.201416015625\n",
            "Eval_StdReturn : 10.205073356628418\n",
            "Eval_MaxReturn : 236.14236450195312\n",
            "Eval_MinReturn : 207.8954315185547\n",
            "Eval_AverageEpLen : 100.2\n",
            "Train_AverageReturn : 225.7751922607422\n",
            "Train_StdReturn : 25.8940486907959\n",
            "Train_MaxReturn : 270.9624938964844\n",
            "Train_MinReturn : 169.4777374267578\n",
            "Train_AverageEpLen : 106.84210526315789\n",
            "Train_EnvstepsSoFar : 444241\n",
            "TimeSinceStart : 478.67623949050903\n",
            "Training Loss : 25.08373260498047\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 217 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.30419921875\n",
            "Eval_StdReturn : 18.576793670654297\n",
            "Eval_MaxReturn : 265.8829040527344\n",
            "Eval_MinReturn : 216.1195068359375\n",
            "Eval_AverageEpLen : 112.5\n",
            "Train_AverageReturn : 229.5175323486328\n",
            "Train_StdReturn : 19.19559097290039\n",
            "Train_MaxReturn : 248.60540771484375\n",
            "Train_MinReturn : 171.97625732421875\n",
            "Train_AverageEpLen : 107.15789473684211\n",
            "Train_EnvstepsSoFar : 446277\n",
            "TimeSinceStart : 480.91801619529724\n",
            "Training Loss : -38.29034423828125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 218 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 249.99462890625\n",
            "Eval_StdReturn : 19.260311126708984\n",
            "Eval_MaxReturn : 274.69232177734375\n",
            "Eval_MinReturn : 221.63980102539062\n",
            "Eval_AverageEpLen : 125.0\n",
            "Train_AverageReturn : 225.29672241210938\n",
            "Train_StdReturn : 28.235389709472656\n",
            "Train_MaxReturn : 258.3999938964844\n",
            "Train_MinReturn : 132.7173614501953\n",
            "Train_AverageEpLen : 106.36842105263158\n",
            "Train_EnvstepsSoFar : 448298\n",
            "TimeSinceStart : 483.23185300827026\n",
            "Training Loss : 7.341838836669922\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 219 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 227.81338500976562\n",
            "Eval_StdReturn : 10.511703491210938\n",
            "Eval_MaxReturn : 244.6189422607422\n",
            "Eval_MinReturn : 217.53213500976562\n",
            "Eval_AverageEpLen : 107.5\n",
            "Train_AverageReturn : 236.3671875\n",
            "Train_StdReturn : 17.951168060302734\n",
            "Train_MaxReturn : 266.22357177734375\n",
            "Train_MinReturn : 204.7633056640625\n",
            "Train_AverageEpLen : 113.22222222222223\n",
            "Train_EnvstepsSoFar : 450336\n",
            "TimeSinceStart : 485.52320766448975\n",
            "Training Loss : 44.53599548339844\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 220 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.30429077148438\n",
            "Eval_StdReturn : 13.525538444519043\n",
            "Eval_MaxReturn : 262.2354431152344\n",
            "Eval_MinReturn : 227.82254028320312\n",
            "Eval_AverageEpLen : 118.0\n",
            "Train_AverageReturn : 229.18344116210938\n",
            "Train_StdReturn : 12.410513877868652\n",
            "Train_MaxReturn : 254.26632690429688\n",
            "Train_MinReturn : 207.16043090820312\n",
            "Train_AverageEpLen : 104.6\n",
            "Train_EnvstepsSoFar : 452428\n",
            "TimeSinceStart : 487.9235110282898\n",
            "Training Loss : 105.5362777709961\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 221 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 227.09344482421875\n",
            "Eval_StdReturn : 24.120567321777344\n",
            "Eval_MaxReturn : 264.1921081542969\n",
            "Eval_MinReturn : 203.18040466308594\n",
            "Eval_AverageEpLen : 107.5\n",
            "Train_AverageReturn : 243.88943481445312\n",
            "Train_StdReturn : 18.192222595214844\n",
            "Train_MaxReturn : 289.33416748046875\n",
            "Train_MinReturn : 223.5626678466797\n",
            "Train_AverageEpLen : 116.22222222222223\n",
            "Train_EnvstepsSoFar : 454520\n",
            "TimeSinceStart : 490.2469530105591\n",
            "Training Loss : 29.86627960205078\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 222 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 231.21060180664062\n",
            "Eval_StdReturn : 6.743680953979492\n",
            "Eval_MaxReturn : 241.3230743408203\n",
            "Eval_MinReturn : 222.49868774414062\n",
            "Eval_AverageEpLen : 106.75\n",
            "Train_AverageReturn : 239.89971923828125\n",
            "Train_StdReturn : 15.644786834716797\n",
            "Train_MaxReturn : 268.17449951171875\n",
            "Train_MinReturn : 219.97906494140625\n",
            "Train_AverageEpLen : 113.77777777777777\n",
            "Train_EnvstepsSoFar : 456568\n",
            "TimeSinceStart : 492.5198087692261\n",
            "Training Loss : -6.303239345550537\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 223 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.8909149169922\n",
            "Eval_StdReturn : 17.027769088745117\n",
            "Eval_MaxReturn : 263.6185302734375\n",
            "Eval_MinReturn : 219.4144287109375\n",
            "Eval_AverageEpLen : 113.75\n",
            "Train_AverageReturn : 222.7909393310547\n",
            "Train_StdReturn : 50.10719680786133\n",
            "Train_MaxReturn : 266.9561767578125\n",
            "Train_MinReturn : 35.24504470825195\n",
            "Train_AverageEpLen : 107.73684210526316\n",
            "Train_EnvstepsSoFar : 458615\n",
            "TimeSinceStart : 494.7696752548218\n",
            "Training Loss : 52.363712310791016\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 224 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 214.0540771484375\n",
            "Eval_StdReturn : 17.288633346557617\n",
            "Eval_MaxReturn : 227.71478271484375\n",
            "Eval_MinReturn : 180.8217010498047\n",
            "Eval_AverageEpLen : 98.6\n",
            "Train_AverageReturn : 225.25393676757812\n",
            "Train_StdReturn : 33.04838180541992\n",
            "Train_MaxReturn : 270.7177734375\n",
            "Train_MinReturn : 96.76544952392578\n",
            "Train_AverageEpLen : 106.7\n",
            "Train_EnvstepsSoFar : 460749\n",
            "TimeSinceStart : 497.0958344936371\n",
            "Training Loss : 28.13630485534668\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 225 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 231.67124938964844\n",
            "Eval_StdReturn : 5.000973224639893\n",
            "Eval_MaxReturn : 239.74334716796875\n",
            "Eval_MinReturn : 226.55027770996094\n",
            "Eval_AverageEpLen : 107.75\n",
            "Train_AverageReturn : 225.62022399902344\n",
            "Train_StdReturn : 24.163850784301758\n",
            "Train_MaxReturn : 264.27227783203125\n",
            "Train_MinReturn : 162.4049835205078\n",
            "Train_AverageEpLen : 107.42105263157895\n",
            "Train_EnvstepsSoFar : 462790\n",
            "TimeSinceStart : 499.35099959373474\n",
            "Training Loss : 64.81892395019531\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 226 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 239.02247619628906\n",
            "Eval_StdReturn : 18.423582077026367\n",
            "Eval_MaxReturn : 268.0804138183594\n",
            "Eval_MinReturn : 218.46209716796875\n",
            "Eval_AverageEpLen : 109.0\n",
            "Train_AverageReturn : 227.0071258544922\n",
            "Train_StdReturn : 10.446413040161133\n",
            "Train_MaxReturn : 244.46414184570312\n",
            "Train_MinReturn : 208.4373779296875\n",
            "Train_AverageEpLen : 102.3\n",
            "Train_EnvstepsSoFar : 464836\n",
            "TimeSinceStart : 501.59059882164\n",
            "Training Loss : -2.828732490539551\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 227 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 245.1496124267578\n",
            "Eval_StdReturn : 27.027372360229492\n",
            "Eval_MaxReturn : 290.435791015625\n",
            "Eval_MinReturn : 221.5079803466797\n",
            "Eval_AverageEpLen : 119.75\n",
            "Train_AverageReturn : 229.59994506835938\n",
            "Train_StdReturn : 17.000965118408203\n",
            "Train_MaxReturn : 259.3288879394531\n",
            "Train_MinReturn : 197.60122680664062\n",
            "Train_AverageEpLen : 109.36842105263158\n",
            "Train_EnvstepsSoFar : 466914\n",
            "TimeSinceStart : 503.8916139602661\n",
            "Training Loss : -43.83587646484375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 228 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 231.75637817382812\n",
            "Eval_StdReturn : 8.189067840576172\n",
            "Eval_MaxReturn : 245.6387481689453\n",
            "Eval_MinReturn : 225.74354553222656\n",
            "Eval_AverageEpLen : 106.25\n",
            "Train_AverageReturn : 235.4506072998047\n",
            "Train_StdReturn : 15.929696083068848\n",
            "Train_MaxReturn : 268.90875244140625\n",
            "Train_MinReturn : 204.95286560058594\n",
            "Train_AverageEpLen : 109.84210526315789\n",
            "Train_EnvstepsSoFar : 469001\n",
            "TimeSinceStart : 506.1830518245697\n",
            "Training Loss : 77.70655822753906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 229 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 230.4312744140625\n",
            "Eval_StdReturn : 18.72536849975586\n",
            "Eval_MaxReturn : 261.384033203125\n",
            "Eval_MinReturn : 212.1508026123047\n",
            "Eval_AverageEpLen : 108.25\n",
            "Train_AverageReturn : 234.12384033203125\n",
            "Train_StdReturn : 16.526933670043945\n",
            "Train_MaxReturn : 268.6334533691406\n",
            "Train_MinReturn : 202.3881378173828\n",
            "Train_AverageEpLen : 109.89473684210526\n",
            "Train_EnvstepsSoFar : 471089\n",
            "TimeSinceStart : 508.5060293674469\n",
            "Training Loss : -84.67022705078125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 230 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 244.68849182128906\n",
            "Eval_StdReturn : 7.7763237953186035\n",
            "Eval_MaxReturn : 251.66021728515625\n",
            "Eval_MinReturn : 231.741455078125\n",
            "Eval_AverageEpLen : 118.25\n",
            "Train_AverageReturn : 237.12196350097656\n",
            "Train_StdReturn : 13.135810852050781\n",
            "Train_MaxReturn : 269.8403625488281\n",
            "Train_MinReturn : 217.01527404785156\n",
            "Train_AverageEpLen : 113.22222222222223\n",
            "Train_EnvstepsSoFar : 473127\n",
            "TimeSinceStart : 510.8357629776001\n",
            "Training Loss : 53.78629684448242\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 231 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 245.98220825195312\n",
            "Eval_StdReturn : 23.977027893066406\n",
            "Eval_MaxReturn : 272.623046875\n",
            "Eval_MinReturn : 220.9125213623047\n",
            "Eval_AverageEpLen : 122.5\n",
            "Train_AverageReturn : 244.83628845214844\n",
            "Train_StdReturn : 16.59862518310547\n",
            "Train_MaxReturn : 289.37774658203125\n",
            "Train_MinReturn : 212.14117431640625\n",
            "Train_AverageEpLen : 119.17647058823529\n",
            "Train_EnvstepsSoFar : 475153\n",
            "TimeSinceStart : 513.1848678588867\n",
            "Training Loss : 1.3790569305419922\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 232 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 239.6249542236328\n",
            "Eval_StdReturn : 12.311159133911133\n",
            "Eval_MaxReturn : 253.83697509765625\n",
            "Eval_MinReturn : 222.4482879638672\n",
            "Eval_AverageEpLen : 113.0\n",
            "Train_AverageReturn : 242.41366577148438\n",
            "Train_StdReturn : 20.241830825805664\n",
            "Train_MaxReturn : 279.2375183105469\n",
            "Train_MinReturn : 212.8155975341797\n",
            "Train_AverageEpLen : 119.29411764705883\n",
            "Train_EnvstepsSoFar : 477181\n",
            "TimeSinceStart : 515.4625535011292\n",
            "Training Loss : 70.06228637695312\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 233 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.93338012695312\n",
            "Eval_StdReturn : 21.003707885742188\n",
            "Eval_MaxReturn : 271.17730712890625\n",
            "Eval_MinReturn : 221.3965301513672\n",
            "Eval_AverageEpLen : 117.25\n",
            "Train_AverageReturn : 233.3888397216797\n",
            "Train_StdReturn : 33.55548095703125\n",
            "Train_MaxReturn : 271.90460205078125\n",
            "Train_MinReturn : 110.95157623291016\n",
            "Train_AverageEpLen : 112.66666666666667\n",
            "Train_EnvstepsSoFar : 479209\n",
            "TimeSinceStart : 517.7172765731812\n",
            "Training Loss : -42.59123992919922\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 234 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 253.40000915527344\n",
            "Eval_StdReturn : 14.261069297790527\n",
            "Eval_MaxReturn : 270.44097900390625\n",
            "Eval_MinReturn : 232.3922882080078\n",
            "Eval_AverageEpLen : 125.75\n",
            "Train_AverageReturn : 243.96826171875\n",
            "Train_StdReturn : 20.560834884643555\n",
            "Train_MaxReturn : 283.4123840332031\n",
            "Train_MinReturn : 215.20889282226562\n",
            "Train_AverageEpLen : 120.41176470588235\n",
            "Train_EnvstepsSoFar : 481256\n",
            "TimeSinceStart : 520.0540127754211\n",
            "Training Loss : -47.76678466796875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 235 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.01065063476562\n",
            "Eval_StdReturn : 27.380428314208984\n",
            "Eval_MaxReturn : 268.6246337890625\n",
            "Eval_MinReturn : 195.03939819335938\n",
            "Eval_AverageEpLen : 120.25\n",
            "Train_AverageReturn : 235.79705810546875\n",
            "Train_StdReturn : 26.782703399658203\n",
            "Train_MaxReturn : 271.0361022949219\n",
            "Train_MinReturn : 138.46426391601562\n",
            "Train_AverageEpLen : 114.27777777777777\n",
            "Train_EnvstepsSoFar : 483313\n",
            "TimeSinceStart : 522.4090657234192\n",
            "Training Loss : -9.145570755004883\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 236 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 240.74183654785156\n",
            "Eval_StdReturn : 10.726922988891602\n",
            "Eval_MaxReturn : 256.1064453125\n",
            "Eval_MinReturn : 226.58151245117188\n",
            "Eval_AverageEpLen : 112.5\n",
            "Train_AverageReturn : 247.20513916015625\n",
            "Train_StdReturn : 19.599342346191406\n",
            "Train_MaxReturn : 306.99578857421875\n",
            "Train_MinReturn : 223.31710815429688\n",
            "Train_AverageEpLen : 121.52941176470588\n",
            "Train_EnvstepsSoFar : 485379\n",
            "TimeSinceStart : 524.7438228130341\n",
            "Training Loss : -120.39338684082031\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 237 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 266.2972106933594\n",
            "Eval_StdReturn : 25.180078506469727\n",
            "Eval_MaxReturn : 293.2138671875\n",
            "Eval_MinReturn : 229.86373901367188\n",
            "Eval_AverageEpLen : 139.25\n",
            "Train_AverageReturn : 244.2512969970703\n",
            "Train_StdReturn : 17.071630477905273\n",
            "Train_MaxReturn : 273.8983459472656\n",
            "Train_MinReturn : 215.2617645263672\n",
            "Train_AverageEpLen : 119.23529411764706\n",
            "Train_EnvstepsSoFar : 487406\n",
            "TimeSinceStart : 527.0959973335266\n",
            "Training Loss : 78.9674301147461\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 238 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 235.46356201171875\n",
            "Eval_StdReturn : 14.748086929321289\n",
            "Eval_MaxReturn : 260.99151611328125\n",
            "Eval_MinReturn : 226.1963653564453\n",
            "Eval_AverageEpLen : 112.75\n",
            "Train_AverageReturn : 231.8473358154297\n",
            "Train_StdReturn : 33.39713668823242\n",
            "Train_MaxReturn : 266.34686279296875\n",
            "Train_MinReturn : 104.0079345703125\n",
            "Train_AverageEpLen : 112.11111111111111\n",
            "Train_EnvstepsSoFar : 489424\n",
            "TimeSinceStart : 529.361615896225\n",
            "Training Loss : 42.3946533203125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 239 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 247.73753356933594\n",
            "Eval_StdReturn : 16.52342414855957\n",
            "Eval_MaxReturn : 272.89288330078125\n",
            "Eval_MinReturn : 226.68515014648438\n",
            "Eval_AverageEpLen : 121.5\n",
            "Train_AverageReturn : 246.4359130859375\n",
            "Train_StdReturn : 27.892812728881836\n",
            "Train_MaxReturn : 322.61126708984375\n",
            "Train_MinReturn : 186.27108764648438\n",
            "Train_AverageEpLen : 122.52941176470588\n",
            "Train_EnvstepsSoFar : 491507\n",
            "TimeSinceStart : 531.7230660915375\n",
            "Training Loss : -71.24877166748047\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 240 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 247.967529296875\n",
            "Eval_StdReturn : 9.518632888793945\n",
            "Eval_MaxReturn : 259.4996643066406\n",
            "Eval_MinReturn : 235.96377563476562\n",
            "Eval_AverageEpLen : 120.25\n",
            "Train_AverageReturn : 243.3060302734375\n",
            "Train_StdReturn : 14.938000679016113\n",
            "Train_MaxReturn : 268.1927490234375\n",
            "Train_MinReturn : 223.8908233642578\n",
            "Train_AverageEpLen : 118.52941176470588\n",
            "Train_EnvstepsSoFar : 493522\n",
            "TimeSinceStart : 534.0798823833466\n",
            "Training Loss : -48.00958251953125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 241 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 238.22219848632812\n",
            "Eval_StdReturn : 9.420563697814941\n",
            "Eval_MaxReturn : 252.45481872558594\n",
            "Eval_MinReturn : 226.6438446044922\n",
            "Eval_AverageEpLen : 115.75\n",
            "Train_AverageReturn : 246.29859924316406\n",
            "Train_StdReturn : 15.122625350952148\n",
            "Train_MaxReturn : 284.3607177734375\n",
            "Train_MinReturn : 227.24021911621094\n",
            "Train_AverageEpLen : 120.41176470588235\n",
            "Train_EnvstepsSoFar : 495569\n",
            "TimeSinceStart : 536.4037554264069\n",
            "Training Loss : 39.46012496948242\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 242 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 252.3832244873047\n",
            "Eval_StdReturn : 15.26117992401123\n",
            "Eval_MaxReturn : 273.02459716796875\n",
            "Eval_MinReturn : 234.54771423339844\n",
            "Eval_AverageEpLen : 127.25\n",
            "Train_AverageReturn : 241.638427734375\n",
            "Train_StdReturn : 14.48410415649414\n",
            "Train_MaxReturn : 266.65411376953125\n",
            "Train_MinReturn : 220.37493896484375\n",
            "Train_AverageEpLen : 118.0\n",
            "Train_EnvstepsSoFar : 497693\n",
            "TimeSinceStart : 538.7817401885986\n",
            "Training Loss : -20.779373168945312\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 243 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 244.71063232421875\n",
            "Eval_StdReturn : 6.307304382324219\n",
            "Eval_MaxReturn : 250.1838836669922\n",
            "Eval_MinReturn : 234.06146240234375\n",
            "Eval_AverageEpLen : 122.75\n",
            "Train_AverageReturn : 239.86444091796875\n",
            "Train_StdReturn : 22.62453269958496\n",
            "Train_MaxReturn : 262.8394775390625\n",
            "Train_MinReturn : 158.19598388671875\n",
            "Train_AverageEpLen : 117.6470588235294\n",
            "Train_EnvstepsSoFar : 499693\n",
            "TimeSinceStart : 541.0895521640778\n",
            "Training Loss : -22.44058609008789\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 244 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 239.47463989257812\n",
            "Eval_StdReturn : 17.343679428100586\n",
            "Eval_MaxReturn : 257.4096984863281\n",
            "Eval_MinReturn : 212.76097106933594\n",
            "Eval_AverageEpLen : 115.0\n",
            "Train_AverageReturn : 240.9130096435547\n",
            "Train_StdReturn : 25.747116088867188\n",
            "Train_MaxReturn : 273.43182373046875\n",
            "Train_MinReturn : 164.29949951171875\n",
            "Train_AverageEpLen : 119.29411764705883\n",
            "Train_EnvstepsSoFar : 501721\n",
            "TimeSinceStart : 543.397784948349\n",
            "Training Loss : -31.88213348388672\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 245 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 259.76165771484375\n",
            "Eval_StdReturn : 31.897558212280273\n",
            "Eval_MaxReturn : 288.6893310546875\n",
            "Eval_MinReturn : 209.62948608398438\n",
            "Eval_AverageEpLen : 138.25\n",
            "Train_AverageReturn : 247.6378936767578\n",
            "Train_StdReturn : 20.15129280090332\n",
            "Train_MaxReturn : 285.81756591796875\n",
            "Train_MinReturn : 221.73687744140625\n",
            "Train_AverageEpLen : 121.88235294117646\n",
            "Train_EnvstepsSoFar : 503793\n",
            "TimeSinceStart : 545.8013029098511\n",
            "Training Loss : -56.081809997558594\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 246 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.67941284179688\n",
            "Eval_StdReturn : 16.4172420501709\n",
            "Eval_MaxReturn : 264.4712219238281\n",
            "Eval_MinReturn : 220.14715576171875\n",
            "Eval_AverageEpLen : 114.0\n",
            "Train_AverageReturn : 256.85760498046875\n",
            "Train_StdReturn : 27.012676239013672\n",
            "Train_MaxReturn : 315.9445495605469\n",
            "Train_MinReturn : 223.37213134765625\n",
            "Train_AverageEpLen : 131.875\n",
            "Train_EnvstepsSoFar : 505903\n",
            "TimeSinceStart : 548.2883343696594\n",
            "Training Loss : 18.395395278930664\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 247 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 245.44393920898438\n",
            "Eval_StdReturn : 18.212804794311523\n",
            "Eval_MaxReturn : 275.1758728027344\n",
            "Eval_MinReturn : 230.27041625976562\n",
            "Eval_AverageEpLen : 125.25\n",
            "Train_AverageReturn : 241.46435546875\n",
            "Train_StdReturn : 17.748273849487305\n",
            "Train_MaxReturn : 273.24273681640625\n",
            "Train_MinReturn : 213.04318237304688\n",
            "Train_AverageEpLen : 118.52941176470588\n",
            "Train_EnvstepsSoFar : 507918\n",
            "TimeSinceStart : 550.5864357948303\n",
            "Training Loss : 1.898406982421875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 248 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.05935668945312\n",
            "Eval_StdReturn : 21.151166915893555\n",
            "Eval_MaxReturn : 275.15069580078125\n",
            "Eval_MinReturn : 216.83627319335938\n",
            "Eval_AverageEpLen : 120.0\n",
            "Train_AverageReturn : 226.13829040527344\n",
            "Train_StdReturn : 35.95526885986328\n",
            "Train_MaxReturn : 266.99749755859375\n",
            "Train_MinReturn : 104.62710571289062\n",
            "Train_AverageEpLen : 109.0\n",
            "Train_EnvstepsSoFar : 509989\n",
            "TimeSinceStart : 552.9010345935822\n",
            "Training Loss : 3.9909706115722656\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 249 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 261.6122741699219\n",
            "Eval_StdReturn : 20.772310256958008\n",
            "Eval_MaxReturn : 288.65924072265625\n",
            "Eval_MinReturn : 238.1600799560547\n",
            "Eval_AverageEpLen : 134.33333333333334\n",
            "Train_AverageReturn : 237.612060546875\n",
            "Train_StdReturn : 33.049503326416016\n",
            "Train_MaxReturn : 276.1380920410156\n",
            "Train_MinReturn : 116.98173522949219\n",
            "Train_AverageEpLen : 115.72222222222223\n",
            "Train_EnvstepsSoFar : 512072\n",
            "TimeSinceStart : 555.1862251758575\n",
            "Training Loss : -128.44419860839844\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 250 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.61000061035156\n",
            "Eval_StdReturn : 10.609892845153809\n",
            "Eval_MaxReturn : 258.8787841796875\n",
            "Eval_MinReturn : 229.52957153320312\n",
            "Eval_AverageEpLen : 120.25\n",
            "Train_AverageReturn : 249.81698608398438\n",
            "Train_StdReturn : 22.777408599853516\n",
            "Train_MaxReturn : 310.57720947265625\n",
            "Train_MinReturn : 219.95077514648438\n",
            "Train_AverageEpLen : 124.94117647058823\n",
            "Train_EnvstepsSoFar : 514196\n",
            "TimeSinceStart : 557.6005895137787\n",
            "Training Loss : -33.43340301513672\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 251 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 241.92755126953125\n",
            "Eval_StdReturn : 11.415325164794922\n",
            "Eval_MaxReturn : 255.3265838623047\n",
            "Eval_MinReturn : 224.41453552246094\n",
            "Eval_AverageEpLen : 112.5\n",
            "Train_AverageReturn : 239.5270233154297\n",
            "Train_StdReturn : 43.87997055053711\n",
            "Train_MaxReturn : 280.3455505371094\n",
            "Train_MinReturn : 81.15497589111328\n",
            "Train_AverageEpLen : 119.6470588235294\n",
            "Train_EnvstepsSoFar : 516230\n",
            "TimeSinceStart : 559.8928637504578\n",
            "Training Loss : 9.718212127685547\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 252 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 260.71099853515625\n",
            "Eval_StdReturn : 24.45342254638672\n",
            "Eval_MaxReturn : 286.37896728515625\n",
            "Eval_MinReturn : 221.57925415039062\n",
            "Eval_AverageEpLen : 136.0\n",
            "Train_AverageReturn : 244.93597412109375\n",
            "Train_StdReturn : 42.07061767578125\n",
            "Train_MaxReturn : 292.7828674316406\n",
            "Train_MinReturn : 91.30835723876953\n",
            "Train_AverageEpLen : 123.47058823529412\n",
            "Train_EnvstepsSoFar : 518329\n",
            "TimeSinceStart : 562.3164219856262\n",
            "Training Loss : 63.1583251953125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 253 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 243.7823944091797\n",
            "Eval_StdReturn : 9.397141456604004\n",
            "Eval_MaxReturn : 255.17481994628906\n",
            "Eval_MinReturn : 231.23910522460938\n",
            "Eval_AverageEpLen : 120.0\n",
            "Train_AverageReturn : 253.66090393066406\n",
            "Train_StdReturn : 25.989839553833008\n",
            "Train_MaxReturn : 335.0380554199219\n",
            "Train_MinReturn : 225.2772979736328\n",
            "Train_AverageEpLen : 128.375\n",
            "Train_EnvstepsSoFar : 520383\n",
            "TimeSinceStart : 564.6481645107269\n",
            "Training Loss : -21.92719268798828\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 254 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 235.13616943359375\n",
            "Eval_StdReturn : 7.967526435852051\n",
            "Eval_MaxReturn : 245.91351318359375\n",
            "Eval_MinReturn : 226.93247985839844\n",
            "Eval_AverageEpLen : 111.0\n",
            "Train_AverageReturn : 247.06246948242188\n",
            "Train_StdReturn : 13.496928215026855\n",
            "Train_MaxReturn : 269.04248046875\n",
            "Train_MinReturn : 227.8740997314453\n",
            "Train_AverageEpLen : 118.70588235294117\n",
            "Train_EnvstepsSoFar : 522401\n",
            "TimeSinceStart : 566.8860578536987\n",
            "Training Loss : 16.27468490600586\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 255 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 256.2783203125\n",
            "Eval_StdReturn : 45.72709274291992\n",
            "Eval_MaxReturn : 293.89434814453125\n",
            "Eval_MinReturn : 191.91566467285156\n",
            "Eval_AverageEpLen : 136.0\n",
            "Train_AverageReturn : 252.02069091796875\n",
            "Train_StdReturn : 17.98448944091797\n",
            "Train_MaxReturn : 281.4607238769531\n",
            "Train_MinReturn : 227.62745666503906\n",
            "Train_AverageEpLen : 127.75\n",
            "Train_EnvstepsSoFar : 524445\n",
            "TimeSinceStart : 569.1740288734436\n",
            "Training Loss : -31.966466903686523\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 256 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.04295349121094\n",
            "Eval_StdReturn : 13.99453067779541\n",
            "Eval_MaxReturn : 264.5506896972656\n",
            "Eval_MinReturn : 226.64718627929688\n",
            "Eval_AverageEpLen : 115.5\n",
            "Train_AverageReturn : 240.06634521484375\n",
            "Train_StdReturn : 15.769240379333496\n",
            "Train_MaxReturn : 282.5813293457031\n",
            "Train_MinReturn : 214.8685760498047\n",
            "Train_AverageEpLen : 116.38888888888889\n",
            "Train_EnvstepsSoFar : 526540\n",
            "TimeSinceStart : 571.5421531200409\n",
            "Training Loss : 18.287761688232422\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 257 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 247.3148956298828\n",
            "Eval_StdReturn : 6.568866729736328\n",
            "Eval_MaxReturn : 255.45343017578125\n",
            "Eval_MinReturn : 239.36642456054688\n",
            "Eval_AverageEpLen : 133.66666666666666\n",
            "Train_AverageReturn : 256.3685302734375\n",
            "Train_StdReturn : 29.748838424682617\n",
            "Train_MaxReturn : 328.1205139160156\n",
            "Train_MinReturn : 205.8798370361328\n",
            "Train_AverageEpLen : 129.0\n",
            "Train_EnvstepsSoFar : 528604\n",
            "TimeSinceStart : 573.8560342788696\n",
            "Training Loss : 47.99415588378906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 258 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 257.2190856933594\n",
            "Eval_StdReturn : 15.159384727478027\n",
            "Eval_MaxReturn : 280.1746826171875\n",
            "Eval_MinReturn : 242.58689880371094\n",
            "Eval_AverageEpLen : 126.75\n",
            "Train_AverageReturn : 241.5809783935547\n",
            "Train_StdReturn : 16.5021915435791\n",
            "Train_MaxReturn : 267.35540771484375\n",
            "Train_MinReturn : 195.72227478027344\n",
            "Train_AverageEpLen : 117.61111111111111\n",
            "Train_EnvstepsSoFar : 530721\n",
            "TimeSinceStart : 576.243200302124\n",
            "Training Loss : 7.780244827270508\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 259 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.5512237548828\n",
            "Eval_StdReturn : 11.521021842956543\n",
            "Eval_MaxReturn : 254.2431640625\n",
            "Eval_MinReturn : 221.9630584716797\n",
            "Eval_AverageEpLen : 110.75\n",
            "Train_AverageReturn : 259.5871276855469\n",
            "Train_StdReturn : 22.736785888671875\n",
            "Train_MaxReturn : 295.45867919921875\n",
            "Train_MinReturn : 223.6864471435547\n",
            "Train_AverageEpLen : 132.75\n",
            "Train_EnvstepsSoFar : 532845\n",
            "TimeSinceStart : 578.636547088623\n",
            "Training Loss : 48.32877731323242\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 260 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 291.5588073730469\n",
            "Eval_StdReturn : 32.76235580444336\n",
            "Eval_MaxReturn : 329.6859130859375\n",
            "Eval_MinReturn : 249.69610595703125\n",
            "Eval_AverageEpLen : 159.0\n",
            "Train_AverageReturn : 253.9483642578125\n",
            "Train_StdReturn : 20.589813232421875\n",
            "Train_MaxReturn : 304.4109802246094\n",
            "Train_MinReturn : 230.2952880859375\n",
            "Train_AverageEpLen : 127.3125\n",
            "Train_EnvstepsSoFar : 534882\n",
            "TimeSinceStart : 580.9641156196594\n",
            "Training Loss : -34.39019012451172\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 261 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 267.2040710449219\n",
            "Eval_StdReturn : 33.23845291137695\n",
            "Eval_MaxReturn : 308.79119873046875\n",
            "Eval_MinReturn : 227.4348602294922\n",
            "Eval_AverageEpLen : 138.33333333333334\n",
            "Train_AverageReturn : 257.8447265625\n",
            "Train_StdReturn : 15.905062675476074\n",
            "Train_MaxReturn : 279.5871276855469\n",
            "Train_MinReturn : 230.63424682617188\n",
            "Train_AverageEpLen : 133.125\n",
            "Train_EnvstepsSoFar : 537012\n",
            "TimeSinceStart : 583.3694305419922\n",
            "Training Loss : 89.17892456054688\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 262 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 249.1674346923828\n",
            "Eval_StdReturn : 10.831113815307617\n",
            "Eval_MaxReturn : 267.1939697265625\n",
            "Eval_MinReturn : 238.5847625732422\n",
            "Eval_AverageEpLen : 120.5\n",
            "Train_AverageReturn : 249.35543823242188\n",
            "Train_StdReturn : 17.9866943359375\n",
            "Train_MaxReturn : 284.6905517578125\n",
            "Train_MinReturn : 220.7996826171875\n",
            "Train_AverageEpLen : 123.82352941176471\n",
            "Train_EnvstepsSoFar : 539117\n",
            "TimeSinceStart : 585.7513234615326\n",
            "Training Loss : 66.7571792602539\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 263 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.2042694091797\n",
            "Eval_StdReturn : 7.939085960388184\n",
            "Eval_MaxReturn : 253.1676788330078\n",
            "Eval_MinReturn : 231.55886840820312\n",
            "Eval_AverageEpLen : 113.0\n",
            "Train_AverageReturn : 250.0963134765625\n",
            "Train_StdReturn : 14.908468246459961\n",
            "Train_MaxReturn : 290.3730163574219\n",
            "Train_MinReturn : 226.50753784179688\n",
            "Train_AverageEpLen : 126.3125\n",
            "Train_EnvstepsSoFar : 541138\n",
            "TimeSinceStart : 588.1061863899231\n",
            "Training Loss : 82.79168701171875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 264 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 263.6524353027344\n",
            "Eval_StdReturn : 26.297231674194336\n",
            "Eval_MaxReturn : 294.0889892578125\n",
            "Eval_MinReturn : 229.92662048339844\n",
            "Eval_AverageEpLen : 136.33333333333334\n",
            "Train_AverageReturn : 245.6824188232422\n",
            "Train_StdReturn : 23.47019386291504\n",
            "Train_MaxReturn : 292.39813232421875\n",
            "Train_MinReturn : 194.80967712402344\n",
            "Train_AverageEpLen : 120.3529411764706\n",
            "Train_EnvstepsSoFar : 543184\n",
            "TimeSinceStart : 590.393012046814\n",
            "Training Loss : 27.883718490600586\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 265 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 255.75457763671875\n",
            "Eval_StdReturn : 15.821698188781738\n",
            "Eval_MaxReturn : 282.0625\n",
            "Eval_MinReturn : 242.25787353515625\n",
            "Eval_AverageEpLen : 129.0\n",
            "Train_AverageReturn : 256.8187561035156\n",
            "Train_StdReturn : 25.120023727416992\n",
            "Train_MaxReturn : 316.4560241699219\n",
            "Train_MinReturn : 227.37278747558594\n",
            "Train_AverageEpLen : 130.5625\n",
            "Train_EnvstepsSoFar : 545273\n",
            "TimeSinceStart : 592.8851864337921\n",
            "Training Loss : -32.86631393432617\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 266 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 270.01483154296875\n",
            "Eval_StdReturn : 4.920785903930664\n",
            "Eval_MaxReturn : 275.1189270019531\n",
            "Eval_MinReturn : 263.36614990234375\n",
            "Eval_AverageEpLen : 141.33333333333334\n",
            "Train_AverageReturn : 246.60475158691406\n",
            "Train_StdReturn : 25.874134063720703\n",
            "Train_MaxReturn : 299.9219055175781\n",
            "Train_MinReturn : 187.6270751953125\n",
            "Train_AverageEpLen : 121.52941176470588\n",
            "Train_EnvstepsSoFar : 547339\n",
            "TimeSinceStart : 595.20769572258\n",
            "Training Loss : -103.90037536621094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 267 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 257.5098571777344\n",
            "Eval_StdReturn : 22.69608497619629\n",
            "Eval_MaxReturn : 293.4534912109375\n",
            "Eval_MinReturn : 234.57241821289062\n",
            "Eval_AverageEpLen : 129.5\n",
            "Train_AverageReturn : 258.55572509765625\n",
            "Train_StdReturn : 21.656177520751953\n",
            "Train_MaxReturn : 316.1097412109375\n",
            "Train_MinReturn : 231.25254821777344\n",
            "Train_AverageEpLen : 131.0625\n",
            "Train_EnvstepsSoFar : 549436\n",
            "TimeSinceStart : 597.6851511001587\n",
            "Training Loss : 11.0123291015625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 268 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 276.37811279296875\n",
            "Eval_StdReturn : 35.536537170410156\n",
            "Eval_MaxReturn : 326.0426025390625\n",
            "Eval_MinReturn : 244.88650512695312\n",
            "Eval_AverageEpLen : 145.33333333333334\n",
            "Train_AverageReturn : 247.67193603515625\n",
            "Train_StdReturn : 17.525291442871094\n",
            "Train_MaxReturn : 287.557861328125\n",
            "Train_MinReturn : 222.902587890625\n",
            "Train_AverageEpLen : 121.11764705882354\n",
            "Train_EnvstepsSoFar : 551495\n",
            "TimeSinceStart : 599.988831281662\n",
            "Training Loss : 9.559083938598633\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 269 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 261.7738952636719\n",
            "Eval_StdReturn : 7.12879753112793\n",
            "Eval_MaxReturn : 271.61395263671875\n",
            "Eval_MinReturn : 254.95396423339844\n",
            "Eval_AverageEpLen : 134.33333333333334\n",
            "Train_AverageReturn : 252.06256103515625\n",
            "Train_StdReturn : 22.602224349975586\n",
            "Train_MaxReturn : 287.7977600097656\n",
            "Train_MinReturn : 192.7144317626953\n",
            "Train_AverageEpLen : 129.25\n",
            "Train_EnvstepsSoFar : 553563\n",
            "TimeSinceStart : 602.2786862850189\n",
            "Training Loss : 53.27321243286133\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 270 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 239.3885040283203\n",
            "Eval_StdReturn : 16.902437210083008\n",
            "Eval_MaxReturn : 263.6773376464844\n",
            "Eval_MinReturn : 217.03167724609375\n",
            "Eval_AverageEpLen : 121.5\n",
            "Train_AverageReturn : 257.3066711425781\n",
            "Train_StdReturn : 22.37700080871582\n",
            "Train_MaxReturn : 305.6380920410156\n",
            "Train_MinReturn : 208.9176483154297\n",
            "Train_AverageEpLen : 133.4\n",
            "Train_EnvstepsSoFar : 555564\n",
            "TimeSinceStart : 604.604325056076\n",
            "Training Loss : -57.291866302490234\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 271 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 271.2648010253906\n",
            "Eval_StdReturn : 23.082683563232422\n",
            "Eval_MaxReturn : 299.582763671875\n",
            "Eval_MinReturn : 243.04220581054688\n",
            "Eval_AverageEpLen : 144.33333333333334\n",
            "Train_AverageReturn : 250.42483520507812\n",
            "Train_StdReturn : 21.32086944580078\n",
            "Train_MaxReturn : 289.16021728515625\n",
            "Train_MinReturn : 219.8612060546875\n",
            "Train_AverageEpLen : 126.125\n",
            "Train_EnvstepsSoFar : 557582\n",
            "TimeSinceStart : 606.9301254749298\n",
            "Training Loss : 73.86749267578125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 272 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 244.74978637695312\n",
            "Eval_StdReturn : 20.23778533935547\n",
            "Eval_MaxReturn : 278.01483154296875\n",
            "Eval_MinReturn : 225.78768920898438\n",
            "Eval_AverageEpLen : 118.25\n",
            "Train_AverageReturn : 255.7128448486328\n",
            "Train_StdReturn : 19.99856948852539\n",
            "Train_MaxReturn : 304.1343078613281\n",
            "Train_MinReturn : 217.45909118652344\n",
            "Train_AverageEpLen : 129.3125\n",
            "Train_EnvstepsSoFar : 559651\n",
            "TimeSinceStart : 609.3496673107147\n",
            "Training Loss : -22.156084060668945\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 273 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 261.3520202636719\n",
            "Eval_StdReturn : 9.458710670471191\n",
            "Eval_MaxReturn : 268.387451171875\n",
            "Eval_MinReturn : 247.98147583007812\n",
            "Eval_AverageEpLen : 134.33333333333334\n",
            "Train_AverageReturn : 252.76698303222656\n",
            "Train_StdReturn : 12.367682456970215\n",
            "Train_MaxReturn : 274.96905517578125\n",
            "Train_MinReturn : 231.9851837158203\n",
            "Train_AverageEpLen : 125.1875\n",
            "Train_EnvstepsSoFar : 561654\n",
            "TimeSinceStart : 611.6229472160339\n",
            "Training Loss : 9.233638763427734\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 274 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.13909912109375\n",
            "Eval_StdReturn : 7.250002384185791\n",
            "Eval_MaxReturn : 249.54049682617188\n",
            "Eval_MinReturn : 231.14515686035156\n",
            "Eval_AverageEpLen : 110.75\n",
            "Train_AverageReturn : 249.1750030517578\n",
            "Train_StdReturn : 21.529508590698242\n",
            "Train_MaxReturn : 289.74554443359375\n",
            "Train_MinReturn : 222.59481811523438\n",
            "Train_AverageEpLen : 122.3529411764706\n",
            "Train_EnvstepsSoFar : 563734\n",
            "TimeSinceStart : 613.9591691493988\n",
            "Training Loss : 95.69340515136719\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 275 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 253.8019561767578\n",
            "Eval_StdReturn : 11.770222663879395\n",
            "Eval_MaxReturn : 273.08343505859375\n",
            "Eval_MinReturn : 241.39199829101562\n",
            "Eval_AverageEpLen : 128.0\n",
            "Train_AverageReturn : 257.9520263671875\n",
            "Train_StdReturn : 19.982908248901367\n",
            "Train_MaxReturn : 293.9331359863281\n",
            "Train_MinReturn : 232.10806274414062\n",
            "Train_AverageEpLen : 129.6875\n",
            "Train_EnvstepsSoFar : 565809\n",
            "TimeSinceStart : 616.4198455810547\n",
            "Training Loss : -14.481463432312012\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 276 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 244.5716552734375\n",
            "Eval_StdReturn : 10.55760383605957\n",
            "Eval_MaxReturn : 261.673828125\n",
            "Eval_MinReturn : 234.7701873779297\n",
            "Eval_AverageEpLen : 118.25\n",
            "Train_AverageReturn : 253.07965087890625\n",
            "Train_StdReturn : 17.482938766479492\n",
            "Train_MaxReturn : 283.5102844238281\n",
            "Train_MinReturn : 222.5694580078125\n",
            "Train_AverageEpLen : 126.375\n",
            "Train_EnvstepsSoFar : 567831\n",
            "TimeSinceStart : 618.7358922958374\n",
            "Training Loss : 34.0133056640625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 277 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 238.67669677734375\n",
            "Eval_StdReturn : 46.0949592590332\n",
            "Eval_MaxReturn : 288.5440673828125\n",
            "Eval_MinReturn : 165.13369750976562\n",
            "Eval_AverageEpLen : 126.25\n",
            "Train_AverageReturn : 258.5273742675781\n",
            "Train_StdReturn : 23.579572677612305\n",
            "Train_MaxReturn : 320.9666748046875\n",
            "Train_MinReturn : 223.7768096923828\n",
            "Train_AverageEpLen : 133.375\n",
            "Train_EnvstepsSoFar : 569965\n",
            "TimeSinceStart : 621.1764290332794\n",
            "Training Loss : -52.38579559326172\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 278 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 252.71990966796875\n",
            "Eval_StdReturn : 12.203469276428223\n",
            "Eval_MaxReturn : 272.512451171875\n",
            "Eval_MinReturn : 241.53945922851562\n",
            "Eval_AverageEpLen : 125.0\n",
            "Train_AverageReturn : 257.10418701171875\n",
            "Train_StdReturn : 22.675546646118164\n",
            "Train_MaxReturn : 320.1463317871094\n",
            "Train_MinReturn : 225.13687133789062\n",
            "Train_AverageEpLen : 129.5625\n",
            "Train_EnvstepsSoFar : 572038\n",
            "TimeSinceStart : 623.6524798870087\n",
            "Training Loss : 73.37509155273438\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 279 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 248.5333709716797\n",
            "Eval_StdReturn : 9.833280563354492\n",
            "Eval_MaxReturn : 261.47979736328125\n",
            "Eval_MinReturn : 238.82899475097656\n",
            "Eval_AverageEpLen : 119.75\n",
            "Train_AverageReturn : 262.4491271972656\n",
            "Train_StdReturn : 25.446853637695312\n",
            "Train_MaxReturn : 324.4567565917969\n",
            "Train_MinReturn : 220.8047637939453\n",
            "Train_AverageEpLen : 134.06666666666666\n",
            "Train_EnvstepsSoFar : 574049\n",
            "TimeSinceStart : 625.9815509319305\n",
            "Training Loss : -10.409904479980469\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 280 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 251.80972290039062\n",
            "Eval_StdReturn : 17.515300750732422\n",
            "Eval_MaxReturn : 268.40814208984375\n",
            "Eval_MinReturn : 225.33096313476562\n",
            "Eval_AverageEpLen : 125.25\n",
            "Train_AverageReturn : 248.1388702392578\n",
            "Train_StdReturn : 15.298530578613281\n",
            "Train_MaxReturn : 291.77899169921875\n",
            "Train_MinReturn : 225.41976928710938\n",
            "Train_AverageEpLen : 122.11764705882354\n",
            "Train_EnvstepsSoFar : 576125\n",
            "TimeSinceStart : 628.3336436748505\n",
            "Training Loss : 72.2054443359375\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 281 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 276.9942932128906\n",
            "Eval_StdReturn : 19.996355056762695\n",
            "Eval_MaxReturn : 304.89544677734375\n",
            "Eval_MinReturn : 259.0529479980469\n",
            "Eval_AverageEpLen : 139.0\n",
            "Train_AverageReturn : 255.59164428710938\n",
            "Train_StdReturn : 25.658315658569336\n",
            "Train_MaxReturn : 315.851318359375\n",
            "Train_MinReturn : 216.67779541015625\n",
            "Train_AverageEpLen : 126.6875\n",
            "Train_EnvstepsSoFar : 578152\n",
            "TimeSinceStart : 630.6065826416016\n",
            "Training Loss : -13.451101303100586\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 282 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 254.0319366455078\n",
            "Eval_StdReturn : 11.868078231811523\n",
            "Eval_MaxReturn : 270.05682373046875\n",
            "Eval_MinReturn : 240.2401885986328\n",
            "Eval_AverageEpLen : 127.25\n",
            "Train_AverageReturn : 252.8561248779297\n",
            "Train_StdReturn : 17.325273513793945\n",
            "Train_MaxReturn : 284.78607177734375\n",
            "Train_MinReturn : 229.71290588378906\n",
            "Train_AverageEpLen : 128.1875\n",
            "Train_EnvstepsSoFar : 580203\n",
            "TimeSinceStart : 632.9720976352692\n",
            "Training Loss : 25.632343292236328\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 283 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 243.68368530273438\n",
            "Eval_StdReturn : 19.111326217651367\n",
            "Eval_MaxReturn : 270.4994812011719\n",
            "Eval_MinReturn : 221.91665649414062\n",
            "Eval_AverageEpLen : 119.25\n",
            "Train_AverageReturn : 250.81036376953125\n",
            "Train_StdReturn : 16.500951766967773\n",
            "Train_MaxReturn : 281.7503662109375\n",
            "Train_MinReturn : 227.01898193359375\n",
            "Train_AverageEpLen : 125.8125\n",
            "Train_EnvstepsSoFar : 582216\n",
            "TimeSinceStart : 635.2534248828888\n",
            "Training Loss : 52.67398452758789\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 284 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 247.3779296875\n",
            "Eval_StdReturn : 26.972204208374023\n",
            "Eval_MaxReturn : 293.2048034667969\n",
            "Eval_MinReturn : 227.55909729003906\n",
            "Eval_AverageEpLen : 120.5\n",
            "Train_AverageReturn : 257.302001953125\n",
            "Train_StdReturn : 15.318086624145508\n",
            "Train_MaxReturn : 284.4515380859375\n",
            "Train_MinReturn : 224.03952026367188\n",
            "Train_AverageEpLen : 128.3125\n",
            "Train_EnvstepsSoFar : 584269\n",
            "TimeSinceStart : 637.5810079574585\n",
            "Training Loss : 29.139780044555664\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 285 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 265.427734375\n",
            "Eval_StdReturn : 21.194265365600586\n",
            "Eval_MaxReturn : 295.0304870605469\n",
            "Eval_MinReturn : 246.557861328125\n",
            "Eval_AverageEpLen : 135.66666666666666\n",
            "Train_AverageReturn : 249.08766174316406\n",
            "Train_StdReturn : 9.51477336883545\n",
            "Train_MaxReturn : 268.7423095703125\n",
            "Train_MinReturn : 230.75926208496094\n",
            "Train_AverageEpLen : 121.82352941176471\n",
            "Train_EnvstepsSoFar : 586340\n",
            "TimeSinceStart : 639.8741180896759\n",
            "Training Loss : -83.98969268798828\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 286 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 251.16429138183594\n",
            "Eval_StdReturn : 22.207828521728516\n",
            "Eval_MaxReturn : 284.80377197265625\n",
            "Eval_MinReturn : 225.3368682861328\n",
            "Eval_AverageEpLen : 125.75\n",
            "Train_AverageReturn : 254.09555053710938\n",
            "Train_StdReturn : 20.805519104003906\n",
            "Train_MaxReturn : 308.2574157714844\n",
            "Train_MinReturn : 214.6503448486328\n",
            "Train_AverageEpLen : 127.3125\n",
            "Train_EnvstepsSoFar : 588377\n",
            "TimeSinceStart : 642.219762802124\n",
            "Training Loss : -20.978967666625977\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 287 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 258.05828857421875\n",
            "Eval_StdReturn : 27.627216339111328\n",
            "Eval_MaxReturn : 293.8139953613281\n",
            "Eval_MinReturn : 229.60809326171875\n",
            "Eval_AverageEpLen : 131.0\n",
            "Train_AverageReturn : 250.73667907714844\n",
            "Train_StdReturn : 19.981597900390625\n",
            "Train_MaxReturn : 298.40545654296875\n",
            "Train_MinReturn : 221.82449340820312\n",
            "Train_AverageEpLen : 125.0\n",
            "Train_EnvstepsSoFar : 590377\n",
            "TimeSinceStart : 644.5376296043396\n",
            "Training Loss : -61.31774139404297\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 288 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 244.24264526367188\n",
            "Eval_StdReturn : 12.219603538513184\n",
            "Eval_MaxReturn : 255.1398162841797\n",
            "Eval_MinReturn : 223.50387573242188\n",
            "Eval_AverageEpLen : 115.5\n",
            "Train_AverageReturn : 247.49546813964844\n",
            "Train_StdReturn : 13.146313667297363\n",
            "Train_MaxReturn : 277.08697509765625\n",
            "Train_MinReturn : 231.1815643310547\n",
            "Train_AverageEpLen : 118.94117647058823\n",
            "Train_EnvstepsSoFar : 592399\n",
            "TimeSinceStart : 646.8022577762604\n",
            "Training Loss : -68.19811248779297\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 289 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 252.6091766357422\n",
            "Eval_StdReturn : 9.063583374023438\n",
            "Eval_MaxReturn : 263.638427734375\n",
            "Eval_MinReturn : 238.94166564941406\n",
            "Eval_AverageEpLen : 121.25\n",
            "Train_AverageReturn : 251.53892517089844\n",
            "Train_StdReturn : 16.819021224975586\n",
            "Train_MaxReturn : 290.60614013671875\n",
            "Train_MinReturn : 228.8163299560547\n",
            "Train_AverageEpLen : 123.88235294117646\n",
            "Train_EnvstepsSoFar : 594505\n",
            "TimeSinceStart : 649.2059147357941\n",
            "Training Loss : -27.99491310119629\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 290 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 238.1220703125\n",
            "Eval_StdReturn : 19.74609375\n",
            "Eval_MaxReturn : 269.9274597167969\n",
            "Eval_MinReturn : 218.9939422607422\n",
            "Eval_AverageEpLen : 114.25\n",
            "Train_AverageReturn : 251.20208740234375\n",
            "Train_StdReturn : 16.76959991455078\n",
            "Train_MaxReturn : 294.59722900390625\n",
            "Train_MinReturn : 229.1414794921875\n",
            "Train_AverageEpLen : 123.76470588235294\n",
            "Train_EnvstepsSoFar : 596609\n",
            "TimeSinceStart : 651.57310962677\n",
            "Training Loss : 59.0601692199707\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 291 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 267.5795593261719\n",
            "Eval_StdReturn : 31.965744018554688\n",
            "Eval_MaxReturn : 312.785888671875\n",
            "Eval_MinReturn : 244.92198181152344\n",
            "Eval_AverageEpLen : 137.33333333333334\n",
            "Train_AverageReturn : 257.1331787109375\n",
            "Train_StdReturn : 18.885690689086914\n",
            "Train_MaxReturn : 297.3558654785156\n",
            "Train_MinReturn : 223.8871307373047\n",
            "Train_AverageEpLen : 128.0625\n",
            "Train_EnvstepsSoFar : 598658\n",
            "TimeSinceStart : 653.8536896705627\n",
            "Training Loss : -45.15415954589844\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 292 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 268.791748046875\n",
            "Eval_StdReturn : 8.158151626586914\n",
            "Eval_MaxReturn : 279.70257568359375\n",
            "Eval_MinReturn : 260.0884704589844\n",
            "Eval_AverageEpLen : 143.33333333333334\n",
            "Train_AverageReturn : 256.19085693359375\n",
            "Train_StdReturn : 18.387414932250977\n",
            "Train_MaxReturn : 299.2526550292969\n",
            "Train_MinReturn : 232.4900665283203\n",
            "Train_AverageEpLen : 126.5\n",
            "Train_EnvstepsSoFar : 600682\n",
            "TimeSinceStart : 656.1240797042847\n",
            "Training Loss : -65.593994140625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 293 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 271.50213623046875\n",
            "Eval_StdReturn : 17.737028121948242\n",
            "Eval_MaxReturn : 292.4285583496094\n",
            "Eval_MinReturn : 249.0611572265625\n",
            "Eval_AverageEpLen : 143.0\n",
            "Train_AverageReturn : 255.1087188720703\n",
            "Train_StdReturn : 21.583086013793945\n",
            "Train_MaxReturn : 304.65875244140625\n",
            "Train_MinReturn : 210.4552459716797\n",
            "Train_AverageEpLen : 130.25\n",
            "Train_EnvstepsSoFar : 602766\n",
            "TimeSinceStart : 658.4401540756226\n",
            "Training Loss : -59.98744201660156\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 294 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 249.11672973632812\n",
            "Eval_StdReturn : 12.091343879699707\n",
            "Eval_MaxReturn : 269.6668395996094\n",
            "Eval_MinReturn : 238.93484497070312\n",
            "Eval_AverageEpLen : 121.25\n",
            "Train_AverageReturn : 256.4258728027344\n",
            "Train_StdReturn : 20.640907287597656\n",
            "Train_MaxReturn : 290.7916259765625\n",
            "Train_MinReturn : 223.6280975341797\n",
            "Train_AverageEpLen : 125.9375\n",
            "Train_EnvstepsSoFar : 604781\n",
            "TimeSinceStart : 660.7282779216766\n",
            "Training Loss : 43.93540573120117\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 295 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 266.8720397949219\n",
            "Eval_StdReturn : 19.38640022277832\n",
            "Eval_MaxReturn : 283.1802062988281\n",
            "Eval_MinReturn : 239.63180541992188\n",
            "Eval_AverageEpLen : 139.33333333333334\n",
            "Train_AverageReturn : 270.3048400878906\n",
            "Train_StdReturn : 25.52827262878418\n",
            "Train_MaxReturn : 334.8664245605469\n",
            "Train_MinReturn : 231.54464721679688\n",
            "Train_AverageEpLen : 139.13333333333333\n",
            "Train_EnvstepsSoFar : 606868\n",
            "TimeSinceStart : 663.1021504402161\n",
            "Training Loss : 20.021827697753906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 296 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 268.3086853027344\n",
            "Eval_StdReturn : 16.98187255859375\n",
            "Eval_MaxReturn : 296.677490234375\n",
            "Eval_MinReturn : 254.3623809814453\n",
            "Eval_AverageEpLen : 137.25\n",
            "Train_AverageReturn : 251.19554138183594\n",
            "Train_StdReturn : 33.531978607177734\n",
            "Train_MaxReturn : 332.69818115234375\n",
            "Train_MinReturn : 160.20803833007812\n",
            "Train_AverageEpLen : 127.4375\n",
            "Train_EnvstepsSoFar : 608907\n",
            "TimeSinceStart : 665.4698779582977\n",
            "Training Loss : 55.19377517700195\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 297 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 248.62216186523438\n",
            "Eval_StdReturn : 6.306000709533691\n",
            "Eval_MaxReturn : 255.12954711914062\n",
            "Eval_MinReturn : 238.31845092773438\n",
            "Eval_AverageEpLen : 122.75\n",
            "Train_AverageReturn : 252.8961181640625\n",
            "Train_StdReturn : 21.15580177307129\n",
            "Train_MaxReturn : 292.8908386230469\n",
            "Train_MinReturn : 224.44566345214844\n",
            "Train_AverageEpLen : 127.125\n",
            "Train_EnvstepsSoFar : 610941\n",
            "TimeSinceStart : 667.8203644752502\n",
            "Training Loss : -62.32155990600586\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 298 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 247.8177490234375\n",
            "Eval_StdReturn : 11.71977710723877\n",
            "Eval_MaxReturn : 262.6686096191406\n",
            "Eval_MinReturn : 230.63336181640625\n",
            "Eval_AverageEpLen : 118.0\n",
            "Train_AverageReturn : 256.853759765625\n",
            "Train_StdReturn : 19.406888961791992\n",
            "Train_MaxReturn : 284.6799621582031\n",
            "Train_MinReturn : 215.7604522705078\n",
            "Train_AverageEpLen : 130.625\n",
            "Train_EnvstepsSoFar : 613031\n",
            "TimeSinceStart : 670.2417528629303\n",
            "Training Loss : -55.4698486328125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 299 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 258.8976135253906\n",
            "Eval_StdReturn : 17.49040412902832\n",
            "Eval_MaxReturn : 288.5542297363281\n",
            "Eval_MinReturn : 244.02085876464844\n",
            "Eval_AverageEpLen : 129.0\n",
            "Train_AverageReturn : 260.5353088378906\n",
            "Train_StdReturn : 22.096839904785156\n",
            "Train_MaxReturn : 303.5511474609375\n",
            "Train_MinReturn : 234.53782653808594\n",
            "Train_AverageEpLen : 134.0\n",
            "Train_EnvstepsSoFar : 615041\n",
            "TimeSinceStart : 672.589298248291\n",
            "Training Loss : -62.377105712890625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/cds_rl_2022/rl_hw/hw2/hw2/scripts/run_hw2.py \\\n",
        "    --env_name Hopper-v2 --ep_len 1000 \\\n",
        "    --discount 0.99 -n 300 -l 2 -s 32 -b 2000 -lr 0.001 \\\n",
        "    --reward_to_go --nn_baseline \\\n",
        "    --action_noise_std 0.5 --gae_lambda 1 \\\n",
        "    --exp_name q5_b2000_r0.001_lambda1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2HthbYOP45q"
      },
      "outputs": [],
      "source": [
        "plot('/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q5_b2000_r0.001_lambda0.99_Hopper-v2_09-05-2022_12-44-57/events.out.tfevents.1652100297.1f515a41fb55', \n",
        "     '/content/cds_rl_2022/rl_hw/hw2/figure/q5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "files = ['/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q5_b2000_r0.001_lambda0_Hopper-v2_09-05-2022_12-22-42/events.out.tfevents.1652098962.1f515a41fb55',\n",
        "         '/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q5_b2000_r0.001_lambda0.95_Hopper-v2_09-05-2022_13-07-46/events.out.tfevents.1652101666.1f515a41fb55',\n",
        "         '/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q5_b2000_r0.001_lambda0.99_Hopper-v2_09-05-2022_12-44-57/events.out.tfevents.1652100297.1f515a41fb55',\n",
        "         '/content/cds_rl_2022/rl_hw/hw2/data/q2_pg_q5_b2000_r0.001_lambda1_Hopper-v2_09-05-2022_12-56-30/events.out.tfevents.1652100990.1f515a41fb55']\n",
        "labels = ['lambda = 0', 'lambda = 0.95', 'lambda = 0.99', 'lambda = 1']\n",
        "for logfile in files:\n",
        "    Eval_AverageReturns = []\n",
        "    for summary in summary_iterator(logfile):\n",
        "        for v in summary.summary.value:\n",
        "            if v.tag == \"Eval_AverageReturn\":\n",
        "                Eval_AverageReturns.append(v.simple_value)\n",
        "\n",
        "    plt.plot(Eval_AverageReturns, label = labels[i])\n",
        "    i+=1\n",
        "plt.legend()\n",
        "plt.savefig('/content/cds_rl_2022/rl_hw/hw2/figure/q5')\n",
        "plt.delaxes()"
      ],
      "metadata": {
        "id": "WUuHRCD2iD8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FUGwPLUA0eR5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "nWHYEZqyP9sr",
        "vuaKDhfcGMQO",
        "FPxNrIeH-sUa",
        "vZaKjaffGgXC"
      ],
      "name": "run_hw2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}